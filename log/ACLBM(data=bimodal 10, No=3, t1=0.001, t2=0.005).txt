('==== Found maximium gradient [0.3480536, 0.3480536, 0.23848975] of gate '
 'e^[Y1 Z2], e^[Y2 Z1], e^[Y0 Z1] ====')
learning rate =  0.06315694272443825
0.12471831227697198 0.12471831227697198 0.5469599366188049
0.09514705790670497 0.09514705790670497 0.4130803048610687
0.047717648302492324 0.047717648302492324 0.1946457326412201
0.03997352784054213 0.03997352784054213 0.10789675265550613
0.05008269731493618 0.05008269731493618 0.2049696147441864
0.05580933155450755 0.05580933155450755 0.2665002942085266
0.05612590934795797 0.05612590934795797 0.28574705123901367
0.05507275307641521 0.05507275307641521 0.27890127897262573
0.05441290861680539 0.05441290861680539 0.2586295008659363
0.051961133067153116 0.051961133067153116 0.2239198237657547
0.04644215644365751 0.04644215644365751 0.17222364246845245
0.04024050723258178 0.04024050723258178 0.11266278475522995
0.036702127468568824 0.036702127468568824 0.07653096318244934
0.03720052368741629 0.03720052368741629 0.10066226124763489
0.04021633263360484 0.04021633263360484 0.14194999635219574
0.04276623874952327 0.04276623874952327 0.1672721654176712
0.04298246941700822 0.04298246941700822 0.16991910338401794
0.04121048478279203 0.04121048478279203 0.15356115996837616
0.03903843361795644 0.03903843361795644 0.1270504593849182
0.03774292433339301 0.03774292433339301 0.10147054493427277
0.03742823774113664 0.03742823774113664 0.08564634621143341
0.03737360590965939 0.03737360590965939 0.08022475242614746
0.03703439289878542 0.03703439289878542 0.08046089112758636
0.036546952355125964 0.036546952355125964 0.08424761891365051
0.036364899169178844 0.036364899169178844 0.09119106084108353
0.03662114074476256 0.03662114074476256 0.09814109653234482
0.036910710662200245 0.036910710662200245 0.0995844379067421
0.03670495418676285 0.03670495418676285 0.09126468002796173
0.03593845744576965 0.03593845744576965 0.0728745087981224
0.035097704061438764 0.035097704061438764 0.04946054145693779
0.03475035804660251 0.03475035804660251 0.035165879875421524
0.03502038829295627 0.03502038829295627 0.0441470630466938
0.03551766264145991 0.03551766264145991 0.05949363112449646
0.03574553886446484 0.03574553886446484 0.06805106997489929
0.03554287334297217 0.03554287334297217 0.06762801855802536
0.03513119542273052 0.03513119542273052 0.06055004894733429
0.03480934880773532 0.03480934880773532 0.05075882747769356
0.03466813192549224 0.03466813192549224 0.04132038354873657
0.03459950500132758 0.03459950500132758 0.033160995692014694
0.03451688156457208 0.03451688156457208 0.027328167110681534
0.034474797357382646 0.034474797357382646 0.02783025987446308
0.034563989789887915 0.034563989789887915 0.03520955890417099
0.03474282749876337 0.03474282749876337 0.04326523095369339
0.03483958807413891 0.03483958807413891 0.04661232605576515
0.03472673349662818 0.03472673349662818 0.04292634502053261
0.034464498630260215 0.034464498630260215 0.03274328261613846
0.03423987234080347 0.03423987234080347 0.019134527072310448
0.034181754355832476 0.034181754355832476 0.009873404167592525
0.03425993769536019 0.03425993769536019 0.0157892107963562
0.03435695783592066 0.03435695783592066 0.023427078500390053
0.0343991300074198 0.0343991300074198 0.027651293203234673
0.03439729929571836 0.03439729929571836 0.028921253979206085
0.03438282046505205 0.03438282046505205 0.028056947514414787
0.034349219464833325 0.034349219464833325 0.024948418140411377
0.03427764685898267 0.03427764685898267 0.019028007984161377
0.03419199357841524 0.03419199357841524 0.010581179521977901
0.03415041630749806 0.03415041630749806 0.004217709414660931
iteration: 1 | epoch: 58 |   loss: 0.034150  |   KL divergence: 0.034150  |  JS divergence: 0.008893
('==== Found maximium gradient [0.16779742, 0.15136786, 0.14666753] of gate '
 'e^[Y1 Z3], e^[Y2 Z0], e^[Y3 Z1] ====')
learning rate =  0.031108317383887887
0.034180134086697754 0.034180134086697754 0.26963624358177185
0.024432422808077683 0.024432422808077683 0.19903947412967682
0.014939011128642429 0.014939011128642429 0.11785291880369186
0.010966047888860552 0.010966047888860552 0.0756741389632225
0.010904657884397654 0.010904657884397654 0.09838306903839111
0.011646974029086463 0.011646974029086463 0.12044689059257507
0.01175647907704287 0.01175647907704287 0.12347257137298584
0.01147097162953889 0.01147097162953889 0.11644497513771057
0.011172508954414608 0.011172508954414608 0.10826398432254791
0.010841309109549162 0.010841309109549162 0.10057482868432999
0.010338485763413986 0.010338485763413986 0.09050639718770981
0.009760448142519317 0.009760448142519317 0.07856262475252151
0.009360550590896022 0.009360550590896022 0.07077746093273163
0.009246224810493676 0.009246224810493676 0.072182297706604
0.009244773720515066 0.009244773720515066 0.07866255939006805
0.00906128455158208 0.00906128455158208 0.08193514496088028
0.008555372869918958 0.008555372869918958 0.07749447226524353
0.007847692471802052 0.007847692471802052 0.06552378088235855
0.007190353425712314 0.007190353425712314 0.049233924597501755
0.006777059000913932 0.006777059000913932 0.03381481394171715
0.006643187608207516 0.006643187608207516 0.02614779584109783
0.006706172092799154 0.006706172092799154 0.02905065380036831
0.0068623467240207375 0.0068623467240207375 0.03650350123643875
0.007040409280795024 0.007040409280795024 0.04425804316997528
0.007183776547068284 0.007183776547068284 0.05063901096582413
0.007227323211846259 0.007227323211846259 0.05399664491415024
0.007119328127710531 0.007119328127710531 0.05264084041118622
0.006868332472290869 0.006868332472290869 0.045783691108226776
0.00656163524769663 0.00656163524769663 0.03428897261619568
0.006314844030587536 0.006314844030587536 0.02104605920612812
0.006196626319224444 0.006196626319224444 0.012967842631042004
0.006194320661326441 0.006194320661326441 0.01732979156076908
0.006246506524927566 0.006246506524927566 0.02407599426805973
0.006298286423754884 0.006298286423754884 0.02783762291073799
0.0063296741514975 0.0063296741514975 0.02856293134391308
0.006342400710314011 0.006342400710314011 0.02736237645149231
0.006336072667354861 0.006336072667354861 0.025060875341296196
0.006309224932841914 0.006309224932841914 0.021883660927414894
0.006270484353506111 0.006270484353506111 0.018364371731877327
0.006240673584686336 0.006240673584686336 0.016337411478161812
0.006233051233851713 0.006233051233851713 0.017371542751789093
0.006237878377446098 0.006237878377446098 0.019729357212781906
0.00623130785113107 0.00623130785113107 0.020608114078640938
0.006202453370126566 0.006202453370126566 0.018751895055174828
0.006163465228981491 0.006163465228981491 0.01462745014578104
0.006136947726129943 0.006136947726129943 0.010175910778343678
0.0061331961997583015 0.0061331961997583015 0.00844759400933981
0.006145948491496325 0.006145948491496325 0.009995227679610252
0.006163625949341206 0.006163625949341206 0.012109288945794106
0.006179520403679969 0.006179520403679969 0.013687808066606522
0.006188569117019612 0.006188569117019612 0.014596511609852314
0.006185234257975316 0.006185234257975316 0.014471196569502354
0.0061668483385665385 0.0061668483385665385 0.012793285772204399
0.006139508686426837 0.006139508686426837 0.009480033069849014
0.006116184522169153 0.006116184522169153 0.005340368952602148
0.006106910557291527 0.006106910557291527 0.0033588523510843515
iteration: 2 | epoch: 114 |   loss: 0.006107  |   KL divergence: 0.006107  |  JS divergence: 0.001540
('==== Found maximium gradient [0.08675449, 0.07080702, 0.04389023] of gate '
 'e^[Y1 Z4], e^[Y4 Z1], e^[Y0 Z4] ====')
learning rate =  0.013888281827980348
0.006109386328281017 0.006109386328281017 0.12041036039590836
0.00469639490332634 0.00469639490332634 0.09627640247344971
0.002645586660074016 0.002645586660074016 0.03849027678370476
0.0024843143707562712 0.0024843143707562712 0.028149785473942757
0.003093761587243898 0.003093761587243898 0.05584707856178284
0.003381309126352966 0.003381309126352966 0.06488482654094696
0.003348591457199666 0.003348591457199666 0.06388220191001892
0.0032303796667540545 0.0032303796667540545 0.060520391911268234
0.0031025014909959753 0.0031025014909959753 0.057002510875463486
0.002875637817980484 0.002875637817980484 0.04965944588184357
0.0025594735433348147 0.0025594735433348147 0.036128368228673935
0.0023087409182154114 0.0023087409182154114 0.018714867532253265
0.002259477031769612 0.002259477031769612 0.011838874779641628
0.0024003815893725478 0.0024003815893725478 0.026058964431285858
0.0025889960694520722 0.0025889960694520722 0.03783802688121796
0.00267494218464537 0.00267494218464537 0.04250146448612213
0.0026216124980597763 0.0026216124980597763 0.04045385867357254
0.0024936857296541984 0.0024936857296541984 0.034220509231090546
0.0023755168407220972 0.0023755168407220972 0.027233963832259178
0.00230361780336294 0.00230361780336294 0.02219342812895775
0.002265408308206498 0.002265408308206498 0.01911390759050846
0.002241516874467372 0.002241516874467372 0.01660778746008873
0.0022346757820680104 0.0022346757820680104 0.015388180501759052
0.0022568004899258783 0.0022568004899258783 0.01752607710659504
0.002297855531956878 0.002297855531956878 0.021762438118457794
0.0023278883305792677 0.0023278883305792677 0.02480357512831688
0.0023151704374518084 0.0023151704374518084 0.024515150114893913
0.002261261478537834 0.002261261478537834 0.02047484740614891
0.0021981724517534714 0.0021981724517534714 0.013792037032544613
0.0021601725898058493 0.0021601725898058493 0.007305909879505634
0.002158392125225835 0.002158392125225835 0.0073023089207708836
0.0021765352806891467 0.0021765352806891467 0.011378798633813858
0.00219366400258707 0.00219366400258707 0.014027096331119537
0.002200144003917508 0.002200144003917508 0.014822954311966896
0.0021977867686801553 0.0021977867686801553 0.014596075750887394
0.002190069546669702 0.002190069546669702 0.013961169868707657
0.002177289432961423 0.002177289432961423 0.01267183292657137
0.002159522682004136 0.002159522682004136 0.010135232470929623
0.002142250668541707 0.002142250668541707 0.006381679326295853
0.002135436415350585 0.002135436415350585 0.003453741082921624
iteration: 3 | epoch: 154 |   loss: 0.002135  |   KL divergence: 0.002135  |  JS divergence: 0.000535
('==== Found maximium gradient [0.04322862, 0.035107892, 0.023282714] of gate '
 'e^[Y1 Z5], e^[Y5 Z1], e^[Y3 Z0] ====')
learning rate =  0.0069698037978899695
0.0021415029367886076 0.0021415029367886076 0.060632217675447464
0.0018167216283932028 0.0018167216283932028 0.05416246876120567
0.0011851080472725045 0.0011851080472725045 0.024372274056077003
0.0010956150455921233 0.0010956150455921233 0.01877455972135067
0.0011900244976129413 0.0011900244976129413 0.028780482709407806
0.0012037402130592781 0.0012037402130592781 0.030677588656544685
0.0011790082892638972 0.0011790082892638972 0.029430409893393517
0.001175299233379272 0.001175299233379272 0.02957206591963768
0.0011755482910226036 0.0011755482910226036 0.030641160905361176
0.0011251221338220024 0.0011251221338220024 0.029058249667286873
0.0010201031816675066 0.0010201031816675066 0.023402877151966095
0.0009115724085428931 0.0009115724085428931 0.014971858821809292
0.000848907954515076 0.000848907954515076 0.007645461708307266
0.0008409584219151634 0.0008409584219151634 0.00953939463943243
0.000862262359128963 0.000862262359128963 0.014875349588692188
0.0008813592563339675 0.0008813592563339675 0.01798384077847004
0.0008837775950967081 0.0008837775950967081 0.018643474206328392
0.0008739983642357895 0.0008739983642357895 0.017864998430013657
0.0008587923103160458 0.0008587923103160458 0.016649184748530388
0.0008410800741470996 0.0008410800741470996 0.015313426032662392
0.0008209053989555038 0.0008209053989555038 0.013500229455530643
0.0007989129278870206 0.0007989129278870206 0.010850179940462112
0.0007810173923937199 0.0007810173923937199 0.00771313114091754
0.0007720716613672258 0.0007720716613672258 0.0057343426160514355
0.0007737540722230766 0.0007737540722230766 0.006884887348860502
0.0007830629072513829 0.0007830629072513829 0.009401840157806873
0.0007930378586143592 0.0007930378586143592 0.011238053441047668
0.0007968478897881732 0.0007968478897881732 0.011677448637783527
0.000792128517589149 0.000792128517589149 0.010675660334527493
0.0007818793263110706 0.0007818793263110706 0.008648772723972797
0.0007711439470786883 0.0007711439470786883 0.006414563395082951
0.0007654112176932159 0.0007654112176932159 0.005023773293942213
0.000763669208450147 0.000763669208450147 0.004873780068010092
iteration: 4 | epoch: 187 |   loss: 0.000764  |   KL divergence: 0.000764  |  JS divergence: 0.000191
('==== Found maximium gradient [0.021588685, 0.01751755, 0.011141228] of gate '
 'e^[Y1 Z6], e^[Y6 Z1], e^[Y0 Z6] ====')
learning rate =  0.003458444295421916
0.0007638509688204758 0.0007638509688204758 0.03039354458451271
0.00068966850210224 0.00068966850210224 0.02521875500679016
0.0005468716279503254 0.0005468716279503254 0.010413066484034061
0.0005316174565639766 0.0005316174565639766 0.006874536629766226
0.0005774152297714372 0.0005774152297714372 0.014644025824964046
0.0005927061650862933 0.0005927061650862933 0.016533974558115005
0.000584215596097357 0.000584215596097357 0.01579774171113968
0.0005783929565292834 0.0005783929565292834 0.015236897394061089
0.0005743163066582069 0.0005743163066582069 0.014845401048660278
0.0005582938451980859 0.0005582938451980859 0.012776701711118221
0.0005331351111567757 0.0005331351111567757 0.008583959192037582
0.0005165276819539004 0.0005165276819539004 0.0036926770117133856
iteration: 5 | epoch: 199 |   loss: 0.000517  |   KL divergence: 0.000517  |  JS divergence: 0.000129
('==== Found maximium gradient [0.010785409, 0.008754246, 0.0069951797] of '
 'gate e^[Y1 Z7], e^[Y7 Z1], e^[Y5 Z0] ====')
learning rate =  0.001795900522121885
0.0005176986537078131 0.0005176986537078131 0.0161129143089056
0.0004888068485124752 0.0004888068485124752 0.013270456343889236
0.00045347489949128396 0.00045347489949128396 0.007778209634125233
0.00043943695887719485 0.00043943695887719485 0.00406642584130168
iteration: 6 | epoch: 203 |   loss: 0.000439  |   KL divergence: 0.000439  |  JS divergence: 0.000110
('==== Found maximium gradient [0.005397401, 0.00437656, 0.003918759] of gate '
 'e^[Y1 Z8], e^[Y8 Z1], e^[Y7 Z0] ====')
learning rate =  0.0009211796252915834
0.0004433992543534995 0.0004433992543534995 0.010342016816139221
0.0004229317173887136 0.0004229317173887136 0.005988691933453083
0.0004178449677387376 0.0004178449677387376 0.004783672746270895
iteration: 7 | epoch: 206 |   loss: 0.000418  |   KL divergence: 0.000418  |  JS divergence: 0.000104
('==== Found maximium gradient [0.0029111009, 0.0027816037, 0.002691407] of '
 'gate e^[Y4 Z3], e^[Y3 Z4], e^[Y1 Z9] ====')
learning rate =  0.0005592316167330166
0.0004145510263966893 0.0004145510263966893 0.006516603287309408
0.00040614533912048366 0.00040614533912048366 0.0037043606862425804
iteration: 8 | epoch: 208 |   loss: 0.000406  |   KL divergence: 0.000406  |  JS divergence: 0.000101
('==== Found maximium gradient [0.0023248652, 0.002076596, 0.0019537206] of '
 'gate e^[Y2 Z6], e^[Y6 Z2], e^[Y5 Z2] ====')
learning rate =  0.00042480229215437925
0.00040315161789533226 0.00040315161789533226 0.004744333680719137
iteration: 9 | epoch: 209 |   loss: 0.000403  |   KL divergence: 0.000403  |  JS divergence: 0.000100
('==== Found maximium gradient [0.0017662905, 0.0016773675, 0.0015426181] of '
 'gate e^[Y7 Z2], e^[Y2 Z7], e^[Y0 Z8] ====')
learning rate =  0.0003329267083563325
0.00039816910580610474 0.00039816910580610474 0.004246721044182777
iteration: 10 | epoch: 210 |   loss: 0.000398  |   KL divergence: 0.000398  |  JS divergence: 0.000099
('==== Found maximium gradient [0.001353627, 0.0012846696, 0.0011117496] of '
 'gate e^[Y3 Z6], e^[Y6 Z3], e^[Y0 Z8] ====')
learning rate =  0.000250829805395089
0.00039493157357501914 0.00039493157357501914 0.0036656565498560667
iteration: 11 | epoch: 211 |   loss: 0.000395  |   KL divergence: 0.000395  |  JS divergence: 0.000098
('==== Found maximium gradient [0.0009929767, 0.0009387017, 0.0009067575] of '
 'gate e^[Y3 Z2], e^[Y3 Z7], e^[Y7 Z3] ====')
Convergence criterion has reached, break the loop!
