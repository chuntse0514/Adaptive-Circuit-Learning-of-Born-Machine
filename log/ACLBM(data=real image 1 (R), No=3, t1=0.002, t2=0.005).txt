nohup: ignoring input
('==== Found maximium gradient [0.28336477, 0.28336474, 0.28336474] of gate '
 'RY[0], e^[X6 Y0], e^[X8 Y0] ====')
learning rate =  0.07084118677394667
0.05972380273197263 0.5908088088035583
0.03488710287971852 0.24459153413772583
0.026599271506720104 0.4017305076122284
0.03622471323377942 0.45607492327690125
0.034046336070893704 0.339040607213974
0.0207357659457008 0.18212637305259705
0.013481537766965795 0.18704216182231903
0.01609564479869046 0.2821350693702698
0.02080243301666573 0.31166210770606995
0.020264583126783347 0.2637748122215271
0.014640204281979355 0.16685155034065247
0.009778844841465194 0.10090400278568268
0.009697633631105818 0.16195228695869446
0.012712361684099865 0.22477279603481293
0.014383250329649485 0.23114557564258575
0.012592793645324318 0.18208979070186615
0.00909503515042571 0.10427594929933548
0.007009896951032969 0.0710206925868988
0.007567999363568716 0.12419679015874863
0.009360678282977479 0.16513782739639282
0.010204026609070438 0.16649430990219116
0.009233814832143899 0.13057740032672882
0.007389027314077745 0.07597079873085022
0.006237365751557202 0.05780653655529022
0.006437143489224295 0.09727070480585098
0.007296269112982765 0.124671071767807
0.007680179536959683 0.12060843408107758
0.00716528699053997 0.08915361762046814
0.006297982303641728 0.05128876119852066
0.005871670272629181 0.054160863161087036
0.0060839842672575015 0.08241435140371323
0.0064345400077278035 0.0945424735546112
0.006378373106981665 0.08256728947162628
0.005930729602039511 0.053127143532037735
0.005570316561725572 0.03283781185746193
0.00561907238119071 0.05251489207148552
0.005874500348044575 0.07139087468385696
0.0059213813006356525 0.07064421474933624
0.005656603046451514 0.05102093145251274
0.005362171479243879 0.02604253962635994
0.005314565218555927 0.03159015625715256
0.0054738274165676126 0.05045728385448456
0.005585749236766004 0.05603482574224472
0.005500696777343328 0.04561491683125496
0.005309652190127805 0.02604813687503338
0.005202111688644929 0.02069004811346531
0.005246498958067297 0.03541445732116699
0.00533531469068764 0.04290757700800896
0.00533377530240718 0.03738623857498169
0.005237905293321768 0.022968554869294167
0.005158456978369073 0.01610719971358776
0.005170544470484002 0.02670540288090706
0.005220738405614363 0.033125776797533035
0.005215040352879071 0.029050912708044052
0.00515108519389943 0.017305120825767517
0.005111798324988973 0.012161210179328918
0.005134930641403141 0.021559791639447212
0.005167644764068292 0.026408394798636436
0.00515004484922415 0.022213801741600037
0.00510224836689633 0.012031752616167068
0.005082581940359894 0.009608876891434193
0.00510396010299184 0.01765202172100544
0.005124657245207058 0.02064393274486065
0.005112358592235301 0.016452081501483917
0.005083350701137081 0.00853712484240532
0.0050713264048382264 0.008842266164720058
0.00508320965416728 0.014646762050688267
0.005093564548442303 0.01570040173828602
0.005085634319027877 0.011371830478310585
0.005070427434372596 0.006108129397034645
0.005067451327480428 0.008868217468261719
0.005074227127316574 0.012335026636719704
0.005075275227983049 0.011375446803867817
0.005067217997728895 0.00686621991917491
0.005062329757801496 0.005086806602776051
0.005065157748650517 0.008722220547497272
0.005068021233988553 0.009999278001487255
0.005063803373708191 0.00753743527457118
0.005058910437207732 0.0038175208028405905
epoch: 1 | iteration: 80 |   loss: 0.005059  |   KL divergence: 0.005059  |  JS divergence: 0.001301
('==== Found maximium gradient [0.06541793, 0.065083094, 0.051851794] of gate '
 'e^[Y1 Z2], e^[Y2 Z1], e^[Y0 Z1] ====')
learning rate =  0.015277926625518745
0.005058629759655828 0.10598328709602356
0.0036965872644499154 0.10596711933612823
0.0018081326506945421 0.028015779331326485
0.0020384579578528604 0.05828526243567467
0.002608388863592889 0.08243516087532043
0.0025810579187540506 0.07414931058883667
0.002301736692819266 0.054895952343940735
0.0021631224723844314 0.04854325205087662
0.0021607772719769063 0.05549081414937973
0.0020758985562195588 0.054998770356178284
0.0018990772726856983 0.04371969401836395
0.001777792320844154 0.03140851855278015
0.0017965986341975642 0.03351393714547157
0.0018854887284244011 0.043974243104457855
0.0019036098473283445 0.04800475016236305
0.0017968968281282794 0.041477981954813004
0.0016480123074715865 0.02689000591635704
0.0015753807836928879 0.013522918336093426
0.001618093697717001 0.020555516704916954
0.0017098096675339312 0.03147982805967331
0.001754285637436614 0.035129364579916
0.0017191013733583718 0.0312688983976841
0.0016460381986358147 0.023782003670930862
0.0015894104888980187 0.019364940002560616
0.0015664948074015875 0.02066207490861416
0.0015559946658430628 0.021650835871696472
0.0015434459968607667 0.0187081228941679
0.0015393006582700615 0.013927296735346317
0.0015584885018532437 0.014183507300913334
0.0015901066051424852 0.019365953281521797
0.0016046663026906718 0.02247270569205284
0.0015813156628217645 0.020494377240538597
0.001535661009462171 0.013731815852224827
0.0015024667694349876 0.005101246293634176
0.0015004493892914381 0.00694115599617362
0.0015180971193865978 0.012918117456138134
0.0015318465984609422 0.014987878501415253
0.0015324917535535964 0.013335232622921467
0.0015256660773232751 0.010486866347491741
0.0015211893948173052 0.009859244339168072
0.0015189443910594968 0.010834228247404099
0.0015132428646907174 0.010294388979673386
0.001504999654298795 0.007641829550266266
0.0015013841876503637 0.005643155425786972
0.001505513786494305 0.0075681996531784534
0.001510614169240115 0.009693274274468422
0.001508940331014519 0.009326876141130924
0.001502406774500008 0.006431104615330696
0.0014977276186267433 0.0032713417895138264
epoch: 2 | iteration: 129 |   loss: 0.001498  |   KL divergence: 0.001498  |  JS divergence: 0.000387
('==== Found maximium gradient [0.018182898, 0.016805522, 0.01484556] of gate '
 'e^[Y1 Z3], e^[Y3 Z1], e^[Y0 Z3] ====')
learning rate =  0.004166918235173094
0.0014999425056495574 0.02927737683057785
0.0014106212301217107 0.02805180288851261
0.001270433744319616 0.009162657894194126
0.0012776217903019455 0.01419935841113329
0.0013198482671445614 0.020789651200175285
0.001319266044552975 0.01895570568740368
0.0013031711643040518 0.015059063211083412
0.0012952406287543034 0.014069614931941032
0.0012890282966583678 0.01427514385432005
0.0012753156680070789 0.01226465217769146
0.0012608642256823743 0.008844265714287758
0.001257505249203979 0.008238953538239002
0.0012650104001382008 0.010928680188953876
0.0012702628590543748 0.012529617175459862
0.0012665473308461092 0.011501331813633442
0.001255803937507101 0.008584356866776943
0.0012469169054289127 0.006035714875906706
0.0012455582273352152 0.0061726318672299385
0.0012485827541110844 0.007287316955626011
0.0012515433625987632 0.007592304144054651
0.0012528415300263709 0.007394291460514069
0.0012520750920441308 0.007496383972465992
0.0012498040607712548 0.007674562279134989
0.001245568562050345 0.006996083538979292
0.0012409374989559218 0.0051405709236860275
0.0012378962852342662 0.0030026137828826904
epoch: 3 | iteration: 155 |   loss: 0.001238  |   KL divergence: 0.001239  |  JS divergence: 0.000319
('==== Found maximium gradient [0.0109607205, 0.01057249, 0.008986806] of gate '
 'e^[Y0 Z2], e^[Y2 Z0], e^[Y1 Z4] ====')
learning rate =  0.0025522767517501795
0.0012385466648944063 0.017969775944948196
0.0012133254145227596 0.018674928694963455
0.0011469605322049984 0.005918115843087435
0.001149336876648038 0.009346290491521358
0.0011707544517096148 0.013943006284534931
0.0011691892999608638 0.012709546834230423
0.001158174943965278 0.009429916739463806
0.0011540850178197654 0.00835947785526514
0.001155834148637477 0.009482679888606071
0.0011534222136999632 0.009289713576436043
0.0011462207692100146 0.00720498850569129
0.0011403828040898783 0.004942483734339476
epoch: 4 | iteration: 167 |   loss: 0.001140  |   KL divergence: 0.001141  |  JS divergence: 0.000293
('==== Found maximium gradient [0.0061983573, 0.005871, 0.004200382] of gate '
 'e^[Y1 Z5], e^[Y5 Z1], e^[Y0 Z4] ====')
learning rate =  0.001373343527982989
0.0011406404097200526 0.010946509428322315
0.0011218194418263266 0.008660807274281979
0.0011077656970028694 0.0036728547420352697
epoch: 5 | iteration: 170 |   loss: 0.001108  |   KL divergence: 0.001108  |  JS divergence: 0.000284
('==== Found maximium gradient [0.0028157968, 0.0027484496, 0.002684254] of '
 'gate e^[Y1 Z6], e^[Y0 Z5], e^[Y6 Z1] ====')
learning rate =  0.0006875061389410308
0.0011096809002068986 0.007129076402634382
0.0011003891025757018 0.003750489093363285
epoch: 6 | iteration: 172 |   loss: 0.001100  |   KL divergence: 0.001101  |  JS divergence: 0.000282
('==== Found maximium gradient [0.002544785, 0.0025269254, 0.0019267168] of '
 'gate e^[Y4 Z3], e^[Y3 Z4], e^[Y2 Z3] ====')
learning rate =  0.0005876067098694525
0.0010983058602957118 0.005458020139485598
0.0010943406281362837 0.0036895624361932278
epoch: 7 | iteration: 174 |   loss: 0.001094  |   KL divergence: 0.001095  |  JS divergence: 0.000280
('==== Found maximium gradient [0.0022594056, 0.0017341023, 0.001566597] of '
 'gate e^[X1 Y0], e^[X2 Y0], e^[X1 Y4] ====')
learning rate =  0.00046918037958031095
0.0010914840825198722 0.004479211289435625
epoch: 8 | iteration: 175 |   loss: 0.001091  |   KL divergence: 0.001092  |  JS divergence: 0.000280
('==== Found maximium gradient [0.0014809561, 0.0013760754, 0.0012782894] of '
 'gate e^[Y1 Z7], e^[Y7 Z1], e^[X1 Y3] ====')
Convergence criterion has reached, break the loop!
