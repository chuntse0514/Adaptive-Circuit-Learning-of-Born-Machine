nohup: ignoring input
('==== Found maximium gradient [0.18926477, 0.18926477, 0.18926477] of gate '
 'e^[X9 Y1], e^[X0 Y1], e^[X11 Y1] ====')
learning rate =  0.03785295635730998
0.05972389433068618 0.17714886732512408 0.44898778200149536
0.04853724047108439 0.15810700170895348 0.234828382730484
0.04608208950628176 0.1531076827500418 0.35074320435523987
0.04493467946209284 0.15107318068704828 0.31080174446105957
0.043957121590443335 0.14976071502572988 0.1983558088541031
0.0432944233903641 0.1492135286339118 0.18599721789360046
0.04346879307968041 0.14997470322818132 0.25971540808677673
0.04298644225753323 0.14931583764557915 0.2699950337409973
0.0418541748135958 0.14726989011494057 0.21263954043388367
0.040848267762974844 0.1452589782997539 0.1355767846107483
0.0405576621784772 0.1444375353163376 0.13589154183864594
0.04075070018434896 0.14455703495057223 0.18666031956672668
0.04067347052759873 0.14442105054018486 0.19905251264572144
0.04014802388086731 0.14371745928758078 0.1633392870426178
0.039540911300277246 0.14297888677660647 0.10814370214939117
0.03922051921208949 0.14271067981215257 0.0988544449210167
0.039233484676247696 0.14287753642881887 0.13668714463710785
0.03931432501350897 0.1429769219302242 0.15527009963989258
0.03926912210099606 0.14272296546219632 0.13788177073001862
0.03914522665695533 0.14228388284167182 0.09912540763616562
0.03905514432673928 0.14191911365127274 0.07857614755630493
0.0390025130036023 0.1416700749613837 0.09701206535100937
0.03888534362444172 0.14139272238044584 0.11155260354280472
0.038669794293614335 0.14105643124952535 0.09979468584060669
0.03847620946957872 0.14087476654478334 0.0695107951760292
0.03842361187457065 0.1410067359495871 0.056888699531555176
0.03847048850526781 0.1412889573521994 0.07920829206705093
0.03846032773499216 0.14137200708696487 0.09522136300802231
0.038311137661260534 0.1410833934033427 0.08700893074274063
0.03812463292690841 0.140632609228985 0.05851050093770027
0.03805977309319081 0.14035658279089042 0.03535587340593338
0.038145201478389734 0.14036239508134224 0.051044899970293045
0.03825446884790799 0.1404708083487478 0.06726475059986115
0.03826098815456115 0.1404780643159819 0.06411632150411606
0.03817078864994021 0.1403866443939232 0.04678228124976158
0.038076434715719774 0.1403293557211415 0.03805796802043915
0.03802076448840954 0.14033494004359323 0.049612369388341904
0.03796731129267709 0.1402992853444707 0.05651213601231575
0.03789147098642996 0.14016104429635318 0.047393761575222015
0.037840912547488725 0.14001446228302897 0.027920512482523918
0.03786825498866167 0.13998237652579762 0.02455860562622547
0.037942074640713114 0.1400476366581614 0.03946778178215027
0.03797111536560076 0.1400775055080317 0.04462979733943939
0.037915577539466935 0.14000565486966612 0.03573152422904968
0.03783134234798506 0.13991116165111617 0.022276490926742554
0.03778956573468789 0.13988690607535353 0.02501177415251732
0.03779296955148261 0.1399100221845952 0.034035295248031616
0.03779692453901157 0.139893419290322 0.03318161889910698
0.03778597868756036 0.1398251147197661 0.022573934867978096
0.03778251719080318 0.13976720393493408 0.014952179044485092
0.03779672560363091 0.13976302717629163 0.022188305854797363
0.037799859830487094 0.13977682629930993 0.02683330327272415
0.03776618688238929 0.13976110164054487 0.022884637117385864
0.037712108728226904 0.13972669665670573 0.016093919053673744
0.03767198691672622 0.13970552838503988 0.01752437837421894
0.03765782536728183 0.13969612261564804 0.021460797637701035
0.03765861281963084 0.13967239093462888 0.019134629517793655
0.0376689253464438 0.13963787990565169 0.011707871221005917
0.03769086348225776 0.13961994011449286 0.010485993698239326
0.03771465360533893 0.13962475256827497 0.016337834298610687
0.037717739378621176 0.13962313491694528 0.01772455871105194
0.037694421350395343 0.13960616850959723 0.013729124329984188
0.03765853653202386 0.13957954525648325 0.010102646425366402
0.03763122807926356 0.13956330317633017 0.011930381879210472
0.03761824664095257 0.13955289503319682 0.012921997345983982
0.03761639853081411 0.13954076496881967 0.010199657641351223
0.03762232031589881 0.13953080161946574 0.008047906681895256
0.03762917170240801 0.1395232175055117 0.010449406690895557
0.03762896298185197 0.1395165306088684 0.01177158486098051
0.03761724930357356 0.1395032834216795 0.009469013661146164
0.037601088200153315 0.13948888749490798 0.006444120779633522
0.03759028238426307 0.1394797685452125 0.0075860763899981976
0.03758772803817994 0.13947250895474267 0.009010924026370049
0.0375918088978374 0.1394653735316271 0.007675963453948498
0.037597525597228454 0.1394541688256649 0.005719784647226334
0.03760221077546701 0.13944833537391296 0.0066655585542321205
0.03759915242750703 0.13944164525021316 0.0076845018193125725
0.037587334236337 0.1394338126494783 0.006505522411316633
0.03757132820887741 0.13942505334766167 0.004794014617800713
iteration: 1 | epoch: 80 |   loss: 0.139425  |   KL divergence: 0.037571  |  JS divergence: 0.009625
('==== Found maximium gradient [0.12868842, 0.12765227, 0.07860755] of gate '
 'e^[Y8 Z1], e^[Y1 Z8], e^[Y8 Z0] ====')
learning rate =  0.02281372608274859
0.03755858462866277 0.1394183612526893 0.19764453172683716
0.03513304747072689 0.13432559179562956 0.1108313649892807
0.03487491049610518 0.13405114686456232 0.1268586665391922
0.035529395499799984 0.1347877206306624 0.12524540722370148
0.03610829264676467 0.135374956391237 0.13405965268611908
0.03608707776568201 0.13519346976140104 0.13847362995147705
0.035242265231613376 0.1338560731001346 0.08549515902996063
0.03464862723068604 0.13312967008096946 0.03967975452542305
0.03465311384974619 0.1334439146395815 0.07952683418989182
0.03475159813475967 0.1337398112148146 0.09002593159675598
0.034791570528907266 0.13377516746287008 0.08280471712350845
0.034852369644540776 0.13379067894463517 0.08784034848213196
0.03478683895527028 0.1336096341234838 0.08519653230905533
0.03455007395033756 0.13318799878380097 0.05506039783358574
0.03440817651915492 0.13298074528446505 0.026100119575858116
0.03449270559289061 0.13316096177265418 0.053594037890434265
0.03461870382370609 0.13332937781582466 0.06836067140102386
0.0346595711630196 0.13326263573916206 0.06052834168076515
0.03468162029883609 0.1331454763769734 0.05225243419408798
0.034696939287154255 0.13307989701701303 0.05262100324034691
0.03463260386187632 0.132974758169913 0.04248402267694473
0.03453398178651463 0.13289973697846272 0.023820534348487854
0.0344975276668823 0.13297003432221466 0.03394899517297745
0.03449609232608663 0.13306667004298767 0.04856933280825615
0.03445820211035745 0.1330210039174969 0.045160915702581406
0.03441561601366391 0.1329052776736293 0.03303234279155731
0.0344157659738485 0.13285530333706508 0.031062591820955276
0.034420659183747385 0.13284347882910652 0.030396392568945885
0.03440491052060268 0.13283525728138074 0.021794036030769348
0.0344035583742803 0.1328685225063916 0.02466345764696598
0.034421337750639845 0.13291145557590525 0.034975141286849976
0.03442401750294526 0.13287802412507757 0.032983265817165375
0.034421273680878973 0.13279939518792006 0.020686659961938858
0.034441204674301444 0.13276994135281425 0.01705193519592285
0.03445848005637194 0.1327808582591351 0.020798755809664726
0.034445157390650155 0.1327903970410194 0.018112560734152794
0.03441960584010682 0.13280650496777574 0.01945454254746437
0.03439897617852387 0.1328207232877726 0.02485024929046631
0.03437740730813403 0.13279170590804756 0.02154698222875595
0.034368455322285024 0.1327494334935686 0.010891415178775787
0.034382913946646027 0.1327420897530975 0.011246399953961372
0.034396495450743976 0.13275370255560529 0.015515678562223911
0.03439095356254142 0.13275893063775535 0.01390030886977911
0.034379493190289434 0.13276494257015736 0.015364587306976318
0.034372434692004294 0.1327645362432707 0.01744769513607025
0.034369564298509736 0.13274343307499564 0.012256098911166191
0.03437831659438745 0.13272812815653492 0.005233836360275745
0.03439329578483914 0.1327329534809712 0.010474883951246738
0.034395125679483184 0.13273802538985008 0.01189477276057005
0.034383284113436705 0.13273761360801076 0.010012555867433548
0.03437253418161543 0.13273743481738962 0.011452069506049156
0.03437001275940384 0.13273348854756886 0.010616893880069256
0.03437610590291122 0.13272445804295813 0.005335284862667322
0.03438804937848871 0.13272264240894432 0.006654397118836641
0.03439250119050089 0.13272373466159035 0.00929053034633398
0.0343830172469087 0.1327220567984213 0.007385301869362593
0.03436941062989141 0.13272178757030556 0.007037164177745581
0.0343615805268476 0.13272205408079973 0.007890451699495316
0.03436150950474656 0.13271731260029704 0.0052789850160479546
0.03436878908261358 0.1327165898940331 0.005048399791121483
0.034374528518403356 0.13271692956943715 0.007226306479424238
0.03437224243302385 0.1327138254986192 0.005647050216794014
0.0343676967982391 0.13271236388870117 0.004093937575817108
iteration: 2 | epoch: 143 |   loss: 0.132712  |   KL divergence: 0.034368  |  JS divergence: 0.008715
('==== Found maximium gradient [0.07144885, 0.071167745, 0.06704727] of gate '
 'e^[Y10 Z0], e^[Y0 Z10], e^[Y1 Z3] ====')
learning rate =  0.013983381483900945
0.03436834186782599 0.13271373317729368 0.12122169882059097
0.034857736712749526 0.13295953458542203 0.16988517343997955
0.03318570517694952 0.13043989719266327 0.04996373504400253
0.03341260304787742 0.13141306834419517 0.11613451689481735
0.033774955662988056 0.1322296681719019 0.14623984694480896
0.03347966587449016 0.1315050768429472 0.11082141101360321
0.0331755338717693 0.13062672100948605 0.05182443559169769
0.03330529296024702 0.1305665283131889 0.058665983378887177
0.03364380896594088 0.13101054033033 0.09637842327356339
0.03373209715524065 0.13113828560698365 0.10179761052131653
0.03349584005768818 0.13079427593156115 0.07801739126443863
0.033186451798319125 0.13039845256325314 0.045585568994283676
0.03302629791835285 0.1303044959406231 0.04520788788795471
0.0330212685857977 0.13045550531234062 0.06447786092758179
0.03305605818632555 0.13058513740291922 0.06991180777549744
0.03306751905681833 0.1305687241206847 0.06039391830563545
0.0330749649404002 0.1304728329641447 0.047955721616744995
0.0331056010847877 0.1303953876886654 0.04675166308879852
0.033138812722842886 0.13034299540057392 0.05100037157535553
0.03314100467130297 0.13028372569332738 0.047813788056373596
0.03311561759773875 0.13023222917425356 0.03694752976298332
0.03309118579798518 0.1302332956567402 0.03039686381816864
0.03307736064213127 0.13027970014823614 0.03703146055340767
0.03305700987273627 0.1303097091426752 0.043685488402843475
0.03301850765998252 0.13027917804446645 0.040953706949949265
0.03298123910461492 0.1302144994261369 0.0301675908267498
0.03297572810681474 0.13018140964755526 0.022223355248570442
0.03300049511977961 0.13019157365981665 0.0271560437977314
0.03302411546765806 0.13020311435729343 0.03264237940311432
0.03302226089494559 0.130181519161438 0.03019772097468376
0.03300533920222004 0.13015330250812768 0.021720362827181816
0.032994018038357296 0.1301485986954608 0.017823055386543274
0.03299391158607372 0.13016870634291414 0.02344740927219391
0.03299120494639361 0.13017584169780758 0.02678350917994976
0.03297988827737646 0.1301537237474158 0.02292831800878048
0.03297223486161377 0.13012912234124469 0.015170253813266754
0.03297775014923507 0.13012429510826243 0.014267419464886189
0.03298956853470624 0.13013602274799044 0.019718332216143608
0.0329901131998313 0.1301356631710293 0.020816149190068245
0.032976965086081944 0.13012080725698577 0.015493323095142841
0.03296290845263309 0.1301083872325512 0.009038279764354229
0.03296085474124741 0.13011685847932003 0.012652217410504818
0.03296669435450239 0.13013081550822334 0.017758024856448174
0.03296954264835844 0.13012610092614427 0.017125949263572693
0.03296877748583343 0.1301069738872681 0.010933502577245235
0.032971029034122246 0.13009524334696604 0.005060921423137188
0.03297676073537317 0.13009946365295633 0.00981409102678299
0.03297838739311865 0.13010940845905672 0.013539940118789673
0.03296975517114415 0.13010972291921102 0.012608185410499573
0.032955685505788646 0.13010230473377044 0.009034805931150913
0.03294591241638595 0.1300968287226453 0.007725376635789871
0.03294539470052969 0.13009630064066202 0.009222556836903095
0.032952392444302314 0.13009671225872985 0.009317094460129738
0.03296281998199868 0.13009631175643308 0.007829767651855946
0.032971642376495844 0.13009354932236478 0.007382511626929045
0.03297597031689923 0.13009395898654874 0.008089535869657993
0.03297208711297919 0.13009110030890178 0.007506809663027525
0.03296312723095274 0.1300899900045421 0.0057221585884690285
0.03295352670860045 0.13009041448787403 0.005798296071588993
0.03294715249963024 0.13009096973817644 0.007356761489063501
0.032945433474833315 0.13008856579271302 0.007088642567396164
0.03294922145677997 0.13008583033183146 0.0043555451557040215
iteration: 3 | epoch: 205 |   loss: 0.130086  |   KL divergence: 0.032949  |  JS divergence: 0.008375
('==== Found maximium gradient [0.06854002, 0.067856446, 0.058346484] of gate '
 'e^[Y9 Z8], e^[Y8 Z9], e^[Y9 Z10] ====')
learning rate =  0.013016166191988128
0.03295670930405932 0.13008354688835583 0.11275198310613632
0.032998591168659955 0.1300957057277144 0.12532921135425568
0.03199856358764376 0.12848752896845855 0.07561468333005905
0.03229436077561589 0.12900433595057492 0.09377775341272354
0.03264937637109666 0.12951823071024474 0.10313846915960312
0.0325873448308138 0.12928819769238717 0.09955237805843353
0.032183594833251686 0.12855435368900864 0.0656544640660286
0.031918600775436456 0.12817716498542683 0.02991326153278351
0.03200201279358339 0.12846782571434737 0.06147005036473274
0.0321363515489127 0.12876112441905535 0.0806240662932396
0.032099176673272736 0.12862163435289842 0.07102910429239273
0.0320017384900973 0.12831655046282034 0.0509093813598156
0.0319685967207272 0.12815336598428675 0.04115109518170357
0.031987817705464154 0.12815785476370353 0.039365604519844055
0.03202497071970986 0.12826094630369198 0.042842376977205276
0.03205253632627853 0.1283754415318851 0.05253647267818451
0.03202441222501261 0.12836519009133107 0.05594806373119354
0.03193700473840643 0.12820183357512283 0.044188786298036575
0.03186518950710074 0.12803914204270783 0.023490214720368385
0.03186886383515395 0.12802064061085117 0.02271932177245617
0.0319091063158353 0.12810087090921338 0.03511200100183487
0.03191514155148873 0.12814811255243763 0.03746172413229942
0.031883604413313484 0.12813997472464755 0.03394724801182747
0.031848101354296915 0.12810751634741915 0.03222372382879257
0.031828402277351814 0.1280645877533211 0.029217950999736786
0.031832890078785314 0.12802575553223572 0.022320419549942017
0.03186472321912327 0.12802215782477772 0.020842142403125763
0.031898463578211765 0.12803925523399023 0.02573402412235737
0.03189918921802812 0.12803334164374008 0.025251323357224464
0.03187064359092769 0.12801043824182962 0.019389202818274498
0.03184419717142093 0.12800663912005042 0.01867573894560337
0.031833115387529046 0.12801936269445927 0.022120174020528793
0.031828654127721276 0.1280139642442564 0.020562000572681427
0.03183028585148473 0.12799641185758734 0.01596801169216633
0.03183720656182858 0.1279830344639844 0.01537624467164278
0.03184038737202756 0.12797805836143147 0.01583525352180004
0.031835212989715436 0.12797940003017236 0.01424331683665514
0.03182647343889981 0.1279818290649678 0.01495822798460722
0.03182107453452253 0.12798682035798434 0.016230886802077293
0.03181667048308037 0.1279741159445543 0.012991420924663544
0.03181986392585165 0.12796369817075845 0.00859158392995596
0.03182945523236151 0.12796622690864287 0.011476214043796062
0.03183288332505065 0.12797008733922785 0.013848626054823399
0.03182422240757088 0.12796613359714717 0.011669852770864964
0.03181185720536987 0.12795801919185404 0.008800724521279335
0.03180692923039621 0.12795351891710052 0.008229018189013004
0.03181266678786466 0.1279538034221837 0.007795912213623524
0.03182499605484978 0.12795868052689974 0.009103415533900261
0.03183320112067545 0.1279620456173335 0.010950924828648567
0.031828004835844054 0.12795564813279786 0.009174630045890808
0.03181420374880253 0.12794711383070204 0.0040799896232783794
iteration: 4 | epoch: 256 |   loss: 0.127947  |   KL divergence: 0.031814  |  JS divergence: 0.008098
('==== Found maximium gradient [0.057031248, 0.05629812, 0.03558115] of gate '
 'e^[Y1 Z2], e^[Y2 Z1], e^[Y3 Z8] ====')
learning rate =  0.010124597232024943
0.03180342628136857 0.12794528989575676 0.08778956532478333
0.03248988655965111 0.12875946847714148 0.13946452736854553
0.03148013124672169 0.12710058226726811 0.052729133516550064
0.03156806134474181 0.1275878922159736 0.08994358032941818
0.031925613605841736 0.12839209281197791 0.12295420467853546
0.03170705707443924 0.12791094366490316 0.09862492978572845
0.03135993132370244 0.12709267436811109 0.046532485634088516
0.03133351943991197 0.12688042057894222 0.03657957911491394
0.03156447525086541 0.12721867497171774 0.07264307886362076
0.03170032670050512 0.12745853052123873 0.08336199820041656
0.03160417071263947 0.12733315570351 0.06917625665664673
0.031412896122773044 0.12707695070365574 0.045903660356998444
0.031292781616409235 0.12696600692185753 0.04064664617180824
0.031273139515492224 0.12700620171894011 0.05199496075510979
0.03128945415123235 0.1270474950761241 0.0556865893304348
0.031298737652603006 0.12701418654387694 0.04805537685751915
0.03131061689859233 0.12695169941241283 0.03771675005555153
0.03134147407538939 0.12692439834906663 0.036903202533721924
0.03137419813424677 0.1269292351336067 0.04189199209213257
0.03137732262351106 0.1269187289117913 0.041620682924985886
0.031348748687453395 0.12689194003218393 0.034770894795656204
0.03130687705223232 0.12686926769441573 0.028265591710805893
0.03126920158769842 0.12686380653841633 0.029426466673612595
0.031238888427908586 0.126858170626606 0.03294485807418823
0.03121684700554649 0.12683679146139026 0.03158747777342796
0.031213672326627452 0.1268179573771923 0.025871988385915756
0.031234289578247525 0.1268191703293346 0.02235030196607113
0.031264600753066696 0.12682863187761192 0.024527497589588165
0.031282881574139214 0.12682312532207202 0.02628622204065323
0.031280418454331584 0.12679761186638547 0.02336251735687256
0.031268307566550975 0.12677766869179483 0.01797162927687168
0.03125895637470718 0.12678231049934846 0.017117567360401154
0.03125065681020972 0.12679642399014956 0.020738735795021057
0.031236514670778915 0.12679517792119738 0.021654024720191956
0.03121917731114769 0.1267748758817211 0.017446184530854225
0.031211742492137203 0.1267602273078541 0.01156583521515131
0.0312192894201869 0.12676354154466693 0.012570560909807682
0.0312333230850824 0.12677749835209334 0.01722898706793785
0.031238310208162857 0.1267752407347536 0.01791595295071602
0.03123294178229292 0.1267598214561387 0.013401474803686142
0.03122633888725069 0.1267481796383526 0.007083319127559662
0.03122595675955712 0.1267510956413239 0.008704964071512222
0.031229550861660783 0.1267603192926477 0.013500255532562733
0.031230817751985947 0.1267621752350068 0.014376646839082241
0.03122800643648168 0.12675403699826296 0.010939151979982853
0.03122429619056274 0.12674353447730832 0.005975635722279549
0.03122354334799085 0.12674267500104974 0.006400851532816887
0.031223582846550583 0.1267476234212058 0.009750698693096638
0.03122086974776095 0.12675027187056198 0.010599276050925255
0.03121532528205221 0.1267474362449577 0.00875790510326624
0.031210512850733237 0.12674140214844867 0.006249179132282734
0.03121069122979562 0.1267386226706153 0.005923971068114042
0.031215464411141505 0.1267382394063993 0.0069943382404744625
0.031222126360808997 0.1267406120535977 0.007203101180493832
0.031226049409062054 0.12673996683180916 0.006483355071395636
0.031226309008654564 0.12673901668163368 0.005821721162647009
0.03122296018317984 0.12673744387494965 0.005592074245214462
0.03121716939246561 0.12673488608867212 0.0052482918836176395
0.031211793621235412 0.12673479764529483 0.004749788902699947
iteration: 5 | epoch: 315 |   loss: 0.126735  |   KL divergence: 0.031212  |  JS divergence: 0.007948
('==== Found maximium gradient [0.025085138, 0.023360621, 0.021569543] of gate '
 'e^[Y0 Z2], e^[Y2 Z0], e^[Y10 Z2] ====')
learning rate =  0.0046765057925596655
0.031208426552397563 0.12673479597517412 0.04077281057834625
0.03152821487305373 0.1270380906228477 0.07221484929323196
0.031192370456389732 0.12652378492568506 0.021476827561855316
0.031185832116646432 0.12667019028879997 0.043661609292030334
0.03125096331097941 0.12685597949630525 0.05961599200963974
0.031202820803295728 0.12672685043922072 0.04730585217475891
0.031146883761220608 0.12653795599735987 0.021876586601138115
0.031172869270379773 0.12650510360856326 0.01628439873456955
0.03125029125902594 0.1265992959227193 0.03547225147485733
0.031285110479529935 0.12665757607425754 0.042364612221717834
0.03124260548176923 0.1266063093971514 0.03564882278442383
0.03116672523302054 0.1265150864611882 0.020436028018593788
0.031115240918315613 0.12647972523069048 0.01012333482503891
0.03110669004274636 0.12651324613168316 0.021209925413131714
0.03112038481166594 0.1265607469413319 0.029617993161082268
0.031128789438598363 0.12656451002422714 0.029486950486898422
0.03112814211379099 0.12652413428972253 0.02215491607785225
0.031133470520560258 0.12648329046631585 0.012674734927713871
0.031154011942408175 0.1264763307740194 0.012298371642827988
0.031178782476313213 0.12649370124724107 0.018645640462636948
0.031189627382516412 0.12650965015106339 0.021349921822547913
0.031177148075775107 0.12650384197944756 0.018829746171832085
0.031150207438975935 0.12648611352986053 0.013335973024368286
0.03112458262554186 0.12647477876413524 0.01051836833357811
0.031110115563796215 0.12647679431067155 0.013354605063796043
0.031106966454405853 0.12648543680013413 0.015865197405219078
0.031109111251671873 0.12648416999557757 0.014915715903043747
0.031115387073044842 0.12647576044671435 0.01101882103830576
0.031125540058928182 0.12646525038669096 0.007607589941471815
0.03113956408972991 0.1264652773917343 0.009084443561732769
0.03115065755532103 0.1264700614815945 0.011823730543255806
0.03115286507890598 0.12647443379153625 0.012168118730187416
0.03114354913113411 0.12646987560812073 0.009778101928532124
0.031128215138078272 0.12646148373041805 0.00644790381193161
0.031115223261910595 0.12645880290344497 0.006071989890187979
0.031108533719580125 0.1264611707342519 0.008281414397060871
0.031107936979210823 0.12646352130703484 0.009302040562033653
0.031111727177474225 0.1264627895870411 0.008162057027220726
0.031118403011645607 0.12645937984834005 0.00572578189894557
0.031126122507793674 0.12645436019834785 0.004524838179349899
iteration: 6 | epoch: 355 |   loss: 0.126454  |   KL divergence: 0.031126  |  JS divergence: 0.007913
('==== Found maximium gradient [0.018283222, 0.018269612, 0.017151361] of gate '
 'e^[Y9 Z3], e^[Y3 Z9], e^[Y8 Z10] ====')
learning rate =  0.0035818508104328087
0.031134172242971117 0.12645634777171305 0.031567737460136414
0.031105790301507646 0.12662923115758815 0.05350157618522644
0.031029281077586353 0.12632941059376362 0.01705097407102585
0.03114408267840041 0.1264068537898907 0.03163496032357216
0.03123627807630716 0.1265165610540192 0.043704237788915634
0.031187624852991102 0.12644563328900163 0.03486479073762894
0.031096075095976963 0.12633952582505883 0.016479074954986572
0.03104632063649782 0.12632211167780102 0.014108785428106785
0.03104478449152661 0.12637267574562178 0.026444166898727417
0.031053328443123765 0.12640009434902189 0.030658317729830742
0.03105056082761222 0.1263722921063632 0.025771521031856537
0.0310448772773489 0.12632199555560725 0.015095780603587627
0.031054830437735666 0.12630164185162532 0.008771048858761787
0.031079037491313043 0.12632075491238343 0.016259126365184784
0.03109575630858544 0.1263439741456151 0.021546028554439545
0.031090804930734996 0.12634766149684526 0.020913004875183105
0.031066410771543228 0.12632626641626635 0.016059374436736107
0.031039551304846397 0.12630726433534514 0.01095131691545248
0.031021850092853576 0.12629981196400172 0.010585890151560307
0.031018951133227675 0.1263068336261399 0.013374573551118374
0.031026753939790076 0.1263143882041298 0.014601659029722214
0.03103863418072505 0.12631112493869565 0.013103362172842026
0.031052533411001546 0.12630448304305783 0.010454699397087097
0.031066217089482397 0.12630098305953946 0.009599602781236172
0.03107467644749116 0.12629907442368885 0.010515202768146992
0.031074599988327206 0.1262996204161706 0.010707877576351166
0.031065073539962372 0.12629825188820681 0.009582923725247383
0.031050037209469042 0.1262953392898348 0.008125875145196915
0.03103534553730594 0.12629302921600175 0.007429562974721193
0.031025860334533417 0.1262927097188906 0.007685501594096422
0.03102336664201758 0.1262934562352304 0.00811019353568554
0.03102652791084104 0.1262932967733956 0.00780830392614007
0.03103292389040988 0.12629164072727522 0.006746446713805199
0.031040117938007046 0.12628820818474454 0.0058697303757071495
0.031046912020734046 0.1262873463330364 0.005774368066340685
0.031050802222329445 0.12628717259972957 0.005914513953030109
0.03105086440625402 0.12628823756972168 0.005855086725205183
0.03104645752899801 0.12628676992846535 0.005455341190099716
0.031040389872258944 0.12628703659746426 0.004666053224354982
iteration: 7 | epoch: 394 |   loss: 0.126287  |   KL divergence: 0.031040  |  JS divergence: 0.007891
('==== Found maximium gradient [0.016311, 0.015086502, 0.012076331] of gate '
 'e^[Y1 Z11], e^[Y11 Z1], e^[Y3 Z4] ====')
learning rate =  0.0029200205677155817
0.03103415153539483 0.12628435229265164 0.025616755709052086
0.03118419677540589 0.12641428378846664 0.04558596387505531
0.031052490224281127 0.1262335456524006 0.020762242376804352
0.031019619781377517 0.12625891408376572 0.026434894651174545
0.031045662353828364 0.12634934673608855 0.03831303492188454
0.031027713462320285 0.12630603113815905 0.03255527466535568
0.031001753334375815 0.12622009249249366 0.017428774386644363
0.031010876062880683 0.12619094589412225 0.010309293866157532
0.0310485546868825 0.12622534895346915 0.021054496988654137
0.031073371890066467 0.12625599042295152 0.026579974219202995
0.031064004824459212 0.12624347659819266 0.02420547977089882
0.031033668074557208 0.12620982602766515 0.016624869778752327
0.03100451701169392 0.12618859254684975 0.009647018276154995
0.030989515225943343 0.12619272530820824 0.012207779102027416
0.030987480623627238 0.12620899906769031 0.01743064820766449
0.03098971212226346 0.1262146578645124 0.018901662901043892
0.030991810069531604 0.1262025752046761 0.01606547087430954
0.03099733611077938 0.1261878471237569 0.01079043559730053
0.03100774951360547 0.1261782470167069 0.00788712315261364
0.03102158700979199 0.12618245450162194 0.010551904328167439
0.031030279713418846 0.12618986522691675 0.013160794042050838
0.03102825012997666 0.12619341789213487 0.012957097962498665
0.031014376334926375 0.12618309608770137 0.010387104004621506
0.030998537946578558 0.12617651771801222 0.007835076190531254
0.030986330214409944 0.12617372758016054 0.007954155094921589
0.030980917697646045 0.1261754942888096 0.009270084090530872
0.030980718624132514 0.12617463407213497 0.009395724162459373
0.030985131616221316 0.12617343642839735 0.00812075100839138
0.03099144348945332 0.12616840819223424 0.006683818995952606
0.030999534677382395 0.12616886580370631 0.0064270999282598495
0.03100530474621275 0.12616949038844236 0.0069390214048326015
0.031006303864125943 0.12616826949326654 0.007088193204253912
0.03100250422327854 0.1261659742631225 0.006532690022140741
0.03099591497625402 0.12616428533395221 0.0055636633187532425
0.03098864547800878 0.1261612564587916 0.0047889892011880875
iteration: 8 | epoch: 429 |   loss: 0.126161  |   KL divergence: 0.030989  |  JS divergence: 0.007876
('==== Found maximium gradient [0.011761359, 0.011170173, 0.011004275] of gate '
 'e^[Y2 Z9], e^[Y9 Z2], e^[Y11 Z10] ====')
learning rate =  0.0022633201917736444
0.030984344337190856 0.12616189939574685 0.02017306722700596
0.03112509005774096 0.12629076307132306 0.041092172265052795
0.031004431341787438 0.1261141399091628 0.012813849374651909
0.030985786430443966 0.12614892468803343 0.021835293620824814
0.031003218366947936 0.12621571828466252 0.03233706206083298
0.030989028859768834 0.1261778726832834 0.026676882058382034
0.030973532646188018 0.12611670700971525 0.013155721127986908
0.030984463779290806 0.12610191153848568 0.00797588936984539
0.031012757514107557 0.12613090535465007 0.018559008836746216
0.03102636609410434 0.12614984112760416 0.02305457927286625
0.03101356367060117 0.12613673821921528 0.019999509677290916
0.030986474305158974 0.12610521167519356 0.011888118460774422
0.03096616833842908 0.12609111480568652 0.004882236011326313
iteration: 9 | epoch: 442 |   loss: 0.126091  |   KL divergence: 0.030966  |  JS divergence: 0.007868
('==== Found maximium gradient [0.010506982, 0.010351287, 0.010314387] of gate '
 'e^[Y2 Z3], e^[Y3 Z2], e^[Y0 Z9] ====')
learning rate =  0.002078244079235935
0.030960374440597602 0.12609904205863334 0.02092106081545353
0.031047471553287638 0.1261677906741138 0.03313811123371124
0.03097589391694826 0.12605143553900583 0.012501141056418419
0.030964003429069367 0.12606975651502741 0.017762837931513786
0.03097509081609413 0.12611006395347787 0.02574087679386139
0.030964594433653986 0.12608169110376793 0.020092682912945747
0.030955604861871502 0.1260430790378429 0.008811361156404018
0.03096541261224834 0.12604233866871895 0.009966005571186543
0.030979918512023297 0.1260649474093978 0.017258761450648308
0.030977276105838676 0.12606927498593654 0.017996756359934807
0.030958089980323095 0.12604835398027886 0.013116089627146721
0.0309405365364454 0.12603298489199327 0.00717589259147644
0.030935288900023387 0.12603318897520355 0.008267228491604328
0.03094089054909309 0.12604032326493428 0.011888856068253517
0.030950049172594328 0.12604309697693025 0.012581730261445045
0.030958224861326565 0.12603957255502235 0.010618865489959717
0.03096376964354372 0.12603160231323238 0.008363218978047371
0.030967198849183045 0.1260289281231697 0.008021165616810322
0.03096619777903893 0.1260303486358644 0.008583325892686844
0.03095851920219372 0.12602823595169232 0.008334435522556305
0.03094766383722924 0.12602673267022138 0.007341424003243446
0.030937560770630743 0.12602490890705365 0.006716120522469282
0.030931810042392593 0.1260229556140597 0.0068400464951992035
0.03093232230398512 0.12602322988883163 0.006966837681829929
0.03093747299858835 0.12602309850584306 0.00663758022710681
0.030944269556685135 0.12602015807310812 0.006039267405867577
0.03095051903385532 0.12601699059530183 0.005492138676345348
0.030954469861717043 0.1260163031858429 0.005065731704235077
0.030954496756700756 0.1260166615877971 0.004827794618904591
iteration: 10 | epoch: 471 |   loss: 0.126017  |   KL divergence: 0.030954  |  JS divergence: 0.007859
('==== Found maximium gradient [0.0057774223, 0.0046524433, 0.004522842] of '
 'gate e^[X8 Y0], e^[Y9 Z1], e^[Y1 Z9] ====')
learning rate =  0.0010031944753336717
0.03095025876721206 0.12601552107309763 0.009969265200197697
0.030939062875677357 0.1260369933421968 0.018188636749982834
0.030937221294504443 0.12600344224010399 0.007786459755152464
0.030953750132019904 0.1260078482424147 0.010826345533132553
0.030964570015430775 0.12601803060065 0.015078708529472351
0.030956522169258267 0.12600965782104737 0.0131926778703928
0.030941176086815847 0.1259972739342845 0.009189908392727375
0.030930427903817795 0.12599661718941924 0.008743541315197945
0.030925689050139364 0.12599938425974222 0.01132118795067072
0.030925115454615723 0.12600018320198897 0.011943580582737923
0.030926286369739202 0.12599424501227421 0.009739149361848831
0.030929989117788072 0.12598692658315902 0.006174473557621241
0.030936654122800014 0.1259848392093957 0.004725942388176918
iteration: 11 | epoch: 484 |   loss: 0.125985  |   KL divergence: 0.030937  |  JS divergence: 0.007855
('==== Found maximium gradient [0.004965069, 0.004916291, 0.00490125] of gate '
 'e^[X0 Y1], e^[X2 Y0], e^[X10 Y0] ====')
learning rate =  0.0009855223413130824
0.030943081510324048 0.12598588762881852 0.010825738310813904
0.030918500621003226 0.12600600919105287 0.019939357414841652
0.03091615535339539 0.1259658509593209 0.01079657580703497
0.03093251573573136 0.1259571853098211 0.011378628201782703
0.030945632496942384 0.12595972589435034 0.016055773943662643
0.0309383609067774 0.12594627348936485 0.014432870782911777
0.03092026730522178 0.12592541294472556 0.009390173479914665
0.030904768842420292 0.12591522922592052 0.00726316450163722
0.03089601689036139 0.12591549666044188 0.009923646226525307
0.030889769746672513 0.12590828703373655 0.011089043691754341
0.030885498177826237 0.12589313535080648 0.009593646042048931
0.030885722923387218 0.12588112763704667 0.007382427342236042
0.030888669807450295 0.1258707050173736 0.0075310226529836655
0.030892000372350188 0.12586431208278198 0.009454620070755482
0.03089147140564087 0.12585662574934606 0.010497056879103184
0.030885252738604985 0.12584368994276018 0.009951581247150898
0.03087596168855835 0.12583048095906907 0.00858217477798462
0.03086763361175477 0.12582425768112906 0.007761687971651554
0.030859437100707654 0.12581492269568115 0.007920446805655956
0.030853149150411308 0.12580588352389016 0.008096191100776196
0.030848722713176964 0.1257954543965494 0.007649645209312439
0.03084627221554656 0.12578447947092766 0.006951458752155304
0.030845429064053864 0.12577456366687273 0.006824841722846031
0.03084499957558024 0.12576637756692635 0.007375307846814394
0.030842516063954023 0.12575545612714265 0.007918037474155426
0.030838470245086576 0.12574623197355025 0.00801661517471075
0.03083264786515453 0.12573671271214873 0.0077887955121695995
0.030826079792093425 0.12572746594036252 0.007574440445750952
0.0308195613695432 0.12571780875873584 0.007480775471776724
0.03081415015166858 0.12570906460684828 0.0073323603719472885
0.030809546972046048 0.12569856695363374 0.007033914793282747
0.030806272206031684 0.1256886379950364 0.006751033011823893
0.030803418212463043 0.12567782573601316 0.006694234907627106
0.030800819687871055 0.125668637114566 0.00683162547647953
0.030797782350833122 0.12566085780283978 0.006974663119763136
0.030792913216881213 0.12564973524232323 0.0070374831557273865
0.030787557273863526 0.12563955952577796 0.007067820988595486
0.030782543821465454 0.12563165298535864 0.007094335276633501
0.030777440822537125 0.1256223687150345 0.007061841432005167
0.030772435029283007 0.12561117137110359 0.006931073032319546
0.03076841873051453 0.1256013652375907 0.006759643089026213
0.03076482716884571 0.12559165079969734 0.006640634499490261
0.030761715267333553 0.12558390167687497 0.006595969665795565
0.030758179560263936 0.12557595404300625 0.006586748640984297
0.030753124798387328 0.12556387410684203 0.006592786870896816
0.030748883952880345 0.12555626029404 0.006625594105571508
0.030743646701395046 0.12554481856944422 0.006675864569842815
0.030739414395042117 0.1255365226628103 0.006701129022985697
0.030735033814818572 0.12552639967525017 0.006673968397080898
0.03073138260525425 0.1255181826515526 0.006607942283153534
0.030727360354305733 0.12550825103856145 0.0065310378558933735
0.030723787269105508 0.12550068508451237 0.006456783041357994
0.030719738495434964 0.12549221323090512 0.0063934968784451485
0.030715074360580435 0.12548201435361178 0.006355829071253538
0.03071032985777869 0.12547152064481476 0.006351389456540346
0.030706274066628403 0.12546313829660252 0.006367776542901993
0.030702776169598107 0.12545612087729777 0.006384462118148804
0.030698840401712266 0.12544678846031862 0.006388002075254917
0.030694869276057704 0.1254372957842271 0.006370412651449442
0.03069092207826126 0.12542841871212027 0.0063261366449296474
0.03068695619985434 0.12542016188741031 0.00626119552180171
0.03068274640268502 0.12541136836860572 0.0061949193477630615
0.030678747292864995 0.12540331169823965 0.006146470084786415
0.03067515883354285 0.12539632659575445 0.0061215246096253395
0.03067082697217682 0.12538572483151253 0.006114549934864044
0.030667348860433936 0.12537808350891408 0.006117848213762045
0.03066390700753046 0.12537060458085064 0.006121670827269554
0.030659767547498558 0.12536074577754472 0.00611175037920475
0.030656345061312956 0.1253542234466194 0.006077759899199009
0.03065189735463158 0.12534391105788414 0.006024510599672794
0.03064808830511977 0.125336041922747 0.005967218894511461
0.030644713755850036 0.12532951107037402 0.005920225288718939
0.03064106142671502 0.12532143302900003 0.005889308638870716
0.03063727144233157 0.12531251589464937 0.0058739203959703445
0.030633630484853444 0.125304163246133 0.005869342479854822
0.03062995234031607 0.12529585032258603 0.005865439306944609
0.03062630837366026 0.12528791207639253 0.0058503043837845325
0.030622626625168348 0.12527998361911505 0.00581739004701376
0.030618914462694206 0.12527188944775028 0.005771677475422621
0.030616012843345794 0.12526681917382032 0.005723333451896906
0.03061223004672127 0.12525798605785893 0.0056825377978384495
0.030608696189397336 0.12524995093340038 0.005653787404298782
0.030605390431608974 0.1252427371322502 0.005636933725327253
0.0306016083459478 0.12523368690804496 0.005626588594168425
0.0305982886867319 0.12522656828319897 0.00561425881460309
0.03059524682677032 0.12522062083985488 0.0055922819301486015
0.030592303466218947 0.12521504352409074 0.005559127312153578
0.030588098231657403 0.12520433942111062 0.005519477184861898
0.030584965337217912 0.1251977224988653 0.005480160471051931
0.03058232822102895 0.12519294190176197 0.00544640701264143
0.030578965594319496 0.12518521551263787 0.005421542562544346
0.030575911681606394 0.12517873682333291 0.005403480026870966
0.03057283673259175 0.12517221031880382 0.0053878892213106155
0.03056970466660743 0.12516545136217697 0.005369088612496853
0.03056622722713355 0.12515724246931792 0.005344012286514044
0.03056304473754139 0.12515008593938548 0.005313052795827389
0.03055953341467468 0.12514151803996953 0.0052794888615608215
0.030557100031470982 0.12513718414873745 0.005247099790722132
0.030554232870978693 0.1251311227112536 0.005219290032982826
0.030551253204449104 0.1251246223773985 0.005196551326662302
0.030548313246344633 0.12511824897605026 0.005177459213882685
0.030545135268547075 0.1251108382288344 0.005158780608326197
0.03054244342932805 0.1251052484084131 0.0051375487819314
0.030539416567001366 0.12509823739805012 0.005112857092171907
0.030536752941426958 0.12509264195351066 0.005084873177111149
0.030533887694895366 0.12508625321059638 0.005055914167314768
0.030530942766405465 0.1250795528931529 0.005028834566473961
0.030528022764888724 0.12507290360064277 0.005005063489079475
0.03052504299358512 0.1250659232961835 0.004984303377568722
iteration: 12 | epoch: 593 |   loss: 0.125066  |   KL divergence: 0.030525  |  JS divergence: 0.007741
('==== Found maximium gradient [0.009477658, 0.008890087, 0.006281959] of gate '
 'e^[Y8 Z9], e^[Y9 Z8], e^[Y0 Z1] ====')
learning rate =  0.0016666239434254184
0.030522605705996686 0.1250610012608558 0.015263632871210575
0.030527709744871276 0.1250421157803835 0.01795860566198826
0.030506690727720245 0.12502642047027496 0.023368485271930695
0.0304805215514527 0.12496390346709599 0.015822643414139748
0.03048103307763791 0.12495306389421389 0.02083648554980755
0.03045896057451761 0.12490851550242987 0.01920263282954693
0.030428397478545 0.12485002762604562 0.015793533995747566
0.030411947516531 0.12480264071770386 0.01536655705422163
0.030407187012577913 0.12477174145961457 0.016457322984933853
0.030397053654903063 0.12473608363582792 0.016968831419944763
0.030373511993761 0.12468972033875012 0.015615724958479404
0.030341298078674035 0.12463993328595738 0.01334811095148325
0.030310014247478617 0.12459415396769799 0.01331725437194109
0.030285885857529088 0.1245548017905879 0.014589916914701462
0.030268599235854524 0.12451378380867895 0.014396497048437595
0.030255151956208884 0.1244648339863014 0.013511620461940765
0.03024491290668855 0.12441998401178259 0.013735741376876831
0.030232108096130347 0.12437594924258183 0.014182478189468384
0.030213546411649105 0.1243305848115105 0.013753239996731281
0.030190739514634017 0.12428441732646038 0.013224425725638866
0.03016749017312817 0.12424009782707976 0.013138571754097939
0.030145189400264 0.12419497487813098 0.012900842353701591
0.030124145038146862 0.12414930341421601 0.01246072631329298
0.03010346870249254 0.12410283154375866 0.012294172309339046
0.030082427487846022 0.12405673277957076 0.012286432087421417
0.030060874707229512 0.12401050845797407 0.012327289208769798
0.030041200507309226 0.12396911028825834 0.01257253997027874
0.030022742488304152 0.12392525052547713 0.012684705667197704
0.030006218436482875 0.12388176917204484 0.012373591773211956
0.029989488264705537 0.12383548716152541 0.012020730413496494
0.0299723857825485 0.12379374360958521 0.011817391030490398
0.02995235140236204 0.12375035377603186 0.011463080532848835
0.029931051393551483 0.12370703110857163 0.011107901111245155
0.02991211643830647 0.12366806738081552 0.011062867008149624
0.029895889164755947 0.12362770296027469 0.011041572317481041
0.029882702801824222 0.12358816938257747 0.010867012664675713
0.029870614345605714 0.12354948937109371 0.010757346637547016
0.029857767760629823 0.12351383096914335 0.010646788403391838
0.029841793460947202 0.12347619726189264 0.010354029014706612
0.029823872905231287 0.12343768272494013 0.009991548024117947
0.02980730037375822 0.12340354761026491 0.009618046693503857
0.02979338650330798 0.12337305308620843 0.009244593791663647
0.029780488762446322 0.12333905143763602 0.009020071476697922
0.029769840456389023 0.1233101632343456 0.008860770612955093
0.029759327223013447 0.12328101043129926 0.00859222561120987
0.029749462996517193 0.12325354031156643 0.008326406590640545
0.029739765056450713 0.12322437054211112 0.008093709126114845
0.02973219636540411 0.12320201921835694 0.007766673807054758
0.02972367878263695 0.12317708235817998 0.007391352206468582
0.029714953652359516 0.12315525008787624 0.00700821029022336
0.029705741732618585 0.12313436221397432 0.006621782202273607
0.029697647514288043 0.12311591372900432 0.006334367673844099
0.029691173327321886 0.12309710041591763 0.006069484166800976
0.02968689195383099 0.1230797203184623 0.00572291761636734
0.029683992790815527 0.12306479871110344 0.005421315785497427
0.029680852854153027 0.12305141001221455 0.005160761997103691
0.029676912115388483 0.12303958015921007 0.004824359435588121
iteration: 13 | epoch: 650 |   loss: 0.123040  |   KL divergence: 0.029677  |  JS divergence: 0.007494
('==== Found maximium gradient [0.0071877996, 0.006858738, 0.0063637285] of '
 'gate e^[Y9 Z0], e^[Y0 Z9], e^[Y10 Z0] ====')
learning rate =  0.00136236946086034
0.029672242047305345 0.12302708880781794 0.01261113304644823
0.029749689135644033 0.12311570113586445 0.03789108991622925
0.029664124979499978 0.12300597292750051 0.0176000464707613
0.02964699222082393 0.12298775238577306 0.01929975487291813
0.029658039616161837 0.12299739881452158 0.02682868391275406
0.029654990747742103 0.12297019125912229 0.02470354363322258
0.029641597925046097 0.12292338151321272 0.0175834558904171
0.029632062038722803 0.12288939296331908 0.012193049304187298
0.02963019440915342 0.12287619335305604 0.014870469458401203
0.029629400811777243 0.12287247703432004 0.018883896991610527
0.0296212936998305 0.1228587361786556 0.019232498481869698
0.029605464928345496 0.12282900876769572 0.015756625682115555
0.0295907667674581 0.12280248102685269 0.010840286500751972
0.029581345486143235 0.12278337626198257 0.009716110303997993
0.029577718094976745 0.12277588269375525 0.013156089000403881
0.02957346750230888 0.12276479222401779 0.015560108236968517
0.029566330300285684 0.12274641936815481 0.014892088249325752
0.029558517372644907 0.12272695615514677 0.011801433749496937
0.029550666838290336 0.12270394052782214 0.008899996988475323
0.029545572068017174 0.12268753270405382 0.009214118123054504
0.029541960353727217 0.12267647527213991 0.011240647174417973
0.029536596859427916 0.1226634354140274 0.01215635146945715
0.029528394947708148 0.12264758731242532 0.0113525390625
0.029517705689796867 0.12263000674846358 0.009618323296308517
0.02950555206920882 0.12261104453777524 0.008404701948165894
0.02949412473432243 0.12259435407546165 0.008666561916470528
0.02948431730763289 0.12257978467190057 0.009593377821147442
0.029476443696025954 0.1225674161759669 0.009929152205586433
0.029468874357648004 0.12255054240656568 0.009179131127893925
0.029462834666987715 0.12253375055653483 0.007826081477105618
0.029458398024538847 0.12251824004087399 0.007187956012785435
0.029454585246497675 0.12250443028559055 0.007933635264635086
0.029449127004312 0.12248953545272784 0.0088608143851161
0.02944221912102838 0.12247810004645789 0.008823171257972717
0.029432188997824134 0.12246167213839469 0.007805436849594116
0.02942203407313554 0.12244740243973243 0.006748240906745195
0.02941261728672745 0.12243385330975086 0.00664559006690979
0.029404796347498777 0.12242120027995872 0.0071625118143856525
0.02939849926378952 0.12240781962360411 0.0073943291790783405
0.02939393346086583 0.12239562143496847 0.0071089304983615875
0.02938970868748337 0.12238200149717604 0.006695290561765432
0.029385291364586057 0.12236803823169583 0.0065831383690238
0.02938078748000715 0.1223564003715838 0.006764071993529797
0.029375085969177428 0.12234380638340435 0.006876471918076277
0.029368339739169795 0.12233085486073896 0.006650263909250498
0.0293616247176057 0.1223199555567006 0.006167114246636629
0.029354089102692583 0.12230473313436341 0.005831182934343815
0.029347990774031045 0.12229275428697878 0.0059102741070091724
0.029342667052756385 0.12228155317771185 0.006136568263173103
0.029338638184284775 0.12227389615629199 0.0061129298992455006
0.029333210231090357 0.12225915740809512 0.005822771228849888
0.029328700745719985 0.12224736056122512 0.00558135099709034
0.029324589870369906 0.12223721852670484 0.005583824124187231
0.02932008548141596 0.12222595794711172 0.005669224075973034
0.02931627348773232 0.12221839366615316 0.005620833020657301
0.029310886978576672 0.12220586450791025 0.005430295132100582
0.029305721029767175 0.1221956088241723 0.005232653580605984
0.029300225203941474 0.12218439210004177 0.005128862336277962
0.029295380984021374 0.12217523415316382 0.005088560748845339
0.02929137877231755 0.12216830270284129 0.005017678719013929
0.029287015704322128 0.12215806441597221 0.004896294325590134
iteration: 14 | epoch: 711 |   loss: 0.122158  |   KL divergence: 0.029287  |  JS divergence: 0.007389
('==== Found maximium gradient [0.008605888, 0.008152423, 0.0067817275] of '
 'gate e^[Y1 Z10], e^[Y10 Z1], e^[Y2 Z0] ====')
learning rate =  0.0015769808603985835
0.029284001206732333 0.12215137339401057 0.014480936340987682
0.029315281713587008 0.12221387735741514 0.03395327925682068
0.02927366608070271 0.12213412050049112 0.02081691287457943
0.029275643684303652 0.12213175950382238 0.02569405548274517
0.029284495563078935 0.12212378985708705 0.023415623232722282
0.02927919561756976 0.12209341307390101 0.021095672622323036
0.029268239851226403 0.12206785844268604 0.021209128201007843
0.029248675228569703 0.12204073317422837 0.017587212845683098
0.02922974046606577 0.12202297854637138 0.013828071765601635
0.029217555241792658 0.12201712417187513 0.015535701997578144
0.029207961623590534 0.12200670284107239 0.017952239140868187
0.02919839088940803 0.12198479621553172 0.01634165085852146
0.029190731495401228 0.12195632965590002 0.011867702007293701
0.02918918377796496 0.12193752788821038 0.009743071161210537
0.029190233969826215 0.12192571684227342 0.012242984026670456
0.029189114850622214 0.12191974730432636 0.014173016883432865
0.029179998691134544 0.12190291677197147 0.013372758403420448
0.029166998954825586 0.12188401676243951 0.010973560623824596
0.0291541123871063 0.12186628353953799 0.009272794239223003
0.02914443756182479 0.12185322056724103 0.00934602227061987
0.02913733902635108 0.1218411681516586 0.009823258966207504
0.02913165986894177 0.12182942462051781 0.009745516814291477
0.02912584255337055 0.12181627572439137 0.009224528446793556
0.029119769224484816 0.12180420810464204 0.008525379933416843
0.02911214646575819 0.12178770386961346 0.007716756779700518
0.02910622354352081 0.12177720910488776 0.007066058926284313
0.029101162083059507 0.12176643537169049 0.007032166700810194
0.029097634329731052 0.1217567198893973 0.007465019356459379
0.0290945242551384 0.12174456478132702 0.0076520987786352634
0.029091948618562687 0.12173418116698968 0.0072298175655305386
0.02908805116787249 0.12172262802356112 0.006460303440690041
0.0290825612834828 0.12171177888346066 0.0059661539271473885
0.029076513625199002 0.1217057621464922 0.006000971421599388
0.029068195831858937 0.12169442120748818 0.00607688445597887
0.02906047670141965 0.12168430601760476 0.005708934739232063
0.029054389684130485 0.12167420616370352 0.005071148741990328
0.02905130897533115 0.12166679358729977 0.004890209995210171
iteration: 15 | epoch: 748 |   loss: 0.121667  |   KL divergence: 0.029051  |  JS divergence: 0.007330
('==== Found maximium gradient [0.004872175, 0.004773814, 0.004721919] of gate '
 'e^[Y9 Z10], e^[Y10 Z9], e^[X8 Y1] ====')
learning rate =  0.0009579415914103825
0.029049721651275368 0.1216577069639994 0.009860904887318611
0.029091059151736837 0.12169264529361898 0.029131945222616196
0.0290519989520504 0.12163788739465244 0.013281927444040775
0.029037339790078786 0.12162899735304702 0.014477310702204704
0.02903150426050822 0.12163315776777073 0.021076513454318047
0.0290218438611482 0.1216153455676178 0.019246289506554604
0.029012843578070838 0.121586812971038 0.012405827641487122
0.029011644756735313 0.12156990704077378 0.008323939517140388
0.02901523762940185 0.12156394711139186 0.012764806859195232
0.029015575537508942 0.12155965658912057 0.015970535576343536
0.029006696798356844 0.12154260404534702 0.014786620624363422
0.02899360972899733 0.12152442814093599 0.010516609996557236
0.02898008367934291 0.1215058192701208 0.007200302556157112
0.02897074056985322 0.12149656283590649 0.009234115481376648
0.028963942588553844 0.12148938412099688 0.012142439372837543
0.028957135365971477 0.12147638322880788 0.012692890129983425
0.02895055088856488 0.1214595460606163 0.010873144492506981
0.028945472404715424 0.12144397862772026 0.008202358148992062
0.02894145111156616 0.1214291644097608 0.007298083044588566
0.028938242678980475 0.12141831260026784 0.00878870952874422
0.02893360092979312 0.12140742117901662 0.010089495219290257
0.02892652996898811 0.12139472434137162 0.009785059839487076
0.028916893139675385 0.12137766940435642 0.008192282170057297
0.028907238588888454 0.12136236323368617 0.006903176195919514
0.028898729691087352 0.12135013236432504 0.007347948849201202
0.028890971929025233 0.1213381067842318 0.008507538586854935
0.02888362390591081 0.12132465954495779 0.00889501627534628
0.02887697678942878 0.1213105803966179 0.008217747323215008
0.028871656954752904 0.12129810521559246 0.007161989342421293
0.0288671023866526 0.12128575679045146 0.006798175163567066
0.028862344751033893 0.12127207220305819 0.007312910631299019
0.02885676221623537 0.12125782679867696 0.007788816001266241
0.028850036541184156 0.12124415214625447 0.0075731538236141205
0.028842350762008865 0.12123191918398245 0.006840325891971588
0.02883360644455072 0.12121834869404834 0.00638627540320158
0.02882496523138397 0.12120478846653526 0.006673621945083141
0.028816850502990366 0.12119016071276903 0.00713816424831748
0.028809675278710388 0.12117487612034482 0.007158865220844746
0.028805129874100048 0.12116628724734109 0.006779531482607126
0.02879971948288281 0.12115199376796054 0.00646543875336647
0.02879461219737233 0.12113947205263163 0.006483079865574837
0.028788385260146043 0.1211249376294401 0.006620500702410936
0.028782107843170805 0.1211133789429598 0.006565923802554607
0.028775049421107077 0.12110100505635303 0.006290850229561329
0.02876719067124759 0.12108631450601401 0.006066348869353533
0.028760131819399876 0.12107456264908577 0.006124368868768215
0.028753225295126413 0.12106222703315211 0.006318047177046537
0.02874631252277469 0.12104818880763366 0.0063507636077702045
0.02874011517384025 0.12103520699151119 0.006174994632601738
0.028734716847467416 0.12102387227526276 0.00599270686507225
0.028728609653374926 0.12100888175544028 0.005952772218734026
0.02872324807559614 0.12099750557142941 0.005976907443255186
0.028717806434784776 0.12098738248127794 0.005930163897573948
0.028711343677106052 0.12097485579386554 0.00580880232155323
0.02870483600313223 0.12096329052256802 0.005716600921005011
0.02869814748253107 0.12095102245764601 0.0057172589004039764
0.028691969062704006 0.12093988992875178 0.0057489462196826935
0.028686180010187846 0.12092889069395549 0.005713809747248888
0.028680048418988992 0.12091509302530241 0.005614462308585644
0.028674708924048095 0.12090368761674179 0.0055370270274579525
0.028669848833288505 0.12089406461272566 0.005514237098395824
0.028664208848332498 0.12088165221467785 0.005488267634063959
0.02865914527866923 0.12087235412385874 0.005411064717918634
0.028653204146731594 0.12086017528617465 0.0053163436241447926
0.028647580945137495 0.12084975440179652 0.005268682260066271
0.028641781239184386 0.12083863708676351 0.005268390290439129
0.028635796822895056 0.12082635968827236 0.0052581666968762875
0.028630632169490373 0.12081663477938044 0.0052076680585742
0.02862547848726686 0.12080593756814102 0.005139881279319525
0.028620713725803937 0.12079595388021135 0.005080733448266983
0.028615539261784666 0.1207838856581364 0.005028671585023403
0.02861078698538061 0.12077383905159589 0.004971277434378862
iteration: 16 | epoch: 820 |   loss: 0.120774  |   KL divergence: 0.028611  |  JS divergence: 0.007223
('==== Found maximium gradient [0.0053906017, 0.005298943, 0.0037283474] of '
 'gate e^[Y10 Z2], e^[Y2 Z10], e^[Y3 Z0] ====')
learning rate =  0.000973227953463134
0.028605919979438954 0.12076413220947589 0.009756699204444885
0.028588562449109796 0.12075564476020559 0.015312240459024906
0.02860124459879932 0.12074171824746098 0.015299324877560139
0.028594530946404437 0.12072808395601684 0.015062645077705383
0.028579828358334856 0.12071024056790731 0.010908568277955055
0.028573302990052965 0.12069780579993414 0.012651391327381134
0.028568484425301924 0.120680887787253 0.01084452960640192
0.028566081505603295 0.12066677582646038 0.00953559298068285
0.028560405786678497 0.12065337164667612 0.010113091208040714
0.028551341259893944 0.12063977183814063 0.009580785408616066
0.028541565195575495 0.12062664660963612 0.008899684064090252
0.028532781372565146 0.12061186262928629 0.009109114296734333
0.028527293521735046 0.12059948442986447 0.00872152391821146
0.028525280310106715 0.12058738581432815 0.007891680113971233
0.0285243346684758 0.12057359299665464 0.0078080883249640465
0.02852141970481737 0.12055923545460481 0.007768785580992699
0.028515653156457273 0.12054604284042833 0.0070253461599349976
0.028508410081333625 0.1205356646959111 0.0066475290805101395
0.028499858544047987 0.1205219255483301 0.007093674037605524
0.0284917399053599 0.12050780885350332 0.00702520040795207
0.028485403088301747 0.12049626485831227 0.00614781491458416
0.02848078654340967 0.12048501302878076 0.005757838953286409
0.028477075845114646 0.1204726907255488 0.006048975046724081
0.028474144221812138 0.12046347430262926 0.005917183589190245
0.028469653552588427 0.1204499333629705 0.005482259672135115
0.028465901782682133 0.12044045700972777 0.0056619481183588505
0.028461697701603596 0.12042948801643726 0.005982011556625366
0.028456785707518892 0.12041763335712709 0.005593194626271725
0.028451781887509936 0.12040851659002366 0.004884025081992149
iteration: 17 | epoch: 849 |   loss: 0.120409  |   KL divergence: 0.028452  |  JS divergence: 0.007179
('==== Found maximium gradient [0.0035139127, 0.0034991005, 0.0033152583] of '
 'gate e^[Y8 Z2], e^[X1 Y9], e^[X2 Y3] ====')
learning rate =  0.0006887885518649194
0.028445741691901873 0.12039700935979128 0.007600695826113224
0.028440573453788236 0.12039932748657721 0.01739160344004631
0.02844249318958609 0.12037776650710347 0.008746108040213585
0.02844732379775857 0.120370221455953 0.012157667428255081
0.028446937368853686 0.12036849045407734 0.013023512437939644
0.028438819998745327 0.12035776626356197 0.010863976553082466
0.02842798712745076 0.12034459622068802 0.009360095486044884
0.028419716530834294 0.12033441354919312 0.00932714156806469
0.028415663681252614 0.12032705412236361 0.009362048469483852
0.028414451346504777 0.12032085752384959 0.008753488771617413
0.02841256814838513 0.12030806589849244 0.0077446396462619305
0.028411654474921944 0.12030188640219093 0.00698821758851409
0.02840722167403846 0.1202885744527992 0.006746256723999977
0.028402964250490364 0.12028390312645218 0.006753445602953434
0.02839621435108945 0.12027383201951104 0.0066137597896158695
0.02838943286557489 0.12026362901794682 0.006465785205364227
0.028385051560428066 0.12025807989802259 0.006578763481229544
0.028381849525019726 0.12024902840370315 0.006626560818403959
0.028380024098580217 0.12023843159474851 0.0062859742902219296
0.028379197902095043 0.12022924776414991 0.0059269266203045845
0.028378329755165733 0.12022276750611285 0.006077466532588005
0.028374190495144055 0.12020997274539165 0.006390451919287443
0.028369383774919144 0.1202026231969257 0.006194951944053173
0.028363342902829207 0.12019540870929896 0.005543208681046963
0.02835653832573785 0.1201852165884845 0.005151219200342894
0.02835100026031724 0.12017599344850824 0.005342818330973387
0.02834778018203045 0.12017004993759343 0.005555904470384121
0.028344996008404677 0.12016036074214097 0.005374722648411989
0.028342700272938046 0.12015004653435024 0.004981377627700567
iteration: 18 | epoch: 878 |   loss: 0.120150  |   KL divergence: 0.028343  |  JS divergence: 0.007148
('==== Found maximium gradient [0.0037830714, 0.003004532, 0.0028426822] of '
 'gate e^[X8 Y3], e^[Y10 Z11], e^[Y8 Z9] ====')
learning rate =  0.0006472473527098945
0.028340699601353613 0.12014213614448754 0.007363400887697935
0.028319607900955904 0.12014667639223763 0.01854025200009346
0.028327883854989917 0.12011942810640727 0.010865889489650726
0.02833441914301995 0.12010890674265484 0.010936399921774864
0.028331781146237696 0.12010005988268403 0.013838887214660645
0.028322202574953593 0.12008958834035019 0.013426144607365131
0.02831014300436213 0.12007227582232664 0.01021355576813221
0.028299505969162767 0.12005675524662184 0.007844104431569576
0.028291925218306223 0.1200501269466983 0.008911817334592342
0.028284294040340115 0.12003971664472102 0.010342278517782688
0.028277322457565944 0.12002710943141458 0.010043095797300339
0.02827182844468726 0.12001173578189372 0.00822362955659628
0.028270773397072763 0.12000316075544264 0.00645574601367116
0.028270567336269786 0.11999066027654996 0.0068106395192444324
0.028270381197293155 0.11998100313631814 0.008220165967941284
0.028267223259417135 0.11997145722344403 0.008653349243104458
0.02825941763777761 0.11995718068413776 0.007863660342991352
0.028250429005505267 0.11994704166489563 0.006749297026544809
0.02824152555997698 0.11993740078370715 0.006273974664509296
0.028233544851066158 0.11992438641331489 0.006491430569440126
0.028229259729180917 0.1199173614112106 0.006859580520540476
0.028225064635641228 0.11990434607879737 0.006954371929168701
0.028221812154334686 0.11989375498286899 0.006569633260369301
0.028218250321895816 0.11988346156566804 0.005930366925895214
0.02821468221589009 0.11987471287685075 0.005749339237809181
0.02821061282204429 0.11986390459371034 0.006234900560230017
0.028206702493963124 0.11985328991266571 0.006613623350858688
0.028203569132340546 0.11984696353469004 0.006353319622576237
0.028198010451560725 0.11983380551307407 0.005675487220287323
0.02819267207683152 0.1198256612734438 0.005199190694838762
0.02818594122253692 0.11981425618779692 0.0052919588051736355
0.02817947026111757 0.11980298173334675 0.0056177955120801926
0.02817477358673784 0.11979466729629265 0.005641740746796131
0.02817103304679616 0.11978468343131721 0.005291092675179243
0.028168622274707726 0.11977654930294031 0.004993771202862263
iteration: 19 | epoch: 913 |   loss: 0.119777  |   KL divergence: 0.028169  |  JS divergence: 0.007104
('==== Found maximium gradient [0.004075382, 0.0036731027, 0.002973271] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[X2 Y3] ====')
learning rate =  0.0007205623887542303
0.02816503474718982 0.11976374648296963 0.008030708879232407
0.02815345583030856 0.11976747224087297 0.018785975873470306
0.028147586201184998 0.11973986170746914 0.012418750673532486
0.028155114176183556 0.11973252577380403 0.014927110634744167
0.028150943655037404 0.11971890370736693 0.014164776541292667
0.02813814075683612 0.11970120686426451 0.012234280817210674
0.028122144121737663 0.1196823106008425 0.00995875895023346
0.02810989514107432 0.1196680722120648 0.010139696300029755
0.028102996940096478 0.11965653736809051 0.011593501083552837
0.028098689455073142 0.1196424598537539 0.01107242051512003
0.028094869219760316 0.11962341788712351 0.008921833708882332
0.028092138670182412 0.11960704302169328 0.00818578153848648
0.028088462999162796 0.1195924078051645 0.009357779286801815
0.02808167127863961 0.11957682002601097 0.009766904637217522
0.028072220184083875 0.11956222604442564 0.008847766555845737
0.02805993823533566 0.11954317826159679 0.008054206147789955
0.028049072643821452 0.11953097438446782 0.008366466499865055
0.028037494920123918 0.1195099645610331 0.008754912763834
0.028030083703812155 0.11949531055427111 0.008445304818451405
0.02802514388464216 0.11947947175144889 0.007885749451816082
0.028021914688076903 0.11946410902683349 0.007680490612983704
0.028017864755223096 0.11944646492948056 0.0077850050292909145
0.028011870279053698 0.11942847181771418 0.00783751904964447
0.02800433061570467 0.1194145539096685 0.00770429614931345
0.02799384135474963 0.11939729983817639 0.007516070734709501
0.027982389877490854 0.11938001249153082 0.007451673503965139
0.027971344161769843 0.11936194721894718 0.0075556086376309395
0.027962651766033415 0.11934621184111807 0.007674886845052242
0.02795518507028459 0.11932695011606097 0.007611806038767099
0.027950200898924867 0.11931220697922719 0.007389187812805176
0.02794412144105815 0.11929192493039531 0.007231392432004213
0.02793827042026875 0.11927619631544843 0.007258888334035873
0.027930097916589063 0.11925687360513768 0.00736622279509902
0.027921674403555703 0.11924227545780523 0.007394846528768539
0.027911922197475684 0.11922517693608731 0.00729985348880291
0.027901655371819257 0.11920526172802741 0.00721223559230566
0.027892992495880255 0.11918867214887809 0.0072663649916648865
0.027884715391098765 0.11916987842471427 0.007365234196186066
0.027877245667826747 0.11915206645692217 0.007334622088819742
0.027870723359590767 0.11913768967953638 0.007218072656542063
0.027862599208706026 0.11911747611107944 0.007198663894087076
0.027854309512538446 0.11909812976323604 0.007278846111148596
0.02784639695800755 0.1190820113455952 0.007300117518752813
0.027837975586946888 0.11906495801637884 0.007236474193632603
0.02782932516845918 0.11904750488047343 0.007191235199570656
0.027820586581804245 0.11902970416823445 0.007205261383205652
0.027811428972303102 0.11900948657000356 0.0072377510368824005
0.027802712666792267 0.11898975717459538 0.007248103152960539
0.027795572857074194 0.11897512568426938 0.007237221579998732
0.027787228914888648 0.11895467262868888 0.007238214369863272
0.027779883118895496 0.11893879099925198 0.007261505350470543
0.027771895672659537 0.11892161496753698 0.007268440909683704
0.027763074575322236 0.11890262125605677 0.007236693985760212
0.027754356563294925 0.11888506953783151 0.007206734735518694
0.027745468623449683 0.11886647938260207 0.00720467371866107
0.027736530981148082 0.1188461642563561 0.00720118498429656
0.027728709199716664 0.118828716644506 0.00718503026291728
0.02772160441970839 0.11881322191761898 0.007178931962698698
0.027713420336953426 0.11879344319971576 0.007187156938016415
0.027705331507198058 0.1187753400214934 0.0071921879425644875
0.027697506028675857 0.11875976789937578 0.007186901289969683
0.027688567165653443 0.1187401547909702 0.007175031118094921
0.027680398397790934 0.11872334957779927 0.007157903630286455
0.027671886349591036 0.11870407882910912 0.007139242719858885
0.02766375525550186 0.11868537956719476 0.007115822285413742
0.027656860336743045 0.1186712045146799 0.0070895967073738575
0.027648721716392453 0.11865164760227699 0.007070048246532679
0.027641048510312096 0.11863433233879836 0.007054050453007221
0.027634289286697887 0.11862142089930984 0.007031782530248165
0.027625308171551392 0.11859976158942995 0.007007500622421503
0.027617442364192266 0.11858306673658184 0.006987564731389284
0.027609619886986105 0.11856627842246513 0.00696695689111948
0.027601865143491104 0.11854893607603559 0.0069422596134245396
0.027594007360806548 0.11853012643120754 0.006914064288139343
0.02758778895176281 0.11851753146199441 0.006881339475512505
0.027580285804109678 0.11849961336652523 0.0068449825048446655
0.027572857134623038 0.11848274582908494 0.006804309319704771
0.02756494502694986 0.11846470727126382 0.006761214695870876
0.027557345934377177 0.11844821407908754 0.006721376907080412
0.027549760660500362 0.11843110082048787 0.006685478612780571
0.02754328331035954 0.11841749428370799 0.006646688561886549
0.027536319271570513 0.11840095171411626 0.006605126895010471
0.027529661687691356 0.11838554116752963 0.006563314236700535
0.027522695770033766 0.11836932983812486 0.006517914589494467
0.02751629618256517 0.11835606942200617 0.006467191968113184
0.027509493527052623 0.11834125243098238 0.006413786206394434
0.02750241329952314 0.11832487609620952 0.006359481252729893
0.027495527480110235 0.11830864073797981 0.006305740214884281
0.027489776045017712 0.11829657013326875 0.0062518129125237465
0.02748307538236944 0.11828022910732072 0.006196875590831041
0.027476954076474505 0.11826632089408769 0.006139563396573067
0.027470313752486177 0.1182502982667187 0.006078261416405439
0.02746447641024439 0.11823764483978953 0.0060137491673231125
0.027458396342589692 0.11822382446845056 0.005949362646788359
0.027452261102364626 0.11820948901118936 0.005886160768568516
0.027446376403546625 0.11819584008226361 0.005823096260428429
0.02744062560714431 0.11818237751027504 0.00575876422226429
0.0274353270071262 0.11817050141043586 0.005692389793694019
0.027429891957389853 0.1181579045537712 0.005622697528451681
0.027424699511799298 0.11814629617004958 0.005549661349505186
0.02741850050259903 0.11813036889306898 0.005475134588778019
0.02741387268704577 0.11812084855233627 0.005399349145591259
0.027409061099836686 0.11811021080830232 0.005324803292751312
0.02740445129450944 0.11810003435603897 0.005251558497548103
0.0273990921124049 0.118086397861997 0.005179184954613447
0.027393813254718062 0.11807293618842407 0.005105617456138134
0.027389277533340643 0.11806251880907559 0.005029161926358938
0.02738480281930336 0.11805222303896866 0.004950119648128748
iteration: 20 | epoch: 1021 |   loss: 0.118052  |   KL divergence: 0.027385  |  JS divergence: 0.006901
('==== Found maximium gradient [0.006764466, 0.005560681, 0.0047179996] of '
 'gate e^[Y8 Z1], e^[Y1 Z8], e^[X3 Y9] ====')
learning rate =  0.0011485567599204799
0.027380339153965382 0.11804171827171668 0.01107502169907093
0.027353687192645228 0.11802552101357124 0.017061609774827957
0.027376941765278814 0.11801925496159886 0.02744373492896557
0.02734063752853939 0.11796723728562505 0.015843629837036133
0.027310553283326714 0.11793841505471143 0.016008013859391212
0.027300291076041067 0.11792318995076503 0.021110203117132187
0.02729302147894782 0.11788767053944883 0.015099436976015568
0.027291457944495993 0.11785472072177741 0.010245227254927158
0.02729242454099736 0.11783694046501253 0.015083358623087406
0.027284411004320053 0.11781831437166293 0.015552274882793427
0.027266470412210697 0.11778739051057853 0.01120796985924244
0.027251178238755364 0.11776673098830859 0.00947396457195282
0.027241495800735586 0.1177509552032786 0.011630558408796787
0.027234184085823662 0.11773009157886759 0.01157836802303791
0.027227694135180402 0.1177060531681139 0.009484786540269852
0.02722239766417632 0.11768794377343633 0.0087438328191638
0.02721572077036073 0.11767223316167798 0.009514099918305874
0.027207159160163495 0.11765681103029857 0.009608077816665173
0.027198310835769925 0.11764075182641165 0.008766408078372478
0.02719100203108082 0.11762281664801291 0.007769922260195017
0.027186910856383924 0.11760673218416129 0.007079110946506262
0.027185486394190335 0.1175947533182635 0.0069885547272861
0.02718311355823362 0.11758071554617329 0.007131129037588835
0.027178740858604607 0.11756822525734775 0.006690088659524918
0.027171055110696122 0.1175538597335675 0.005820948630571365
0.0271616377019238 0.11753934630371854 0.005763648543506861
0.02715374277104575 0.1175301534313204 0.006439816672354937
0.027146684231885616 0.11751627381208604 0.006468180567026138
0.027144429676334375 0.11751179086408656 0.005588391330093145
0.02714142529634116 0.1174963578518296 0.004944273736327887
iteration: 21 | epoch: 1051 |   loss: 0.117496  |   KL divergence: 0.027141  |  JS divergence: 0.006835
('==== Found maximium gradient [0.0044913106, 0.004027754, 0.003812629] of '
 'gate e^[Y10 Z2], e^[Y2 Z0], e^[Y0 Z2] ====')
learning rate =  0.0008240616073615945
0.027139554067720395 0.11748538803587272 0.008859552443027496
0.027121232073512053 0.1175147214804373 0.02752123586833477
0.02713823604294599 0.11746610442121551 0.011480137705802917
0.027155515867782025 0.11746183730606562 0.018595034256577492
0.02714398450150625 0.11745257714784277 0.019097883254289627
0.027117992171299142 0.11743296422586513 0.01432377751916647
0.027096520742036598 0.11741609291088145 0.01245107688009739
0.027087497737205 0.11740245356602437 0.013318419456481934
0.027090190257882767 0.11739550990681875 0.01260449644178152
0.027095585742067843 0.11738129274722305 0.011033831164240837
0.027099948567142196 0.11736825453902967 0.01067452784627676
0.027099653065652398 0.11735844045925212 0.010928086005151272
0.027091897920235045 0.11734365961178649 0.009980078786611557
0.02708201942308336 0.11733573663850166 0.008323324844241142
0.02707136864693352 0.11732455303913039 0.008284343406558037
0.027063855084662664 0.11731571245004216 0.00968173798173666
0.027059376522951713 0.11730493693702099 0.010032886639237404
0.027057197582499994 0.11729137253380062 0.008459522388875484
0.027057611049215155 0.11728184644114474 0.0063851079903542995
0.027057544697618452 0.11727084075232883 0.006348882801830769
0.027055763338796043 0.11726150671738657 0.007629252504557371
0.02705101916946303 0.11725359000474445 0.007967165671288967
0.02704228069417964 0.1172408247014276 0.006962588056921959
0.02703361213279542 0.11723240506278053 0.005729720927774906
0.02702592777922734 0.11722214888024976 0.005844296887516975
0.027021086774661352 0.11721115489155352 0.006718723103404045
0.027019404041191228 0.11720047525222033 0.006868442986160517
0.027020449024489364 0.11719398969638466 0.006194178946316242
0.0270203957775746 0.11718420021117781 0.0055693075992167
0.02701801846942041 0.11717364293688208 0.0055535021238029
0.027012927866677007 0.11716360116306414 0.005699115805327892
0.02700535781227314 0.1171521201705332 0.005513059441000223
0.02699838174515516 0.11714563682037482 0.005155906081199646
0.026991296102393827 0.11713448253773684 0.005077764391899109
0.026987560311542806 0.11712941234794567 0.005168542731553316
0.026984232118187422 0.11711770008013174 0.0050584543496370316
0.02698264451627836 0.11710789611995304 0.004905433859676123
iteration: 22 | epoch: 1088 |   loss: 0.117108  |   KL divergence: 0.026983  |  JS divergence: 0.006791
('==== Found maximium gradient [0.0038416446, 0.0034449345, 0.0031151772] of '
 'gate e^[Y10 Z8], e^[Y2 Z4], RY[9] ====')
learning rate =  0.0006959897978044423
0.026981980736877458 0.11710136868683542 0.007797411642968655
0.026974984446011797 0.11711599138419947 0.02368782088160515
0.02697873629626353 0.11708108453467321 0.012179531157016754
0.02698812233135279 0.11707455890105051 0.01714813895523548
0.02698445311358738 0.11706909489478111 0.017694951966404915
0.02696625912005947 0.11704899649502862 0.01260455884039402
0.026948735467177555 0.1170360419238894 0.009692555293440819
0.02693817593516836 0.1170279625777913 0.012357902713119984
0.026933616365889507 0.11701698502321899 0.013340473175048828
0.026932631338061223 0.11700421275515184 0.01168804056942463
0.026933296880427747 0.11699460889779839 0.009630097076296806
0.026931993593505302 0.11698117457738313 0.00922552589327097
0.02692933646869014 0.11697191654997352 0.009363207034766674
0.026923931560938863 0.11696120919453129 0.00892995111644268
0.026917606751549573 0.11695274070226695 0.0084924241527915
0.02691066255770472 0.11694353506711924 0.008202238008379936
0.026903993109518465 0.11693351362860703 0.007772356737405062
0.026898295230598453 0.11692221763535177 0.007414480205625296
0.026894631562234404 0.11691376498043982 0.007259698584675789
0.026890896962997374 0.11690187691070138 0.00700334832072258
0.026887535907183874 0.11689123589767174 0.006854915991425514
0.026884474087615552 0.11688318430460251 0.007045680657029152
0.026880592378506825 0.11687391035934512 0.00685665849596262
0.026875900251399885 0.11686321321956782 0.005912501830607653
0.026871197965099108 0.11685330981537842 0.005184229929000139
0.026866717742149958 0.11684473573576827 0.005567334126681089
0.02686184174360043 0.11683533494080794 0.006041356362402439
0.026856936475991876 0.11682625843355804 0.005726433824747801
0.026852719931317978 0.11681860546637213 0.005066603887826204
0.026849436399521073 0.1168117021017521 0.004980089608579874
iteration: 23 | epoch: 1118 |   loss: 0.116812  |   KL divergence: 0.026849  |  JS divergence: 0.006756
('==== Found maximium gradient [0.0037508649, 0.003563974, 0.0030250642] of '
 'gate e^[X3 Y8], e^[Y8 Z3], e^[Y2 Z9] ====')
learning rate =  0.0006920685178337748
0.026845634432474248 0.11679964553304469 0.008054121397435665
0.02686000858376974 0.11682230220931572 0.026242172345519066
0.026839736655630463 0.11677412560466906 0.010943382978439331
0.02684584093591746 0.11677699932117565 0.01951822079718113
0.026843772973516367 0.11676867909259853 0.018749235197901726
0.02683417535325421 0.11674756239462596 0.012955274432897568
0.02682622524166798 0.11673414487986385 0.012799705378711224
0.026819674796535534 0.11672373777203325 0.014621193520724773
0.026811900544656084 0.11670746560418727 0.013160381466150284
0.026805005061761714 0.11669362910982124 0.010761858895421028
0.02680010521433128 0.11668528151471304 0.010717608034610748
0.026794563260639146 0.11667341111521658 0.011387965641915798
0.026788673361029296 0.1166621555863379 0.010380636900663376
0.026781952158733746 0.11664815900327863 0.008622839115560055
0.026776386558875452 0.116637570953983 0.008366278372704983
0.026771263163827566 0.1166274864784862 0.009293358772993088
0.026765491208052813 0.11661413487593071 0.009326109662652016
0.026760487300803118 0.11660253610364064 0.008100271224975586
0.026755865274240134 0.11658946135839553 0.0070184702053666115
0.026752578910641832 0.11657933353875527 0.007209226489067078
0.026749325291629218 0.11656884993216464 0.007786931935697794
0.02674542601086296 0.1165574700931871 0.007675703149288893
0.02674093197801025 0.11654643560317252 0.0069305612705647945
0.02673584106200909 0.11653568494855764 0.006402411963790655
0.026729944572479465 0.11652388781052332 0.006437670439481735
0.02672446753624398 0.11651513703029948 0.006464257836341858
0.026718596756261828 0.11650403993770266 0.006224860902875662
0.02671382862077836 0.1164953109276451 0.005977902561426163
0.026708679430539027 0.11648214331512045 0.00587815186008811
0.02670461729910923 0.11647153965912513 0.005868861917406321
0.026700954873359724 0.11646187215642138 0.005852577276527882
0.026696626724122333 0.11644994307223198 0.005759686231613159
0.026693034319088368 0.11644262684300216 0.00560900429263711
0.026687881517472936 0.11643021723827743 0.0054514179937541485
0.026682806835114044 0.11641902830420997 0.0053629279136657715
0.026677580593890728 0.11640696313402019 0.005406474694609642
0.026673321533647532 0.11639778213924792 0.005474702920764685
0.026669652747281513 0.11638938285946511 0.00543591845780611
0.026665832592522802 0.11637898835436992 0.005348950158804655
0.026662060316808223 0.11636868329238423 0.0053449771367013454
0.026657972864913518 0.11635840869940774 0.005395322106778622
0.026652744523547996 0.11634549744567414 0.005347335245460272
0.026648078925370543 0.11633693801273462 0.005186741705983877
0.026642778961182088 0.1163263931505511 0.005091977305710316
0.026637423525773835 0.11631504970058447 0.005133350379765034
0.02663238296316949 0.11630371745953673 0.005172620061784983
0.02662834407707281 0.11629520053862981 0.005137485917657614
0.026623642267674573 0.1162827239962558 0.005108125042170286
0.026619338902343956 0.11627152877680078 0.005131084006279707
0.026615563320936383 0.11626298638708159 0.005133551545441151
0.026610588791889177 0.11625021227979716 0.0050852419808506966
0.02660575699608255 0.11623890982058714 0.00507214805111289
0.026600550156019025 0.11622647550527146 0.0051217107102274895
0.026596455318731445 0.11621887400337491 0.005150726065039635
0.026591156908964735 0.11620604093208813 0.005131261423230171
0.026586562206966605 0.1161962699453176 0.005113143473863602
0.026581726885274742 0.11618568391259064 0.005113360472023487
0.026576491828157574 0.11617356414450805 0.005104624666273594
0.026571923097218408 0.11616417645050482 0.0050813257694244385
0.02656692621501238 0.11615260465172533 0.005065330769866705
0.026562592286370527 0.11614362272078688 0.005060091149061918
0.026557543280786567 0.11613165745472978 0.005059885326772928
0.02655152959263551 0.11611589845395763 0.005076464731246233
0.026546661045308253 0.11610540166185201 0.0051033287309110165
0.026541686852282947 0.11609462170618243 0.005109878256917
0.02653666665076649 0.11608352989814662 0.005095697473734617
0.02653132079861821 0.11607071850204807 0.005090821068733931
0.026525969515013043 0.11605754826648959 0.005107476841658354
0.026522182008485145 0.11605102498621199 0.005126021336764097
0.02651606222007814 0.11603487309718696 0.005129016470164061
0.02651082561361732 0.1160231798296463 0.005120012443512678
0.026505971930682 0.11601369247828919 0.005113369785249233
0.026500566592352878 0.11600191799099802 0.0051155188120901585
0.026494337159605384 0.11598621426133712 0.005121643655002117
0.026490055642339506 0.11597836489040504 0.005123005714267492
0.026484676384681945 0.11596555063262033 0.0051232292316854
0.026479236385871893 0.115952548238937 0.005128804128617048
0.026474620322662866 0.11594334214978369 0.005138525273650885
0.026468834837444357 0.1159293586047507 0.00514408852905035
0.026463768684171336 0.11591857417821776 0.005143637303262949
0.0264583180675822 0.11590612632429917 0.005145188886672258
0.026452757203353255 0.11589313926299082 0.005151278804987669
0.026447122981711202 0.11587981646751509 0.005159071180969477
0.02644228414079266 0.11586999476235571 0.0051648723892867565
0.026436551341175493 0.1158564594493727 0.005168233998119831
0.026430571113997568 0.11584194385903072 0.005167825147509575
0.026425889903686675 0.1158329710908888 0.0051653748378157616
0.02642038711016635 0.1158203581008545 0.005164454225450754
0.026414971926746293 0.11580803374855998 0.005164123605936766
0.02640976439930839 0.115796598062035 0.005163563881069422
0.026403962432018264 0.1157827097443312 0.005166973918676376
0.02639917690890737 0.11577334609984868 0.005174138117581606
0.026393683561037325 0.1157610805739128 0.005180027335882187
0.02638799218019121 0.11574797510335635 0.005181188695132732
0.026382487165154893 0.11573554596903866 0.005179277621209621
0.026376899861987334 0.11572256841169529 0.005177773535251617
0.02637191795467062 0.11571207362136032 0.0051781190559268
0.026366214235910495 0.11569851424425068 0.005180219653993845
0.026360560461422957 0.11568532159222918 0.005181101616472006
0.026355019683459487 0.11567281568945191 0.005180489271879196
0.026349710395053696 0.1156614519279885 0.005179821513593197
0.026343572802413742 0.11564654585325912 0.005178004037588835
0.02633848888419634 0.11563604715830453 0.005173532757908106
0.026332430438999046 0.11562118421203073 0.005168161820620298
0.026327252747543904 0.1156100108646887 0.005166465416550636
0.02632192696376038 0.11559819089657716 0.005168947856873274
0.026317107538793703 0.115588623471755 0.005171666387468576
0.02631110816910665 0.11557404049426838 0.005171544849872589
0.026305112172794513 0.11555953750425496 0.00516691105440259
0.026299874509940604 0.11554833090113123 0.005160830914974213
0.026294962564911352 0.11553852055254507 0.005156269297003746
0.02628897431690403 0.11552404221464914 0.0051534539088606834
0.02628433744206144 0.11551536398480072 0.005150421056896448
0.02627822814702223 0.11550033959049548 0.005147632211446762
0.02627256710092576 0.1154872535607064 0.005144376773387194
0.02626752692277432 0.11547682907960566 0.005139926914125681
0.02626216236448363 0.11546500603591371 0.0051342337392270565
0.02625695761814181 0.11545385272081216 0.005128097720444202
0.02625139240019212 0.11544113216532494 0.0051233903504908085
0.026244986345109612 0.11542479006036624 0.005119923036545515
0.026240157427792905 0.1154152692208008 0.005116391461342573
0.0262348564765207 0.11540371794138017 0.005112057086080313
0.026229196139522026 0.1153906154094099 0.0051062763668596745
0.026223911177579853 0.11537911836789647 0.005099713336676359
0.026218129501654378 0.11536547784852001 0.005093226674944162
0.02621305326993657 0.11535488332138924 0.005086945835500956
0.026207300480735593 0.11534136960623279 0.0050809639506042
0.026201751548791112 0.11532872308218811 0.005074376706033945
0.026196218283751918 0.11531613348481196 0.00506778247654438
0.026191048269632023 0.11530511190168459 0.005061530973762274
0.026186041475093742 0.1152947822220261 0.005055340472608805
0.026180886186494556 0.11528383144971228 0.005049294792115688
0.02617481562296401 0.11526894477996526 0.00504258880391717
0.026169422987574943 0.11525697170114396 0.0050353785045444965
0.026164548939646246 0.11524721488605454 0.00502789719030261
0.02615981090602471 0.11523802698691953 0.005020639859139919
0.026154369790714095 0.11522580660942223 0.005013676360249519
0.026148708499746154 0.11521265596339976 0.005006267223507166
0.026143512784874607 0.11520152572948038 0.004999278113245964
iteration: 24 | epoch: 1257 |   loss: 0.115202  |   KL divergence: 0.026144  |  JS divergence: 0.006572
('==== Found maximium gradient [0.003964156, 0.0035627217, 0.0035474948] of '
 'gate e^[Y8 Z0], e^[X10 Y8], e^[X0 Y8] ====')
learning rate =  0.0007392991136964159
0.02613847888104203 0.11519110321935758 0.008118640631437302
0.02611656667056636 0.11519440193952889 0.02243286557495594
0.0261169248507567 0.11516651023314455 0.015017311088740826
0.026130619617019367 0.11516146918646854 0.021045826375484467
0.026122680481113526 0.11514090455728053 0.0158913042396307
0.02610513552573372 0.11511795639506067 0.011624797247350216
0.02608886842914467 0.1151046652254533 0.01348193734884262
0.02607674761820928 0.11509071664976994 0.014063291251659393
0.026070228077831888 0.11507392041374909 0.011911376379430294
0.02606882654590583 0.11505803865009899 0.010054755955934525
0.026068891330180206 0.11504489383497558 0.0105122160166502
0.026065904694077928 0.11503283084024142 0.011643734760582447
0.026057405607232555 0.1150167057696284 0.011577002704143524
0.02604553764411286 0.11499790275355878 0.010337263345718384
0.02603494443545863 0.11498434321294629 0.00902098324149847
0.026026070783987148 0.11496898965122772 0.008820809423923492
0.026019585239349767 0.11495293524941282 0.009213406592607498
0.02601541887990356 0.11493999831679819 0.008936191909015179
0.02600984664805662 0.11492005596194783 0.007899901829659939
0.026005232882465402 0.1149074778362275 0.007451191544532776
0.025998890455247177 0.11489296275693558 0.008175317198038101
0.025990548354543966 0.11487649839106942 0.00865577720105648
0.025981548233074518 0.1148623350357325 0.008046778850257397
0.02597185888963351 0.11484573625301583 0.007139344699680805
0.025963912068531107 0.11483268888634447 0.00709952786564827
0.025957380107709264 0.11482004963205747 0.007455411832779646
0.025951125249704384 0.11480347496221292 0.007241813465952873
0.02594518579002604 0.1147845913041374 0.006722648162394762
0.025940263150815872 0.11476913914060094 0.006776775233447552
0.02593525706054126 0.11475632471564143 0.007219982333481312
0.0259283716027921 0.11474156981886648 0.007189752068370581
0.02592034658831953 0.11472809511292761 0.006609764881432056
0.025910936682164393 0.11471160065953505 0.006203107535839081
0.02590191988398597 0.11469547147232173 0.006347679998725653
0.025893971745935843 0.11467941878335108 0.006547086872160435
0.025887579139188106 0.11466447906932738 0.006467044353485107
0.025882373276292232 0.11465034585349373 0.006379327736794949
0.025876896445013335 0.11463407141688063 0.00651754392310977
0.025871142862791026 0.1146197286823872 0.006611073389649391
0.025863893435169642 0.11460429935626794 0.00640506949275732
0.02585552457062614 0.11458830100512997 0.006085681263357401
0.025847242150373477 0.11457345688955005 0.005955834407359362
0.02583991972619082 0.11456012238961259 0.005993930622935295
0.025832847353518658 0.11454378843205164 0.0060264053754508495
0.025826716161807886 0.11452841309610373 0.006046473979949951
0.025821735197989377 0.11451739176757987 0.006132472772151232
0.025814543042306397 0.1144985723753824 0.006238466594368219
0.025807764345579944 0.11448433031147806 0.006222617346793413
0.02580050731723956 0.11446995960180767 0.006067588459700346
0.025793543999228608 0.1144570719241379 0.005916255060583353
0.025786018680972425 0.11444055138258488 0.005858983378857374
0.02577903047854644 0.11442473133326729 0.005836008582264185
0.02577286224160806 0.1144111629069279 0.005813147872686386
0.025766117681546442 0.11439461540688106 0.005844037979841232
0.025759656563695815 0.114379922343598 0.005916972178965807
0.025753205970537138 0.11436675838425228 0.005944585893303156
0.02574542873574413 0.11434925912579462 0.0059008062817156315
0.025738628660829446 0.11433632388071903 0.005833695642650127
0.02573143661714277 0.11432045100718402 0.005781278945505619
0.02572498118977813 0.11430580347558365 0.005742659792304039
0.025718496794722063 0.11428980860228836 0.005719363689422607
0.025713241726465847 0.11427967573350294 0.0057186284102499485
0.02570577476415769 0.11426169121354311 0.005731468554586172
0.025698743183632133 0.11424719612067413 0.005732713732868433
0.02569184025790837 0.11423346425741704 0.005708329379558563
0.025685211615711412 0.11421977637654453 0.0056710923090577126
0.025679046772022644 0.11420668357052212 0.005644853226840496
0.02567306017320638 0.11419371537407183 0.005631987005472183
0.02566636631970901 0.1141779749264453 0.0056190285831689835
0.025659082926723868 0.11416036449313931 0.005608838051557541
0.025652520697276963 0.11414638203684795 0.0056057097390294075
0.025646004965110335 0.11413262853017438 0.005591962486505508
0.02563926558010233 0.11411762429358696 0.005555616691708565
0.02563337852815354 0.11410600510044604 0.00551986787468195
0.025626926980021038 0.11409172773366873 0.005505258683115244
0.025619194282109098 0.11407189796894629 0.005502977874130011
0.025613776233823153 0.11406232652059678 0.005500713363289833
0.02560721449228856 0.11404787546558882 0.005498878192156553
0.025600318215291497 0.11403188109165345 0.005486993119120598
0.02559475438173999 0.11402146949134656 0.005454540718346834
0.025588221446173648 0.11400658383725724 0.005416689906269312
0.025581719874330274 0.11399173895071815 0.005392699036747217
0.02557521946848458 0.11397697914605222 0.005382682662457228
0.02556867763292188 0.11396223880684091 0.005376658868044615
0.025561848451298858 0.1139463967465736 0.0053717754781246185
0.025555996805906006 0.11393480657828274 0.005365156568586826
0.02554980716225367 0.11392149643227817 0.005350461695343256
0.025543834741471608 0.11390881648051389 0.005327433347702026
0.025537641181682336 0.11389501014146172 0.005303691141307354
0.025531528112535055 0.11388165718890284 0.005281033460050821
0.025525098915557647 0.11386713378785074 0.00526076415553689
0.02551898616488079 0.11385405102489063 0.00524695310741663
0.025512840782131552 0.11384069379948764 0.005239712540060282
0.02550619980766464 0.1138250177726177 0.005231838673353195
0.02550039515172513 0.11381293137066427 0.005218952428549528
0.02549398273034 0.11379817809060024 0.005202260799705982
0.025487972951353844 0.1137851405143 0.005181871820241213
0.025481585164429273 0.11377038027252215 0.005160968750715256
0.025475620699725185 0.11375743192163974 0.0051444037817418575
0.025469800900194184 0.11374508275685527 0.005131397396326065
0.02546387325401939 0.113732192155264 0.005118191242218018
0.02545754709442084 0.11371747022904319 0.005104247014969587
0.025452102070155067 0.11370659175995573 0.005089838523417711
0.025446198329186244 0.11369379889025907 0.005074700806289911
0.025440165640316217 0.11368048520541434 0.0050590550526976585
0.02543359246798979 0.11366467241803231 0.005043381825089455
0.025428484499692615 0.1136550208249282 0.00502750463783741
0.02542191030787513 0.11363875182160177 0.005012491252273321
0.02541620558602155 0.11362626768300989 0.004997657611966133
iteration: 25 | epoch: 1366 |   loss: 0.113626  |   KL divergence: 0.025416  |  JS divergence: 0.006394
('==== Found maximium gradient [0.0042805136, 0.004211881, 0.003765843] of '
 'gate e^[Y1 Z3], e^[Y1 Z11], e^[Y11 Z1] ====')
learning rate =  0.0008184889451805091
0.025409889341916042 0.1136112368920386 0.008664698339998722
0.025408315910556464 0.11360853656604512 0.01963663287460804
0.025409696060474624 0.11358614732257195 0.020624849945306778
0.025389004432200005 0.11356909923711737 0.018202533945441246
0.02537285165985157 0.11354743432449324 0.017001675441861153
0.02536498855520978 0.11352731642542342 0.01477882545441389
0.025363389057317914 0.11350866919800753 0.013135133311152458
0.025362977634204174 0.11349198682226971 0.01392995472997427
0.025357658288301214 0.11347533239864759 0.013139178976416588
0.025346480981957735 0.1134557985204908 0.010958921164274216
0.02533455534360292 0.1134399233046976 0.010666470974683762
0.02532451697431228 0.11342426168640682 0.011264831759035587
0.025316997294240636 0.11340428374116535 0.010472221300005913
0.02531393010141491 0.11339151161976715 0.009121270850300789
0.0253099484595374 0.11337150926297054 0.00916261039674282
0.0253059491634862 0.1133588377078685 0.009573385119438171
0.02529792990009347 0.11334085481035898 0.008789710700511932
0.025289204889153146 0.11332784763308533 0.007689615245908499
0.02527992961949445 0.11331168894789669 0.007771004922688007
0.025273168721191085 0.11329944965975032 0.008041334338486195
0.025267086871655117 0.11328145874903842 0.007325343322008848
0.02526393675770603 0.11326996483766688 0.006564892828464508
0.02526047762231183 0.11325652099378487 0.006888099480420351
0.02525482628712592 0.11323954594362798 0.007346729282289743
0.025248137307620537 0.11322697862949559 0.006975593976676464
0.02523975376598961 0.11321284900352906 0.006231097038835287
0.025231072288385007 0.11319693356967138 0.006009350065141916
0.025223797831529317 0.11318166909786356 0.00615813909098506
0.025219204710979964 0.11317142648189372 0.006033746525645256
0.02521415887153505 0.11315479730986631 0.005755533929914236
0.025209692110118177 0.11314084815598649 0.005766314920037985
0.02520421346451876 0.11312678439762565 0.005919291637837887
0.025197621443317844 0.11311340510773592 0.005799734964966774
0.025190285205924465 0.11310001683836789 0.005422481335699558
0.025182765800867986 0.11308534863550383 0.005169191863387823
0.025176138623920916 0.11307171927274402 0.005186480935662985
0.025169978410459024 0.11305693393562934 0.0052264356054365635
0.025165061591614017 0.11304521302119076 0.005180011503398418
0.025159672981026927 0.11303028544379534 0.005163031630218029
0.025154696294120454 0.11301770496111663 0.005180611275136471
0.025148712299514125 0.11300268549918628 0.005104074254631996
0.025142201052546238 0.11298773448452076 0.004930166061967611
iteration: 26 | epoch: 1408 |   loss: 0.112988  |   KL divergence: 0.025142  |  JS divergence: 0.006322
('==== Found maximium gradient [0.004415677, 0.0043049487, 0.003853576] of '
 'gate e^[Y0 Z1], e^[Y1 Z0], e^[Y2 Z3] ====')
learning rate =  0.0008396890858751067
0.025135720856972774 0.11297433451330968 0.00871654599905014
0.02515238316890469 0.11299375524256765 0.025990493595600128
0.025125207147410608 0.11295067720025896 0.01821781136095524
0.02511891047120037 0.11294257648203092 0.019244255498051643
0.025120505264195483 0.11292720473555347 0.0183479655534029
0.025120752133128456 0.11290400875580751 0.01647021993994713
0.025115030116227302 0.11288417206076043 0.01258243527263403
0.02510238856079533 0.11286306103763846 0.011505897156894207
0.025088186153453065 0.11284896398492301 0.01451994851231575
0.025073956031153907 0.1128349798548312 0.014964205212891102
0.02506337134636838 0.11281695965608277 0.01219719648361206
0.025058174426857805 0.11279173679706277 0.009773398749530315
0.025060021383341638 0.11277587689482467 0.01032424159348011
0.025062727958190735 0.1127649247083678 0.011105557903647423
0.025059343122719492 0.11274681003586304 0.010314001701772213
0.0250514227527903 0.11273142159474522 0.00900336168706417
0.02504025137560826 0.1127149088979377 0.008654583245515823
0.02502874759894863 0.11269689936856873 0.008904140442609787
0.025020405129967213 0.11268353830416103 0.00891544483602047
0.025014116759560168 0.11266780569138526 0.008677566424012184
0.025008657636229163 0.11264831179712155 0.008333820849657059
0.025003525938567597 0.11262903815679497 0.007887075655162334
0.024998659301070397 0.11261399170244589 0.007544000167399645
0.024992706798418855 0.11259823930300364 0.0073373932391405106
0.024986373383111472 0.11258302961874332 0.007015220820903778
0.024979252747671446 0.11256394496734444 0.0066806357353925705
0.024973872000788645 0.11255117120294313 0.0067477780394256115
0.024968101737920613 0.11253653379309066 0.006959615275263786
0.024961831476918706 0.1125213116689165 0.006791126914322376
0.02495418011224929 0.11250161832677072 0.006444503553211689
0.024947576568244652 0.11248670506651498 0.00641481950879097
0.02494086286358195 0.11247012733505438 0.0065163555555045605
0.02493481347144303 0.11245499203795331 0.006352212745696306
0.02492825301227125 0.11243670877312617 0.00602694321423769
0.024922640874161565 0.11242272668499406 0.005789924878627062
0.024916540124519528 0.11240731760151144 0.005657954607158899
0.02490984296140273 0.11238969479142451 0.005658552050590515
0.02490428773295656 0.1123766064682713 0.005812325514853001
0.024898370304186908 0.11236065594925178 0.005925058387219906
0.024892002931469766 0.11234166828767847 0.005841433070600033
0.02488713039822249 0.11232944903643145 0.005694298073649406
0.024880713240287226 0.11231196806877747 0.0056578307412564754
0.024874333336073993 0.11229695760098607 0.005606562364846468
0.02486744451644881 0.11228115303808621 0.0054215844720602036
0.024861053382954676 0.11226687323573917 0.005307585000991821
0.024854816705481488 0.11225081203845376 0.005387088283896446
0.024848787874960317 0.11223325534583557 0.0054480405524373055
0.02484415991908779 0.11222103851861984 0.00538991391658783
0.02483766126654524 0.11220133146580819 0.0053446632809937
0.024832170701917657 0.11218771133210574 0.005360637325793505
0.02482649054133558 0.1121744286963522 0.005371253006160259
0.024819421901061282 0.11215501952849449 0.0053412653505802155
0.024813740113701476 0.11214100050914765 0.00527925742790103
0.02480761387498057 0.11212434505858333 0.005212907679378986
0.02480132292864947 0.11210696301075003 0.005166692193597555
0.024796018476278485 0.1120944248087348 0.005130671430379152
0.024790206897774003 0.11207996915457225 0.005103693343698978
0.02478355675865232 0.11206151928757174 0.005115333944559097
0.02477804638282682 0.11204739230801412 0.005152048543095589
0.024773114976296223 0.11203514665290236 0.00515745859593153
0.024767217202147015 0.11201836411004117 0.005121581722050905
0.024760836212992337 0.11199968865551302 0.005080686416476965
0.02475529490008223 0.11198530970591755 0.005050987470895052
0.024749323540129126 0.11196957518528422 0.005026080645620823
0.024743761584560528 0.1119558972716639 0.004991178400814533
iteration: 27 | epoch: 1473 |   loss: 0.111956  |   KL divergence: 0.024744  |  JS divergence: 0.006208
('==== Found maximium gradient [0.005005741, 0.004346184, 0.0041340436] of '
 'gate e^[Y3 Z0], e^[Y10 Z9], e^[X0 Y2] ====')
learning rate =  0.0009021239908713441
0.024737832333231298 0.11194031425522313 0.009245648048818111
0.02474831885923817 0.11193410920704286 0.02214580960571766
0.024723642860023206 0.11191247034592228 0.021789496764540672
0.024712267533867457 0.11188232448007028 0.020586388185620308
0.02470646547569288 0.11185857240901273 0.017532994970679283
0.024699997013081815 0.11183249313326019 0.014464430510997772
0.024694313041231684 0.11181122322388341 0.0161097701638937
0.02468591610571623 0.11178757490447327 0.016167692840099335
0.024675764142003356 0.11176405278524616 0.012477231211960316
0.02466543328430361 0.11174224074010404 0.010896085761487484
0.024655911833315617 0.11172658710482274 0.013059630058705807
0.024644252291455428 0.11170366937126519 0.012971281073987484
0.024633405869493342 0.11167936154745026 0.010766609571874142
0.024626121941110773 0.11165841888484664 0.009732827544212341
0.024621784938072912 0.11163849150636748 0.01016760803759098
0.02461819978393523 0.111616306605766 0.01033425610512495
0.024615191818948223 0.11159981090010637 0.009954511187970638
0.024608198753301332 0.11157727859821338 0.009316039271652699
0.024598546319514056 0.11155723868308136 0.008424531668424606
0.024587336948752186 0.11153748258414176 0.00807578582316637
0.024576384617827712 0.11151574062266313 0.00847555696964264
0.024568614806856483 0.11149861954386818 0.008299343287944794
0.02456244638992825 0.1114782839434188 0.007466469891369343
0.024557418483001137 0.111456880012045 0.007375152315944433
0.024552960982169882 0.1114393974556902 0.007832441478967667
0.024546216488981833 0.11141909754675793 0.0076239281333982944
0.02453795162128582 0.11139932032634023 0.006926037836819887
0.024530495443739246 0.11138566893770833 0.006788403727114201
0.024521878343153232 0.11136472547193675 0.007101147435605526
0.0245144014135546 0.11134443751371959 0.006927493028342724
0.024508991879549583 0.11132817027930757 0.006448245141655207
0.02450408517764751 0.11131038128963988 0.006392098497599363
0.024499122349099754 0.11129288206019497 0.006527876481413841
0.024492216378958202 0.111271668933477 0.006404059007763863
0.024484622181011488 0.11125337747193492 0.006200435105711222
0.024476896013232947 0.11123735521643788 0.006173331756144762
0.024468844899406563 0.11121762737504752 0.006168448831886053
0.024462770779520953 0.11120088438080067 0.006078919395804405
0.024457550191682997 0.11118260590578379 0.005970948841422796
0.024453072860591507 0.11116644291822915 0.005824374035000801
0.0244478015060899 0.11114972847782903 0.005739842541515827
0.024441562971429104 0.11113293383462039 0.005784856155514717
0.0244349499435015 0.11111686431864981 0.005740062333643436
0.02442782468603806 0.11109791678009795 0.005515549797564745
0.024421554203809856 0.1110802897031865 0.005372181069105864
0.024416781345602927 0.11106711180318805 0.005450316239148378
0.0244105946617548 0.11104717544122854 0.005499751772731543
0.02440546460336912 0.11103296449496253 0.005392664577811956
0.02439989487822099 0.11101761535126589 0.005297038704156876
0.024394635614019097 0.11100357153236472 0.00525936484336853
0.024388453429103153 0.1109849992910114 0.005184425972402096
0.0243831406004462 0.11097053588441386 0.00510751735419035
0.024377160767580106 0.11095395952480096 0.005088424775749445
0.024371328510061782 0.11093849417905911 0.005060513503849506
0.02436596163813011 0.11092385946626171 0.00499599939212203
iteration: 28 | epoch: 1528 |   loss: 0.110924  |   KL divergence: 0.024366  |  JS divergence: 0.006095
('==== Found maximium gradient [0.0030933646, 0.0030585248, 0.0029450343] of '
 'gate e^[Y8 Z2], e^[X2 Y4], e^[Y3 Z4] ====')
learning rate =  0.0006065938413938833
0.02436091070498987 0.11090816406870393 0.00721294479444623
0.024374036079320906 0.11091506158007537 0.02053951658308506
0.024347936613541156 0.11089253336733833 0.01611557975411415
0.024347841074098077 0.11088442982918376 0.0161119494587183
0.024352569688451113 0.1108691464310267 0.015026130713522434
0.024353602520142084 0.11085573193493191 0.014061210677027702
0.02434832609899893 0.11084498158465608 0.013415985740721226
0.024337477361022854 0.1108318257650302 0.01069151982665062
0.024325450216096476 0.11081535405190962 0.00893575232475996
0.024318752956005302 0.11080945517861482 0.01081005297601223
0.02431390885522626 0.11079804794818866 0.011927596293389797
0.02430995919002664 0.11078177646150095 0.010214121080935001
0.0243078029515141 0.11076717445568014 0.007423960603773594
0.02430691324603424 0.11075661699728662 0.007166688796132803
0.02430539830059463 0.11074913465899258 0.00890783965587616
0.02430053838512116 0.11073638414987691 0.009434827603399754
0.024294528389487938 0.1107248636888454 0.008372544310986996
0.024288608786930975 0.11071356554795987 0.0071411896497011185
0.02428247101241833 0.1106973270929715 0.006932693067938089
0.024278468902188925 0.11068713883769665 0.007296731695532799
0.02427535961854089 0.11067966078105161 0.007466290146112442
0.024271005056903747 0.1106670548779331 0.007229036185890436
0.024266775382752466 0.11065553136107574 0.006775171961635351
0.024262457563109692 0.11064282667165677 0.006386098451912403
0.02425977470513699 0.11063503472499389 0.006130616646260023
0.02425620903452017 0.11062068140393921 0.00603047339245677
0.024253768235360514 0.11061140467647058 0.006110386457294226
0.024250703959394243 0.11060306167936962 0.006201631855219603
0.024245674924466817 0.11059128687728226 0.006037717219442129
0.02424015320772203 0.11058084805838941 0.0056267669424414635
0.02423488562531991 0.11057124690224644 0.005386246368288994
0.02423098105859628 0.11056414960576197 0.005529318004846573
0.02422703444271681 0.1105517136103156 0.005660820286720991
0.024224411654248476 0.11054090212790071 0.0055115739814937115
0.02422302304022169 0.11053435846583391 0.005254208575934172
0.02421904498047108 0.1105183356413867 0.005123275797814131
0.024216466726207406 0.11051237090828113 0.005143200978636742
0.02421297969276142 0.11050532788524363 0.005196335259824991
0.024207092159632834 0.11048880285048468 0.005141560919582844
0.02420378004239576 0.11048345300123169 0.004973216913640499
iteration: 29 | epoch: 1568 |   loss: 0.110483  |   KL divergence: 0.024204  |  JS divergence: 0.006047
('==== Found maximium gradient [0.0050132587, 0.0036153826, 0.0030529976] of '
 'gate e^[Y4 Z3], e^[Y10 Z2], e^[Y9 Z3] ====')
learning rate =  0.000796028060845391
0.02420019240661917 0.1104750842204836 0.008438564836978912
0.02422684038642492 0.1104989512904 0.02885877713561058
0.024185246055467458 0.11044807143915991 0.018407633528113365
0.024181131570868257 0.11044469361646674 0.023041903972625732
0.02416936222204387 0.11042599352861042 0.019299238920211792
0.02416711907875048 0.11040397465636018 0.016652068123221397
0.024171162411963373 0.110384779446903 0.016802024096250534
0.024170308511289616 0.11036400713541505 0.015703938901424408
0.024160976455726263 0.11034309000220574 0.013442221097648144
0.024146384851447416 0.1103275087015056 0.012616142630577087
0.024130630637950817 0.11031505563705823 0.013268175534904003
0.0241160387676439 0.11029500215232889 0.013542655855417252
0.0241073490208094 0.11027751683474812 0.012298104353249073
0.024103275082264824 0.11025642891702812 0.010137342847883701
0.02410358601449962 0.11024133356786649 0.00937863439321518
0.02410348173694859 0.11022869908618241 0.010526567697525024
0.02409912255078603 0.1102152120287213 0.011086034588515759
0.024088620909919305 0.11019250475683233 0.010228650644421577
0.024077703735362325 0.11017607068925547 0.009033557958900928
0.02406830895258191 0.11016268981226408 0.0085902726277709
0.024059302508484925 0.11014096145048306 0.008719087578356266
0.02405447393974023 0.11012900733631681 0.008935335092246532
0.02404940959706346 0.11011205276030699 0.008741560392081738
0.024043564328405445 0.11009216982306043 0.007867477834224701
0.024039088229929846 0.11007990920210009 0.007167129777371883
0.024033757992114393 0.11006428734815435 0.007482223212718964
0.024028366685193328 0.1100490385395974 0.007885520346462727
0.024022152230587648 0.11003177957409273 0.007542285602539778
0.02401635520209704 0.11001859273705651 0.006977987475693226
0.024009756408556394 0.11000381428762881 0.006870323792099953
0.02400297220143871 0.10998924401837765 0.006990979425609112
0.023996252497994253 0.1099737419304609 0.006994874216616154
0.023990000238028594 0.10995677388865313 0.00685223238542676
0.023985552059065086 0.10994378090952649 0.006615807302296162
0.023980563548835265 0.10992598923696846 0.006408500485122204
0.02397616252098487 0.10991182775051739 0.006257307715713978
0.023970750320484548 0.1098967932696497 0.006080596707761288
0.023964653718881606 0.1098826636505227 0.006022261921316385
0.023958557456117597 0.10987050358905855 0.0061713773757219315
0.023951073204481334 0.10985112391007121 0.0062233684584498405
0.023945937963336848 0.10983918113983308 0.006017936859279871
0.023940418489189333 0.10982168504710711 0.0058411285281181335
0.02393607770148485 0.10980719133746084 0.005912136752158403
0.023932087964040838 0.10979462987529538 0.006011419929563999
0.02392675237577306 0.10977847390829651 0.005897012539207935
0.02392176172116975 0.10976685293515633 0.0056775412522256374
0.023915862424462843 0.10975295581584515 0.00556999072432518
0.023910299784791884 0.10974068515337154 0.005537389777600765
0.023904101946287344 0.10972401779080862 0.005473013035953045
0.023898488917157366 0.10970762439625854 0.005417281296104193
0.02389523585418961 0.10969981640148578 0.00541981216520071
0.023889837933189537 0.10968139125054768 0.005456352606415749
0.023885286897714138 0.1096675047390061 0.005469960626214743
0.02388063425763976 0.10965498530801453 0.005432619247585535
0.02387504563288266 0.10964019949948471 0.005384801421314478
0.0238696915887743 0.10962758842851843 0.005337798036634922
0.023864402792353658 0.10961493704891885 0.0052510094828903675
0.0238596932301944 0.10960321626854348 0.005175229627639055
0.023854417032161408 0.10958679942567469 0.005164014641195536
0.023850132314196852 0.10957363088682509 0.005149576812982559
0.0238462272875119 0.10956256931417963 0.005101796239614487
0.0238417049622473 0.10955038666669303 0.0050658793188631535
0.023836888572080366 0.10953861408491895 0.005053812637925148
0.02383218519079967 0.10952783083484098 0.005048129707574844
0.02382646347525808 0.10951116718058429 0.005028860177844763
0.02382209957568355 0.10949858841337397 0.005003305617719889
0.023817834208461633 0.10948513648639153 0.004991278052330017
iteration: 30 | epoch: 1635 |   loss: 0.109485  |   KL divergence: 0.023818  |  JS divergence: 0.005939
('==== Found maximium gradient [0.0033151677, 0.00313292, 0.0030981824] of '
 'gate e^[Y2 Z1], e^[X8 Y0], e^[X2 Y10] ====')
learning rate =  0.000636702530969694
0.023814690570747803 0.10947723253212688 0.00742148794233799
0.023807551954750216 0.10946459700414113 0.014979241415858269
0.02382149758954894 0.10945594452132235 0.018900642171502113
0.02380300775844438 0.10943892042539755 0.01530395820736885
0.023789452236690746 0.10942535002103301 0.014619973488152027
0.023782718438318307 0.1094105720133067 0.014413257129490376
0.02378129591387133 0.10939165320450381 0.012620464898645878
0.023783568538025178 0.10937927587210873 0.01108008623123169
0.023781822629820315 0.10936532118340377 0.01183086633682251
0.023773237366800988 0.10935111569614861 0.011524035595357418
0.02375998093989837 0.1093334298809231 0.010438099503517151
0.023748518570536916 0.10931912390141141 0.010308356024324894
0.023741465691174767 0.10930688222114254 0.010051451623439789
0.023737669540048772 0.10929175052919822 0.009124821983277798
0.023735659327481777 0.10927668137508176 0.008475731126964092
0.02373355901944468 0.10926522501435788 0.008550372906029224
0.02372978190168605 0.10925572533726632 0.0088272113353014
0.023721716252517813 0.10923522377167826 0.00885311234742403
0.02371443713759422 0.10922270453578867 0.008544734679162502
0.02370600833072921 0.10920460738368933 0.007965938188135624
0.023700551871756997 0.1091962556212603 0.0075979698449373245
0.023694299099382452 0.10917924419961465 0.0078001730144023895
0.023689937126816323 0.10916677599061546 0.007875287905335426
0.023685223310106425 0.10915066031234151 0.007417281158268452
0.023680025004219195 0.10913270111746609 0.00712730223312974
0.023675702460961116 0.10912183500075433 0.0074059320613741875
0.0236691562603749 0.10910507995451792 0.007519018370658159
0.023663258562116207 0.10909369525182347 0.007137512322515249
0.023656135199574546 0.1090756160950441 0.006799644790589809
0.02365110444072041 0.10906424359577709 0.006832539103925228
0.023645501699161187 0.10904854199619123 0.006977674085646868
0.023640093084113405 0.10903409423562467 0.006986585445702076
0.0236348683912215 0.10902191190595016 0.006869043223559856
0.02362790189489454 0.109002382936075 0.006780651398003101
0.023622834890837094 0.10899052700506683 0.0067781261168420315
0.023617483184860025 0.10897590449545343 0.006719844415783882
0.023612636553010845 0.10896321709372564 0.006581628695130348
0.023606917054520067 0.10894763865971012 0.0065503958612680435
0.023600434310839354 0.10893032456634417 0.0066543943248689175
0.02359496055885405 0.10891884679491409 0.006673956289887428
0.023588100609990996 0.10890109105551467 0.006513620261102915
0.02358237014442833 0.10888750876311219 0.0063420445658266544
0.02357761769189601 0.10887687449120645 0.006312666926532984
0.023571800448911814 0.10885997384247302 0.006366375368088484
0.023566970467505728 0.10884714865283303 0.0064234244637191296
0.02356139683332739 0.10883183263732545 0.006447313819080591
0.02355564305823403 0.10881731077032747 0.006391344591975212
0.02354990085205051 0.10880397362716102 0.0062848422676324844
0.023544328359535405 0.10879131988918424 0.006219904869794846
0.023537844747544893 0.10877342448719281 0.006216398440301418
0.023533540320344402 0.10876446379562728 0.006238771136850119
0.02352829859531317 0.10875118642976762 0.006242343690246344
0.02352209572720654 0.10873444052510761 0.006206118501722813
0.023517259808242576 0.10872461111077077 0.006151331122964621
0.023511265457758692 0.10870901741139868 0.006090222857892513
0.023505788658973847 0.1086948995919387 0.006051955744624138
0.023500920845410642 0.1086835376548104 0.006074342876672745
0.023494247856217565 0.10866481847869416 0.006097158417105675
0.023489044374940052 0.10865347666216382 0.00605692807585001
0.023483605410728123 0.10864053238072975 0.0059917401522397995
0.02347856209310261 0.1086281628463156 0.005947694182395935
0.02347354603420805 0.10861520614957758 0.005930118262767792
0.023468353425287 0.10860193732622982 0.005925121251493692
0.023462720872577066 0.10858778829954738 0.005911595653742552
0.023457021662814992 0.10857388845845195 0.005878343712538481
0.02345195168122295 0.10856241082966804 0.005839422345161438
0.02344701269436215 0.10855063033834034 0.005809614434838295
0.023442334248897717 0.1085393388748891 0.005792506504803896
0.02343682995164017 0.10852397594778274 0.0057810042053461075
0.023432124906648734 0.10851253202062726 0.005746182519942522
0.023427206717513877 0.10850079075736702 0.005690637975931168
0.023420682468612015 0.10848228048233709 0.005653590429574251
0.02341560019528619 0.10847040994265955 0.005640816409140825
0.0234116538249053 0.10846311905522048 0.005631878040730953
0.02340601290726555 0.10844721604918924 0.005606377962976694
0.023400806832309308 0.10843286905550785 0.0055604781955480576
0.02339706371683474 0.10842540277840297 0.005514170508831739
0.02339263315337546 0.10841512092151334 0.005485765635967255
0.023386809379254553 0.10839861842548358 0.0054714977741241455
0.02338246480762602 0.10838897341678255 0.005453338380903006
0.023377763903479558 0.10837772389009016 0.005419231951236725
0.023372850611427697 0.10836527526858242 0.005371761042624712
0.023368776948665033 0.108356139212743 0.005327572114765644
0.023364476386745072 0.10834542616479617 0.00529900100082159
0.023359485305743548 0.1083314051155719 0.0052819037809967995
0.023354904139763807 0.10831966137268459 0.005259440280497074
0.023350043179202515 0.10830712775294679 0.005220449063926935
0.02334595790027444 0.10829824789899685 0.005173100624233484
0.02334152923999329 0.10828742248304718 0.0051338463090360165
0.023336938459857015 0.10827533982311012 0.005107303149998188
0.023333032054729353 0.10826604232634741 0.005083300173282623
0.023328891030120983 0.10825562831219789 0.005050900857895613
0.023324030230030896 0.1082421275792935 0.005010850727558136
0.02332024966112229 0.10823377345398626 0.004971310030668974
iteration: 31 | epoch: 1729 |   loss: 0.108234  |   KL divergence: 0.023320  |  JS divergence: 0.005806
('==== Found maximium gradient [0.003248123, 0.0030977488, 0.003086019] of '
 'gate e^[Y2 Z1], e^[X3 Y4], e^[Y1 Z2] ====')
learning rate =  0.0006289660053380407
0.023315287025849972 0.10821992498237985 0.0073530180379748344
0.02333034199485536 0.10822105026446154 0.01819678582251072
0.023302210444614474 0.10820788002450188 0.020945247262716293
0.02329475838948731 0.1081906475024382 0.017258495092391968
0.023291998767033608 0.10817708126743536 0.014519755728542805
0.02329012388525394 0.10816276834821603 0.01520835142582655
0.02328760156506554 0.10814837815417502 0.013877426274120808
0.02328434871465143 0.10813737609839859 0.011799448169767857
0.023278544515511458 0.10812016042916645 0.010966623201966286
0.023274367154614832 0.10811211092514607 0.01109206210821867
0.023269329806697624 0.10809877385817235 0.010898145847022533
0.02326557446254171 0.10808919699613977 0.010121135041117668
0.023260816200316618 0.10807636897759934 0.009161478839814663
0.023255334997071185 0.10806599684437797 0.00869475957006216
0.023248006037421595 0.10805332836438429 0.008568737655878067
0.023241294215834204 0.10804419139660044 0.008344478905200958
0.02323601841536626 0.10803430252701673 0.00795696396380663
0.023232704791585207 0.10802185692226407 0.0074410997331142426
0.023232145185106218 0.10801373775364656 0.007014603354036808
0.023230690954423015 0.10800244460341765 0.006745643448084593
0.02322803550525853 0.10799523848639811 0.006397952325642109
0.023222302968145134 0.1079848287220618 0.006283896043896675
0.02321526687038019 0.10797348148501637 0.006507957819849253
0.023209765416367677 0.1079659505019232 0.006285641808062792
0.02320588724096927 0.10795720834327294 0.005425133276730776
0.02320332411403686 0.10794625923641436 0.00499779311940074
iteration: 32 | epoch: 1755 |   loss: 0.107946  |   KL divergence: 0.023203  |  JS divergence: 0.005775
('==== Found maximium gradient [0.0025881452, 0.0024141925, 0.0023168381] of '
 'gate e^[X10 Y11], e^[Y0 Z3], e^[X8 Y9] ====')
learning rate =  0.0004884609739615699
0.023201698875979438 0.10793706015506277 0.0068604229018092155
0.023192138059436172 0.10796257533332758 0.026856666430830956
0.02319987208081911 0.10793097555100593 0.013999798335134983
0.023211995381215662 0.10792423040972364 0.017525723204016685
0.023211069989094987 0.1079238104495315 0.019083578139543533
0.023199008246159558 0.10791105547999856 0.016109414398670197
0.023186966989725444 0.10790166341509416 0.011318190023303032
0.023178072020129767 0.10789258189767696 0.010680053383111954
0.023174396495622133 0.10789047090132253 0.013378570787608624
0.02317209581915322 0.10788596775013477 0.013722080737352371
0.02316858034930383 0.10787225147413333 0.01110659446567297
0.023167692605019358 0.10786576528300537 0.008489307947456837
0.023167685621444015 0.10785905790061157 0.008937672711908817
0.02316758274373072 0.10785196451584318 0.010342077352106571
0.023167335869002065 0.10784901777654905 0.010314425453543663
0.02316348740176155 0.10783696524752154 0.009047670289874077
0.023159493646877208 0.1078320579695748 0.007765499409288168
0.023153505055414428 0.10782363955514102 0.007261543534696102
0.0231478476886562 0.10781851827989183 0.007407648954540491
0.023141765404033083 0.10780885041937709 0.007723052985966206
0.023138063261396644 0.1078044207425363 0.007679129485040903
0.023134937968745568 0.1077957653520914 0.006952333264052868
0.023133392155206357 0.10778844205717106 0.006015133112668991
0.02313361543281981 0.10778600634024646 0.005930876825004816
0.02313254981816394 0.10777807941063094 0.006507284007966518
0.023130378704317188 0.10776892928679074 0.006536738947033882
0.023127850030423308 0.1077633374047837 0.005750152748078108
0.023124091231356586 0.10775614501370143 0.005080145783722401
0.023119679908763343 0.10774769375492878 0.005272448528558016
0.02311691817835693 0.10774636224852828 0.005563497077673674
0.02311286213975832 0.10773705344314423 0.005281754303723574
0.023109805732544682 0.10772997351798141 0.004802091978490353
iteration: 33 | epoch: 1787 |   loss: 0.107730  |   KL divergence: 0.023110  |  JS divergence: 0.005753
('==== Found maximium gradient [0.002287549, 0.0022211964, 0.0020250455] of '
 'gate e^[X9 Y2], e^[X3 Y2], e^[X1 Y2] ====')
learning rate =  0.00043615597501047305
0.0231076461138068 0.10772549694410133 0.006078070495277643
0.02312740168295166 0.1077450895618442 0.02583567425608635
0.02310535881271555 0.10771334733876455 0.010276969522237778
0.023100560826389074 0.10771560510511086 0.016263648867607117
0.02309949287242061 0.10771839399553165 0.018709896132349968
0.023094426791847915 0.1077029017629156 0.013554967008531094
0.02309176121629275 0.10769213190392257 0.009390358813107014
0.023092383971855847 0.1076863866992576 0.010153423994779587
0.02309403569621957 0.10768386233080456 0.011500711552798748
0.023092795725628588 0.10767577126297416 0.011483602225780487
0.023089796626694574 0.10767083517448392 0.010219968855381012
0.023084122195056605 0.10766143552478354 0.008808072656393051
0.02307929876494626 0.1076573825174649 0.008060508407652378
0.023074314255723725 0.10764924104020325 0.007879653945565224
0.02307160688589632 0.1076468206592896 0.007889294996857643
0.02306897119625828 0.10764026814156386 0.007854391820728779
0.023066537930083914 0.10763138831797875 0.007662241347134113
0.023064861719806724 0.10762481645683122 0.007176110055297613
0.023063312932422773 0.10761935359922305 0.0064816963858902454
0.02306159069369657 0.10761435326812839 0.006073537282645702
0.023059849981456753 0.10761104716299742 0.006099429447203875
0.023056628140223842 0.10760277264331507 0.006154934410005808
0.023053549640461694 0.10759620139910255 0.0060842218808829784
0.02305057977190941 0.10758992445602895 0.005873627495020628
0.023048223501959435 0.10758558409488313 0.005406686570495367
0.023045757779331804 0.10757975432155994 0.00490423571318388
iteration: 34 | epoch: 1813 |   loss: 0.107580  |   KL divergence: 0.023046  |  JS divergence: 0.005736
('==== Found maximium gradient [0.0022277113, 0.0020768454, 0.0019140244] of '
 'gate e^[Y1 Z10], e^[Y8 Z2], RY[11] ====')
learning rate =  0.0004153628727156169
0.02304285441496204 0.10757123576524125 0.006022194866091013
0.023055713095620017 0.1075911428683648 0.023831108585000038
0.023041936526947467 0.10756336901853801 0.010649804025888443
0.023036256601474292 0.10756538094893786 0.016526896506547928
0.023036735564632937 0.10756496462310745 0.016765333712100983
0.023034696398316602 0.10754996157006771 0.012379794381558895
0.023032144418853488 0.1075398002081356 0.009636661037802696
0.02302955186473451 0.10753486414609557 0.011073540896177292
0.023026484717823 0.107531251962869 0.011937037110328674
0.023022613183592673 0.10752214002704484 0.010521261021494865
0.023020728064452666 0.10751729936197467 0.00868077389895916
0.02301950406076958 0.10751048510580015 0.008399061858654022
0.02301874502187648 0.10750554032811865 0.008659454993903637
0.023017306346770915 0.10750073092811188 0.008238373324275017
0.0230145525547893 0.10749280036936956 0.007641282863914967
0.023012063356659753 0.10748771150849808 0.007556402590125799
0.023009788538564092 0.10748426974092457 0.007619109936058521
0.023006862361315345 0.10747776851177929 0.007341162301599979
0.023004189142935505 0.10747168510892126 0.00695355050265789
0.02300183756041061 0.10746605614999592 0.006767896469682455
0.02299930657824444 0.10745880737726328 0.0065475585870444775
0.022998014926134798 0.10745649816030406 0.0060024927370250225
0.022995267864869103 0.10744615881039 0.005407131742686033
0.022994427441237753 0.10744331021886593 0.0053108492866158485
0.0229935181732896 0.10743982020946613 0.005585185252130032
0.022991831131482406 0.10743402757225289 0.005624846555292606
0.022989479054630682 0.10742744764711948 0.005365608725696802
0.022987938149185455 0.1074267659560092 0.005233041010797024
0.022984162956122534 0.10741680875789983 0.005360767710953951
0.022981422270316736 0.10741135928877207 0.005382099188864231
0.022978525258202293 0.10740352091371778 0.005064190365374088
0.02297695413906503 0.10739930119123599 0.004657330922782421
iteration: 35 | epoch: 1845 |   loss: 0.107399  |   KL divergence: 0.022977  |  JS divergence: 0.005717
('==== Found maximium gradient [0.0021890039, 0.0019617523, 0.0017476141] of '
 'gate e^[Y10 Z11], e^[X10 Y11], e^[Y8 Z3] ====')
learning rate =  0.0003948732210428138
0.02297556981431162 0.10739356179019426 0.0056778197176754475
0.022985835050892803 0.10740202885391052 0.016243360936641693
0.022968767776252952 0.10738446555528385 0.010032450780272484
0.02296755827144225 0.10737906498942652 0.010876494459807873
0.022966729907848895 0.10737392493483827 0.011916414834558964
0.022965435643981586 0.10736612504035546 0.009985096752643585
0.022963476730240566 0.10735468360407549 0.007619558833539486
0.022962355193247984 0.10734963101623513 0.007738121785223484
0.022959678051735898 0.10734385217067763 0.008876018226146698
0.022955513504407322 0.10733583503669851 0.008723229169845581
0.022953037790815842 0.10733379213346811 0.007672895211726427
0.02295004856629021 0.10732530090836198 0.006126790307462215
0.022947636666703866 0.10731717616602307 0.0055985162034630775
0.022945754200707557 0.1073114639262368 0.006355722900480032
0.02294402543328294 0.10730716061622542 0.006992540787905455
0.02294157015300908 0.10729910676463211 0.006712784059345722
0.022939676050170246 0.10729260780130988 0.005630723666399717
0.022937431355092033 0.10728501289365133 0.00511323194950819
0.022935009450445354 0.10727997903577373 0.005536739248782396
0.02293181298232945 0.10727487780873265 0.0058581773191690445
0.022928130140164434 0.10726714154872115 0.00563047593459487
0.022925347743130584 0.1072591608286286 0.00503609050065279
0.022923386236489755 0.10725017028337798 0.00474320026114583
iteration: 36 | epoch: 1868 |   loss: 0.107250  |   KL divergence: 0.022923  |  JS divergence: 0.005702
('==== Found maximium gradient [0.0020098686, 0.0018814632, 0.0018643177] of '
 'gate RY[3], e^[Y10 Z1], e^[Y9 Z10] ====')
learning rate =  0.0003839298027824965
0.02292338170008076 0.10724881405273205 0.005915709305554628
0.022930285624408953 0.10726227891121098 0.019858039915561676
0.022920818217495635 0.10724456202946056 0.013277605175971985
0.022916418327121466 0.10723222374473913 0.012713583186268806
0.022914654107079397 0.10722710669408175 0.013220518827438354
0.02291278042245477 0.10722408446083205 0.01332149188965559
0.02290860902167352 0.10721185602197693 0.011023306287825108
0.022905444542267357 0.10720077028709908 0.008114293217658997
0.022904711554993087 0.10719790035415105 0.00852710660547018
0.022902981434846564 0.1071951719926942 0.010100143030285835
0.02289796661526944 0.10718676666117886 0.009974940679967403
0.0228923161585313 0.10718027359431612 0.008546405471861362
0.0228874171963745 0.10717373640392736 0.007448485121130943
0.022884605424044385 0.10716828135719388 0.00717280525714159
0.02288333329802026 0.1071608825310675 0.00702590262517333
0.022884489838126496 0.10715880652468797 0.00711720809340477
0.022883499732152212 0.10714676093362542 0.007478993386030197
0.022882787097438927 0.10714210851048331 0.007317387033253908
0.022880417284446952 0.10713818357532869 0.006391508970409632
0.02287536473026698 0.10712803939559092 0.005617776419967413
0.02287054573913002 0.10712097560760196 0.005838504061102867
0.022867326562320045 0.10711962384435007 0.006305329501628876
0.02286324712560768 0.10711036386620676 0.006210276857018471
0.02286058107298401 0.10710327947173469 0.0057578072883188725
0.022858835166994013 0.1070973762142699 0.005463471170514822
0.022857769035159223 0.10709379443986634 0.00534834573045373
0.02285539692479778 0.10708501886296773 0.005301313009113073
0.022853527676696274 0.10707989817680746 0.005337198730558157
0.022850738358666994 0.10707134445332493 0.005307590123265982
0.02284843446731663 0.10706524382935945 0.005109116900712252
0.02284629197360585 0.10706001496038069 0.004917978774756193
iteration: 37 | epoch: 1899 |   loss: 0.107060  |   KL divergence: 0.022846  |  JS divergence: 0.005681
('==== Found maximium gradient [0.0019807802, 0.0018324205, 0.0018177032] of '
 'gate e^[X1 Y3], e^[Y11 Z10], RY[11] ====')
learning rate =  0.0003756824896636113
0.02284312186926477 0.10705078055291484 0.005904848221689463
0.022835656803575417 0.10706315857397132 0.0180564783513546
0.022836085049467082 0.10704074563662078 0.011984938755631447
0.022839851705807847 0.10703379630816412 0.012728249654173851
0.022840349340067123 0.10703567006696264 0.014646186493337154
0.022833082333393196 0.10702277860179542 0.010565427131950855
0.022826028585801475 0.10701731054656231 0.00932108610868454
0.022817987301223287 0.1070064448198241 0.009636836126446724
0.022813598090258524 0.10700235253784214 0.009184550493955612
0.022811715596607846 0.10699443861286453 0.009140755981206894
0.02281192309528434 0.10698607932355843 0.008855970576405525
0.022812572460247094 0.10697977257465913 0.00775539455935359
0.022812495103605883 0.10697692645654094 0.006945560686290264
0.022808933633370942 0.10696705642317987 0.00718466704711318
0.02280468808565579 0.10696022522306894 0.0076622446067631245
0.02280004260794804 0.10695275656637668 0.0072835092432796955
0.02279645823215122 0.10694769299272322 0.0062426310032606125
0.022793174744313506 0.10694087195071866 0.005921045783907175
0.022789821838783718 0.10693268674201191 0.006513811647891998
0.022786914761054315 0.10692765294449923 0.006721684709191322
0.022782674366180714 0.10691673225630945 0.006269213743507862
0.02277965402674109 0.10690907955824247 0.005764436908066273
0.022777545675213152 0.10690169640672109 0.005569472908973694
0.02277640153926555 0.1068960377442859 0.0055787088349461555
0.022775434011331263 0.10689151100701007 0.005604343488812447
0.02277221629910954 0.10687969266211114 0.005575362592935562
0.02276979842197268 0.10687596077404708 0.00543510215356946
0.022765357297727433 0.10686619198062218 0.005172876175493002
0.022762270219351236 0.1068637693724232 0.005038006231188774
0.022758237748152936 0.10685561732981808 0.005146979354321957
0.022755268720577673 0.10684979207897381 0.005199078004807234
0.022752223773504183 0.10684079341993222 0.005121295340359211
0.02275081155189004 0.10683748837283624 0.005083047319203615
0.02274816713971865 0.1068283511692874 0.004987143445760012
iteration: 38 | epoch: 1933 |   loss: 0.106828  |   KL divergence: 0.022748  |  JS divergence: 0.005657
('==== Found maximium gradient [0.001947765, 0.0016626478, 0.0016572417] of '
 'gate e^[Y3 Z2], e^[Y0 Z8], e^[Y4 Z2] ====')
learning rate =  0.00035222409239945673
0.022745652298809583 0.10682140784702343 0.005661142989993095
0.02273710428948718 0.10682932410669298 0.020494770258665085
0.022744410670419952 0.10681056545755793 0.010835018940269947
0.022748729900192416 0.1068067685382722 0.014270407147705555
0.022744618982719764 0.10679963151882138 0.015294442884624004
0.022734476234564406 0.10678812877022602 0.011518376879394054
0.02272443707516403 0.10677603615492023 0.008447770960628986
0.022718744566216996 0.10677173696195046 0.00998044665902853
0.022715898350699176 0.10676866611050499 0.011159450747072697
0.022713729788936467 0.10676044183887223 0.00972009263932705
0.02271285634285425 0.10675158446361933 0.007563611958175898
0.022713266471069474 0.10674443830863706 0.00751142343506217
0.022713466945497536 0.10673816219092824 0.008454065769910812
0.022711042170885487 0.10672798846199436 0.008350071497261524
0.022706770557465457 0.10671993052958993 0.007309750188142061
0.02270192259928424 0.10671739931189003 0.006536394357681274
0.022695422699618738 0.10670970040068807 0.006680943537503481
0.022689342159460196 0.10670123106617496 0.007025607395917177
0.02268519620936503 0.10669539660378963 0.0068413191474974155
0.02268162084834902 0.10668394103724733 0.006244030315428972
0.022681008322081378 0.10667914481843814 0.005936182104051113
0.022679909879904273 0.10666939479215305 0.006083696614950895
0.02267961992877244 0.10666648402744658 0.006097368896007538
0.022677168316163114 0.10665963225309338 0.005779858212918043
0.022673262154177552 0.10665123285304311 0.00553834717720747
0.022668492409443533 0.1066411675619256 0.005565047264099121
0.022664393680603138 0.10663415450428895 0.005551430396735668
0.022660826954314046 0.10662821841086469 0.005371347069740295
0.022657087948890015 0.10661982506596061 0.005220266059041023
0.02265366747516557 0.10661155567255987 0.00521027622744441
0.02265107022598775 0.10660621188466082 0.005287195555865765
0.02264857794903765 0.10660059137143063 0.005315188784152269
0.02264585609597644 0.10659283224158503 0.005169674288481474
0.022643666022529707 0.10658660455858743 0.004919362720102072
iteration: 39 | epoch: 1967 |   loss: 0.106587  |   KL divergence: 0.022644  |  JS divergence: 0.005631
('==== Found maximium gradient [0.0017645833, 0.0017025484, 0.0014556028] of '
 'gate e^[Y9 Z0], e^[Y0 Z2], e^[Y3 Z4] ====')
learning rate =  0.0003292659437154864
0.02264114524504557 0.10657904454144314 0.0055934712290763855
0.02263259458628305 0.10657807193965715 0.014674678444862366
0.02263172576200758 0.10656449543551295 0.009651947766542435
0.02263864243554797 0.10655885740881295 0.010977002792060375
0.02263960410816172 0.10654998018058548 0.010584499686956406
0.022632595547055406 0.10654155912435131 0.008895822800695896
0.022622674371264074 0.10653277083881854 0.007556166034191847
0.022613781562253462 0.10652394102331704 0.007917219772934914
0.02260804116849613 0.10651859640037757 0.008379809558391571
0.022604629774176353 0.10651215109700485 0.007821227423846722
0.022602582735269067 0.10650133958201247 0.007247559726238251
0.022602861336498935 0.1064954689156781 0.0068940576165914536
0.022602631283419067 0.10648761762059025 0.006220911629498005
0.022601682147322923 0.10648153166701961 0.006093219853937626
0.022598860959537167 0.10647444364016911 0.0066812774166464806
0.022594224334379204 0.10646595201081217 0.006732163950800896
0.02258917146718891 0.10645853574163366 0.006087334360927343
0.022584312321902725 0.10645076537105169 0.005574030335992575
0.02258044755719626 0.1064444315976554 0.005597363691776991
0.022576837436215105 0.10643622510554979 0.005735436920076609
0.022574315949090908 0.10643100655098202 0.005699878558516502
0.022571412952656633 0.10642268727871719 0.005504895467311144
0.02256864899639182 0.10641412014886069 0.005186003167182207
0.02256636181506924 0.10640730645311862 0.004986563231796026
iteration: 40 | epoch: 1991 |   loss: 0.106407  |   KL divergence: 0.022566  |  JS divergence: 0.005613
('==== Found maximium gradient [0.0016955371, 0.0014706084, 0.001452771] of '
 'gate e^[Y9 Z2], e^[Y1 Z0], e^[X3 Y0] ====')
learning rate =  0.00030871948410750137
0.022564499310408014 0.10640276279158895 0.005755962338298559
0.022564229731254548 0.10640478922843251 0.01716293953359127
0.02255863510341346 0.10639200024695927 0.009404714219272137
0.022557503864211237 0.10638481245093948 0.012027318589389324
0.022555664420918435 0.10637727263855956 0.011097610928118229
0.02255271682749495 0.10637409332383943 0.009875882416963577
0.022547046214686377 0.10636253760470159 0.008757004514336586
0.022541776550676542 0.1063540227917054 0.007896657101809978
0.02253855725934147 0.10634949018656921 0.007805112283676863
0.02253724563951928 0.10634671179319304 0.007806987501680851
0.02253507412661023 0.10633678542188336 0.007548504043370485
0.022533077536657446 0.10632938790883699 0.007176138460636139
0.02253035121556066 0.10632306912348598 0.006591700948774815
0.022527144797000707 0.10631809216696997 0.006009909324347973
0.022523415584002074 0.10631133202528967 0.006062157917767763
0.022519421080064238 0.1063017428376452 0.006436401978135109
0.022517251059488135 0.10629836280164394 0.006336565595120192
0.022514198541707466 0.10628918518548776 0.005704932380467653
0.022511773959634798 0.10628252630095053 0.005151207558810711
0.022509537319663844 0.10627748308868157 0.005177996587008238
0.022506512497417443 0.10627023936666448 0.005518489517271519
0.02250299759170743 0.10626212928598636 0.005589696113020182
0.02249919365142675 0.10625321649333992 0.005220684222877026
0.022496616190970715 0.10624947301356283 0.004772107116878033
iteration: 41 | epoch: 2015 |   loss: 0.106249  |   KL divergence: 0.022497  |  JS divergence: 0.005596
('==== Found maximium gradient [0.0013409465, 0.0013102243, 0.0012503866] of '
 'gate e^[Y3 Z4], e^[Y10 Z0], e^[X11 Y10] ====')
learning rate =  0.00026021252443853726
0.022493240122117397 0.10624073730668758 0.0051997811533510685
0.022496926756475712 0.10624152994491211 0.014883076772093773
0.02249181272431319 0.10623385523777251 0.007467207033187151
0.022485956924756318 0.10622649367605681 0.012094834819436073
0.02248142125869906 0.10622158451861502 0.009331231005489826
0.022478108971590645 0.10621352110846255 0.0064112115651369095
0.022477421422101337 0.10621054945781722 0.008178804069757462
0.02247536582339426 0.10620188485507347 0.008635001257061958
0.022472717665429378 0.10619446681307822 0.006788649130612612
0.022470562543637315 0.10619126831769364 0.005770355463027954
0.02246733819265508 0.10618319435468182 0.006757823750376701
0.022465313094833753 0.10618091155834386 0.007088933605700731
0.02246205238655987 0.1061733420998128 0.006149667780846357
0.022459538560762125 0.1061697231871439 0.005307712592184544
0.022456725153905312 0.1061651255910924 0.005489765200763941
0.022453411136597212 0.10615863643883242 0.005739192012697458
0.02245030184341713 0.10615267863905739 0.005460227839648724
0.0224466709309263 0.10614205462442641 0.0051335678435862064
0.022446065694403484 0.10614242412110086 0.005199591163545847
0.0224438660133735 0.10613307590757237 0.00528931338340044
0.022442972509553405 0.10612998345810351 0.0050507280975580215
0.022440897829503023 0.1061239538420884 0.004723446909338236
iteration: 42 | epoch: 2037 |   loss: 0.106124  |   KL divergence: 0.022441  |  JS divergence: 0.005583
('==== Found maximium gradient [0.0014493192, 0.001408226, 0.0013977825] of '
 'gate e^[X0 Y10], e^[Y3 Z9], e^[Y11 Z1] ====')
learning rate =  0.0002837233742732266
0.022438612189350476 0.10612090070921996 0.005259265657514334
0.022427267592284077 0.10612603375600636 0.0178008321672678
0.022431754866167792 0.10610886118120547 0.00763936759904027
0.022438183175185644 0.1061063164658069 0.012580971233546734
0.022437898352868545 0.10610252769195144 0.012849018909037113
0.022430863425939473 0.10609005574305147 0.008937790058553219
0.022424231572679244 0.10608484969912524 0.006909273099154234
0.02241838914233665 0.10608005028110305 0.008817589841783047
0.022412670181321412 0.10607078706382173 0.00954765360802412
0.022409277801849814 0.10606547855819055 0.00816506426781416
0.022406935324821207 0.10605713916436561 0.006668260786682367
0.022406811936766982 0.10605313648207802 0.006792731117457151
0.02240731402497677 0.1060502313562209 0.007277209311723709
0.022405351694666585 0.10603832106766772 0.006892689503729343
0.022403941608266448 0.10603382213048294 0.006102840416133404
0.022401182184291706 0.10602789514429262 0.0058881924487650394
0.02239798371009572 0.10602380289458505 0.006201823707669973
0.022394100841669644 0.10601854894374448 0.006242835894227028
0.02238954378402592 0.10600986677400448 0.00574391009286046
0.022386206578932862 0.10600479238717517 0.005204417742788792
0.02238208999766271 0.10599326946073762 0.005234131123870611
0.022381757214746622 0.10599730507618307 0.005544799380004406
0.022379339892864468 0.10599034969439747 0.00548891257494688
0.022375730858543663 0.10597729239065311 0.005014779511839151
0.02237417179857268 0.10597364866869591 0.004657607525587082
iteration: 43 | epoch: 2062 |   loss: 0.105974  |   KL divergence: 0.022374  |  JS divergence: 0.005568
('==== Found maximium gradient [0.0013802107, 0.0012905598, 0.0011865512] of '
 'gate e^[Y11 Z1], RY[4], e^[X3 Y1] ====')
learning rate =  0.0002576413537385581
0.022371669349485788 0.10596582340531668 0.005279698874801397
0.022368319188845617 0.10597271832589465 0.019176453351974487
0.02236119729397503 0.10596011575354221 0.008613986894488335
0.02236472813001237 0.10595610686398058 0.01246230024844408
0.022367253896802934 0.10595088024628631 0.013208738528192043
0.022365897836897686 0.1059445566166583 0.010433916933834553
0.02236088466421844 0.10593422336094628 0.008219761773943901
0.022356570144196074 0.10593471639236478 0.008497009053826332
0.022349882502469255 0.10592552245185784 0.009321811608970165
0.022345470062749707 0.10592285326760066 0.009270599111914635
0.022342105548978843 0.10591800451725718 0.00823870301246643
0.022339751980654004 0.10591035885628573 0.006947032641619444
0.0223393007982954 0.10590537237067527 0.006464516278356314
0.02233904505861126 0.10589810709279 0.006868328433483839
0.02233949722430858 0.10589539618554622 0.007246758788824081
0.02233800577502113 0.10588847249260706 0.0069856285117566586
0.02233524923825487 0.10588184792389434 0.006268794648349285
0.02233172059067185 0.1058769652894776 0.005710492841899395
0.02232691463901169 0.10586927126156499 0.005648769438266754
0.022323486948866315 0.10586855204870937 0.005829043220728636
0.022318903765289375 0.105860203728011 0.005858300253748894
0.022315774617354563 0.10585440280217286 0.005639342591166496
0.02231293091617361 0.10584474030009583 0.005329205188900232
0.022312190534029237 0.10584050501779299 0.005112082697451115
0.022311804804319456 0.10583577186575659 0.005071120336651802
0.02231116235207057 0.10583076541068469 0.00512648792937398
0.02231048472224238 0.10582920240727868 0.005105640273541212
0.022307205834655668 0.10582018319522886 0.004919450730085373
iteration: 44 | epoch: 2090 |   loss: 0.105820  |   KL divergence: 0.022307  |  JS divergence: 0.005552
('==== Found maximium gradient [0.0012613415, 0.0011942355, 0.0011683434] of '
 'gate e^[Y9 Z1], e^[Y10 Z8], e^[Y1 Z10] ====')
learning rate =  0.00024172179694401585
0.022303944931139214 0.1058153199026263 0.005134087521582842
0.022295793702855515 0.10581374264572284 0.014317816123366356
0.022294595746867537 0.10580386432133031 0.0076977042481303215
0.02229832593958416 0.10579771018090227 0.010218828916549683
0.022297397872706404 0.10579435671865013 0.009594333358108997
0.022292030429293168 0.10578277011554293 0.00851695891469717
0.022288142118727833 0.10577874110211638 0.007185705006122589
0.02228471490674063 0.10577626374063899 0.006475412752479315
0.022280414740168095 0.10576908342760746 0.006975628435611725
0.02227684143016356 0.10576248160478977 0.0073577528819441795
0.022274441088554836 0.10575721557850144 0.006809252314269543
0.022272784560246416 0.10575241460171583 0.005678216926753521
0.022270608856232374 0.10574427513223561 0.005113212391734123
0.022269115202909362 0.10573853176472395 0.005611554719507694
0.022268394907573562 0.10573527642850797 0.006129931658506393
0.02226697669104758 0.10572946800406641 0.005975986365228891
0.02226364715141358 0.10571872999066358 0.00542377308011055
0.0222608427233948 0.10571621535527576 0.00494390120729804
iteration: 45 | epoch: 2108 |   loss: 0.105716  |   KL divergence: 0.022261  |  JS divergence: 0.005541
('==== Found maximium gradient [0.0015394291, 0.001286805, 0.001240653] of '
 'gate e^[Y10 Z11], e^[X11 Y10], e^[X8 Y10] ====')
learning rate =  0.0002723950170560071
0.02225630781139878 0.10570882181410758 0.00543696666136384
0.022262671232770044 0.10571713519620438 0.020100733265280724
0.022251678321898935 0.10569546116555685 0.01027391292154789
0.022250239086951427 0.10569353844751647 0.012380576692521572
0.02224936543094115 0.10569255808448783 0.01382965687662363
0.02224575572968972 0.10568563625915406 0.011896292679011822
0.022240065920775876 0.10567102746966119 0.008634011261165142
0.022238107607046628 0.10566850358934922 0.007676905486732721
0.02223648689645678 0.10566195672407853 0.009568112902343273
0.022235588504600383 0.10565845937791447 0.010265746153891087
0.02223295803155306 0.10564964638516174 0.00887820404022932
0.022229873844063906 0.10564116001557372 0.00703995767980814
0.022226875282271807 0.10563450559175194 0.006674889009445906
0.022223460620288488 0.10562694017818962 0.007175420876592398
0.022220285665116423 0.10562092268700933 0.0072228615172207355
0.02221823754753562 0.1056198197098906 0.006771353539079428
0.022215625835234815 0.1056148600577955 0.0062959035858511925
0.022213022129552566 0.10560832821254061 0.006014119368046522
0.022210472361488775 0.10560089688561951 0.0059191444888710976
0.02220775144665121 0.1055924864565801 0.005946921184659004
0.022205217421118268 0.10558576253877433 0.0059143719263374805
0.022202807707308758 0.10558086528208098 0.0057158214040100574
0.022200170507418154 0.10557566584952338 0.005511444061994553
0.022196841081578114 0.10556700097396772 0.005425292532891035
0.022194565464822853 0.10556226689259983 0.005300682969391346
0.0221924173114069 0.10555685360242426 0.005053275264799595
0.022189952983162342 0.10554923272892128 0.004897576756775379
iteration: 46 | epoch: 2135 |   loss: 0.105549  |   KL divergence: 0.022190  |  JS divergence: 0.005524
('==== Found maximium gradient [0.001219604, 0.0010842915, 0.0010641828] of '
 'gate e^[X8 Y3], e^[X0 Y10], e^[Y11 Z10] ====')
learning rate =  0.0002249624344366118
0.0221878661808309 0.10554391267955412 0.005327991209924221
0.022185758593255223 0.10554206069034859 0.015505468472838402
0.022184385249933193 0.10553000944592132 0.007534444332122803
0.022183357220603345 0.1055284426433951 0.010035017505288124
0.022177565000158155 0.10552279354044686 0.010230940766632557
0.02217157081994002 0.1055156940120103 0.008748173713684082
0.022168036752804474 0.10550871948796059 0.007701091002672911
0.022167385942574187 0.10550398075246326 0.006899759639054537
0.022166459669665697 0.10549384607825987 0.00691235763952136
0.022166476074529026 0.10549065752409104 0.007476257625967264
0.02216505431187373 0.10548693753872819 0.00753084197640419
0.022161510356888778 0.1054794069485705 0.006583651062101126
0.022157406632381534 0.10547244339957759 0.005418127868324518
0.022153188239596243 0.10546511872412884 0.005440174136310816
0.022149926487648137 0.10546063877104546 0.006204307544976473
0.022147524986856043 0.10545745761916966 0.006402052938938141
0.022145221158202947 0.1054513889483319 0.005822627805173397
0.02214388967723388 0.10544687295847316 0.005114626605063677
0.02214103426980157 0.1054338357006308 0.0049829911440610886
iteration: 47 | epoch: 2154 |   loss: 0.105434  |   KL divergence: 0.022141  |  JS divergence: 0.005512
('==== Found maximium gradient [0.0012136655, 0.0012097022, 0.0011583541] of '
 'gate e^[Y10 Z11], e^[X0 Y10], e^[X10 Y9] ====')
learning rate =  0.0002388345934574474
0.02214072345350019 0.10543397389535641 0.005662711337208748
0.02213341204026484 0.10543701026216461 0.01675987057387829
0.022130799342258207 0.10542234486086914 0.0074643781408667564
0.022135383227833094 0.10541730775240915 0.009913040325045586
0.022137069812393176 0.10541341229782929 0.01150466874241829
0.022133368509476198 0.10540616964820561 0.009654155001044273
0.022126556280934413 0.10539837716552375 0.007003944832831621
0.022119639707188634 0.10539246559934305 0.007104070391505957
0.022114297932578426 0.10538685217412098 0.008441711775958538
0.02211118650617426 0.10538071829557333 0.008263462223112583
0.02210984292844754 0.10537336696988511 0.006973132025450468
0.022110015131046986 0.10536882349364247 0.006025735754519701
0.022109639219951748 0.1053633402705297 0.005942389369010925
0.02210754397881841 0.105355152378226 0.006192825734615326
0.02210498436742443 0.10535044755922154 0.006299673579633236
0.022100580657064033 0.10534018585115974 0.006162378471344709
0.022097916580529994 0.10533847220322307 0.0059022377245128155
0.02209438938993665 0.10533125162151491 0.005684117320924997
0.022091374535666106 0.10532460805153065 0.005539620295166969
0.022089166662293887 0.10532030234690068 0.00541392108425498
0.022086423343452254 0.10531260437506187 0.0052673774771392345
0.022083800645523278 0.10530518399257702 0.005075445398688316
0.022081081479415808 0.10529744167667025 0.00493357889354229
iteration: 48 | epoch: 2177 |   loss: 0.105297  |   KL divergence: 0.022081  |  JS divergence: 0.005498
('==== Found maximium gradient [0.0011780858, 0.00112015, 0.001087041] of gate '
 'e^[X0 Y3], e^[X10 Y9], e^[Y0 Z3] ====')
learning rate =  0.00022581054760426354
0.022078018595961188 0.1052884782945329 0.005342303775250912
0.02207821379853336 0.10529069804834336 0.011826131492853165
0.022076994523939387 0.1052791531383788 0.007739849388599396
0.022072481887391575 0.10527673865589475 0.00856608897447586
0.0220672903950504 0.10526948107336706 0.007364541757851839
0.022064461768499303 0.10526248957512263 0.007391366176307201
0.02206275546770363 0.10525520723101271 0.006974042858928442
0.022061094368429762 0.1052479933598825 0.00607150886207819
0.022059686277700035 0.10524502595213141 0.0060431575402617455
0.022056208557063653 0.1052364990440383 0.006219072267413139
0.022052859924155586 0.10523169133535094 0.005884257610887289
0.02204887886518049 0.10522423372047318 0.0056104715913534164
0.022045840782992453 0.10521849263864369 0.005680522881448269
0.02204342034074791 0.10521198213910411 0.0056622214615345
0.02204103441799636 0.10520350678160845 0.005341873038560152
0.02203936249338928 0.10519876866339513 0.005055921617895365
0.022036221846572016 0.10518932408914994 0.005050991661846638
0.022033336369767592 0.10518362564622245 0.005085264332592487
0.022030785770287255 0.10518073566933048 0.004991880618035793
iteration: 49 | epoch: 2196 |   loss: 0.105181  |   KL divergence: 0.022031  |  JS divergence: 0.005485
('==== Found maximium gradient [0.0011236668, 0.0010671215, 0.0010599823] of '
 'gate RY[8], e^[Y10 Z1], e^[X3 Y4] ====')
learning rate =  0.00021679291296961917
0.02202685912706044 0.10517092188883148 0.005260130390524864
0.022034900958495453 0.10517489275880422 0.01303080003708601
0.022022015349574858 0.10516045340995471 0.009680096991360188
0.02201870438023315 0.10515817004103645 0.009157659485936165
0.02201607154229723 0.10514904278096472 0.008544029667973518
0.02201512785748112 0.10514673635092124 0.008488060906529427
0.022012212282921106 0.10513761918616 0.007564129773527384
0.02201053922451534 0.10513580898553296 0.0067274305038154125
0.022007181481318305 0.10512628761827662 0.0067609259858727455
0.022003817386768106 0.10511660536684517 0.006913972087204456
0.022001049205611793 0.1051096224204614 0.006524637341499329
0.02199857555443257 0.10510409333696297 0.0059833950363099575
0.021996196191550584 0.10509933264851823 0.005954830441623926
0.021993284603767267 0.10509302433008273 0.00607600761577487
0.021990827005449277 0.10509051316020751 0.005846862215548754
0.021986532433130285 0.10508058506900914 0.00553177623078227
0.021984176454715183 0.10507966597969581 0.005423104390501976
0.0219802653507357 0.10506945589314026 0.005360572133213282
0.021977518223839775 0.10506159987508927 0.005241111386567354
0.021976921116291383 0.10506088678657702 0.005124302115291357
0.02197541721323032 0.10505452438233366 0.00508946692571044
0.02197364611960203 0.10504803178165108 0.005086860619485378
0.021969981730317344 0.10503582112888098 0.004961106926202774
iteration: 50 | epoch: 2219 |   loss: 0.105036  |   KL divergence: 0.021970  |  JS divergence: 0.005471
('==== Found maximium gradient [0.001196352, 0.0010163134, 0.0009951395] of '
 'gate e^[Y4 Z3], e^[Y3 Z8], e^[Y0 Z10] ====')
learning rate =  0.00021461449130944348
0.0219681625823784 0.10503606718092758 0.005138047970831394
0.021960685307734817 0.10502903995484428 0.011556396260857582
0.021963831060765462 0.10502034194004024 0.006336742080748081
0.02196449164415555 0.10501777026481286 0.009349600411951542
0.021959964764046967 0.10500710927891097 0.008653204888105392
0.021954719635978902 0.10499859053452261 0.005963760893791914
0.02195126161646642 0.10499519150957047 0.006196219008415937
0.021948242161477567 0.10498775720712167 0.007083526346832514
0.02194654410607946 0.10498199912942804 0.0069074505008757114
0.02194568150214661 0.10497873547993938 0.006037306040525436
0.021943193227414157 0.10496973078718227 0.005353814456611872
0.021940504003176844 0.10496346328753794 0.005664536263793707
0.021937208840758254 0.10495685168479205 0.006073198281228542
0.021933713923897088 0.10494860894477155 0.005797608755528927
0.021931583541770026 0.10494386590115518 0.005260684993118048
0.021928652800835356 0.10493276488023154 0.005154648330062628
0.021927270643846655 0.104929058576197 0.005414921324700117
0.02192509782013941 0.10492424174677092 0.005525239277631044
0.021922109683347814 0.10491866529554962 0.005220614839345217
0.021918789238013395 0.10491275972699858 0.00482527120038867
iteration: 51 | epoch: 2239 |   loss: 0.104913  |   KL divergence: 0.021919  |  JS divergence: 0.005458
('==== Found maximium gradient [0.0012339955, 0.0011489191, 0.001137657] of '
 'gate e^[Y10 Z9], e^[Y4 Z3], e^[Y2 Z0] ====')
learning rate =  0.00023486233958942786
0.021916025472348378 0.10490816063288935 0.005246939603239298
0.02192211093670307 0.10490041868584513 0.013738722540438175
0.021909719600402108 0.1048883426005523 0.008051810786128044
0.02190300270496998 0.10488558844436248 0.011090177111327648
0.021900839432123412 0.10487703325568445 0.008958352729678154
0.02190127718800766 0.10487134906241198 0.007060923147946596
0.021901816904056425 0.10486866826395938 0.007912254892289639
0.021899026431716408 0.10485901540981916 0.00792306661605835
0.021895765829799175 0.10485360894583297 0.007259024772793055
0.021892142361229536 0.10484770085360708 0.006874144077301025
0.021888373277534075 0.1048384846088981 0.006734009832143784
0.02188621200863311 0.10483382348224694 0.006547846831381321
0.02188353512567521 0.10482596990634914 0.0061381203122437
0.02188122793222327 0.10482176023083518 0.005790161434561014
0.021876936460115945 0.10481071953506911 0.0057236384600400925
0.021872598788746426 0.10480066954948247 0.0059113772585988045
0.02186952562882214 0.10479573030392575 0.006011063698679209
0.021867861189787424 0.1047950526064648 0.005718689877539873
0.021864084386360106 0.10478167648013968 0.005338591057807207
0.02186276708404055 0.1047782632396916 0.005292035173624754
0.021860181300512094 0.10476870934813275 0.005392177030444145
0.02185742286004915 0.10475988052935194 0.005338801071047783
0.021854748734614057 0.10475403479634542 0.005120386835187674
0.021851384308661008 0.1047474616103492 0.004997923504561186
iteration: 52 | epoch: 2263 |   loss: 0.104747  |   KL divergence: 0.021851  |  JS divergence: 0.005441
('==== Found maximium gradient [0.0012663398, 0.0012203282, 0.0009858208] of '
 'gate e^[X0 Y3], e^[Y3 Z1], e^[Y9 Z8] ====')
learning rate =  0.0002327991872250839
0.021848037935667072 0.10474247422503973 0.005497689358890057
0.02184892787919615 0.10473529200033105 0.01365893054753542
0.021844575570453016 0.10472895604059748 0.010309595614671707
0.021837599699321506 0.10472713812973133 0.009986057877540588
0.02182988139452309 0.10471328978215153 0.01065822597593069
0.021828120881577828 0.10470973447775046 0.008574563078582287
0.021828129215497927 0.10470100665954683 0.007243429776281118
0.021829012311841308 0.1046937931319718 0.007550566457211971
0.021828768938634144 0.10468896670356027 0.007914096117019653
0.02182573888134262 0.10468322541820428 0.007603317964822054
0.021820576125300417 0.10467685667880197 0.006743934005498886
0.02181440673898625 0.10466753298100058 0.006260296329855919
0.021809333006432223 0.10465920468919349 0.006309792399406433
0.021805263105929916 0.10464939256533476 0.006305924151092768
0.021803687993388603 0.10464608642253408 0.006152702495455742
0.021802250022770454 0.10464052531702611 0.006036045029759407
0.021800484851523784 0.10463325456460687 0.005779064726084471
0.02179780504459539 0.10462327440171361 0.005431920289993286
0.02179437320572406 0.10461210349991047 0.005370085593312979
0.021791854581550918 0.10460773978016519 0.005563604645431042
0.021788444269289237 0.104600961796344 0.005692746490240097
0.021785355723796026 0.1045962746249863 0.005560471210628748
0.0217819098324383 0.1045892260527859 0.005214839708060026
0.02177773437321206 0.10457748136987714 0.005000235512852669
0.021775735218180596 0.1045751427997148 0.005087852478027344
0.021772451409973956 0.10456628926921525 0.005184066481888294
0.021769618368089425 0.10455938268869608 0.005085275042802095
0.021766823855615083 0.10455230574148415 0.004945979919284582
iteration: 53 | epoch: 2291 |   loss: 0.104552  |   KL divergence: 0.021767  |  JS divergence: 0.005421
('==== Found maximium gradient [0.0011075996, 0.0010710543, 0.0010374598] of '
 'gate e^[X0 Y1], e^[X1 Y11], e^[Y10 Z0] ====')
learning rate =  0.00021448408577721454
0.02176383154777141 0.10454406114713763 0.005297655239701271
0.02176512113070559 0.10454095886447058 0.012415285222232342
0.021757900421716173 0.10453124241610312 0.009932280518114567
0.021752135777252476 0.10452504168774399 0.009842987172305584
0.02174970365649354 0.10451799626675794 0.009363089688122272
0.021749557151836567 0.10451204969620258 0.008268523029983044
0.021749393713264252 0.1045081398534936 0.007129277102649212
0.021746503236560206 0.10449868057129771 0.007154240272939205
0.0217421062941097 0.10448791183892728 0.007569905370473862
0.021738888884912527 0.10448545315740206 0.007125944830477238
0.02173486424364729 0.10447721084078358 0.006260874215513468
0.021732619151702194 0.10447364492243104 0.006050754804164171
0.021730060022442852 0.10446586179805765 0.006166026461869478
0.021727751763576178 0.10445858342584699 0.006143913604319096
0.02172621236104252 0.1044559699859382 0.0062052714638412
0.02172253979118057 0.10444466030121713 0.006058612838387489
0.021720163980263555 0.10444056625971404 0.005551452748477459
0.02171674171618788 0.10443195250358767 0.00524950074031949
0.021713556111517148 0.10442463814085808 0.00542626203969121
0.02171060680466544 0.10441817905792349 0.005647479090839624
0.021708021038661717 0.10441254919529255 0.005575141403824091
0.021705858704768537 0.10440761322388757 0.005306883715093136
0.021702717271437348 0.10439703672796632 0.005207021255046129
0.021700113172735694 0.1043893170485723 0.005325946491211653
0.021697361310185837 0.10438248867400254 0.005319313146173954
0.021694086874048054 0.10437495008171141 0.005148957949131727
0.02169194679221267 0.10437356649863962 0.005085571203380823
0.021688008604824144 0.10436304784881587 0.00513905705884099
0.021685584883598955 0.1043584746006678 0.005113397724926472
0.021682068993957627 0.10434748372194079 0.005007787141948938
0.02167966632362516 0.10434130310004545 0.004962825682014227
iteration: 54 | epoch: 2322 |   loss: 0.104341  |   KL divergence: 0.021680  |  JS divergence: 0.005399
('==== Found maximium gradient [0.0011487941, 0.0010724643, 0.0009909549] of '
 'gate e^[X8 Y3], e^[X9 Y0], e^[X3 Y2] ====')
learning rate =  0.00021453512688698398
0.02167696148040609 0.10433402263085871 0.005328345112502575
0.021678011298241595 0.10433276978379342 0.013966633938252926
0.021668554180562412 0.10432070049162474 0.008633687160909176
0.021667112999541986 0.1043188545212939 0.010919292457401752
0.02166334760816865 0.10430678849772616 0.009248681366443634
0.02166224449981474 0.10430234966020774 0.007507923524826765
0.02165989023908044 0.10428973465548513 0.007846077904105186
0.021659297964229954 0.10429008598573278 0.008255821652710438
0.02165569178282165 0.10428290608371905 0.007613911759108305
0.021650576602441886 0.10427316179334062 0.006858736742287874
0.02164660742409661 0.1042683638316041 0.006758422125130892
0.021642340204780893 0.10425763161165011 0.006781438365578651
0.021641330453702007 0.10425749114622611 0.006457447074353695
0.02163851851822067 0.10424599676801875 0.006199255120009184
0.021637553333864787 0.1042437951858413 0.006208652630448341
0.021634068077173288 0.10423242407029686 0.0061392467468976974
0.021630880082470126 0.10422542572122175 0.005915675312280655
0.021628138225646854 0.10422171975745516 0.0057629430666565895
0.021624524682455414 0.10421303926565073 0.005731968674808741
0.021621563164241336 0.10420577702595947 0.005712609738111496
0.021618439522838814 0.10419647390386635 0.0056458888575434685
0.021616728885982067 0.10419389279361713 0.005579217337071896
0.021613095609439973 0.10418316730724708 0.00551658496260643
0.02161046691566939 0.1041785403474306 0.005391281563788652
0.02160647337902074 0.10416808608180915 0.005265816580504179
0.021603520258541106 0.10416239637052616 0.005254081916064024
0.021600470928277948 0.10415533303905734 0.005283061880618334
0.021597798136174417 0.10414887050127704 0.00521793682128191
0.02159483536550836 0.10413995583130675 0.005139019340276718
0.021593113488908126 0.1041365693711786 0.005192737560719252
0.021589848076399243 0.10412637454878222 0.005280673503875732
0.02158736863613981 0.10412127822035554 0.005242215469479561
0.021583336349628043 0.1041100612305829 0.005136180203408003
0.02158022579738498 0.10410388783633528 0.0050781117752194405
0.02157750021948917 0.1040993787276302 0.005046962294727564
0.021574472752485405 0.10409266888270154 0.005015967413783073
0.021570563699962478 0.10408076825489884 0.005015530623495579
0.02156856247995804 0.10407714990733398 0.005041909869760275
0.02156604905315911 0.10407067924971983 0.005061859264969826
0.02156302201378177 0.1040619737187028 0.005048670340329409
0.021560080014842303 0.10405439665902261 0.005008998792618513
0.02155713338912167 0.10404761287248816 0.004984662868082523
iteration: 55 | epoch: 2364 |   loss: 0.104048  |   KL divergence: 0.021557  |  JS divergence: 0.005369
('==== Found maximium gradient [0.0012677781, 0.0012459181, 0.0011454104] of '
 'gate e^[Y11 Z10], e^[Y0 Z1], e^[X8 Y2] ====')
learning rate =  0.000244173114461297
0.02155445407752408 0.10404257273562681 0.005418937653303146
0.021559971410270724 0.10403610307812486 0.012072190642356873
0.021546570907613964 0.10402993882173467 0.014572071842849255
0.02153955856686015 0.10402175767357617 0.010613197460770607
0.021537576024930685 0.10400912926054051 0.010014387778937817
0.021538803499072643 0.10400582506722009 0.010490188375115395
0.02153884464141053 0.10399909013756714 0.008626392111182213
0.02153771889282471 0.10399135245021619 0.0079936683177948
0.021535419851496575 0.10398621014785502 0.008680302649736404
0.021529675600877443 0.10397234353411025 0.008034497499465942
0.02152548552051975 0.10397044928046327 0.006973383016884327
0.021518758320761073 0.10395586424689664 0.007065406534820795
0.02151568901450201 0.10395441412954864 0.007330084219574928
0.02151208795600338 0.10394469028747917 0.0069166128523647785
0.021511189869360382 0.10394265190840504 0.0063142417930066586
0.02150907405762469 0.10393164816154868 0.006179600954055786
0.02150710933598532 0.10392110937921306 0.006170579232275486
0.02150650367505523 0.10391942092666068 0.006080234423279762
0.02150343093777739 0.10391004733414179 0.006098692771047354
0.021498793364105973 0.10389747113047888 0.006065168417990208
0.021494821374545878 0.10389059399718674 0.005846662912517786
0.021491426933077887 0.10388631389660756 0.005586383398622274
0.021488327473178456 0.10388121063901701 0.00549443531781435
0.021485572006460157 0.10387506789007613 0.0054853237234056
0.021482886854055493 0.10386736411757701 0.005398908164352179
0.02147960846742103 0.10385600531973953 0.005371584091335535
0.021477130778839938 0.1038486499775943 0.005433970130980015
0.0214736237615539 0.10383713278166853 0.005400856491178274
0.021472143610582882 0.1038362942392869 0.005263837985694408
0.02146807812679519 0.10382385214935326 0.005190081894397736
0.021465860127392048 0.10382074565531402 0.0052040438167750835
0.02146231420663596 0.10381150204786592 0.005140314344316721
0.0214581466565467 0.10379938021512898 0.005029721651226282
0.021455436457644746 0.10379421890726143 0.005034816917032003
0.021451642775521505 0.10378359000656597 0.005128554534167051
0.02145008274661521 0.10378326944207115 0.005159653257578611
0.021447387592377912 0.10377723310414565 0.005051071755588055
0.02144337381188472 0.10376496018663882 0.00491646071895957
iteration: 56 | epoch: 2402 |   loss: 0.103765  |   KL divergence: 0.021443  |  JS divergence: 0.005340
('==== Found maximium gradient [0.0010656336, 0.0009854527, 0.0009768798] of '
 'gate e^[Y1 Z8], e^[Y1 Z10], e^[Y3 Z0] ====')
learning rate =  0.00020202263474259025
0.021439885538293662 0.10375543441081124 0.00519241439178586
0.02143813069987435 0.10375275699195373 0.013462667353451252
0.021433365055852596 0.10374401426764703 0.010926928371191025
0.021433068234370325 0.10374093741778405 0.011101648211479187
0.021431137799757 0.10373265270652747 0.009114576503634453
0.021429221992593173 0.10372560749929384 0.008564451709389687
0.021427348381471176 0.10371954452841332 0.008699673227965832
0.021425226806978823 0.10371568503562155 0.007962971925735474
0.021421839022016675 0.10370840252007589 0.00733568100258708
0.02141852612291617 0.10370206059902796 0.007371216081082821
0.021414244472496655 0.10369033322019082 0.007141291629523039
0.021411182327416976 0.10368285381209542 0.00655920896679163
0.021410213877503706 0.10368333201000753 0.006362675689160824
0.021407533944115327 0.10367311830560642 0.006421780679374933
0.021406432723298764 0.10366840841152453 0.006180413533002138
0.02140584371255893 0.10366568639587852 0.005975216161459684
0.021403454850468535 0.103656206588956 0.006197073962539434
0.021401190718837296 0.10365085254905802 0.006314783822745085
0.021397836225500164 0.10364358823543326 0.005922302603721619
0.021394985210574057 0.10364034900770432 0.005464752670377493
0.021390769398606593 0.10363008630892494 0.0055037629790604115
0.02138839577631982 0.1036269665941578 0.005655854940414429
0.02138558546688788 0.1036197033609251 0.005471022333949804
0.02138280954992401 0.10361074958614012 0.005219080485403538
0.02138136028773861 0.10360708677255114 0.005259089171886444
0.02137897803168761 0.1035990047057646 0.005415583495050669
0.021376597295252014 0.1035918310676924 0.005443073343485594
0.0213735776666614 0.10358269031000365 0.005399820860475302
0.021372061787074608 0.10358181627627791 0.005352708976715803
0.021367781088045372 0.1035686067613222 0.005227738991379738
0.021365282273239666 0.1035647471856728 0.005056846421211958
0.021362633070825164 0.10356035582626964 0.004997396841645241
iteration: 57 | epoch: 2434 |   loss: 0.103560  |   KL divergence: 0.021363  |  JS divergence: 0.005319
('==== Found maximium gradient [0.0010938091, 0.0010742279, 0.0010364533] of '
 'gate e^[Y8 Z0], e^[X9 Y1], e^[Y9 Z10] ====')
learning rate =  0.00021368572324091824
0.021359848723592166 0.10355469264713231 0.005375843495130539
0.021362509685257252 0.10354763485673356 0.013664236292243004
0.02135333456302338 0.10353975059458155 0.010505101643502712
0.021351485938783346 0.103535399342162 0.011223803274333477
0.021348586439553587 0.10352964743725986 0.009471363388001919
0.021346386711908808 0.1035190024104977 0.00905139371752739
0.021346546265230776 0.10351587935746968 0.0087075000628829
0.02134491638195821 0.10350867796100933 0.0075850170105695724
0.02134111061618966 0.10349905090316693 0.007506689988076687
0.021336575200168947 0.10349191428175547 0.008154903538525105
0.02133267656039844 0.10348850730385753 0.007701484020799398
0.021328722008805742 0.10348090644318925 0.006495568435639143
0.021325863701914485 0.10347280935905043 0.006299544125795364
0.021324064362704884 0.10346589060963285 0.006702357903122902
0.0213227062607533 0.10346103490905482 0.006547273136675358
0.0213200125427525 0.10345190836328982 0.006263709161430597
0.02131725852542833 0.10344439925171811 0.006208803504705429
0.021314658192863642 0.1034384838175315 0.006003678310662508
0.021311756320007615 0.10343166411320082 0.005777321755886078
0.021309116291985238 0.10342698847634449 0.005866446532309055
0.02130468734846159 0.10341477534164818 0.0060112737119197845
0.02130214045919517 0.10341223644904765 0.005871163681149483
0.02129775193991977 0.10340012359568938 0.005510341841727495
0.0212960383832903 0.10339887667120502 0.0052871969528496265
0.021292991255735253 0.10338894401502292 0.005322649143636227
0.021291139027352603 0.10338359977049247 0.0053592221811413765
0.021288210668300077 0.10337341263655951 0.005348146427422762
0.021285860505551615 0.10336737067992381 0.005412441212683916
0.02128224252138611 0.10335679428466527 0.0054555777460336685
0.02128011838760961 0.1033546183986852 0.005357943009585142
0.021276538638168058 0.10334601619157317 0.0052175940945744514
0.021273449123358018 0.10333982639730187 0.005139675922691822
0.021270269540372817 0.10333272790253592 0.005110893864184618
0.021267265850182897 0.10332542203532256 0.005080052185803652
0.021264525876439927 0.1033180487159228 0.005059832241386175
0.021262095780105607 0.10331114832782493 0.00507824681699276
0.021259680007016515 0.10330415203857511 0.005103777162730694
0.02125720533678815 0.10329775777658774 0.005125795491039753
0.021253862882319743 0.10328864730062004 0.005125212017446756
0.02125004380765378 0.10327838171432842 0.005046060308814049
0.021246842832592795 0.10327132244115506 0.0049498556181788445
iteration: 58 | epoch: 2475 |   loss: 0.103271  |   KL divergence: 0.021247  |  JS divergence: 0.005290
('==== Found maximium gradient [0.0011181919, 0.0010683537, 0.0010651792] of '
 'gate e^[Y0 Z9], RY[9], e^[X8 Y9] ====')
learning rate =  0.00021683602301413604
0.02124426984692474 0.1032667130209093 0.005290731322020292
0.021250241856678547 0.10326166318952405 0.011875128373503685
0.021237247005562426 0.10325093439983679 0.013671746477484703
0.021231226609893246 0.1032443526542728 0.009699657559394836
0.021231084802446128 0.10323634482003592 0.01006236020475626
0.021233366029395365 0.10323473363688947 0.010158617980778217
0.021232944168061867 0.10323082735615456 0.008102827705442905
0.021229258041584615 0.10322118297098584 0.008103633299469948
0.021225241737002864 0.10321365205285896 0.008536056615412235
0.021221811625722002 0.10320807077366104 0.00756303733214736
0.02121786260582976 0.10319690830539655 0.006899893283843994
0.021216484684438777 0.1031959030281281 0.0071624163538217545
0.021213388393240863 0.10318676390307666 0.0071840849705040455
0.021210229133639437 0.10317827628420245 0.006818908266723156
0.021207920561103554 0.10317436252300471 0.006511530838906765
0.021204917336421207 0.10316705005144457 0.0063478779047727585
0.021201591077463836 0.10315741775871036 0.006126987282186747
0.02119974472031824 0.10315350458370404 0.005964736919850111
0.02119723389774178 0.10314531552162697 0.005974052008241415
0.02119539105079913 0.10314045014286527 0.0060379416681826115
0.021191827923615462 0.10312847819207274 0.005943344905972481
0.021190244018433474 0.10312781620926602 0.0056803361512720585
0.021187321626329057 0.10312216582990832 0.005483604036271572
0.02118348048990128 0.10311281139303866 0.005510904360562563
0.021180333761397042 0.10310666693355314 0.005638978909701109
0.02117689898482201 0.10309805033706655 0.005580849479883909
0.021174570691196222 0.10309292137222724 0.005354784894734621
0.021172009752537385 0.10308474258266136 0.005258019082248211
0.021169626888683308 0.10307653265642333 0.005362125113606453
0.021167076849691564 0.10306826621692969 0.005369850900024176
0.021165059841792937 0.10306438707797409 0.0052465032786130905
0.02116079448480111 0.10305145544970376 0.005260996054857969
0.02115729626435077 0.10304335476840865 0.00533401221036911
0.021154950030848087 0.103041023260509 0.005234180949628353
0.021151604051774603 0.10303310670326007 0.00510950293391943
0.02114862034598991 0.10302559974896332 0.005142983049154282
0.02114570572599374 0.10301718642893261 0.0051513067446649075
0.021144477555680184 0.10301631204533462 0.005072654690593481
0.021140970874130346 0.10300449632044427 0.005092951003462076
0.021138607259725856 0.10299878267145789 0.0051618413999676704
0.021135351749474222 0.10298956578780731 0.005099623464047909
0.02113239868760634 0.10298259119934658 0.005020487122237682
0.02113004598525651 0.10297903952953916 0.00504693016409874
0.02112610267484765 0.10296782495469453 0.00506229605525732
0.021123172294140204 0.10296098876511561 0.005018165800720453
0.021120584513629838 0.10295508621317596 0.005000860895961523
0.021117907705340163 0.10294826246974319 0.005007607396692038
0.021114299587081612 0.10293677799824667 0.004991588182747364
iteration: 59 | epoch: 2523 |   loss: 0.102937  |   KL divergence: 0.021114  |  JS divergence: 0.005256
('==== Found maximium gradient [0.0013167015, 0.0012113623, 0.0011994385] of '
 'gate e^[Y9 Z3], e^[X1 Y9], e^[X10 Y9] ====')
learning rate =  0.00024872350265877773
0.021112995824458473 0.10293656577427017 0.005416771862655878
0.02111436218655663 0.10292739540241548 0.013475710526108742
0.02110500317869409 0.10291868953762405 0.016842937096953392
0.021102258209204215 0.10291568135202214 0.011297522112727165
0.021099086184707877 0.10290351185769103 0.010928761214017868
0.02109910517681008 0.1029026769336327 0.012374143116176128
0.021096692434891394 0.10289437116138077 0.00966579094529152
0.021092709388309077 0.10288287873419882 0.008249995298683643
0.021088830915862326 0.10287495473032297 0.009697279892861843
0.021086176633502637 0.10287449939529045 0.009402668103575706
0.021082036299736612 0.10286530728819027 0.007577571086585522
0.0210793277641672 0.10285905925119741 0.00717955082654953
0.02107710089116516 0.1028525317566631 0.007959302514791489
0.021074009019532592 0.10284198041515516 0.007888591848313808
0.02107184508369235 0.10283745004116093 0.007022400852292776
0.021068856235778165 0.10283065043507061 0.006391742266714573
0.021065802452700837 0.10282476206109134 0.006475046742707491
0.02106256591565857 0.10281834527287945 0.0067187221720814705
0.021058714598683206 0.10280841414906765 0.006544752512127161
0.021055200284922436 0.10279874202770904 0.0060631330125033855
0.021052858218115308 0.10279313532555204 0.005828190129250288
0.02105065756680926 0.1027874705016116 0.006021180190145969
0.021048702768551426 0.10278380243018491 0.006120859179645777
0.021044491261227014 0.10277098679275164 0.005833510775119066
0.021041149518365686 0.10276360093514807 0.0054905712604522705
0.0210381309301393 0.10275753400120745 0.005359958857297897
0.021035382655588842 0.10275153129393456 0.0054131923243403435
0.021032112229738307 0.10274183307675794 0.005548871587961912
0.021029580902800986 0.10273537621893232 0.005563491024076939
0.02102724049822965 0.10273025061721205 0.005379198119044304
0.021024061185336153 0.10272163711963915 0.00522127328440547
0.02102039188572393 0.10271101901936847 0.005252217408269644
0.021017039298329213 0.10270207255982973 0.005233432166278362
0.021014227124578566 0.10269564615400169 0.005048573017120361
0.021011374777936857 0.10268871502473943 0.004986878018826246
iteration: 60 | epoch: 2558 |   loss: 0.102689  |   KL divergence: 0.021011  |  JS divergence: 0.005231
('==== Found maximium gradient [0.0012343911, 0.0011716239, 0.0010969753] of '
 'gate e^[Y1 Z3], e^[Y1 Z10], e^[Y2 Z10] ====')
learning rate =  0.00023380272238671888
0.021008314580289907 0.10268045771343365 0.005501043517142534
0.021006247983259597 0.10268322816031028 0.018407480791211128
0.0210059102647153 0.10267106729969033 0.014441906474530697
0.021003809468624495 0.1026679776963318 0.013574657961726189
0.021000660973955497 0.10265654778223846 0.013889174908399582
0.02099892647942308 0.10264900259554909 0.012211560271680355
0.02099660638650833 0.10264342364788255 0.009608561173081398
0.020992817949115082 0.1026383846581346 0.009239553473889828
0.020988732129148854 0.10263370524132207 0.010058710351586342
0.02098485228814663 0.10262531464595046 0.00981820747256279
0.02098211718492308 0.10261598432718204 0.008614647202193737
0.020981695562588023 0.10261271083052549 0.007719098590314388
0.020980210751453888 0.10260260157158546 0.00775647908449173
0.020979136625381454 0.10259759861911012 0.00785871036350727
0.020976412774612443 0.10258980167493983 0.007489488925784826
0.020972238470904094 0.10257871928915012 0.007218069396913052
0.020969347806566035 0.10257477188854396 0.007169900927692652
0.020967541806997357 0.10257482673545085 0.0068098437041044235
0.020963490196141875 0.10256211459055321 0.0061689214780926704
0.020961079150650982 0.10255629753490138 0.00600794330239296
0.020959163473976136 0.1025532408089656 0.006382534746080637
0.020955229503691816 0.10254117366315228 0.006425997242331505
0.020952447504016487 0.10253420061231565 0.005958423018455505
0.020950573571523586 0.10252977964641176 0.00560800964012742
0.020948523205618 0.10252300722035168 0.005711155477911234
0.020945801630071932 0.10251333788279272 0.005832334514707327
0.020943599063682965 0.10250820566090595 0.005757581442594528
0.02094040499413229 0.10250077646847958 0.00560381356626749
0.020936964676781442 0.10249404051047895 0.005401419010013342
0.02093336171840367 0.1024869666210133 0.005211829207837582
0.020930701998274286 0.10248316856492459 0.005215800832957029
0.020927200143108927 0.102472792889016 0.005351967178285122
0.020924147493252398 0.10246229864158805 0.005339763592928648
0.02092191768920337 0.10245484863715808 0.005192764103412628
0.020920923836580733 0.10245400477517914 0.005138143431395292
0.020917522200826183 0.10244294675343926 0.00520946504548192
0.020914139800620606 0.1024335123414577 0.005221698433160782
0.020910359628082915 0.10242324069021626 0.005088769365102053
0.020908161871899884 0.10242109061408683 0.004945144988596439
iteration: 61 | epoch: 2597 |   loss: 0.102421  |   KL divergence: 0.020908  |  JS divergence: 0.005204
('==== Found maximium gradient [0.0016988843, 0.0012500315, 0.0012236821] of '
 'gate e^[Y10 Z2], e^[X2 Y10], e^[X10 Y0] ====')
learning rate =  0.00028157142086302097
0.020905241477124487 0.10241511044741056 0.005510556511580944
0.020911670194202675 0.10241617451620692 0.01933252438902855
0.020900960783401753 0.1024033119824199 0.019258515909314156
0.020892002618602537 0.10239419292798337 0.015333056449890137
0.02089043288213885 0.10238518195901196 0.016288241371512413
0.020890913971109554 0.1023779088239918 0.0134127177298069
0.020890484168417274 0.10236960311561741 0.01066941674798727
0.02088952169376916 0.10236505126870839 0.011460870504379272
0.020886457070455094 0.10235714301370769 0.011825768277049065
0.020882490470240923 0.10235057277558629 0.010724994353950024
0.020877231513519563 0.10234062074087716 0.009724348783493042
0.02087340248596183 0.10233773119490898 0.009066290222108364
0.02086803594552846 0.10232460048857528 0.008501775562763214
0.020865064566821676 0.10231760510795213 0.008427109569311142
0.020864223536183026 0.10231511624338402 0.008265458978712559
0.02086222733408246 0.10230345369484369 0.007844357751309872
0.020861193354980878 0.10229698320002549 0.007749263197183609
0.02085889655600011 0.10228925551319193 0.007601155433803797
0.020855118061215972 0.10228072492505716 0.006939172279089689
0.020849824447627462 0.10226852126579129 0.00662741344422102
0.020847172970289554 0.10226890936550453 0.00708915526047349
0.020842046006332576 0.10225500645821874 0.007124238647520542
0.020837931144826023 0.10224379921933803 0.006341985892504454
0.020836318960212857 0.1022431404912998 0.005818921606987715
0.020832899735877406 0.10223250664955695 0.006153744179755449
0.02083103413756992 0.10222849726692916 0.006424800027161837
0.020827896927623393 0.10221746784339639 0.006174071691930294
0.020824894858534483 0.10220711205010011 0.0058937277644872665
0.020822925699924673 0.10220361780666633 0.0058397818356752396
0.020819354140996102 0.10219550038921088 0.005747505929321051
0.02081393108656673 0.10218079967056126 0.005690422374755144
0.02081111997792816 0.10217883258422678 0.0057611167430877686
0.020807170848234777 0.10216907848042907 0.005705793388187885
0.020804027955952285 0.10216042108548955 0.005510570481419563
0.0208011812266954 0.10215149358006548 0.005371875129640102
0.02079866494288791 0.10214420935581038 0.00537066999822855
0.020794729978703408 0.10213121015819294 0.005463607609272003
0.02079184405897172 0.10212488000560653 0.005490539129823446
0.020788504814438155 0.10211763315988515 0.005360554438084364
0.020784410972668803 0.10210733084475193 0.005199220031499863
0.02078101156302717 0.10210015755026883 0.005201771855354309
0.02077804190842741 0.1020941023268337 0.005302011966705322
0.020774200074722436 0.10208274973155787 0.005287928506731987
0.020770822975934626 0.1020732501622872 0.00519175361841917
0.02076836338850299 0.10206864307193861 0.0051351748406887054
0.020763923941126267 0.10205506792481461 0.0051217940635979176
0.02076073976749933 0.10204785982344888 0.0051456899382174015
0.020756846921942643 0.10203689466945812 0.005158843006938696
0.020753707707265513 0.10202939598191098 0.005094863474369049
0.02074907811293223 0.1020149993343205 0.0050334446132183075
0.0207456119364903 0.10200704219287464 0.005060541909188032
0.020742879687384683 0.10200303984392844 0.0050950078293681145
0.020739269669604692 0.10199420317363395 0.005064886994659901
0.020735182036420708 0.1019819341389795 0.005024068523198366
0.020731725766040616 0.10197204258084311 0.005027928855270147
0.020729709868427846 0.10196949670067754 0.005033869296312332
0.020724681611574675 0.10195328891592133 0.005006819032132626
0.02072204032097575 0.10194972876112092 0.004980358295142651
iteration: 62 | epoch: 2655 |   loss: 0.101950  |   KL divergence: 0.020722  |  JS divergence: 0.005156
('==== Found maximium gradient [0.0012750675, 0.0012074363, 0.0011173609] of '
 'gate e^[Y1 Z11], e^[Y2 Z3], e^[Y1 Z0] ====')
learning rate =  0.00024033851162410153
0.020717789977141042 0.1019385481974655 0.005389597732573748
0.020717024454125113 0.10193264764545841 0.014833194203674793
0.020711564854936033 0.10192673916722413 0.019675377756357193
0.020709291102617503 0.10191766248780168 0.012524541467428207
0.020709586601956632 0.10191636076226315 0.014417380094528198
0.020704824707881576 0.10190518722080487 0.012904386967420578
0.020700547401999978 0.1018998829795953 0.0101052550598979
0.020697465466593686 0.10189275582399097 0.01144448947161436
0.020696434307371784 0.10188964005801514 0.011141468770802021
0.020693203479354227 0.1018748405412551 0.00925397127866745
0.0206923143722237 0.10187446943093915 0.009129342623054981
0.020688460284527296 0.10186533745530309 0.009273833595216274
0.02068408130380481 0.10185752839382273 0.008324247784912586
0.020680345054197073 0.10185247645012646 0.007894298993051052
0.020676371626059953 0.10184325148198277 0.008300053887069225
0.020673066953851835 0.10183359320719791 0.008002928458154202
0.020671726068050275 0.10183001683440535 0.007105283439159393
0.020669490093811332 0.10181989395447315 0.006943950895220041
0.02066815762503671 0.10181468043678606 0.00730067677795887
0.02066536143265048 0.10180540708464085 0.007092304527759552
0.020662852151372618 0.10180153030852274 0.006560998503118753
0.020658536439904514 0.10179192212648204 0.006421587895601988
0.02065432567147376 0.10178398035315858 0.006421907804906368
0.020650742812142353 0.10177774963674356 0.006226297002285719
0.0206482208402873 0.1017732901281566 0.006162142846733332
0.02064503551917686 0.10176193425184851 0.0062357415445148945
0.020642876591070433 0.10175373658047993 0.006030848249793053
0.02064026009214704 0.10174391521410868 0.00571114756166935
0.02063838009085632 0.1017400405166668 0.005749114789068699
0.02063486298487329 0.1017308223505799 0.005928097292780876
0.020631149414909962 0.10172222279449161 0.005807925947010517
0.0206274266364014 0.10171345481669179 0.00551252206787467
0.020624155664141972 0.10170574478090094 0.005442407913506031
0.020621949003858896 0.10170227893175449 0.00558398338034749
0.020618765802974788 0.10169386002534699 0.005618520081043243
0.02061495877834866 0.10168251965334266 0.005454352591186762
0.02061249672749235 0.10167745623749531 0.0052854265086352825
0.020608806896843176 0.10166553706681135 0.005290222354233265
0.02060582648573338 0.1016564742144532 0.0053827473893761635
0.020603144609056243 0.10164930345227198 0.005366991739720106
0.020600987179884143 0.10164620790540596 0.005254930816590786
0.020597741224881075 0.10163943806431729 0.0052329013124108315
0.020593364494641313 0.10162783320202758 0.005296750925481319
0.02058991659647164 0.10162008851858648 0.00526984641328454
0.02058674419014486 0.10161202890515282 0.005160970613360405
0.020583549870685745 0.10160230961507075 0.005116288084536791
0.02058134718844974 0.10159699094049425 0.0051439483650028706
0.020578124379208418 0.10158745221042172 0.005160800646990538
0.020576710695263824 0.10158819069293176 0.00514775887131691
0.020571201778838574 0.10156999779763884 0.005136493593454361
0.02056752766182516 0.10156112097120232 0.005138010252267122
0.02056482992582751 0.10155646348721771 0.005130274686962366
0.020561554082011727 0.10154794961527225 0.005097175482660532
0.020558849074905815 0.10154142342050314 0.0050634047947824
0.02055529732494112 0.10153064670251265 0.005052452441304922
0.020551969424785044 0.1015216113152281 0.005043761804699898
0.020549109113183646 0.10151572638589329 0.005032498389482498
0.020545794657944753 0.1015079851335749 0.005043754354119301
0.02054149311800495 0.1014950014319914 0.005061176139861345
0.0205396057862749 0.10149309486421851 0.005050441715866327
0.020536172308822553 0.10148313819989237 0.005028522107750177
0.020532079809587524 0.10147018391286286 0.005011513363569975
0.020528989918634583 0.10146285643792434 0.004989036824554205
iteration: 63 | epoch: 2718 |   loss: 0.101463  |   KL divergence: 0.020529  |  JS divergence: 0.005108
('==== Found maximium gradient [0.0011407987, 0.0011074599, 0.0010960633] of '
 'gate e^[X3 Y8], e^[X11 Y1], e^[X1 Y2] ====')
learning rate =  0.00022298711525931908
0.02052599028477066 0.10145647563811959 0.00532999262213707
0.020527696840439914 0.1014526255896529 0.011355231516063213
0.02051661513424239 0.10144727637429343 0.016901463270187378
0.020514134104879816 0.10143762560527983 0.010843613184988499
0.020515933918751672 0.10142864289526286 0.011911064386367798
0.020515769486526135 0.10142457456930663 0.01052319910377264
0.0205120353845343 0.10141914782525169 0.009303458966314793
0.020506346511834948 0.10140928596030106 0.00958437193185091
0.02050213147408551 0.10140222744908385 0.009009194560348988
0.02050026586465417 0.10139935134728886 0.00808044709265232
0.020497577475867754 0.10138734849499464 0.00769766652956605
0.02049610484207009 0.10138076452508787 0.007781240623444319
0.02049416409279205 0.10137477012086875 0.00780352670699358
0.020491438794743612 0.10136899421412073 0.0071480125188827515
0.020487031177359807 0.10135711689660898 0.006343131419271231
0.020485120317473657 0.10135613380906092 0.006621795706450939
0.020481857875395956 0.10134539818286595 0.007090109866112471
0.0204804031914359 0.10134136546340548 0.006562141235917807
0.020478122861172725 0.10133341888216679 0.005866301245987415
0.020474772056237205 0.10132287710953848 0.0060693444684147835
0.020472456512559738 0.10132097172955086 0.006347548682242632
0.020468575318507078 0.10131298854081104 0.00604233518242836
0.0204651548169388 0.10130592521553154 0.005673988256603479
0.020462514791944688 0.10129949167802188 0.005660138558596373
0.020459780085378493 0.10128959410835646 0.005731418263167143
0.020457638816755684 0.10128158431139932 0.005728279706090689
0.02045607053424349 0.10127789238364975 0.005703436676412821
0.02045253040127188 0.10126770847956165 0.005589260254055262
0.020449658188140173 0.10126375370021136 0.005421748850494623
0.020445568649262794 0.10125459658634121 0.005377989262342453
0.02044184452238591 0.10124555905290653 0.005433681420981884
0.020439261896112143 0.10123937613627954 0.005392048042267561
0.020436480753476892 0.1012301977763568 0.005266064777970314
0.020433938330096865 0.10122183946721025 0.005294461268931627
0.020432098879253124 0.10121811006636125 0.005395765881985426
0.020428309896213394 0.10120657666581491 0.005313822068274021
0.020425821117790333 0.10120289216392499 0.0051832967437803745
0.020422515536618027 0.10119565898831887 0.005183335859328508
0.02041976000396179 0.10119043143379983 0.005184843670576811
0.020414975291877663 0.10117374601393667 0.005133196711540222
0.020413712104534007 0.10117325359083006 0.005128174554556608
0.020410585582924436 0.1011636169762371 0.005143259186297655
0.02040698231188061 0.10115261075534165 0.005131441168487072
0.020404369340718695 0.10114739590015323 0.0051106675527989864
0.020401880304186985 0.10114295132440908 0.005070035345852375
0.020398963830313883 0.10113590945220889 0.005035037640482187
0.020396255641493954 0.10112931853996075 0.005038389004766941
0.020392224676065093 0.10111603689588063 0.005033171270042658
0.020389394434099234 0.10110898505641008 0.0050067841075360775
0.020386320885349682 0.10110124590199386 0.005003088619560003
0.02038304700282004 0.10109274009082655 0.005006704479455948
0.020380894135653645 0.10108946790995994 0.004985225852578878
iteration: 64 | epoch: 2770 |   loss: 0.101089  |   KL divergence: 0.020381  |  JS divergence: 0.005070
('==== Found maximium gradient [0.0010923811, 0.0010615943, 0.0010211299] of '
 'gate e^[Y8 Z9], e^[X10 Y0], e^[X2 Y3] ====')
learning rate =  0.00021175411901989895
0.020377709655397234 0.10108054433660796 0.005286580417305231
0.02038072908384896 0.10107420458815926 0.01218327321112156
0.020367923264136598 0.10107195374416507 0.01628388650715351
0.020369722601647936 0.10106151067467344 0.010580434463918209
0.02037301227128914 0.10105861929672613 0.010589483194053173
0.02036996514131207 0.10105181789285382 0.011430754326283932
0.020363035343071226 0.10104253910316809 0.00910523347556591
0.020358109892040337 0.10103877352625572 0.008424868807196617
0.02035501060257521 0.10102961244064046 0.00910582859069109
0.020354188637785344 0.10102145155137637 0.008620667271316051
0.02035477773091445 0.10101834534956058 0.007500943262130022
0.02035273139734878 0.1010084871686962 0.007271931506693363
0.02035043583077173 0.10100678158694812 0.007753768004477024
0.02034463138379821 0.1009938797685691 0.007627064362168312
0.020340763481786678 0.10099024323386765 0.0067641856148839
0.020338447226633284 0.10098872296124999 0.0063288346864283085
0.02033435146661149 0.10097240160323058 0.006642973516136408
0.020333236034646925 0.10096802872442198 0.006627706345170736
0.02033162678187097 0.10096163781390997 0.006145932245999575
0.020329493817587998 0.10095496019359461 0.005966040771454573
0.02032679461517838 0.10094839081732854 0.006147005129605532
0.020322813097335926 0.10093781067024334 0.0061621833592653275
0.020320798029725695 0.10093790142856256 0.005876083858311176
0.02031716765927727 0.10092933213522441 0.005604269448667765
0.020314530105470012 0.10092390925419674 0.00561431422829628
0.020312237656015 0.10091862018629061 0.005691541358828545
0.020310054623358095 0.10091332330452048 0.00553264981135726
0.020305878144603183 0.10089849573996425 0.0053230170160532
0.020303448800983993 0.10089290178778643 0.005372357554733753
0.020300874241545194 0.10088709254479512 0.005459466017782688
0.02029813771200164 0.10088078035773976 0.005337725859135389
0.020295077969676226 0.10087308276574454 0.005217768717557192
0.020292252766814654 0.1008666800407144 0.005269770510494709
0.020289363901147106 0.10085989635220774 0.005285194609314203
0.020286586182462794 0.10085334082607864 0.005139186512678862
0.020283030660876368 0.10084260032229984 0.005032436456531286
0.020280075584440414 0.10083473733933605 0.005061965901404619
0.02027820212620918 0.10083230678373153 0.005083425436168909
0.020275387229776787 0.10082522127054 0.005058224778622389
0.02027265599279776 0.10081849539721387 0.0050386907532811165
0.02027046110031193 0.10081461521802453 0.005021966062486172
0.020267058388496927 0.10080517937670641 0.00498847896233201
iteration: 65 | epoch: 2812 |   loss: 0.100805  |   KL divergence: 0.020267  |  JS divergence: 0.005042
('==== Found maximium gradient [0.0011847019, 0.0009881915, 0.00097315386] of '
 'gate e^[X3 Y8], e^[X1 Y2], e^[Y10 Z9] ====')
learning rate =  0.00021062033963583683
0.020263999838687458 0.10079756632975727 0.00526982918381691
0.020263647985565902 0.10078988337129138 0.013011286966502666
0.020257859463069464 0.10078498919564283 0.015683626756072044
0.02025855465654539 0.10078122389936917 0.012011313810944557
0.020255626162095038 0.10077081280206489 0.010239649564027786
0.02025356492256954 0.10077130988153206 0.010650333017110825
0.020249430128705413 0.1007612638133854 0.010286182165145874
0.020247221009345666 0.10075624926820027 0.008455379866063595
0.020245359946674153 0.10074909888921946 0.00847178976982832
0.020243997746617448 0.10074528468072122 0.008897275663912296
0.020240526857594886 0.10073509089004737 0.0078080035746097565
0.020238388152209602 0.10073433638010189 0.006984001956880093
0.020234944651458708 0.10072617606122794 0.007388782687485218
0.020232901214664045 0.1007221122632208 0.007495688274502754
0.020231366883787166 0.10071807036350482 0.006982453167438507
0.020228614490319076 0.10070710622429521 0.006454707123339176
0.02022745444009659 0.10070458411217371 0.006322239991277456
0.02022513803788777 0.10069793933744595 0.006393775809556246
0.020222375980262497 0.10069119223229091 0.006296971812844276
0.02021925134113975 0.10068418468349498 0.006083762738853693
0.0202165428784857 0.10067940323611557 0.0059804064221680164
0.020212473225587637 0.1006667026057035 0.005873885937035084
0.020210754037335292 0.1006637749980136 0.0056812576949596405
0.02020880991786859 0.10065809652900347 0.005563493352383375
0.02020586786142607 0.10064667560198857 0.005517889745533466
0.020203864830170597 0.10064037208453865 0.0054739732295274734
0.02020207947616232 0.10063686394980167 0.0054748812690377235
0.02019842452082033 0.10062633709983461 0.005478098522871733
0.020196444091257773 0.10062563597544441 0.005351115018129349
0.020192794183215988 0.1006166420921304 0.005144019611179829
0.02018940810064139 0.10060757208248065 0.0051015024073421955
0.02018770645010132 0.1006051080064347 0.005212940275669098
0.020185773737558785 0.10060025191177416 0.00518686743453145
0.020183363204963625 0.10059258012580842 0.005031922832131386
0.020181704512690343 0.10058904906273379 0.005026029888540506
0.020178415700288818 0.10057863138844471 0.0051121897995471954
0.020175919748079453 0.10057354928135244 0.005058605689555407
0.02017386421127375 0.1005715308245875 0.004933975636959076
iteration: 66 | epoch: 2850 |   loss: 0.100572  |   KL divergence: 0.020174  |  JS divergence: 0.005018
('==== Found maximium gradient [0.0011996232, 0.00096815143, 0.0009458482] of '
 'gate e^[Y8 Z2], e^[Y3 Z2], e^[Y0 Z2] ====')
learning rate =  0.0002088393853271657
0.02016955787191159 0.10055835981221088 0.005226879846304655
0.020173536160850557 0.10055498991628455 0.014520927332341671
0.0201637084106582 0.10054785016680726 0.014836608432233334
0.02015815937934616 0.10053841444275513 0.01229042373597622
0.020157275495006968 0.10053223651085279 0.011146336793899536
0.020157246356667408 0.10052648373816339 0.01049515139311552
0.0201576425214553 0.10052609942626693 0.008935220539569855
0.02015389363401921 0.1005102101009686 0.008995743468403816
0.02015197063500628 0.10050846964087837 0.009568048641085625
0.020149121819498544 0.10050556419289487 0.008214766159653664
0.02014584753847723 0.10050063882276851 0.0067013828083872795
0.02014248715628627 0.10049318374421025 0.007335531525313854
0.020139493973196525 0.10048552143360291 0.007773681543767452
0.02013772654679438 0.10048209227825136 0.007044441532343626
0.02013533740657678 0.10047324280528634 0.006593851372599602
0.020134406374560796 0.10047002657309897 0.006655061151832342
0.02013165272333647 0.1004582058613236 0.006383528001606464
0.02012968147444484 0.10045256018296732 0.006129059940576553
0.02012791612200649 0.10045084182034922 0.006241137627512217
0.02012401681611845 0.10044050439538574 0.006151194218546152
0.020121599112195045 0.10043754512281884 0.00570980180054903
0.020118471177814224 0.10042940312341914 0.005543083883821964
0.02011607796849045 0.10042295231772323 0.005840156227350235
0.02011375671688554 0.10041609127066853 0.005886191036552191
0.02011168027814543 0.100410874909633 0.0054424842819571495
0.020109470033504592 0.10040557441045203 0.005186375696212053
0.020106502412589454 0.10039670160144472 0.005377125460654497
0.020103869512664924 0.10038946734845365 0.005453221965581179
0.02010163463527331 0.1003842895851722 0.005302735138684511
0.020098647177760005 0.1003758191398637 0.0052086650393903255
0.020096528922965266 0.10037237801335534 0.005203895270824432
0.020093027482408727 0.10036251858386944 0.0051986281760036945
0.020089968085073493 0.10035455944009221 0.005163464229553938
0.020088825592271133 0.10035527843518521 0.005082880612462759
0.02008571667227371 0.10034546855189061 0.00499798683449626
iteration: 67 | epoch: 2885 |   loss: 0.100345  |   KL divergence: 0.020086  |  JS divergence: 0.004996
('==== Found maximium gradient [0.0011333084, 0.001128943, 0.0010746139] of '
 'gate e^[Y0 Z3], e^[Y10 Z1], e^[Y11 Z10] ====')
learning rate =  0.00022252177680872948
0.0200828615838017 0.10033675100720635 0.005348279140889645
0.020077897902592692 0.10033418923741297 0.01747346855700016
0.02007750645521842 0.10032238991548582 0.014994936063885689
0.020077512629987054 0.10032053138210563 0.014183653518557549
0.020074909703977302 0.10031223373461572 0.011726858094334602
0.020069655669497536 0.10029982418354928 0.011016862466931343
0.02006471843188461 0.10029614151331112 0.010313857346773148
0.020060225139341723 0.10029296317117506 0.009762036614120007
0.020057100063567725 0.10028505941074563 0.009096391499042511
0.020056832753822754 0.10028024920204986 0.008845428936183453
0.020055924098811403 0.10027046400992069 0.008896552957594395
0.020053990554604655 0.10026313397238043 0.007919920608401299
0.020051211319834377 0.10026003246923489 0.006948142312467098
0.020047089945957563 0.10025390144933721 0.007585362531244755
0.020042928032605156 0.10024581609324375 0.008207683451473713
0.020040374191914016 0.10024117957070847 0.007346438243985176
0.020036417861953936 0.10022532677568073 0.00602473970502615
0.020035758267820194 0.10022411492840408 0.006168389227241278
0.0200338154497802 0.10021848343848297 0.00689274026080966
0.020031844682134266 0.100216761960161 0.006749521940946579
0.02002621295765341 0.10019945522948454 0.0060263327322900295
0.02002356779016351 0.10019622803874546 0.005705284420400858
0.020021828096380676 0.10019412903101413 0.005920139607042074
0.020018783654403946 0.10018244540339966 0.006114258896559477
0.02001621206919587 0.10017272319894353 0.006012162659317255
0.020014505184253708 0.10016961425171902 0.005684728268533945
0.02001099626363219 0.10016060714324694 0.005427053663879633
0.02000687064646388 0.10015047506433017 0.005426347255706787
0.020003794878221605 0.10014583917674973 0.005545139312744141
0.020000910923424448 0.10014111147159492 0.005526004359126091
0.0199970547651772 0.10012952509449356 0.005380870308727026
0.019994503768788915 0.10012211844262844 0.00524948863312602
0.019992401636709442 0.10011552956938043 0.005241062957793474
0.019990302361646655 0.10010954157118857 0.005351716186851263
0.019987874225282937 0.10010433993215019 0.005309515167027712
0.01998404794157024 0.10009483739600138 0.005082189105451107
0.01998095201811245 0.10009015299870583 0.0050213453359901905
0.0199766151543705 0.1000786144614675 0.005182481836527586
0.01997314658385087 0.10006962416895208 0.005218816921114922
0.01997029355431503 0.10006191355076652 0.005092157982289791
0.01996813321122487 0.10005669709091813 0.0050128367729485035
0.019965182707617317 0.10004780796296607 0.005024035926908255
0.019961896871605753 0.10003835434168769 0.005054717883467674
0.019958887121985992 0.10003140615099139 0.005033881403505802
0.019956311053613462 0.10002725298376786 0.004978463519364595
iteration: 68 | epoch: 2930 |   loss: 0.100027  |   KL divergence: 0.019956  |  JS divergence: 0.004965
('==== Found maximium gradient [0.0012200323, 0.0010828843, 0.000935483] of '
 'gate e^[Y8 Z10], e^[X10 Y0], e^[Y3 Z2] ====')
learning rate =  0.00021714037428258214
0.019953205534547692 0.10002058542791284 0.005329797975718975
0.01995322094406634 0.10001128428246749 0.016720082610845566
0.01994996881759549 0.10000584288333281 0.019596366211771965
0.019944002730447417 0.1000016626151594 0.013707347214221954
0.019940220487504687 0.09999274555680994 0.01440421398729086
0.01993961911692383 0.09998866441987275 0.012435336597263813
0.01993896850577201 0.09998007145437923 0.009768160060048103
0.019939267499564407 0.09997940297223115 0.011644424870610237
0.01993634342961805 0.09997264439572172 0.011505181901156902
0.01993245855910738 0.09996777624055476 0.008909069932997227
0.01992846497752202 0.0999598782642223 0.008390648290514946
0.019926400734180633 0.099956625550628 0.009267529472708702
0.019922656509196376 0.09994298452163482 0.008662761189043522
0.019920767673262015 0.09993842458296276 0.007692763116210699
0.01991911152384131 0.09993495124685549 0.007850992493331432
0.01991844718849354 0.09993587716813582 0.007955297827720642
0.019915209809913736 0.09992318351773624 0.0072935037314891815
0.019912736111125238 0.09991416668960176 0.006832532584667206
0.019909428636754187 0.09990227804743287 0.0070355976931750774
0.01990828926948403 0.09990352191127767 0.0069925314746797085
0.01990539173719607 0.09989764488702617 0.006472846958786249
0.01990164254052618 0.09988728656545288 0.006262040697038174
0.01990022807573577 0.09988708537769364 0.006506987847387791
0.019897456307147215 0.0998786338925093 0.006365195848047733
0.01989523051940134 0.09987201568741831 0.005815734621137381
0.01989151733828777 0.09985794953772921 0.005749471951276064
0.01989001542987703 0.09985591110948294 0.006018698215484619
0.019886595983492784 0.09984561105695684 0.005819343961775303
0.01988463086583085 0.09984319019161171 0.00544704869389534
0.019881929205920967 0.09983678208324535 0.005578684154897928
0.019878667657441798 0.09982701483262729 0.0058370656333863735
0.019876676357859283 0.09982321810008636 0.005644537042826414
0.01987435611173544 0.09981752355259625 0.005241351202130318
0.019871108570409742 0.09980708784836044 0.005211776588112116
0.019868135917296612 0.09979843814705723 0.005417435429990292
0.019866034764121826 0.09979516327723102 0.005371870938688517
0.019863473425964825 0.09979053207316425 0.005142967216670513
0.01986031566291989 0.09978292144393906 0.0051163057796657085
0.01985611595268828 0.09976906651925477 0.005259511061012745
0.019854023273448408 0.09976446884274498 0.0052707744762301445
0.01985351982356884 0.09976719363932948 0.005151011049747467
0.019849202108677945 0.09975116397180829 0.005081615410745144
0.019847115190779557 0.09974722880304099 0.005092103499919176
0.019844158169174977 0.09974010530899863 0.0051024965941905975
0.019841140307632565 0.09973355151533023 0.005055123940110207
0.019838250956944154 0.09972768713278578 0.004990119952708483
iteration: 69 | epoch: 2976 |   loss: 0.099728  |   KL divergence: 0.019838  |  JS divergence: 0.004935
('==== Found maximium gradient [0.0013217931, 0.0010643876, 0.0010320654] of '
 'gate e^[Y8 Z3], e^[Y10 Z8], e^[Y2 Z9] ====')
learning rate =  0.0002293532065852639
0.019834190701061988 0.09971503518084475 0.00538739375770092
0.019839759178600404 0.09971520229373047 0.01532113179564476
0.01982914107938844 0.09970698192323361 0.01740574650466442
0.01982335084932694 0.09969695066010248 0.012342448346316814
0.01982307355763346 0.09969697450410617 0.013712434098124504
0.0198199500060803 0.0996854161635094 0.012249968014657497
0.019817622672644496 0.09967510215412054 0.009157177060842514
0.019816166429866968 0.09966401744714938 0.0099495155736804
0.01981533837232329 0.09965910998828531 0.011016306467354298
0.01981275046765321 0.09965522683129066 0.010063108056783676
0.019806944390742855 0.09964276659647979 0.00804263073951006
0.019802795899665316 0.09963902585210882 0.007567469961941242
0.019799418028923984 0.09963341218915663 0.008582158014178276
0.01979651602051061 0.09962385042663376 0.008699559606611729
0.019794741904754064 0.09961668197197676 0.007604585029184818
0.01979302995284242 0.0996094934884871 0.006608873605728149
0.019792455879632444 0.09960927371317316 0.006829154212027788
0.019789639782056074 0.0996000322554655 0.007301227189600468
0.01978644656370966 0.09959100114805955 0.0072108106687664986
0.019782203091054922 0.09957797998058973 0.0067399595864117146
0.019779781834914804 0.0995750697322341 0.006323143374174833
0.019776243527420603 0.0995677448080562 0.006077720783650875
0.01977264225105591 0.0995606696637595 0.006063224747776985
0.01976895447102681 0.09955214389957998 0.006220561917871237
0.01976577578174276 0.09954366895938327 0.006121266167610884
0.019763165197468492 0.09953513894779266 0.0058047776110470295
0.019761520502521984 0.09952995696555123 0.005685605574399233
0.019759232200187406 0.09952269784274477 0.005785918794572353
0.01975449860715949 0.09950626863765968 0.005760903470218182
0.01975138335683745 0.09950087335590721 0.005624397657811642
0.019748563656608473 0.09949791325378335 0.005540268961340189
0.019744434342681808 0.09948719011979905 0.005458921659737825
0.01974104018224103 0.09947815809861582 0.005359097849577665
0.01973948097163495 0.09947721077039398 0.005349884275346994
0.019735321210695624 0.09946338628312036 0.005396279506385326
0.019732446042963776 0.09945654825340199 0.00533256633207202
0.019730256611947487 0.09945315806394048 0.005204404704272747
0.019726461490107858 0.09944121738767087 0.005209570750594139
0.019722526429105654 0.09942836053779044 0.005307285115122795
0.019719669076925832 0.099421623236597 0.005273394286632538
0.019717056040629573 0.09941752176449024 0.005105866119265556
0.019712978484879958 0.09940714613870735 0.005064492579549551
0.019709403816267658 0.09939908669671439 0.005173162091523409
0.019705439428675323 0.09938764223349791 0.005186969414353371
0.019703572959292783 0.09938514717662308 0.005061679054051638
0.019700236606617936 0.09937480938858467 0.005003202706575394
0.019695993458857777 0.09936077498671807 0.005048454739153385
0.019693120480746878 0.09935490054463054 0.005087428726255894
0.019689296457462722 0.09934498497784468 0.005090160295367241
0.019687887290768404 0.09934707533947 0.005069286562502384
0.019683216637448233 0.09933225803212772 0.005029058083891869
0.0196802452019064 0.09932554458143956 0.00499590253457427
iteration: 70 | epoch: 3028 |   loss: 0.099326  |   KL divergence: 0.019680  |  JS divergence: 0.004896
('==== Found maximium gradient [0.000998214, 0.0009733719, 0.00097272155] of '
 'gate e^[Y2 Z0], e^[X1 Y8], e^[X3 Y1] ====')
Convergence criterion has reached, break the loop!
