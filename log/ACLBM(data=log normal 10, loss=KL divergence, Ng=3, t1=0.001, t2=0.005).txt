('==== Found maximium gradient [0.6811609, 0.68116087, 0.68116087] of gate '
 'e^[X1 Y0], e^[X8 Y0], e^[X6 Y0] ====')
learning rate =  0.13623217905877277
0.3778377401269746 1.4007285833358765
0.17203110996363646 0.5546349883079529
0.1103053627162769 0.5944826006889343
0.21679194045421335 1.53188157081604
0.18110233414222265 1.0206429958343506
0.11128477506602073 0.3996870815753937
0.08489926600864275 0.21695420145988464
0.10243518348339052 0.4567898213863373
0.13360586599857083 0.6260156631469727
0.1447643276662342 0.6628332138061523
0.12696756184257582 0.5758819580078125
0.09662058797328091 0.39880815148353577
0.07565743647788645 0.17618787288665771
0.07542234389845193 0.13836365938186646
0.09086244327582334 0.3582683801651001
0.10506805456020385 0.513617217540741
0.10391776916829602 0.5291783809661865
0.08962540812264373 0.4101974070072174
0.07551530263299408 0.22478868067264557
0.07109427652363946 0.06999669969081879
0.07597471697909784 0.1650048792362213
0.08343455499531552 0.27412134408950806
0.08696071545852578 0.3260338604450226
0.08454323673861663 0.31731921434402466
0.0786845623170875 0.25655654072761536
0.07342793302677249 0.16112518310546875
0.0713901779426087 0.073696568608284
0.07266229219727594 0.12122669816017151
0.07535141616227739 0.20651814341545105
0.0769679532436271 0.24964506924152374
0.07615949827982735 0.23475544154644012
0.07359584471803257 0.17137746512889862
0.07113477233696137 0.08763124793767929
0.07025790774120597 0.05804414302110672
0.07111193879567584 0.11565179377794266
0.0725787631162136 0.1595897376537323
0.07322067441740905 0.16976764798164368
0.07241845654765675 0.14522169530391693
0.07080241223813236 0.09373222291469574
0.06963501905003347 0.03851906955242157
0.0696905679251063 0.0633174404501915
0.07060363219040464 0.11084944754838943
0.07127532014691049 0.13098029792308807
0.07097535841755151 0.11703898012638092
0.07000604462944579 0.07618892192840576
0.06927686122263436 0.028537217527627945
0.06934446958007522 0.043577685952186584
0.06992900688314109 0.07904926687479019
0.07029796855133717 0.0940488800406456
0.07004650616189899 0.08489653468132019
0.06944731716070526 0.0558161586523056
0.06908171005056184 0.019869903102517128
0.06921052721813935 0.033491671085357666
0.06956557721317169 0.06156264245510101
0.0697042993671471 0.07187124341726303
0.06948397111339885 0.061764270067214966
0.06914889549616547 0.03645389899611473
0.06901746727613413 0.01216637622565031
0.06914825231139055 0.030778661370277405
0.06933206158080199 0.048541486263275146
0.06935004056454783 0.05209775269031525
0.06919718155836604 0.04149838164448738
0.06903712623282049 0.021721122786402702
0.06900517799257536 0.011726774275302887
0.06908498688489469 0.028201259672641754
0.06916193264360496 0.03878031298518181
0.06915043391019372 0.0377507321536541
0.06906416012595909 0.026313824579119682
0.06898706611641733 0.010581478476524353
0.0689855725469267 0.013843880034983158
0.0690408720348965 0.025680050253868103
0.0690756244644547 0.029803775250911713
0.06904559435215307 0.024892760440707207
0.06898678012290238 0.01346077024936676
0.06896179915349868 0.006370585411787033
0.06898603920125038 0.016306979581713676
0.06901733116226268 0.02246323600411415
0.06901270568935568 0.02116457372903824
0.06897856020251758 0.013476064428687096
0.0689555558338002 0.004639887250959873
epoch: 1 | iteration: 81 |   loss: 0.068956  |   KL divergence: 0.068956  |  JS divergence: 0.020475
('==== Found maximium gradient [0.13845055, 0.12995034, 0.124461435] of gate '
 'e^[Y1 Z2], e^[Y2 Z1], e^[Y2 Z3] ====')
learning rate =  0.026216099951402196
0.06896525690433318 0.22727306187152863
0.06288576095410613 0.21924175322055817
0.05468788340684158 0.10717613250017166
0.0524166489283576 0.09690327942371368
0.05263178214831904 0.12846717238426208
0.05244698627239831 0.12355248630046844
0.05202327961605106 0.10159959644079208
0.052041376775419715 0.09248936176300049
0.05253667889175014 0.10496887564659119
0.05281103156120984 0.11161622405052185
0.052485114530251495 0.09919565171003342
0.051894033697581846 0.0764874592423439
0.05151715177469567 0.06435176730155945
0.05147952309810792 0.07323495298624039
0.051505814024754175 0.08439725637435913
0.051290396435768035 0.0834287703037262
0.050827228653544027 0.06903547048568726
0.0503560582042483 0.04816698655486107
0.050099941882616905 0.03625035285949707
0.05007366715283804 0.04275630787014961
0.050118283226836195 0.05026533082127571
0.050108721944905836 0.048503097146749496
0.0500757661476949 0.040152907371520996
0.050121272624504484 0.03590219095349312
0.050263494103031166 0.042053911834955215
0.05039360789797642 0.04952836409211159
0.05038282709300806 0.05007774010300636
0.050209391400584134 0.042107388377189636
0.049973574422981906 0.029153000563383102
0.04979587477746197 0.02026417665183544
0.04972028593567017 0.02308517135679722
0.04970550601165743 0.027272893115878105
0.04970396863661108 0.02575245313346386
0.04971290616416442 0.020418517291545868
0.04975036709808748 0.018977796658873558
0.04980654379044725 0.023947419598698616
0.049836479090043996 0.027882620692253113
0.04980889356427872 0.02653522789478302
0.04974418385914189 0.020426448434591293
0.0496919852996802 0.014390367083251476
0.04967859017015595 0.015267832204699516
0.04968603759040287 0.018971005454659462
0.0496812585318514 0.019122352823615074
0.04965625471630557 0.015012765303254128
0.04962998360269464 0.010120106860995293
0.049619413227639735 0.010389835573732853
0.049620412314897853 0.013197265565395355
0.04961994932186272 0.01340242475271225
0.049617660927006826 0.01091177761554718
0.04962097229733188 0.009446701034903526
0.04963252022378197 0.01170345675200224
0.04963803868095119 0.013855879195034504
0.04962709037057097 0.01303499098867178
0.049604339185071025 0.009366813115775585
0.04958520306823663 0.0055418433621525764
0.04957709281922289 0.00592023367062211
0.049577224435604 0.007527902722358704
0.04957857107680696 0.007126388140022755
0.04957986402737251 0.005712774582207203
0.04958346490580346 0.006288759410381317
0.04958727412709864 0.008135141804814339
0.049585373339601696 0.00853682216256857
0.049577745523278184 0.0068577914498746395
0.04956985186517389 0.004445534199476242
epoch: 2 | iteration: 145 |   loss: 0.049570  |   KL divergence: 0.049570  |  JS divergence: 0.014501
('==== Found maximium gradient [0.097235665, 0.09643125, 0.075642474] of gate '
 'e^[Y1 Z3], e^[Y3 Z1], e^[Y2 Z4] ====')
learning rate =  0.01806489800843447
0.0495654990808577 0.15650351345539093
0.04691602136766929 0.1509936898946762
0.043289610961203956 0.07219938933849335
0.042317131217413304 0.058108340948820114
0.04302450401420374 0.09382735937833786
0.04327762018740601 0.09559276700019836
0.04313122990814274 0.07982237637042999
0.04315956137640451 0.07226931303739548
0.04335029229572441 0.07992225885391235
0.04326437442555665 0.08251672983169556
0.042810945449859264 0.0703875795006752
0.04231238669171984 0.0488818921148777
0.042066254980070925 0.033776793628931046
0.042080994153104616 0.040391478687524796
0.04216637254316679 0.052295807749032974
0.04215784265851479 0.056251898407936096
0.042044481760382925 0.051127802580595016
0.04191720192469808 0.04110672324895859
0.04185262733949381 0.0335533544421196
0.041861834274870086 0.0341227650642395
0.041897104479206866 0.03818565234541893
0.041903563267340675 0.03907341510057449
0.04186134992062408 0.03548796474933624
0.041789897902258545 0.0302464347332716
0.041723068084494955 0.027835795655846596
0.041679129977426524 0.02919849008321762
0.041646337556933415 0.030087990686297417
0.041603292966910184 0.0269314032047987
0.04155303188550694 0.01967889815568924
0.04152739855994805 0.013298003934323788
0.041547282848829255 0.016443243250250816
0.04158837932495073 0.02290731482207775
0.04160275186632761 0.02526484988629818
0.04156810876204558 0.022266004234552383
0.04151057561830278 0.01633206568658352
0.04146864926554082 0.012927393428981304
0.041453354267074964 0.014624690636992455
0.041446896604929964 0.01607336662709713
0.04143496365299423 0.014348311349749565
0.04142245639324302 0.010980223305523396
0.04142056536356877 0.010541580617427826
0.04142418927334822 0.013390729203820229
0.0414195077948676 0.015024256892502308
0.041400496626002835 0.013548491522669792
0.041375572315481494 0.00973836425691843
0.041357277224222444 0.006729199085384607
0.04134992328228616 0.00790621992200613
0.04134727155588297 0.010035062208771706
0.04134187230180472 0.010333445854485035
0.041332023288594824 0.00880679301917553
0.041320100070752125 0.0070982868783175945
0.04130998545083232 0.007155155763030052
0.04130195180131087 0.008042414672672749
0.041292481532646017 0.007778394501656294
0.04128117970055617 0.006136488169431686
0.04127200899807196 0.004958170931786299
epoch: 3 | iteration: 201 |   loss: 0.041272  |   KL divergence: 0.041272  |  JS divergence: 0.011824
('==== Found maximium gradient [0.061180674, 0.055721436, 0.05508648] of gate '
 'e^[Y0 Z2], e^[Y0 Z3], e^[Y2 Z0] ====')
learning rate =  0.011478950886216872
0.04126573065692429 0.09959201514720917
0.040323876718570205 0.10155364125967026
0.03841347826214481 0.04919787123799324
0.03796609667310005 0.046720970422029495
0.03799924532127909 0.059330232441425323
0.03785572300297606 0.053074777126312256
0.03772131604073846 0.04064822196960449
0.03779140785529579 0.04044110327959061
0.03798110441133873 0.05005848407745361
0.038047901282609334 0.05310513824224472
0.037914927828432046 0.04637494683265686
0.03769829752444834 0.03488276153802872
0.037537340259440444 0.028255531564354897
0.037465348676763106 0.03127216175198555
0.03741460415238485 0.0349242128431797
0.03732528369546726 0.03285937383770943
0.03721059038939488 0.025390584021806717
0.03712974904158726 0.017676185816526413
0.03711351253102328 0.018383024260401726
0.03713283729629244 0.02427215315401554
0.03713085481673299 0.027094032615423203
0.037080432389101275 0.024692634120583534
0.037003922978204165 0.018916742876172066
0.03694197035056976 0.014897748827934265
0.036912649102566725 0.016840528696775436
0.03689882959978939 0.0203186497092247
0.036874128463713185 0.020950768142938614
0.036829251548650056 0.018251197412610054
0.036776944966492794 0.014420955441892147
0.03673195832518958 0.013060723431408405
0.036696670543098095 0.014490525238215923
0.03666092576452944 0.015185875818133354
0.03662075052062137 0.013434880413115025
0.03658144791204536 0.01030852273106575
0.036551787159651114 0.009089709259569645
0.03653261821278034 0.011028989218175411
0.03651510860029132 0.01288860384374857
0.036489905555579634 0.012803628109395504
0.03645655061726684 0.011136394925415516
0.0364201111909544 0.009702661074697971
0.03638634423032015 0.009831101633608341
0.036352919815829984 0.010255730710923672
0.0363189932194283 0.009379686787724495
0.036284350052518906 0.007186312228441238
0.036253415789359936 0.005517242476344109
0.036228607908035185 0.006452609784901142
0.03620720081548531 0.00819394364953041
0.03618543381922478 0.008863862603902817
0.03615966185250227 0.008377833291888237
0.03613172287859961 0.007643716875463724
0.03610322972631212 0.007374387234449387
0.03607508487764067 0.0071652778424322605
0.03604652819404839 0.006351689342409372
0.03601891373695449 0.005137274041771889
0.035993165325182375 0.0046243383549153805
epoch: 4 | iteration: 256 |   loss: 0.035993  |   KL divergence: 0.035994  |  JS divergence: 0.010340
('==== Found maximium gradient [0.051927045, 0.04821564, 0.04646538] of gate '
 'e^[Y1 Z4], e^[Y4 Z1], e^[Y3 Z4] ====')
learning rate =  0.009784475299961688
0.03597066617292666 0.08489710837602615
0.035403600072029806 0.08748071640729904
0.03415609489462087 0.04263247922062874
0.03389792352901136 0.03820735588669777
0.034089791140220496 0.0538601316511631
0.034140926894009785 0.05517473816871643
0.0339971064887626 0.04607898369431496
0.03388692412392517 0.03817950189113617
0.033893563223539105 0.03917901962995529
0.03390507823986463 0.04173479601740837
0.03381989449506981 0.03841202333569527
0.033675313525053346 0.02993854694068432
0.03357518811735062 0.022961745038628578
0.03356381922426811 0.02489272505044937
0.03359467109201952 0.030817851424217224
0.03358889276982637 0.033324480056762695
0.03351455047022524 0.0303641427308321
0.0334054308067238 0.02320576086640358
0.03331963280041635 0.01548932958394289
0.03328764072927559 0.01358045730739832
0.03329854990199637 0.01763806864619255
0.0333146401911186 0.020898889750242233
0.03330936017047621 0.02110728994011879
0.03328403078094312 0.019268253818154335
0.03325511436285139 0.01781238242983818
0.03323215657119179 0.018056431785225868
0.03320613362347425 0.018351471051573753
0.0331659118233744 0.016467846930027008
0.03311611038344355 0.0117984963580966
0.03307633987473761 0.005981385242193937
0.033061420221526354 0.006206117570400238
0.03306550623308961 0.011227543465793133
0.03306850231146535 0.014304512180387974
0.0330566527899451 0.014373433776199818
0.0330321393242536 0.012162876315414906
0.03300655500057305 0.009585303254425526
0.0329867126701762 0.008722548373043537
0.032970831477511287 0.009193586185574532
0.032953544229342255 0.009057453833520412
0.03293459714404463 0.007791334297508001
0.032918660936115875 0.0066425432451069355
0.03290763331920923 0.007170902565121651
0.032898420939212414 0.008355913683772087
0.03288600958522796 0.008431277237832546
0.03287012670735598 0.006971317809075117
0.03285461077937908 0.004981362260878086
epoch: 5 | iteration: 302 |   loss: 0.032855  |   KL divergence: 0.032855  |  JS divergence: 0.009290
('==== Found maximium gradient [0.036171388, 0.030367233, 0.03032512] of gate '
 'e^[Y2 Z5], e^[X2 Y1], e^[Y1 Z5] ====')
learning rate =  0.006480895726927891
0.032843749576411896 0.056318189948797226
0.03262642585554964 0.06376311182975769
0.0319283504974581 0.04010089486837387
0.03161123898794547 0.03546202555298805
0.031544817857686 0.04286721721291542
0.0313946538958468 0.041226837784051895
0.03119950967218687 0.03529606759548187
0.031085434326587065 0.034691158682107925
0.031054953012976623 0.04033366218209267
0.030998059545833092 0.04447390139102936
0.0308444044387429 0.043483879417181015
0.03061916106841045 0.03879875689744949
0.030385898140135044 0.033921509981155396
0.030182788912535796 0.031721100211143494
0.030004919798142193 0.03176077827811241
0.029825074902739543 0.031396299600601196
0.029631581379987778 0.029295537620782852
0.029432935288327168 0.026291072368621826
0.029248655861502285 0.024476153776049614
0.029087506561648838 0.025121284648776054
0.028937391862855107 0.02690364420413971
0.028776236312871486 0.0277054812759161
0.028593457984595675 0.026792995631694794
0.028398559249441124 0.02504878118634224
0.028206877773643536 0.024045558646321297
0.028026089540146126 0.02437082678079605
0.027849218133447474 0.0249955914914608
0.027667211694772913 0.02476666495203972
0.027480290010680416 0.023670166730880737
0.027298013493451605 0.022696375846862793
0.027125583341182074 0.022736981511116028
0.026960644685966623 0.023549456149339676
0.026793339727123916 0.024184569716453552
0.026620976380010184 0.02410483919084072
0.026445529804984737 0.023526785895228386
0.02627204022443498 0.02299768105149269
0.02610171293224846 0.022781314328312874
0.025933239848185186 0.022650066763162613
0.025765217353840443 0.022258704528212547
0.02559739179239228 0.02159080281853676
0.025432833864806707 0.02100283093750477
0.02527312380738369 0.020833522081375122
0.02511754028401682 0.020982643589377403
0.02496305277495483 0.021023986861109734
0.02480814231012228 0.020705867558717728
0.024654208814965203 0.020188959315419197
0.024503139364247674 0.019795384258031845
0.024355038796417247 0.019603004679083824
0.02420853557192309 0.019411489367485046
0.02406390258127403 0.019080709666013718
0.023920880149217377 0.018724121153354645
0.02378152687840053 0.018530694767832756
0.02364568340247277 0.018498405814170837
0.023511689113000035 0.0184453297406435
0.02337965668225464 0.01824558898806572
0.02324938710589458 0.017957840114831924
0.02312157798033848 0.017720947042107582
0.02299622030587451 0.017573166638612747
0.022873619103730494 0.0174231119453907
0.022752487799694642 0.017191298305988312
0.02263402437284271 0.016919681802392006
0.02251824670831596 0.01670307107269764
0.02240530935238355 0.016549188643693924
0.02229467322396202 0.016374971717596054
0.022186289264808708 0.0161343552172184
0.022080219330217622 0.015875035896897316
0.021976288565798367 0.015650851652026176
0.021874610503812453 0.015439295209944248
0.02177534216138125 0.015187685377895832
0.02167804021038318 0.014900695532560349
0.021583130727413108 0.014636370353400707
0.02149055196078403 0.01442792173475027
0.021400892901637016 0.014247543178498745
0.02131235165560571 0.014054285362362862
0.021226240091733493 0.01384714525192976
0.021142231434078288 0.013650151900947094
0.021060450907792176 0.013466055504977703
0.020980545595273115 0.013273554854094982
0.0209023125706072 0.01306925155222416
0.02082681788670849 0.012878618203103542
0.020753121724251183 0.0127161405980587
0.02068135718671304 0.01256060041487217
0.020611540413459042 0.012385434471070766
0.02054320130889562 0.012191671878099442
0.02047633928550366 0.011996540240943432
0.020412134216067274 0.011805282905697823
0.02034936551494081 0.011610906571149826
0.020288271317269457 0.011412963271141052
0.02022871224039563 0.011220108717679977
0.020170513082282765 0.011035499162971973
0.02011481005031396 0.010851268656551838
0.020060157373105004 0.010661755688488483
0.0200069807950815 0.010473647154867649
0.019955508565893124 0.010295976884663105
0.01990531531688437 0.01012739073485136
0.019856785389922804 0.009960918687283993
0.019809469665772347 0.009796321392059326
0.019763672576116893 0.009638575837016106
0.019719105436994122 0.009488251060247421
0.019675618960115195 0.009339913725852966
0.019633517636493292 0.00919045228511095
0.019592961075651585 0.009040938690304756
0.019553269257481593 0.00889222975820303
0.0195152748428081 0.00874375831335783
0.019477958038559475 0.008596363477408886
0.01944201891662601 0.008452488109469414
0.019407040106090786 0.008311916142702103
0.01937309890620445 0.008169994689524174
0.019339971680774615 0.008022832684218884
0.01930806673126833 0.007873249240219593
0.01927721236669096 0.007727933116257191
0.019247286705467215 0.007590762805193663
0.019218162615182544 0.007461157161742449
0.019189947967470672 0.007336097303777933
0.019162503826283737 0.007212214171886444
0.019136459067032277 0.0070866006426513195
0.019110350056935285 0.006959659978747368
0.01908590746747676 0.0068357400596141815
0.019061616039506287 0.006718887481838465
0.019038076229713954 0.006608651950955391
0.019015475706744805 0.006500883959233761
0.01899373059389338 0.006391522008925676
0.018972421648515064 0.006279918365180492
0.018951602640433746 0.00616802554577589
0.01893196144900008 0.006058067549020052
0.018912521086151726 0.005951179191470146
0.01889410847697785 0.00584754254668951
0.018875654693907454 0.005745658650994301
0.018858491419629773 0.005644102580845356
0.01884136837398018 0.0055435835383832455
0.01882482209657181 0.005445355549454689
0.018808605021158695 0.005350114777684212
0.018793375693953118 0.005257283803075552
0.018778421011651756 0.005165823735296726
0.018763678242081295 0.005075979977846146
0.01875011804118994 0.004988478496670723
epoch: 6 | iteration: 438 |   loss: 0.018750  |   KL divergence: 0.018750  |  JS divergence: 0.005209
('==== Found maximium gradient [0.028909024, 0.027447073, 0.02380257] of gate '
 'e^[X1 Y0], e^[X2 Y0], e^[Y0 Z1] ====')
learning rate =  0.0053611390039315825
0.018735961159194826 0.04668706655502319
0.018487148955025998 0.04413103312253952
0.018033080285610927 0.04202968254685402
0.017680662591277773 0.033743832260370255
0.017405041009016065 0.03384988009929657
0.0171013709175478 0.033449992537498474
0.016795064339948037 0.02964804321527481
0.016531423390522583 0.028320157900452614
0.01630277260779538 0.02916928380727768
0.01608547894478299 0.029748370870947838
0.01587321366100822 0.028041547164320946
0.01567019740560626 0.024913450703024864
0.015481061869933418 0.022096963599324226
0.015314250564906805 0.020388765260577202
0.015174530547402787 0.02008749544620514
0.015053796365503603 0.019460219889879227
0.014939284402563409 0.01786458119750023
0.014829165740822152 0.016220321878790855
0.014727872971690122 0.015415729954838753
0.014638850463989448 0.015635795891284943
0.014557966136441535 0.01564691960811615
0.014479826056353715 0.01483297161757946
0.014406687475449442 0.01398968044668436
0.014338625025505557 0.013668679632246494
0.014273485392211804 0.013604803942143917
0.014210304987056253 0.013063233345746994
0.014148326680699099 0.011911769397556782
0.014088634160338492 0.010966326110064983
0.014031107718915097 0.010588135570287704
0.013975683277311274 0.010604818351566792
0.01392106042182538 0.010673774406313896
0.013866585735774506 0.010374996811151505
0.013811642985444187 0.009749531745910645
0.013757536285153731 0.009100434370338917
0.013706954388577473 0.008778748102486134
0.013660891816867724 0.008673683740198612
0.013617649610081571 0.00835034903138876
0.013575669932178704 0.00787064153701067
0.01353533297838435 0.007487820461392403
0.013496434474026032 0.007273421157151461
0.013461218160740633 0.006937880534678698
0.013428615065138755 0.006396357901394367
0.013399406496325211 0.005984287243336439
0.013372189207135593 0.005769895855337381
0.013346960541742756 0.005570936482399702
0.01332441643295718 0.005277789197862148
0.01330414343311492 0.005089963786303997
0.01328569637123923 0.005051352549344301
0.013268734574406721 0.005040646996349096
0.013253345988675561 0.004953900817781687
epoch: 7 | iteration: 488 |   loss: 0.013253  |   KL divergence: 0.013253  |  JS divergence: 0.003723
('==== Found maximium gradient [0.02706458, 0.021926258, 0.02173352] of gate '
 'e^[X3 Y4], e^[X2 Y4], e^[Y2 Z6] ====')
learning rate =  0.004740742796891086
0.01323878591034406 0.041336122900247574
0.01301551596283715 0.03595821559429169
0.0128191142340935 0.03992200642824173
0.012591653215436772 0.030227981507778168
0.01247035907173099 0.035408906638622284
0.012318000250651153 0.036782536655664444
0.01212439491014147 0.03144153207540512
0.011947158957555104 0.028114059939980507
0.011789959760209814 0.028003230690956116
0.011633894034068183 0.02678464911878109
0.011472096271057797 0.025357848033308983
0.011303855697000681 0.025822579860687256
0.011130477517808171 0.02647596225142479
0.010950817628591505 0.02521994523704052
0.010773900771041027 0.023252984508872032
0.01060678278239112 0.022473501041531563
0.010446560815274904 0.022097231820225716
0.010286951207756048 0.020685533061623573
0.010131962881020725 0.019110077992081642
0.009986941172292438 0.018997572362422943
0.009849953517810537 0.019620999693870544
0.0097122049200051 0.0193643681704998
0.009573856118797075 0.018346106633543968
0.009439140670298279 0.01764630153775215
0.009308573762513872 0.01737165078520775
0.009180044244662153 0.016784099861979485
0.009052773836778322 0.015939882025122643
0.00893185696014798 0.01560234185308218
0.008818797703304153 0.01573937013745308
0.008710583481503836 0.01553613692522049
0.008605703948035458 0.01484887395054102
0.008505468334135662 0.014260577037930489
0.008409117875756437 0.013902269303798676
0.008317789329867516 0.013398288749158382
0.008229425996319643 0.012838376685976982
0.008145189170227739 0.012635237537324429
0.00806525410043672 0.01260597724467516
0.007987545015254874 0.012254168279469013
0.007912384096821944 0.011632260866463184
0.007840752240919659 0.01114156749099493
0.007773801933046252 0.010811194777488708
0.007710857188416331 0.010462301783263683
0.007650476393899551 0.01022386271506548
0.007593864065069109 0.010185728780925274
0.007540408191790519 0.010054541751742363
0.007488549674187094 0.009662235155701637
0.007439152233227143 0.009227792732417583
0.007393474650148872 0.008887240663170815
0.007349228123960182 0.008529194630682468
0.007307649802469839 0.008224901743233204
0.007268733597121521 0.008144188672304153
0.007231311190218865 0.008081045001745224
0.007196362763862674 0.0077977715991437435
0.007162865640090157 0.007475873921066523
0.0071320256322482635 0.0072957780212163925
0.007102476610785138 0.007128683850169182
0.007074412504870547 0.0069396416656672955
0.007047876614498959 0.006811372470110655
0.007023305940348059 0.006648009642958641
0.006999514265059688 0.006374725606292486
0.0069766471563775774 0.006129064597189426
0.006955102038148049 0.00599647918716073
0.0069349032595514195 0.005903745535761118
0.0069153254610589895 0.005823652725666761
0.006897302755391014 0.005743233021348715
0.006880131467833929 0.005593213718384504
0.0068639029004340015 0.0053976490162312984
0.006848094213210851 0.005252950359135866
0.006832975528921505 0.005161988083273172
0.006818381990071642 0.00509544787928462
0.006804749121240602 0.00505836820229888
0.006791744733827157 0.004992750007659197
epoch: 8 | iteration: 560 |   loss: 0.006792  |   KL divergence: 0.006792  |  JS divergence: 0.001861
('==== Found maximium gradient [0.021073302, 0.019477835, 0.017413069] of gate '
 'e^[Y5 Z2], e^[Y3 Z5], e^[X3 Y5] ====')
learning rate =  0.00387588266070171
0.006778930486205918 0.03391328826546669
0.006802855856746219 0.048584096133708954
0.006430966759251535 0.02609262987971306
0.0063056107317003545 0.029068317264318466
0.006252025997097035 0.03596445173025131
0.006128537041496545 0.03042389079928398
0.006002932104225738 0.022087056189775467
0.005919992540394923 0.021207910031080246
0.005869323686628297 0.025627506896853447
0.005813764566604464 0.027155091986060143
0.00573937459395823 0.0242256261408329
0.00565851868039185 0.019358668476343155
0.005587466834509357 0.016882291063666344
0.0055261025178313175 0.018091890960931778
0.005466755669828882 0.01921176165342331
0.005403442688642837 0.017815249040722847
0.005340455046708209 0.014445125125348568
0.005284880809817802 0.011834848672151566
0.005240461427710907 0.01247574482113123
0.005201259277567148 0.01427218783646822
0.005160552411026263 0.01447098795324564
0.005116681285300035 0.01276578288525343
0.0050752200975323555 0.010632500983774662
0.005039843850694 0.01029294729232788
0.00501019230285632 0.011896380223333836
0.00498199109992916 0.013238796032965183
0.004949072134723238 0.012991977855563164
0.004913151417210269 0.011549833230674267
0.004876983082451203 0.01041753776371479
0.004844183997114095 0.010594160296022892
0.004812317997011529 0.011172900907695293
0.004779330827683011 0.01084226742386818
0.004746326380511201 0.009469284676015377
0.00471450925734413 0.00813376996666193
0.004687339279328804 0.007994481362402439
0.00466236421140678 0.008580132387578487
0.004636663667082878 0.008642091415822506
0.004611010343664556 0.007864447310566902
0.004585764459500738 0.007022521458566189
0.004562747397445542 0.006968391127884388
0.00454206537489958 0.007399856112897396
0.00452078442543392 0.007490935269743204
0.004499284738009623 0.006972070783376694
0.00447866500019608 0.006338126491755247
0.004460129318440122 0.006253376137465239
0.004441887314687797 0.0065553560853004456
0.004424314330981012 0.006624799687415361
0.004407008045994747 0.006299857050180435
0.0043910524142546856 0.005986853502690792
0.00437604582399628 0.006041812244802713
0.004361570148784678 0.006201344542205334
0.004347414987921586 0.006053396034985781
0.0043327968574970645 0.0055848052725195885
0.004318987241025857 0.005172249395400286
0.004306072791109318 0.005071873776614666
0.004293150430161189 0.005067870020866394
0.00428141534360936 0.004902873653918505
epoch: 9 | iteration: 617 |   loss: 0.004281  |   KL divergence: 0.004282  |  JS divergence: 0.001134
('==== Found maximium gradient [0.015803197, 0.015256697, 0.014986044] of gate '
 'e^[Y1 Z6], e^[Y2 Z0], e^[Y3 Z6] ====')
learning rate =  0.0030704817475957443
0.004269901819726255 0.02699016034603119
0.004256594981087108 0.035499509423971176
0.004058889529263658 0.02079830877482891
0.003986686336115734 0.02531321533024311
0.0039022641038722727 0.021915867924690247
0.0038284955230777793 0.016330398619174957
0.0037878784070558584 0.017426807433366776
0.0037522785919469905 0.019698357209563255
0.003706539525718949 0.018484918400645256
0.0036612801457328644 0.016239164397120476
0.0036224249842968714 0.016071995720267296
0.003582612320897043 0.017033614218235016
0.0035343961337059495 0.01666681468486786
0.0034822294733472437 0.014754854142665863
0.0034332317645395013 0.012990608811378479
0.003390124017424167 0.012560375034809113
0.003349215246605641 0.012719636783003807
0.0033100573401339704 0.012310138903558254
0.0032750483039388698 0.011287951841950417
0.003244057324134292 0.010462920181453228
0.0032161519949966376 0.01037101075053215
0.0031890335134356312 0.010606382042169571
0.0031608971860469792 0.010464416816830635
0.0031310001972466137 0.009813868440687656
0.0031021396858215496 0.009106132201850414
0.003073057243472412 0.008804293349385262
0.0030471319145646764 0.008730555884540081
0.003021842517741657 0.008370335213840008
0.002996399533188647 0.007634514477103949
0.0029726398038538446 0.006968912202864885
0.002951907770023669 0.006786694284528494
0.0029324809271453517 0.006899277679622173
0.0029138522114405653 0.006925949361175299
0.00289707696773959 0.006836357060819864
0.00287955444679973 0.006783538032323122
0.002863546047945571 0.006704952102154493
0.002847403857161411 0.006384550128132105
0.002832124310324097 0.0058098710142076015
0.002816907965579344 0.0052472432143986225
0.002802116046542732 0.004946678411215544
epoch: 10 | iteration: 657 |   loss: 0.002802  |   KL divergence: 0.002803  |  JS divergence: 0.000738
('==== Found maximium gradient [0.013837825, 0.013390927, 0.013042926] of gate '
 'e^[X2 Y6], e^[Y0 Z5], e^[X1 Y6] ====')
learning rate =  0.002685566879623913
0.002788981594190947 0.02375379577279091
0.002824383344754989 0.03624419867992401
0.002635552964422602 0.016266286373138428
0.002619375299550741 0.02248910441994667
0.002628691433029855 0.028132688254117966
0.0025835861818123604 0.02464783750474453
0.00252464102908656 0.019095871597528458
0.002486251645806874 0.017720196396112442
0.0024664276302274156 0.019376296550035477
0.002445245195446639 0.019054774194955826
0.002413188970511768 0.01602586731314659
0.002379031104883393 0.012630628421902657
0.0023496202589572217 0.011793117970228195
0.00232502980709365 0.012954824604094028
0.002300862356805688 0.013371572829782963
0.0022738059565155103 0.012177235446870327
0.002244562995589651 0.010195339098572731
0.0022158190950253885 0.008861876092851162
0.002190074117453804 0.008868127129971981
0.002169899356319076 0.009351929649710655
0.002154047650075013 0.00945421401411295
0.0021404919414467777 0.00921925250440836
0.002127859295444314 0.008941485546529293
0.0021129085650801378 0.008562380447983742
0.0020976951258762505 0.00784473679959774
0.0020832304728792316 0.006809114944189787
0.002070822299570627 0.005865538492798805
0.002060556241351821 0.005464295856654644
0.0020514206137567316 0.005437638610601425
0.0020417763914904715 0.005262547638267279
0.0020329464754133 0.004755775444209576
epoch: 11 | iteration: 688 |   loss: 0.002033  |   KL divergence: 0.002034  |  JS divergence: 0.000529
('==== Found maximium gradient [0.012211196, 0.011900064, 0.010844152] of gate '
 'e^[Y2 Z7], e^[Y6 Z0], e^[Y0 Z4] ====')
learning rate =  0.0023332965988512224
0.0020254388910108502 0.020646365359425545
0.0020086224648426295 0.027038050815463066
0.0018832871728939615 0.017183681949973106
0.001842366248891406 0.019870422780513763
0.0018000011897105852 0.01658990979194641
0.001759767020768562 0.01149722095578909
0.001734776338087711 0.011159858666360378
0.0017203262507389013 0.012610677629709244
0.0017090418859350926 0.011745772324502468
0.0016998986727653322 0.01023763045668602
0.0016926574436985722 0.010564818046987057
0.0016835648586004516 0.011850337497889996
0.0016701561809350368 0.011789156123995781
0.0016547003457249964 0.010024274699389935
0.0016424449607906598 0.00812899973243475
0.0016323049453665316 0.007936895824968815
0.0016237304386879149 0.008394182659685612
0.001611777867771164 0.00776083255186677
0.0016009047884817098 0.006266623269766569
0.0015935784679812473 0.005706023424863815
0.0015892398290119727 0.006616754457354546
0.0015859483224199698 0.007245803251862526
0.001579298497421827 0.006777700036764145
0.0015722546063807556 0.005790247581899166
0.0015655467599141786 0.005436934996396303
0.0015610449521366095 0.005777738988399506
0.0015558219541873912 0.005731131881475449
0.0015493617933503056 0.004833148326724768
epoch: 12 | iteration: 716 |   loss: 0.001549  |   KL divergence: 0.001550  |  JS divergence: 0.000399
('==== Found maximium gradient [0.008338704, 0.007690192, 0.0073861945] of '
 'gate e^[Y3 Z7], e^[Y1 Z7], e^[Y4 Z5] ====')
learning rate =  0.0015630265946886585
0.0015431931303719558 0.014033918268978596
0.001538704293951441 0.016134904697537422
0.0014952747943858492 0.01292943675071001
0.0014706388042342899 0.008192775771021843
0.0014699833459339492 0.010534703731536865
0.0014633528335589918 0.00941393617540598
0.0014540011678814075 0.0059574362821877
0.0014529245517575357 0.005984470248222351
0.0014580598153254478 0.008145601488649845
0.0014607182894492642 0.008441315963864326
0.0014585998105594686 0.007503565866500139
0.0014551462149337115 0.006935706827789545
0.00145155135776007 0.006856624968349934
0.0014474981476111741 0.006291753612458706
0.0014433270195431803 0.005203336011618376
0.0014390177836518226 0.004417942836880684
epoch: 13 | iteration: 732 |   loss: 0.001439  |   KL divergence: 0.001440  |  JS divergence: 0.000369
('==== Found maximium gradient [0.005905929, 0.0054534944, 0.00545311] of gate '
 'e^[Y2 Z8], e^[X2 Y7], e^[Y1 Z8] ====')
learning rate =  0.0011216477040322545
0.001436296386514435 0.010560292750597
0.0014428156705335276 0.015805287286639214
0.0014064825362807142 0.0075864652171730995
0.0013989520320417583 0.007798368111252785
0.0014020437590956231 0.01053902879357338
0.001395621227927586 0.009012124501168728
0.0013875502070700195 0.006588336545974016
0.0013877799574588245 0.007357877679169178
0.0013914711433386214 0.00946005154401064
0.0013912938029281697 0.009912097826600075
0.0013864467480293535 0.008723365142941475
0.0013800969182950601 0.007241139188408852
0.001375946570396679 0.006812158040702343
0.0013734022568417017 0.007053972687572241
0.0013697790916190786 0.006745534483343363
0.001365671796543521 0.0056672957725822926
0.0013618439847808196 0.004584889858961105
epoch: 14 | iteration: 749 |   loss: 0.001362  |   KL divergence: 0.001362  |  JS divergence: 0.000348
('==== Found maximium gradient [0.0049860487, 0.0045331027, 0.003992895] of '
 'gate e^[Y4 Z6], e^[Y6 Z4], e^[Y0 Z3] ====')
learning rate =  0.000904455025046456
0.001359647968931306 0.008998343721032143
0.0013676825282684982 0.013169145211577415
0.001340394608588097 0.0066193267703056335
0.0013353942060523997 0.007454499136656523
0.0013374674946702815 0.010037042200565338
0.0013324938238771496 0.009450826793909073
0.001324129500825274 0.007398025132715702
0.0013184089002658416 0.006228173617273569
0.001315555184567103 0.006778096780180931
0.0013129914285235447 0.007172702345997095
0.0013083405946048609 0.006395610049366951
0.0013031824504210747 0.004947624169290066
epoch: 15 | iteration: 761 |   loss: 0.001303  |   KL divergence: 0.001303  |  JS divergence: 0.000333
('==== Found maximium gradient [0.004325249, 0.00398093, 0.0038254308] of gate '
 'e^[X1 Y5], e^[Y5 Z3], e^[Y0 Z7] ====')
learning rate =  0.0008098518806956364
0.0012992364708496267 0.008182895369827747
0.0013006924017794253 0.010564655065536499
0.0012818566643842601 0.007782540284097195
0.001272827607471484 0.007886369712650776
0.001264387586196879 0.007456914987415075
0.0012560249253778326 0.007102564908564091
0.0012470429015575951 0.006792564410716295
0.0012392979875770328 0.006326613482087851
0.0012321882000579359 0.006227824836969376
0.0012252107432738158 0.006462911609560251
0.0012185478677968849 0.006414285860955715
0.001210541669396137 0.006047398783266544
0.0012020948130320765 0.005800206214189529
0.0011946470892393781 0.005861019250005484
0.001187485046891541 0.00588085176423192
0.0011800468746527232 0.005657099653035402
0.0011721046551689276 0.005411712918430567
0.0011658149971214243 0.00533540453761816
0.0011587996284035357 0.005297136027365923
0.0011523665887552144 0.005185363814234734
0.0011456511502961255 0.005097906570881605
0.0011392317702124855 0.005101086106151342
0.0011322566461063352 0.005080282688140869
0.001126312007062462 0.004967338405549526
epoch: 16 | iteration: 785 |   loss: 0.001126  |   KL divergence: 0.001126  |  JS divergence: 0.000287
('==== Found maximium gradient [0.0035429753, 0.0034108516, 0.0034041603] of '
 'gate e^[X2 Y8], e^[Y4 Z7], e^[X1 Y8] ====')
learning rate =  0.0006906508197561545
0.0011200614678547722 0.007721379864960909
0.001116246059798225 0.009136434644460678
0.0010989565045439057 0.0060774777084589005
0.00109354273878618 0.006684477441012859
0.0010902140646277777 0.00776003347709775
0.001083557219386599 0.007575973402708769
0.0010752860341994444 0.007007624488323927
0.001069196411760699 0.006913918536156416
0.0010646887713961634 0.006999057251960039
0.001059737778471916 0.006917167920619249
0.001053926831394446 0.006346544250845909
0.0010473237721271417 0.005592989735305309
0.0010415908047624082 0.005209264345467091
0.001036153172479253 0.005178047809749842
0.0010314271808049295 0.005257846787571907
0.0010267824770148262 0.0052590020932257175
0.0010210001617320065 0.005050336942076683
0.0010149088779806738 0.0048307268880307674
epoch: 17 | iteration: 803 |   loss: 0.001015  |   KL divergence: 0.001016  |  JS divergence: 0.000258
('==== Found maximium gradient [0.0033090296, 0.003043351, 0.0027506826] of '
 'gate e^[Y2 Z9], e^[X4 Y0], e^[Y4 Z2] ====')
learning rate =  0.0006085821460102167
0.0010094137919993004 0.007145014591515064
0.0010117112978445708 0.010908621363341808
0.000995549958636047 0.007189285475760698
0.000985846589147175 0.006475800182670355
0.0009819371657067088 0.007933471351861954
0.0009748031706581361 0.008032815530896187
0.0009661555619416399 0.006771913263946772
0.0009582937598791018 0.0055815535597503185
0.0009534105338328772 0.005729756783694029
0.0009488477981170199 0.0064361183904111385
0.0009436810682873192 0.006589756812900305
0.0009366090224869291 0.006084690801799297
0.0009302416971232905 0.00543082132935524
0.0009248817798549959 0.005242488346993923
0.0009200938833481764 0.0055475845001637936
0.0009150772914312703 0.005798516795039177
0.0009097292638923651 0.005643777083605528
0.0009045643349630063 0.005200171377509832
0.0008987167103331097 0.004849515855312347
epoch: 18 | iteration: 822 |   loss: 0.000899  |   KL divergence: 0.000899  |  JS divergence: 0.000228
('==== Found maximium gradient [0.0026304054, 0.0025350486, 0.0023931025] of '
 'gate e^[Y5 Z1], e^[Y3 Z8], e^[X6 Y7] ====')
learning rate =  0.0005042809488385005
0.0008941231404184211 0.006516577675938606
0.0008928312793376581 0.008033807389438152
0.0008813423950625127 0.005404419731348753
0.0008756001143550344 0.005807554814964533
0.0008714240451822273 0.006076889578253031
0.0008648269696061915 0.005330753978341818
0.000858278910108937 0.004718445241451263
epoch: 19 | iteration: 829 |   loss: 0.000858  |   KL divergence: 0.000859  |  JS divergence: 0.000217
('==== Found maximium gradient [0.0024543, 0.0023889737, 0.0021718687] of gate '
 'e^[X4 Y0], e^[X1 Y7], e^[Y3 Z1] ====')
learning rate =  0.0004682990231510159
0.0008534034534293416 0.0063859992660582066
0.0008518041836969071 0.008588988333940506
0.0008410895659306272 0.0064004394225776196
0.0008331893937916354 0.0054781618528068066
0.0008265902234429872 0.006288853939622641
0.0008202419341841176 0.006678370293229818
0.0008128843771801703 0.00626914668828249
0.0008063316428833451 0.0056221988052129745
0.0008000868898068404 0.005384589545428753
0.0007936569008905488 0.00548888836055994
0.0007884757650245093 0.005481450818479061
0.0007821185610462055 0.005209122318774462
0.0007759420101081402 0.004856110084801912
epoch: 20 | iteration: 842 |   loss: 0.000776  |   KL divergence: 0.000776  |  JS divergence: 0.000196
('==== Found maximium gradient [0.0023014965, 0.002252209, 0.0022458143] of '
 'gate e^[X1 Y4], e^[Y4 Z1], e^[Y8 Z0] ====')
learning rate =  0.00045332861322995284
0.000769743224222394 0.006123081780970097
0.000764007461319703 0.0069836946204304695
0.0007534978130861595 0.005595790222287178
0.0007455896443101413 0.005696421954780817
0.0007379381657329227 0.00571275083348155
0.0007304199341594799 0.00566980941221118
0.0007223958939807258 0.0056822411715984344
0.0007157172874817313 0.0055611031129956245
0.0007084345767796076 0.005399365443736315
0.0007016795858961491 0.005266090389341116
0.0006944592787748039 0.005112929735332727
0.0006887610971244671 0.004996404517441988
epoch: 21 | iteration: 854 |   loss: 0.000689  |   KL divergence: 0.000689  |  JS divergence: 0.000174
('==== Found maximium gradient [0.0021616246, 0.0019316876, 0.0019312646] of '
 'gate e^[Y1 Z9], e^[Y3 Z9], e^[Y3 Z5] ====')
learning rate =  0.0004022241624783579
0.0006815491919648476 0.006090251263231039
0.0006763469264566589 0.006418693345040083
0.0006680071215582722 0.0054481057450175285
0.0006607807351680219 0.0047643110156059265
epoch: 22 | iteration: 858 |   loss: 0.000661  |   KL divergence: 0.000661  |  JS divergence: 0.000167
('==== Found maximium gradient [0.002351744, 0.0019165849, 0.0017561641] of '
 'gate e^[X3 Y6], e^[X6 Y5], e^[X0 Y6] ====')
learning rate =  0.0004047733681603325
0.0006556649479795238 0.0059577906504273415
0.000648135824117166 0.005927380174398422
0.0006406459499902883 0.0054206885397434235
0.0006343530457724018 0.005272044334560633
0.0006277014598583422 0.004885105416178703
epoch: 23 | iteration: 863 |   loss: 0.000628  |   KL divergence: 0.000628  |  JS divergence: 0.000158
('==== Found maximium gradient [0.0018041742, 0.0016786921, 0.0015957262] of '
 'gate e^[Y5 Z3], e^[X1 Y9], e^[X2 Y9] ====')
learning rate =  0.00033900628658940774
0.0006213657068452111 0.005671054124832153
0.0006151166908748566 0.005835064221173525
0.0006074266742336644 0.0050596147775650024
0.0006011417259748604 0.005065021105110645
0.0005953511619815019 0.005337048321962357
0.0005898635429638296 0.00535848643630743
0.0005836495955666468 0.005288131069391966
0.0005777835531218184 0.005198773927986622
0.000571707155466964 0.005045113153755665
0.0005665753969816121 0.004845661111176014
epoch: 24 | iteration: 873 |   loss: 0.000567  |   KL divergence: 0.000567  |  JS divergence: 0.000143
('==== Found maximium gradient [0.0017606806, 0.0017489694, 0.001729211] of '
 'gate e^[X5 Y9], e^[X6 Y9], e^[X7 Y9] ====')
learning rate =  0.0003492670686536987
0.0005602588132664168 0.00555464206263423
0.0005575412894362727 0.006052063312381506
0.0005494691850762309 0.004952685907483101
epoch: 25 | iteration: 876 |   loss: 0.000549  |   KL divergence: 0.000550  |  JS divergence: 0.000139
('==== Found maximium gradient [0.0017180297, 0.0016554695, 0.0016351963] of '
 'gate e^[X1 Y9], e^[X2 Y9], e^[Y7 Z2] ====')
learning rate =  0.00033398748161262066
0.000543788648152288 0.0055807712487876415
0.0005411264706040235 0.0075498404912650585
0.000533229938800488 0.0057051340118050575
0.0005268209852066152 0.005159430671483278
0.0005215552719530263 0.005182607099413872
0.0005161193849488833 0.004750041291117668
epoch: 26 | iteration: 882 |   loss: 0.000516  |   KL divergence: 0.000516  |  JS divergence: 0.000130
('==== Found maximium gradient [0.0016156789, 0.0014421924, 0.0013624025] of '
 'gate e^[X5 Y6], e^[X3 Y7], e^[Y4 Z8] ====')
learning rate =  0.00029544266579498
0.0005099440744404857 0.005125010851770639
0.0005039921066111886 0.005431754514575005
0.0004987056848632016 0.004575627855956554
epoch: 27 | iteration: 885 |   loss: 0.000499  |   KL divergence: 0.000498  |  JS divergence: 0.000126
('==== Found maximium gradient [0.0014185149, 0.0013811156, 0.0013073814] of '
 'gate e^[X5 Y6], e^[Y2 Z4], e^[Y6 Z2] ====')
learning rate =  0.000273956469051951
0.0004920838305898901 0.005086870864033699
0.00048673675428749486 0.005834153387695551
0.00048006257600036943 0.004497694317251444
epoch: 28 | iteration: 888 |   loss: 0.000480  |   KL divergence: 0.000481  |  JS divergence: 0.000121
('==== Found maximium gradient [0.0014203187, 0.0013044734, 0.0012397828] of '
 'gate e^[X4 Y5], e^[X5 Y6], e^[Y0 Z9] ====')
learning rate =  0.0002647267254704927
0.00047496632900712727 0.004912045784294605
epoch: 29 | iteration: 889 |   loss: 0.000475  |   KL divergence: 0.000475  |  JS divergence: 0.000120
('==== Found maximium gradient [0.0015463611, 0.001523607, 0.0014614845] of '
 'gate e^[X5 Y8], e^[X6 Y8], e^[X7 Y8] ====')
learning rate =  0.0003021820280021674
0.00046856910204443557 0.005835435353219509
0.00046283139850028916 0.0065831574611365795
0.00045590815584281666 0.005211336072534323
0.000448875989280623 0.004599445033818483
epoch: 30 | iteration: 893 |   loss: 0.000449  |   KL divergence: 0.000449  |  JS divergence: 0.000113
('==== Found maximium gradient [0.0011704064, 0.0010997268, 0.0010942064] of '
 'gate e^[X4 Y0], e^[X1 Y4], e^[Y6 Z5] ====')
learning rate =  0.00022439659997953383
0.0004428773770282319 0.005141285713762045
0.0004384179407787153 0.005894020199775696
0.0004327766612616455 0.004981750622391701
epoch: 31 | iteration: 896 |   loss: 0.000433  |   KL divergence: 0.000434  |  JS divergence: 0.000109
('==== Found maximium gradient [0.0011128142, 0.0010250686, 0.0009793418] of '
 'gate e^[X6 Y5], e^[X3 Y8], e^[X7 Y5] ====')
learning rate =  0.00020810994240366582
0.00042827142191412536 0.00469535356387496
epoch: 32 | iteration: 897 |   loss: 0.000428  |   KL divergence: 0.000429  |  JS divergence: 0.000108
('==== Found maximium gradient [0.0013326678, 0.0013179316, 0.001283112] of '
 'gate e^[X3 Y9], e^[X4 Y0], e^[X4 Y5] ====')
learning rate =  0.00026228035478713185
0.00042502516313745015 0.006342095322906971
0.00041947430511509424 0.006534882355481386
0.0004128568933823673 0.005820723250508308
0.00040717954663396024 0.004211662337183952
epoch: 33 | iteration: 901 |   loss: 0.000407  |   KL divergence: 0.000408  |  JS divergence: 0.000103
('==== Found maximium gradient [0.0011090386, 0.0010514939, 0.0009989592] of '
 'gate e^[X3 Y6], e^[Y3 Z4], e^[X4 Y5] ====')
learning rate =  0.00021082458472981543
0.0004027588532991925 0.004980846773833036
epoch: 34 | iteration: 902 |   loss: 0.000403  |   KL divergence: 0.000403  |  JS divergence: 0.000102
('==== Found maximium gradient [0.0017628968, 0.0017573, 0.001754393] of gate '
 'RY[0], e^[X3 Y0], e^[X9 Y0] ====')
learning rate =  0.00035164001649229783
0.0003999425422312438 0.007510119583457708
0.000396236165924311 0.011623560450971127
0.00038615071721303574 0.006919519510120153
0.00037735593901021725 0.00458328565582633
epoch: 35 | iteration: 906 |   loss: 0.000377  |   KL divergence: 0.000378  |  JS divergence: 0.000095
('==== Found maximium gradient [0.0020678341, 0.0020594858, 0.0020449709] of '
 'gate RY[0], e^[X9 Y0], e^[X8 Y0] ====')
learning rate =  0.0004114903889599779
0.00037406165264358275 0.008688625879585743
0.0003798768252370568 0.018852919340133667
0.00036261727350424055 0.008450706489384174
0.00035551155341857565 0.007466266397386789
0.00035626856158647743 0.01312104519456625
0.0003489644744768104 0.010789971798658371
0.0003402812905635346 0.004808853380382061
epoch: 36 | iteration: 913 |   loss: 0.000340  |   KL divergence: 0.000341  |  JS divergence: 0.000086
('==== Found maximium gradient [0.0011427084, 0.0010394993, 0.00088285503] of '
 'gate e^[X4 Y0], e^[X5 Y0], e^[X2 Y0] ====')
learning rate =  0.0002054515031009416
0.0003361408533161508 0.0054788305424153805
0.00033794694382180987 0.013598969206213951
0.00033265883265447293 0.005563532467931509
0.000330959530993116 0.0054604592733085155
0.0003309804445407418 0.009068695828318596
0.00032795230974391363 0.007634128909558058
0.0003248564606661681 0.00378386746160686
epoch: 37 | iteration: 920 |   loss: 0.000325  |   KL divergence: 0.000325  |  JS divergence: 0.000082
('==== Found maximium gradient [0.0008425897, 0.00077903294, 0.00077829545] of '
 'gate e^[Y6 Z8], e^[Y8 Z6], e^[X3 Y0] ====')
Convergence criterion has reached, break the loop!
