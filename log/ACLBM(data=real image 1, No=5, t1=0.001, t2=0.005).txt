nohup: ignoring input
('==== Found maximium gradient [0.1265235, 0.12652348, 0.12652348, 0.12652348, '
 '0.12652348] of gate RY[1], e^[X0 Y1], e^[X2 Y1], e^[X14 Y1], e^[X3 Y1] ====')
learning rate =  0.02530469719196825
0.059723894330686284 0.3514033257961273
0.047283579124360944 0.14696134626865387
0.04675586349726339 0.26701533794403076
0.04415855325408434 0.22917866706848145
0.04100848194465537 0.1138424500823021
0.04018400114350891 0.08216337859630585
0.04167461351345482 0.16501246392726898
0.04273156178197575 0.19111785292625427
0.0422210063396148 0.15681900084018707
0.04098624784366832 0.09392036497592926
0.04026353061113521 0.07446122914552689
0.04036694732704034 0.11797057092189789
0.040548049629812455 0.14176031947135925
0.040206732734954974 0.12648072838783264
0.039529659320808694 0.08302927762269974
0.039065690466191495 0.04748879000544548
0.03906087321296257 0.07135337591171265
0.03921945220524744 0.09970207512378693
0.03912310297406438 0.10124760121107101
0.038745953346964804 0.0758967325091362
0.03842131892845769 0.03890269249677658
0.03842780883169983 0.039574481546878815
0.03867996962843111 0.0690685287117958
0.03884957538425761 0.08196371793746948
0.03875312412715927 0.07191019505262375
0.03851651779427811 0.04673658311367035
0.03836702294821385 0.031894583255052567
0.03835674625732888 0.047642409801483154
0.038338970314772666 0.06030011922121048
0.038195993281609275 0.05545197054743767
0.03800256545529347 0.034686703234910965
0.037925573677522244 0.013257975690066814
0.038013860898064356 0.030136680230498314
0.03813995864481347 0.0461563915014267
0.03816195859596881 0.04700515791773796
0.03808080428931929 0.03435393422842026
0.03800528675706285 0.020277805626392365
0.03799503307722452 0.026059947907924652
0.037996673456258526 0.03599535673856735
0.0379429888953217 0.03513811528682709
0.03785484648452869 0.02299460396170616
0.03781185593002153 0.008878718130290508
0.03783983802208887 0.01866033487021923
0.03787972666254717 0.02838856726884842
0.03787032342410817 0.027733149006962776
0.03782530960861416 0.018267961218953133
0.03779961249422515 0.010722259990870953
0.03780854929461147 0.018011990934610367
0.03781456417195639 0.023367559537291527
0.037788599783917465 0.020420119166374207
0.03775225408524668 0.011374907568097115
0.03773870733539987 0.008541470393538475
0.03774620742508404 0.01580699160695076
0.037743611302819294 0.01820860616862774
0.03772189221700285 0.013632126152515411
0.03770160997250142 0.006189960055053234
0.037699698345227885 0.00919286534190178
0.0377059789320283 0.014373631216585636
0.03770144712428163 0.014079405926167965
0.037685855896612025 0.009168319404125214
0.03767353976088413 0.0063977427780628204
0.03766891273655449 0.010161946527659893
0.03766237510660315 0.011651704087853432
0.03764977007190172 0.008586742915213108
0.0376384865903661 0.0038462721277028322
epoch: 1 | iteration: 66 |   loss: 0.037638  |   KL divergence: 0.037639  |  JS divergence: 0.009659
('==== Found maximium gradient [0.066955194, 0.06693133, 0.043209698, '
 '0.042915296, 0.039947234] of gate e^[Y8 Z1], e^[Y1 Z8], e^[Y8 Z0], e^[Y0 '
 'Z8], e^[Y0 Z10] ====')
learning rate =  0.010683588527759712
0.03763496044918171 0.11961452662944794
0.03575424108676997 0.10595142096281052
0.034172137840662524 0.046412911266088486
0.03417571041533167 0.07157229632139206
0.03411277498066283 0.05702159181237221
0.034235618418294686 0.05057418718934059
0.03455309418771559 0.07039619982242584
0.034583992402229244 0.07245960831642151
0.03432106817023653 0.055165454745292664
0.03410616317264288 0.042443662881851196
0.03404983777496511 0.04835554212331772
0.03398260118079016 0.04935484007000923
0.033841608103134364 0.03704779967665672
0.03374770342859118 0.025525638833642006
0.03376562321854926 0.03301464393734932
0.033806640092180915 0.040413592010736465
0.033789535810965 0.036573100835084915
0.03375725812348021 0.02828071638941765
0.03377213785020177 0.029516855254769325
0.03380152994467098 0.035496748983860016
0.03377313169923524 0.03403154015541077
0.03369397178941571 0.024750245735049248
0.033630960172399305 0.0176596250385046
0.033609900306937675 0.02095784805715084
0.0335994582633374 0.0227265115827322
0.03358221410277865 0.018160536885261536
0.03358269771493727 0.015258441679179668
0.03360977466649338 0.0207686610519886
0.033627314375135164 0.024569964036345482
0.03360802495890402 0.021580155938863754
0.033571562958956996 0.01492812018841505
0.03354779488841825 0.012945720925927162
0.03353623334099313 0.014773697592318058
0.033524233758174274 0.01290652435272932
0.03351701216684727 0.009082104079425335
0.03352374159112925 0.011645463295280933
0.03353447159638238 0.01569506898522377
0.0335287259440074 0.015136749483644962
0.03351168648471388 0.01098614651709795
0.03349836820057959 0.00899861752986908
0.03349230484989305 0.010217119008302689
0.03348605530181672 0.009079021401703358
0.03348059757408206 0.006113159470260143
0.03348144387386351 0.007646309211850166
0.03348422060183808 0.010412183590233326
0.03347930138160146 0.009816833771765232
0.033470366168011134 0.007041690405458212
0.033464166314015324 0.006558229215443134
0.03346116331278317 0.007469170726835728
0.033456272285078865 0.006153986323624849
0.03345241576977674 0.004272563382983208
epoch: 2 | iteration: 117 |   loss: 0.033452  |   KL divergence: 0.033453  |  JS divergence: 0.008532
('==== Found maximium gradient [0.03633575, 0.035129767, 0.0321428, '
 '0.03182594, 0.031694256] of gate e^[Y9 Z8], e^[Y8 Z9], e^[Y9 Z10], e^[Y10 '
 'Z9], e^[Y1 Z3] ====')
learning rate =  0.0066962456476954285
0.03345142498298574 0.07508479058742523
0.033163361516188726 0.0936850756406784
0.032057353451507134 0.03024735487997532
0.03204821666302152 0.04419935867190361
0.03233872942959441 0.06713493913412094
0.03231540596248041 0.06007663160562515
0.032159749088875825 0.04189179837703705
0.03210252094445385 0.036472201347351074
0.03214432924331888 0.04656977578997612
0.0321302008161254 0.04960043355822563
0.03201651296128072 0.039958447217941284
0.03190567892377714 0.023243093863129616
0.03189127512042889 0.017657797783613205
0.03196270344569332 0.030575038865208626
0.032023935014699044 0.03936909884214401
0.032005030691787145 0.038319382816553116
0.03192152476301905 0.029007313773036003
0.03184228882089846 0.017294643446803093
0.03181417838973002 0.015477767214179039
0.031826941853827284 0.02231545001268387
0.031841450256220795 0.02535482868552208
0.031838475798104435 0.022341474890708923
0.03182914286752241 0.016460899263620377
0.0318323362076239 0.01508217304944992
0.03184586128534039 0.019575700163841248
0.031850240791631367 0.022580420598387718
0.03183089533714035 0.020650796592235565
0.03179752537675119 0.014174840413033962
0.031772578457345664 0.006783030461519957
0.031769665651879796 0.00857048574835062
0.031780189777749615 0.01386481523513794
0.03178781890650264 0.015556730329990387
0.031784922570614854 0.013389269821345806
0.03177746986030919 0.009812060743570328
0.03177379931732375 0.009168862365186214
0.03177369389294214 0.01123620755970478
0.03177226675181185 0.011878501623868942
0.03176564557044592 0.00978937093168497
0.031758690362414826 0.006404253654181957
0.03175553823574787 0.005956501699984074
0.03175739415278267 0.008447007276117802
0.031757780982980474 0.009601110592484474
0.03175446496208522 0.008305344730615616
0.03174850573611946 0.0055509223602712154
0.03174507239825815 0.004364035092294216
epoch: 3 | iteration: 162 |   loss: 0.031745  |   KL divergence: 0.031746  |  JS divergence: 0.008108
('==== Found maximium gradient [0.024733791, 0.024699578, 0.019351272, '
 '0.018966245, 0.013315931] of gate e^[Y2 Z1], e^[Y1 Z2], e^[Y3 Z8], e^[Y8 '
 'Z3], CRY[2, 1] ====')
learning rate =  0.004131182694927313
0.03174541231106783 0.046565573662519455
0.03173737204744112 0.05945247411727905
0.031303620400269454 0.020284727215766907
0.031305478837150055 0.02081470377743244
0.03147801238629849 0.0411757156252861
0.031501039517692134 0.04053499549627304
0.03142810205528923 0.030364664271473885
0.03137376419012806 0.023819731548428535
0.03136336395575032 0.02650306187570095
0.03134665012405561 0.027703335508704185
0.03130190927263391 0.02203117497265339
0.031262821738061 0.01214359886944294
0.03126540158313361 0.010612229816615582
0.031304513751010836 0.019230710342526436
0.03133538183801522 0.02420116774737835
0.03132900068626578 0.02296818420290947
0.03129377256991792 0.01702704280614853
0.03126097488852728 0.010685672052204609
0.031249617347735018 0.010571020655333996
0.031254178897627695 0.013669836334884167
0.031258225989137405 0.014134065248072147
0.03125588496896515 0.0117424838244915
0.03125179220423077 0.00972180999815464
0.03125348959547058 0.011270647868514061
0.03125740945894874 0.013558091595768929
0.031254735589646004 0.013395876623690128
0.03124362775929282 0.010268251411616802
0.03123213175330286 0.0057426025159657
0.031227060744283865 0.0047061871737241745
epoch: 4 | iteration: 191 |   loss: 0.031227  |   KL divergence: 0.031228  |  JS divergence: 0.007973
('==== Found maximium gradient [0.012637831, 0.012238827, 0.01170461, '
 '0.011701434, 0.011701316] of gate e^[Y3 Z11], e^[Y11 Z3], e^[Y3 Z9], e^[Y12 '
 'Z11], e^[Y11 Z12] ====')
learning rate =  0.0024005763940970273
0.031229540981466564 0.02789883129298687
0.031201172740022022 0.03386244922876358
0.031047691899173828 0.012269580736756325
0.031040331454072756 0.014612270519137383
0.031082887220755515 0.023529909551143646
0.031076131312959807 0.02068665437400341
0.031054042186258495 0.014412572607398033
0.03104858799209259 0.01410989835858345
0.03105625815839982 0.017714403569698334
0.03105018724779117 0.017133057117462158
0.031029696074021118 0.011829518713057041
0.03101577688909063 0.006006577517837286
0.03101926450413261 0.008650809526443481
0.03103028043682969 0.01310021337121725
0.031034186343796066 0.014091789722442627
0.03102667567928975 0.011713260784745216
0.031015500146745124 0.008120008744299412
0.031008170770521655 0.00712874298915267
0.031006845531194753 0.008646209724247456
0.03100582829683347 0.008900454267859459
0.031003069774142245 0.007035990711301565
0.031000604002510507 0.004792660940438509
epoch: 5 | iteration: 213 |   loss: 0.031001  |   KL divergence: 0.031001  |  JS divergence: 0.007924
('==== Found maximium gradient [0.010407938, 0.009807957, 0.009363272, '
 '0.009280448, 0.009174348] of gate e^[Y0 Z2], e^[Y2 Z0], e^[Y10 Z8], e^[Y10 '
 'Z2], e^[Y8 Z10] ====')
learning rate =  0.0019235123284959473
0.03100139657184226 0.02220654860138893
0.030991970165866342 0.02954464964568615
0.03088479053828034 0.01064281351864338
0.03087901728481843 0.013570738956332207
0.0309105309472879 0.021295230835676193
0.030904771242552226 0.018972426652908325
0.03088262924411679 0.012660553678870201
0.030874891514268556 0.010839247144758701
0.030880222750691848 0.014602204784750938
0.030880045020046556 0.0158285703510046
0.030865506739309493 0.012782756239175797
0.030851709394140912 0.007338819094002247
0.030847735003962685 0.005485578905791044
0.030854625298038976 0.009701061993837357
0.030859425247354355 0.01249021477997303
0.030855609712941837 0.012077865190804005
0.03084579751379292 0.009052972309291363
0.03083721018380553 0.005419546738266945
0.030833276948311186 0.00516967149451375
0.0308337471568648 0.007414733059704304
0.03083382988068174 0.008334354497492313
0.03083138315626574 0.007284835446625948
0.03082880421733329 0.005255994386970997
0.030827700517702315 0.004668694920837879
epoch: 6 | iteration: 237 |   loss: 0.030828  |   KL divergence: 0.030828  |  JS divergence: 0.007866
('==== Found maximium gradient [0.008850576, 0.008265039, 0.0075477934, '
 '0.0070607523, 0.00654605] of gate e^[Y1 Z4], e^[Y4 Z1], e^[Y1 Z11], e^[Y11 '
 'Z1], e^[Y8 Z11] ====')
learning rate =  0.0015396564909149195
0.030827571074233277 0.018288277089595795
0.03082388982176381 0.02291862852871418
0.030751543436414945 0.008541053161025047
0.030748532900710168 0.009983609430491924
0.030769127618973914 0.01585095003247261
0.03076579530585249 0.014117414131760597
0.03075391564839105 0.009886899963021278
0.030750764177467926 0.0095102209597826
0.03075401257247614 0.011997192166745663
0.030751663172006206 0.011967403814196587
0.030741350080323655 0.008783139288425446
0.030731285796442825 0.004473527427762747
epoch: 7 | iteration: 249 |   loss: 0.030731  |   KL divergence: 0.030732  |  JS divergence: 0.007848
('==== Found maximium gradient [0.0064521227, 0.0064475266, 0.006400331, '
 '0.0061473437, 0.00553672] of gate e^[Y1 Z5], e^[Y11 Z4], e^[Y4 Z11], e^[Y5 '
 'Z1], e^[Y3 Z5] ====')
learning rate =  0.0012413213720914003
0.030729384189578962 0.014738268218934536
0.030731178588542508 0.018538828939199448
0.03067899648152423 0.006775622256100178
0.030678703238030403 0.008057729341089725
0.03069365213656229 0.012944200076162815
0.030689444846236646 0.01150909811258316
0.030680056748830224 0.007981963455677032
0.030677355064284942 0.007602097000926733
0.030680408560300097 0.00960920937359333
0.030678631357127912 0.009564308449625969
0.030672161747674797 0.006981992162764072
0.030665530870952282 0.0035920192021876574
epoch: 8 | iteration: 261 |   loss: 0.030666  |   KL divergence: 0.030666  |  JS divergence: 0.007826
('==== Found maximium gradient [0.0054523256, 0.005254402, 0.005228758, '
 '0.0051700557, 0.005161603] of gate e^[Y11 Z10], e^[Y1 Z6], e^[Y10 Z11], '
 'e^[Y9 Z13], e^[Y13 Z9] ====')
learning rate =  0.0010508972686239192
0.030664459719797414 0.012442360632121563
0.030666072466571433 0.01633504033088684
0.030627688025098805 0.0063383206725120544
0.030625690902262317 0.007123243995010853
0.030636045300276617 0.011335805058479309
0.030633119487131155 0.01022973470389843
0.030624687831632604 0.006980378180742264
0.030620787683806827 0.006091156508773565
0.030623180914343365 0.007868587039411068
0.030622985206721152 0.008222806267440319
0.030618218014287865 0.006437311414629221
0.030613296101229 0.0038369176909327507
epoch: 9 | iteration: 273 |   loss: 0.030613  |   KL divergence: 0.030614  |  JS divergence: 0.007814
('==== Found maximium gradient [0.0049551358, 0.0049443836, 0.004936462, '
 '0.004864848, 0.0045882245] of gate e^[Y12 Z9], e^[Y9 Z12], e^[Y11 Z9], e^[Y9 '
 'Z11], e^[Y4 Z0] ====')
learning rate =  0.0009719568352174855
0.030612041435644548 0.01149085070937872
0.03061610312511312 0.01578381471335888
0.030578784237445485 0.0054628620855510235
0.03057861679932946 0.007082966156303883
0.03058934544388224 0.011251579970121384
0.030586372576543404 0.010015302337706089
0.030578802747715295 0.0066633992828428745
0.03057558141211001 0.005760406609624624
0.030577539137776548 0.007717006374150515
0.030577660273517594 0.008277476765215397
0.030573370129274732 0.006590086966753006
0.030568802176534297 0.0037615185137838125
epoch: 10 | iteration: 285 |   loss: 0.030569  |   KL divergence: 0.030569  |  JS divergence: 0.007801
('==== Found maximium gradient [0.004557586, 0.0045166994, 0.0045055966, '
 '0.0044402215, 0.004063951] of gate e^[Y0 Z13], e^[Y3 Z6], e^[Y6 Z3], e^[Y13 '
 'Z0], e^[Y3 Z4] ====')
learning rate =  0.0008840987178024523
0.030567100573371933 0.010336670093238354
0.030573006395669785 0.01499329786747694
0.030541425632103714 0.005179586820304394
0.030541158159238146 0.006895833183079958
0.030550591875610343 0.01062888652086258
0.030548957001317087 0.009681874886155128
0.030541826067644384 0.006504160352051258
0.030538674153337036 0.0051427134312689304
0.03054091106335866 0.006978255230933428
0.03054201623896364 0.00783451460301876
0.030538427673891904 0.00659826397895813
0.03053423374427247 0.0040980069898068905
epoch: 11 | iteration: 297 |   loss: 0.030534  |   KL divergence: 0.030535  |  JS divergence: 0.007792
('==== Found maximium gradient [0.0039136875, 0.0037714299, 0.0037612312, '
 '0.0036766548, 0.0036476254] of gate e^[Y1 Z7], e^[Y3 Z7], e^[Y4 Z9], e^[Y7 '
 'Z1], e^[Y9 Z4] ====')
learning rate =  0.0007510550024764301
0.03053212594071896 0.008821437135338783
0.030535230597778407 0.010461299680173397
0.030514536102520216 0.005231545772403479
0.030513006938719205 0.005270926747471094
0.030519204368947898 0.0066403234377503395
0.03051771888108077 0.006875660736113787
0.03051363729743549 0.005585759412497282
0.030510987843053887 0.004244603216648102
epoch: 12 | iteration: 305 |   loss: 0.030511  |   KL divergence: 0.030512  |  JS divergence: 0.007783
('==== Found maximium gradient [0.0036409812, 0.0036381076, 0.0035112544, '
 '0.0034823192, 0.0032036344] of gate e^[Y5 Z4], e^[Y4 Z5], e^[Y7 Z4], e^[Y4 '
 'Z7], e^[Y7 Z6] ====')
learning rate =  0.0006997788400521275
0.030512222480828338 0.009168864227831364
0.030510525946017962 0.011647839099168777
0.030493586388065683 0.004961686208844185
epoch: 13 | iteration: 308 |   loss: 0.030494  |   KL divergence: 0.030495  |  JS divergence: 0.007778
('==== Found maximium gradient [0.0031605905, 0.0031513404, 0.0030885166, '
 '0.0030828484, 0.0030539543] of gate e^[Y4 Z6], e^[Y6 Z4], e^[Y7 Z2], e^[Y2 '
 'Z7], e^[Y2 Z3] ====')
learning rate =  0.0006215452073445216
0.030491511306679833 0.008653350174427032
0.030493208531321064 0.009373254142701626
0.030478655939755975 0.005230161361396313
0.03047657441271527 0.0037496716249734163
epoch: 14 | iteration: 312 |   loss: 0.030477  |   KL divergence: 0.030477  |  JS divergence: 0.007772
('==== Found maximium gradient [0.0030382995, 0.0030269201, 0.002921196, '
 '0.0028176035, 0.0028103476] of gate e^[Y4 Z12], e^[Y12 Z4], e^[Y2 Z9], e^[Y6 '
 'Z2], e^[Y9 Z2] ====')
learning rate =  0.0005849022767366378
0.030481972188079434 0.009115328080952168
0.030469978523402184 0.007681454997509718
0.030467495961007576 0.005851157940924168
0.03046342345594695 0.003879694966599345
epoch: 15 | iteration: 316 |   loss: 0.030463  |   KL divergence: 0.030463  |  JS divergence: 0.007768
('==== Found maximium gradient [0.0028080405, 0.0028008448, 0.002577428, '
 '0.0025606845, 0.002478681] of gate e^[Y2 Z11], e^[Y11 Z2], e^[Y14 Z12], '
 'e^[Y12 Z14], e^[Y13 Z12] ====')
learning rate =  0.0005297088057603722
0.030463151473431493 0.007727879099547863
0.03046447506658228 0.008150886744260788
0.03045312139840854 0.004743088036775589
epoch: 16 | iteration: 319 |   loss: 0.030453  |   KL divergence: 0.030453  |  JS divergence: 0.007763
('==== Found maximium gradient [0.0024519637, 0.0024300362, 0.0024118088, '
 '0.0023759403, 0.0022941793] of gate e^[X8 Y0], e^[Y13 Z2], e^[Y3 Z10], e^[Y2 '
 'Z13], e^[Y10 Z3] ====')
learning rate =  0.0004786846675569657
0.03045099816581456 0.006343283224850893
0.030451153121932546 0.00844096764922142
0.030443335272847587 0.003966799937188625
epoch: 17 | iteration: 322 |   loss: 0.030443  |   KL divergence: 0.030444  |  JS divergence: 0.007764
('==== Found maximium gradient [0.0026867213, 0.0022728767, 0.0022506744, '
 '0.0022388538, 0.002110654] of gate e^[X0 Y1], e^[Y5 Z2], e^[Y2 Z5], e^[Y0 '
 'Z11], e^[Y14 Z11] ====')
learning rate =  0.00046404568803892993
0.030441718747369673 0.006565687246620655
0.03044443569486538 0.007976672612130642
0.03043383158761988 0.0051768128760159016
0.030432408236972193 0.003912381827831268
epoch: 18 | iteration: 326 |   loss: 0.030432  |   KL divergence: 0.030432  |  JS divergence: 0.007760
('==== Found maximium gradient [0.0035001591, 0.0033218903, 0.0028765914, '
 '0.0028134105, 0.0026631244] of gate e^[X10 Y0], e^[X2 Y0], e^[X12 Y0], '
 'e^[X11 Y0], e^[X3 Y0] ====')
learning rate =  0.0006103661775997911
0.03043416669566482 0.008934910409152508
0.03044146497275374 0.011383813805878162
0.030430099385773787 0.008202646858990192
0.03042443471522834 0.006539157126098871
0.030426670728519283 0.007969668135046959
0.030424180815545633 0.007483950816094875
0.03041854342052653 0.00550462631508708
0.030414848488232307 0.0044783540070056915
epoch: 19 | iteration: 334 |   loss: 0.030415  |   KL divergence: 0.030416  |  JS divergence: 0.007754
('==== Found maximium gradient [0.0020966372, 0.0020959047, 0.0020756482, '
 '0.0020501553, 0.0020390262] of gate e^[Y5 Z7], e^[Y7 Z5], e^[X3 Y1], e^[Y13 '
 'Z1], e^[X8 Y1] ====')
learning rate =  0.0004143214467011925
0.030414559485321017 0.007222367916256189
0.03041207003235507 0.007350021041929722
0.030406227708319668 0.00648151058703661
0.03040148973111016 0.003803050145506859
epoch: 20 | iteration: 338 |   loss: 0.030401  |   KL divergence: 0.030402  |  JS divergence: 0.007748
('==== Found maximium gradient [0.0020978446, 0.0020191963, 0.0020027587, '
 '0.0019832852, 0.001972318] of gate e^[X8 Y0], e^[Y4 Z10], e^[Y10 Z4], e^[Y8 '
 'Z4], e^[Y3 Z0] ====')
learning rate =  0.0004031139699984598
0.03040078225287804 0.006631272844970226
0.030398612675209265 0.009220815263688564
0.03038941311482291 0.005192557815462351
0.030386507470359318 0.004999035038053989
epoch: 21 | iteration: 342 |   loss: 0.030387  |   KL divergence: 0.030386  |  JS divergence: 0.007747
('==== Found maximium gradient [0.0020251388, 0.0019196011, 0.0019144294, '
 '0.0018980427, 0.0018811325] of gate e^[X8 Y2], e^[Y3 Z12], e^[Y0 Z7], e^[Y7 '
 'Z0], e^[X3 Y1] ====')
learning rate =  0.00038566640524035164
0.03038388882239638 0.00742817809805274
0.030380090806076454 0.008284574374556541
0.03037251887213016 0.006650999188423157
0.03036748563486691 0.004557587206363678
epoch: 22 | iteration: 346 |   loss: 0.030367  |   KL divergence: 0.030368  |  JS divergence: 0.007739
('==== Found maximium gradient [0.0021098587, 0.0020534936, 0.0019677079, '
 '0.0018515295, 0.0017691419] of gate e^[X3 Y2], e^[X0 Y2], e^[X8 Y0], e^[Y12 '
 'Z1], e^[Y1 Z12] ====')
learning rate =  0.00039087836275650755
0.03036556775783223 0.007268201094120741
0.030362700883941607 0.009582143276929855
0.030352059356717753 0.006001188885420561
0.03034617621886337 0.005508140195161104
0.03034374222683716 0.007031491957604885
0.030337547755105304 0.006615191698074341
0.03033090399135226 0.00593371968716383
0.03032550304487968 0.00632157176733017
0.030322064453378934 0.006683736108243465
0.030316191730641984 0.0061480095610022545
0.03031068459510041 0.005277254618704319
0.030304978634102406 0.005086200777441263
0.030300345331749308 0.005478486884385347
0.03029578506558871 0.005626017693430185
0.03028994348946197 0.005359272938221693
0.03028421492692234 0.005099791567772627
0.03027947115538781 0.005130085628479719
0.030274765001110038 0.005205512046813965
0.030270387753757084 0.005105082876980305
0.030264334749921244 0.004970813635736704
epoch: 23 | iteration: 366 |   loss: 0.030264  |   KL divergence: 0.030265  |  JS divergence: 0.007710
('==== Found maximium gradient [0.0021751118, 0.002136921, 0.0017645905, '
 '0.0016827477, 0.0016295684] of gate e^[X8 Y2], e^[X8 Y0], e^[Y8 Z9], e^[Y14 '
 'Z9], e^[Y9 Z14] ====')
learning rate =  0.00037840143534667055
0.03025972570616283 0.006547616329044104
0.03026275842384306 0.011889329180121422
0.03024386123277171 0.006002920214086771
0.030239027612825903 0.00838315300643444
0.030235903929524244 0.009749800898134708
0.030225551667428463 0.008010635152459145
0.030215962467870477 0.006169208325445652
0.030207703374711622 0.006786365061998367
0.03020211985576902 0.008090788498520851
0.030194832392971136 0.008178049698472023
0.030186075653929244 0.007238882128149271
0.03017714467017822 0.006377007812261581
0.03016967967181721 0.006478707771748304
0.030162684882428525 0.007058476097881794
0.03015523548249016 0.007230824790894985
0.030146847325729063 0.006870622280985117
0.03013816100377678 0.006493770983070135
0.030130110896217324 0.006610549986362457
0.030122469325505344 0.007049277424812317
0.03011394106976298 0.007272212766110897
0.03010650468698428 0.007073767948895693
0.03009737414481288 0.006695937365293503
0.03008910939463573 0.006532758008688688
0.03008115339672872 0.0066964225843548775
0.03007275072825883 0.006934573873877525
0.030064503918294627 0.007004906889051199
0.030055615903570056 0.006917259190231562
0.030046643746092266 0.00685081398114562
0.030038343314175913 0.006916710175573826
0.030030513383218823 0.007034922018647194
0.030020867785575632 0.007075154222548008
0.030013298236374723 0.007028659339994192
0.03000364226943774 0.006993849296122789
0.029994215320574745 0.00703740818426013
0.02998553755330019 0.007118626497685909
0.02997732681116782 0.0071631562896072865
0.02996829096248308 0.0071639614179730415
0.029958927777830456 0.007178439758718014
0.029950412428485812 0.007243012078106403
0.029940974957928048 0.007321921642869711
0.029931597081140036 0.007356040179729462
0.029921987661944857 0.007339946459978819
0.029913175237007265 0.0073247309774160385
0.029903615401182915 0.0073540303856134415
0.02989354615562622 0.007418885827064514
0.029884711936312057 0.007481311913579702
0.029875532733510058 0.007521740160882473
0.029865689832986403 0.007548558060079813
0.02985606950480177 0.007573099806904793
0.02984700736691741 0.00759523082524538
0.02983758332000708 0.007613185793161392
0.02982818238570052 0.007636260706931353
0.029817962854280775 0.007674581836909056
0.02980796866335054 0.007722437381744385
0.029798369319806596 0.007761402055621147
0.029787886659159282 0.007782962638884783
0.029778989651528188 0.0077974009327590466
0.029768962068236204 0.00781853124499321
0.029759540960955115 0.007847554050385952
0.02974964702363323 0.007876683957874775
0.0297387836943633 0.00790088064968586
0.029729227493901177 0.007923036813735962
0.029719396494807437 0.007946666330099106
0.029709808442586947 0.007970670238137245
0.029699975483335986 0.0079930629581213
0.029689945579764142 0.008013720624148846
0.02967936284536882 0.008032690733671188
0.029669758043610717 0.008049201220273972
0.029659491953125686 0.008062784560024738
0.029648963220586765 0.008076444268226624
0.02964006387370338 0.008093699812889099
0.02962957257246203 0.008113403804600239
0.02961972732825198 0.008130586706101894
0.029609024328123654 0.0081419562920928
0.029599165649833205 0.008148297667503357
0.029588934316446262 0.00815389771014452
0.029578776954583937 0.008161170408129692
0.02956949812578849 0.008170612156391144
0.02955941829656027 0.008180682547390461
0.02954883540679746 0.008188890293240547
0.029539201101727062 0.00819360837340355
0.02952940709820445 0.008194747380912304
0.029518950109746346 0.008194122463464737
0.029509434618313575 0.008193908259272575
0.02950007471112316 0.008193829096853733
0.029489155011294184 0.0081930635496974
0.02947962021565649 0.008190592750906944
0.02946976479511 0.008186571300029755
0.029460078242065448 0.008181339129805565
0.029450238694020164 0.008175070397555828
0.029440699592887445 0.00816734042018652
0.02943034202783655 0.008157706819474697
0.029420376161719466 0.008146383799612522
0.029410916471894907 0.008134120143949986
0.029401693323803428 0.008121437393128872
0.029391965775574506 0.008108559064567089
0.02938263611464796 0.008094701915979385
0.029373255446897888 0.008078956045210361
0.029363903878831595 0.00806030910462141
0.02935359040706753 0.008039923384785652
0.029344870826948546 0.008018809370696545
0.029336016495546374 0.00799764133989811
0.029326891446263735 0.007976096123456955
0.029317823906237578 0.007953168824315071
0.029308012679071085 0.007928215898573399
0.029299612510832206 0.007901431061327457
0.029290978515747374 0.007873576134443283
0.029281425714404445 0.007844952866435051
0.029272016053392847 0.007815374992787838
0.029264239964960463 0.007784612011164427
0.02925510412731383 0.0077524129301309586
0.029245760754452448 0.007719252724200487
0.02923781091244888 0.007685272954404354
0.029229165488695676 0.007650286890566349
0.02922102536295932 0.0076139867305755615
0.02921227775341292 0.007576039992272854
0.029204121653547764 0.0075370995327830315
0.02919637306864007 0.00749706756323576
0.029187907056992493 0.007456472609192133
0.029179102048396962 0.00741523876786232
0.029171471941451324 0.0073730130679905415
0.02916387134934708 0.007329393178224564
0.029156015206628427 0.00728460680693388
0.02914815999256868 0.00723881833255291
0.029141202110382423 0.0071921986527740955
0.029133363841458794 0.007145060691982508
0.029125624342627193 0.007096950896084309
0.02911793928363514 0.007048183586448431
0.029110649327065925 0.006998308468610048
0.029103882002619035 0.006947760470211506
0.029096370089876505 0.006896376609802246
0.029089672184083423 0.0068441410548985004
0.0290827262584199 0.0067909792996943
0.029075804236588093 0.006737365387380123
0.02906972800974913 0.00668322155252099
0.029062147479355323 0.006628624629229307
0.029055383976063207 0.006573196966201067
0.029049285796690166 0.0065171848982572556
0.02904195644662042 0.0064604440703988075
0.02903656780890696 0.00640312023460865
0.029029297975601845 0.0063452995382249355
0.029023780977372054 0.006287068594247103
0.029018386217390953 0.006228701211512089
0.029012318731000186 0.006169923581182957
0.02900660114277842 0.0061106295324862
0.02900050233283697 0.006050682161003351
0.02899503797910074 0.005990291479974985
0.02898940696095576 0.005929859355092049
0.028983414489504707 0.005869265645742416
0.028978497606338284 0.005808591842651367
0.028973399028446506 0.0057475087232887745
0.02896765951106229 0.005686212796717882
0.02896276600729375 0.0056245713494718075
0.028957540251160832 0.005562876351177692
0.028952497794205813 0.005501394625753164
0.028947664045967957 0.005439732689410448
0.028942462378779087 0.0053778765723109245
0.028937800903957762 0.005315952003002167
0.028932805285702693 0.005254222545772791
0.028928141997618177 0.005192727316170931
0.028923974017081938 0.0051311771385371685
0.02892002718025421 0.005069574806839228
0.028914499071044486 0.005008046515285969
0.02891034284286764 0.004946787841618061
epoch: 24 | iteration: 530 |   loss: 0.028910  |   KL divergence: 0.028911  |  JS divergence: 0.007343
('==== Found maximium gradient [0.004673985, 0.004350711, 0.003810151, '
 '0.0036652747, 0.0036264844] of gate e^[Y8 Z11], e^[Y11 Z8], e^[Y8 Z9], e^[Y9 '
 'Z8], e^[Y9 Z0] ====')
learning rate =  0.0008093340312706823
0.028906607653265554 0.010283482261002064
0.028890090137120315 0.013189058750867844
0.028873207342801382 0.013205182738602161
0.028849325834771237 0.010817735455930233
0.02883817437392739 0.009004292078316212
0.028827332288101956 0.011066298931837082
0.02880833453816452 0.00992477498948574
0.02879269803806166 0.006740036886185408
0.028786823169635753 0.007609572261571884
0.02878090956895018 0.00932939350605011
0.02876925196312118 0.008196941576898098
0.028756300758641558 0.005825735628604889
0.028748151185398106 0.005886221304535866
0.028742791408947588 0.006909865885972977
0.028736051820408594 0.006410630885511637
0.02872837033429799 0.005267414730042219
0.028721112898507664 0.0052425796166062355
0.028715324163628257 0.005543153267353773
0.028709879442517457 0.005004898179322481
0.02870436977738533 0.004460194613784552
epoch: 25 | iteration: 550 |   loss: 0.028704  |   KL divergence: 0.028705  |  JS divergence: 0.007284
('==== Found maximium gradient [0.0037618154, 0.003643023, 0.0025732855, '
 '0.0025599967, 0.0025088233] of gate e^[Y3 Z2], e^[Y2 Z3], e^[Y9 Z10], e^[Y1 '
 'Z3], e^[Y8 Z2] ====')
learning rate =  0.0006124864130962266
0.028699274241365404 0.00844837911427021
0.02871680202648453 0.019230157136917114
0.02868177640308653 0.009718751534819603
0.02867531425434091 0.011626724153757095
0.028674970256409693 0.014648204669356346
0.028662528348455545 0.012484573759138584
0.028645784016546348 0.007538746111094952
0.02863696454220461 0.007662476040422916
0.028634584024279573 0.01090115588158369
0.028626587729007058 0.010860001668334007
0.02861550854573022 0.008275358937680721
0.02860351093132846 0.006512333173304796
0.028596024613478627 0.007348096463829279
0.028589305141954957 0.008363968692719936
0.02858188800757743 0.008322582580149174
0.028572535581323687 0.0074013774283230305
0.02856330746808254 0.006179938558489084
0.02855412884124688 0.005832125898450613
0.02854671902767693 0.006634044926613569
0.02853964456039601 0.0071305399760603905
0.028530307671663493 0.006509298924356699
0.02852246524486629 0.005509215872734785
0.028514271935961753 0.005516864359378815
0.02850607024453309 0.006181303411722183
0.028498507079370572 0.006320128683000803
0.028489736817345068 0.005870615132153034
0.028482328346767824 0.005449459422379732
0.02847371228500331 0.005349764600396156
0.028465815936262462 0.0053990487940609455
0.02845794323849568 0.005437500774860382
0.028449839013803095 0.005324586760252714
0.028441954125564273 0.005021346267312765
0.028434142268248523 0.004860861226916313
epoch: 26 | iteration: 583 |   loss: 0.028434  |   KL divergence: 0.028435  |  JS divergence: 0.007214
('==== Found maximium gradient [0.0024958248, 0.0023468726, 0.0021392682, '
 '0.0019946382, 0.0019342442] of gate e^[Y9 Z10], e^[Y10 Z9], e^[Y10 Z0], '
 'e^[Y1 Z2], e^[Y13 Z8] ====')
learning rate =  0.00043848195209769247
0.028426006370627734 0.007067902944982052
0.02843397698523823 0.01481567695736885
0.028407319039461407 0.0067741782404482365
0.028404361963055322 0.010894197970628738
0.028398484243576674 0.011148807592689991
0.028386037188809166 0.008121264167129993
0.02837391009782892 0.007115823682397604
0.02836718702203311 0.008459911681711674
0.028360272103751263 0.008843109011650085
0.028350262506849865 0.008007341995835304
0.02834063331174065 0.007267695385962725
0.02833162350814921 0.007232277654111385
0.028322384060892443 0.0072813453152775764
0.028313871799674557 0.007049887906759977
0.028305788887284623 0.006773542147129774
0.028297286323443867 0.006707808002829552
0.028287596295007093 0.006695701275020838
0.028278109454267394 0.00658695213496685
0.028269575316549823 0.006506370380520821
0.028261172256211223 0.006577698979526758
0.02825223539068575 0.006645326502621174
0.028243814643524427 0.0064963907934725285
0.028234032733138827 0.00620978744700551
0.028225131669754495 0.006050074473023415
0.028215057032263707 0.006091135088354349
0.028207506851596904 0.006125313229858875
0.028198778431878326 0.006011586636304855
0.028189594294455313 0.005877979565411806
0.028180461576185336 0.005897663999348879
0.028171130219394103 0.0060117230750620365
0.028162482662328375 0.006031131837517023
0.02815386535967364 0.005926167592406273
0.02814530905827261 0.005845298524945974
0.028136194548337008 0.005871460773050785
0.02812635081915396 0.00590112479403615
0.02811779449822337 0.005830180365592241
0.02810868756070935 0.00571775296702981
0.028099281725758353 0.005683974362909794
0.02808928947268489 0.005719546694308519
0.028080903542193853 0.005717779975384474
0.02807147175107801 0.005657254718244076
0.02806295635983122 0.00562587846070528
0.02805416911699877 0.005668303929269314
0.02804458733704929 0.0057113077491521835
0.028036203976530616 0.005683980882167816
0.02802759633910129 0.005619805306196213
0.02801870657101184 0.00558868795633316
0.028008962895719643 0.005586537998169661
0.02800009096967413 0.0055610318668186665
0.02799093373101137 0.005511946976184845
0.02798097667797523 0.005489882081747055
0.02797242565836978 0.005506925750523806
0.02796248907273334 0.005517836194485426
0.02795394105110726 0.0054952907375991344
0.027945332042961138 0.00546440901234746
0.027936830847997147 0.005450005643069744
0.02792768530905176 0.005438057240098715
0.027918479874856537 0.00541103957220912
0.02791002344038307 0.005381768569350243
0.027901493276455778 0.0053673190996050835
0.027892916015053712 0.005359411705285311
0.02788374528238068 0.005342741031199694
0.02787454858660775 0.00531992269679904
0.027866375453843524 0.005300245713442564
0.027857315288912526 0.005281691439449787
0.02784842612799629 0.0052587795071303844
0.027839906173375402 0.005234729498624802
0.02783140351579373 0.005214127246290445
0.0278230947781582 0.005195550620555878
0.02781454262112126 0.005176696926355362
0.027805045702109607 0.0051584187895059586
0.027797457488718823 0.005139440298080444
0.027789310202432915 0.00511638168245554
0.027781648125296664 0.005089821293950081
0.027772261322147437 0.005063068587332964
0.0277637571534571 0.005037137772887945
0.027755414518924455 0.0050118532963097095
0.027747618015360534 0.004989460576325655
epoch: 27 | iteration: 661 |   loss: 0.027748  |   KL divergence: 0.027748  |  JS divergence: 0.007037
('==== Found maximium gradient [0.00238737, 0.002308132, 0.0021245154, '
 '0.0019470121, 0.0018603291] of gate e^[Y1 Z9], e^[Y9 Z1], e^[Y1 Z8], e^[Y8 '
 'Z3], e^[Y1 Z2] ====')
learning rate =  0.00042701058092072463
0.02773976456244704 0.00689187366515398
0.027734004743465976 0.00999450869858265
0.02771853868550161 0.008551156148314476
0.027708522774012583 0.007772183045744896
0.027701613456732138 0.00801947433501482
0.027690226128649277 0.007484326604753733
0.02767895420889222 0.007096386048942804
0.02766861234713872 0.007010327652096748
0.02766026904034426 0.006642719730734825
0.027651602106550512 0.0064009069465100765
0.027641901777206934 0.006537450011819601
0.027631054103893174 0.006418431643396616
0.027620990020415737 0.005817307624965906
0.027612608401777317 0.005471446551382542
0.027604388752862006 0.005760510452091694
0.027595463591202025 0.005960332229733467
0.02758725123030134 0.0056149582378566265
0.027577973701986308 0.005170946475118399
0.027568308109331016 0.005180553998798132
0.02756016508402094 0.0053925663232803345
0.02755207520422207 0.005342248361557722
0.02754385056353524 0.005103197880089283
0.027535273417222426 0.004973652306944132
epoch: 28 | iteration: 684 |   loss: 0.027535  |   KL divergence: 0.027536  |  JS divergence: 0.006981
('==== Found maximium gradient [0.002016159, 0.002005089, 0.0018923511, '
 '0.0018892217, 0.0016342817] of gate e^[Y10 Z13], e^[Y3 Z9], e^[Y9 Z3], '
 'e^[Y13 Z10], e^[Y12 Z2] ====')
learning rate =  0.00037848440217000965
0.027526508832003832 0.006491863168776035
0.02752819698409719 0.012340660206973553
0.027509212337960498 0.005575437564402819
0.027503834928394876 0.007821093313395977
0.02749951089960652 0.009033921174705029
0.02749069522248008 0.007523850072175264
0.027481167878663837 0.005969888065010309
0.027474033450773868 0.006174977403134108
0.027468876246384256 0.007008019369095564
0.02746160388130879 0.00694425031542778
0.027452430976016434 0.005919971968978643
0.027446017041668005 0.004878335166722536
epoch: 29 | iteration: 696 |   loss: 0.027446  |   KL divergence: 0.027447  |  JS divergence: 0.006957
('==== Found maximium gradient [0.0016217659, 0.0015925909, 0.0015912335, '
 '0.0015591086, 0.0015440489] of gate e^[Y6 Z0], e^[Y5 Z6], e^[Y6 Z5], e^[Y0 '
 'Z6], e^[Y13 Z14] ====')
learning rate =  0.0003163972295045029
0.027439158058993357 0.006157431285828352
0.02743764326398317 0.009377948008477688
0.02742557708166938 0.005777077749371529
0.027419891900710862 0.005624833982437849
0.027416713274589485 0.006789807695895433
0.027410493371756262 0.006429987493902445
0.027402771566188942 0.005163813941180706
0.027398272630387202 0.0049364701844751835
epoch: 30 | iteration: 704 |   loss: 0.027398  |   KL divergence: 0.027398  |  JS divergence: 0.006943
('==== Found maximium gradient [0.0013872365, 0.0013643192, 0.0013635095, '
 '0.0013541771, 0.0012909287] of gate e^[Y8 Z12], e^[Y8 Z1], e^[Y1 Z2], e^[Y10 '
 'Z0], e^[X9 Y1] ====')
learning rate =  0.00027048465146400994
0.027392969043161543 0.006424956023693085
0.027388978148281933 0.007709444500505924
0.027381997433038725 0.005406093318015337
0.027376082081054763 0.004861499648541212
epoch: 31 | iteration: 708 |   loss: 0.027376  |   KL divergence: 0.027376  |  JS divergence: 0.006939
('==== Found maximium gradient [0.0014830271, 0.0014549657, 0.0013459256, '
 '0.0013014376, 0.00126639] of gate e^[Y9 Z2], e^[Y2 Z9], e^[Y8 Z1], CRY[9, '
 '2], e^[X11 Y2] ====')
learning rate =  0.0002745948828702435
0.027370336748503865 0.006304487120360136
0.02736947954362645 0.009406969882547855
0.027359830891420685 0.005997409112751484
0.027353587852691288 0.005627462174743414
0.027349027488505928 0.006882175803184509
0.02734272917727068 0.006268962752074003
0.02733558799836213 0.005173791199922562
0.027329858135896064 0.005131237208843231
0.027325622956641628 0.005656412802636623
0.027318887399793563 0.005669687874615192
0.02731226215957446 0.005154094658792019
0.027306322586845046 0.004618276376277208
epoch: 32 | iteration: 720 |   loss: 0.027306  |   KL divergence: 0.027307  |  JS divergence: 0.006920
('==== Found maximium gradient [0.0015251052, 0.001445804, 0.0013111194, '
 '0.001288022, 0.0012120762] of gate e^[X9 Y2], e^[X10 Y8], e^[Y10 Z12], '
 'e^[Y12 Z10], e^[Y10 Z14] ====')
learning rate =  0.0002722272463042127
0.027301428323501395 0.0054273041896522045
0.027296895150737556 0.007941337302327156
0.027287138924921114 0.004967067390680313
epoch: 33 | iteration: 723 |   loss: 0.027287  |   KL divergence: 0.027287  |  JS divergence: 0.006917
('==== Found maximium gradient [0.0018479812, 0.0018232823, 0.001512532, '
 '0.001410638, 0.0012844817] of gate e^[X3 Y8], e^[X1 Y8], e^[X2 Y8], e^[X1 '
 'Y0], e^[X2 Y9] ====')
learning rate =  0.00031833239317387643
0.02728017956925306 0.006849221419543028
0.027278425588442148 0.011076992377638817
0.0272645924908497 0.0061996630392968655
0.027257553839564984 0.006380806677043438
0.02725166372353894 0.008155970834195614
0.027244014370215758 0.00704605458304286
0.027234305420790667 0.005590758286416531
0.027227321105171925 0.005966556258499622
0.027220146710932584 0.00676872581243515
0.02721313105288751 0.0066669839434325695
0.027204390223359506 0.005915538407862186
0.02719732547299891 0.0052299113012850285
0.02719071927729185 0.00509855430573225
0.027183626165590606 0.005303151439875364
0.027177390833623985 0.005335438996553421
0.027168606508283434 0.005054066423326731
0.027161530306017798 0.004762356169521809
epoch: 34 | iteration: 740 |   loss: 0.027162  |   KL divergence: 0.027162  |  JS divergence: 0.006882
('==== Found maximium gradient [0.002156837, 0.0014652419, 0.0013614456, '
 '0.0013189276, 0.0012668353] of gate e^[X10 Y8], e^[X0 Y8], e^[X9 Y8], e^[Y1 '
 'Z10], e^[Y3 Z4] ====')
learning rate =  0.0003097980766981203
0.02715445138342884 0.005982824135571718
0.02715191484466115 0.010073953308165073
0.027135810868455294 0.005835626740008593
0.02712847010535966 0.007481719832867384
0.027123242028492783 0.0083319041877985
0.027113397269189272 0.007179069332778454
0.027104153018110998 0.005768380127847195
0.027095370543890142 0.005650891922414303
0.027088026624237954 0.006540794391185045
0.02708023647159532 0.006508313585072756
0.027072724360181634 0.005603185389190912
0.027063375737801487 0.005118688568472862
0.02705564209225674 0.005527544301003218
0.02704712713190177 0.0059356228448450565
0.02704075539715402 0.0058537875302135944
0.027032641725322114 0.005331001244485378
0.02702347890206607 0.004781242925673723
epoch: 35 | iteration: 757 |   loss: 0.027023  |   KL divergence: 0.027025  |  JS divergence: 0.006848
('==== Found maximium gradient [0.0014766691, 0.0013444297, 0.0012055179, '
 '0.0011770857, 0.0011654764] of gate e^[X1 Y9], e^[X3 Y8], e^[X1 Y8], e^[Y3 '
 'Z13], e^[X8 Y9] ====')
learning rate =  0.00025589344450941293
0.027015738083021778 0.005559224169701338
0.02701079331562216 0.0081510990858078
0.027001085278878612 0.005743629764765501
0.026995479105515464 0.006693892180919647
0.0269872083235854 0.006059626117348671
0.026979980856308546 0.005724503193050623
0.026973323628990995 0.006356392987072468
0.026966530150682563 0.0063677686266601086
0.02695906128504756 0.005769014358520508
0.026952489541007395 0.0054575311951339245
0.02694622717962978 0.0055071222595870495
0.026938048465299833 0.0053357938304543495
0.026931753115054365 0.004999990109354258
epoch: 36 | iteration: 770 |   loss: 0.026932  |   KL divergence: 0.026932  |  JS divergence: 0.006824
('==== Found maximium gradient [0.0016995552, 0.001213875, 0.0011934, '
 '0.0011523686, 0.0011367201] of gate e^[X10 Y8], e^[X9 Y0], e^[X9 Y2], e^[Y4 '
 'Z0], e^[X0 Y8] ====')
learning rate =  0.00025932634260010843
0.02692390373493321 0.005767872557044029
0.02692163308108056 0.0100191505625844
0.02690926860457201 0.006541920360177755
0.026902982221675927 0.007632850669324398
0.026895144672325167 0.008131662383675575
0.026886492551500045 0.007297187112271786
0.026878896102122324 0.00614323141053319
0.02687043974540257 0.005901306867599487
0.0268634922223561 0.00655877310782671
0.026855639343540693 0.006699463818222284
0.026847833122900795 0.005992467049509287
0.02683906025277081 0.0053476812317967415
0.026832255922999766 0.005624098237603903
0.02682475244115463 0.006201007403433323
0.026816875526239896 0.006255914457142353
0.026808768615508377 0.00584432203322649
0.026801156050357565 0.005480659194290638
0.026792376469725383 0.005425721872597933
0.026785147437595948 0.005509854294359684
0.026777909637518537 0.005516194738447666
0.026771537649568515 0.005406091455370188
0.026763985718243673 0.005273107439279556
0.02675494988420614 0.00525817321613431
0.026748173559514594 0.00539609557017684
0.0267407924357603 0.005517341196537018
0.026732898044555815 0.005447786767035723
0.026726190200140533 0.00524465786293149
0.02671853051679619 0.005118831992149353
0.026711463860985312 0.00513798650354147
0.02670308265182339 0.005169856362044811
0.02669608361023402 0.005128110758960247
0.02668886734718892 0.005070292856544256
0.026681408199139268 0.005069052334874868
0.026675833921811255 0.005114249885082245
0.026667250559500554 0.0051489626057446
0.02665973079967448 0.005127922166138887
0.026653764675020872 0.005054937209933996
0.026646495727857173 0.004986595828086138
epoch: 37 | iteration: 808 |   loss: 0.026646  |   KL divergence: 0.026647  |  JS divergence: 0.006754
('==== Found maximium gradient [0.0013759055, 0.0013215613, 0.0013129355, '
 '0.0013037991, 0.0012935633] of gate e^[X3 Y8], e^[Y14 Z2], e^[Y2 Z14], e^[Y0 '
 'Z1], e^[Y1 Z0] ====')
learning rate =  0.00026437303286977373
0.026638046822091727 0.00578148290514946
0.02663164427879366 0.007208176422864199
0.026623113662771647 0.006681070197373629
0.026614312033231564 0.005760938860476017
0.026609159431715813 0.005892321467399597
0.026601275566441276 0.006448773667216301
0.026593160413754115 0.0056557487696409225
0.026585700228988395 0.005238146986812353
0.02657891984453021 0.005515572614967823
0.026571819892112807 0.005475188605487347
0.02656506073528272 0.005190405063331127
0.026556729938699508 0.005090218037366867
0.02655002928151795 0.005183784756809473
0.02654234779621597 0.005212090443819761
0.02653529912821288 0.00510149821639061
0.02652882421628869 0.005010669119656086
0.026520788202364413 0.005017455201596022
0.026514150173970755 0.004991123918443918
epoch: 38 | iteration: 826 |   loss: 0.026514  |   KL divergence: 0.026514  |  JS divergence: 0.006720
('==== Found maximium gradient [0.0013321061, 0.0013105934, 0.0012951897, '
 '0.0012555497, 0.0012519434] of gate e^[Y10 Z6], e^[X2 Y9], e^[X10 Y8], e^[Y1 '
 'Z2], e^[Y9 Z5] ====')
learning rate =  0.00025789060422122637
0.02650579739637551 0.00564797967672348
0.026503388045506737 0.009372466243803501
0.026490526077956954 0.006182684097439051
0.026483593524295204 0.007716596592217684
0.026477399972466405 0.007004661485552788
0.02646921181064263 0.0058317631483078
0.026461098111440217 0.005939571186900139
0.02645358395168417 0.00606122612953186
0.02644662814398275 0.005859543569386005
0.026440223652891726 0.005921519361436367
0.026433670001778695 0.006013919599354267
0.026425372936816547 0.005699171684682369
0.026417889693624942 0.0052232034504413605
0.026412365242796058 0.005110427737236023
0.026403503425844337 0.0052612219005823135
0.02639710290265706 0.005275546107441187
0.026389606570066684 0.005155536811798811
0.026381321280888638 0.005143139511346817
0.026374986824722047 0.005241138394922018
0.026368295209564102 0.005233665928244591
0.026360198372175757 0.005076052621006966
0.026354366451350454 0.004918581340461969
epoch: 39 | iteration: 848 |   loss: 0.026354  |   KL divergence: 0.026354  |  JS divergence: 0.006679
('==== Found maximium gradient [0.0015022961, 0.001427092, 0.0012753161, '
 '0.0012296833, 0.0012133599] of gate e^[Y9 Z1], e^[Y1 Z9], e^[X2 Y4], e^[Y1 '
 'Z2], e^[Y4 Z3] ====')
learning rate =  0.0002668974192548993
0.02634623444896645 0.005701363552361727
0.02634182815931683 0.00915972888469696
0.02633032924072352 0.0061995843425393105
0.026322249726727618 0.006989116780459881
0.02631526062933867 0.0064887176267802715
0.026303804068936693 0.00616485346108675
0.026294417399877867 0.006366685964167118
0.026286469464299776 0.006411144509911537
0.02627860198024132 0.006413748022168875
0.02626978646804623 0.006433465518057346
0.02626055826216729 0.006158146541565657
0.026251043614063427 0.00572422007098794
0.026242214098435065 0.005602914374321699
0.026233215952342497 0.005765139125287533
0.026224496227599887 0.005783068016171455
0.026214754267919856 0.005630589555948973
0.026204691969607993 0.005630455911159515
0.026195620560664518 0.0057997633703053
0.026188092342346245 0.005849237088114023
0.026178283798098015 0.005709208548069
0.026168436104602823 0.005572046618908644
0.026160044053219006 0.005543652456253767
0.02615086737510948 0.005521508399397135
0.026141188949555097 0.0054614730179309845
0.02613182550018269 0.005457739811390638
0.026122733925576756 0.005536475218832493
0.026113627273634074 0.005614263936877251
0.026104147838495947 0.005650021135807037
0.02609473568914447 0.005663824267685413
0.026084750471830367 0.005648334976285696
0.026075072507998558 0.005581983365118504
0.026066202561212625 0.005506063811480999
0.026056624495413374 0.0054764291271567345
0.026047591721870253 0.005481405183672905
0.02603822905702862 0.00549353240057826
0.026028707974260285 0.005527891218662262
0.02601995751308014 0.005583592690527439
0.026009786840432186 0.005607799626886845
0.02599998913372465 0.005574730224907398
0.025990808531016762 0.0055245161056518555
0.025981917524585375 0.005492285825312138
0.025972869366436453 0.00547388568520546
0.02596329864445562 0.005469922441989183
0.025953327719706078 0.00549085671082139
0.025944168308529303 0.005521096754819155
0.02593520499631343 0.005534351337701082
0.025925941743034607 0.005529108922928572
0.025915864550866488 0.005516388453543186
0.025906014646039855 0.005499225575476885
0.025896963871806462 0.0054842024110257626
0.025886985747097323 0.005480543244630098
0.025878792412460574 0.00548302149400115
0.025869435236912985 0.005482759326696396
0.025860022725276058 0.005482877604663372
0.025850274453637658 0.005485211964696646
0.025841078785391446 0.005483728367835283
0.02583189379868691 0.0054784249514341354
0.025822652817481175 0.005472839809954166
0.02581346373003836 0.005464531015604734
0.025803516750834313 0.005452353972941637
0.025794293931772683 0.005443425849080086
0.025786080949121493 0.0054412828758358955
0.025776210398137434 0.005441672168672085
0.025767350375608768 0.005440619308501482
0.025758230951423662 0.00543547049164772
0.025747720054596298 0.005424164701253176
0.02574008009573343 0.0054097543470561504
0.02573013361941566 0.005398131906986237
0.025720417507628594 0.005391704384237528
0.02571150750771142 0.005389626603573561
0.025703327767475394 0.005389198660850525
0.02569360651097838 0.005385609343647957
0.02568493061278132 0.00537647632881999
0.025676537206970048 0.005364567507058382
0.025665880175686696 0.005353623069822788
0.025657014362726945 0.005345031153410673
0.025648980532402298 0.005339356604963541
0.025639888323335643 0.005335309077054262
0.02563133667669862 0.005329667124897242
0.025621667957010843 0.005321030039340258
0.025612930735792412 0.0053106993436813354
0.025604695547284194 0.005300086457282305
0.02559562240406228 0.005289908032864332
0.025586174479024892 0.005280579440295696
0.025577756449146286 0.00527188228443265
0.025569439798359347 0.005263342987746
0.025560047978297654 0.005254844203591347
0.025551186622831873 0.005245857406407595
0.02554236532729514 0.005236554890871048
0.025533389420641133 0.00522695342078805
0.02552439944119212 0.005216753110289574
0.025516836138951053 0.005205975845456123
0.02550776743532117 0.005196067038923502
0.025499484997082725 0.005187194794416428
0.0254908816615878 0.005178617313504219
0.02548234617239375 0.005169411189854145
0.025475034362883852 0.005159270018339157
0.025465939861002554 0.005148251075297594
0.025456903446597658 0.0051369694992899895
0.025448544647053095 0.00512648606672883
0.025439793462817696 0.005116849206387997
0.025432592719846624 0.005107372533529997
0.025423667341273985 0.0050972397439181805
0.025414669436723616 0.00508604571223259
0.025407721645426127 0.005074610933661461
0.025398760496093277 0.005063601303845644
0.025390024805539962 0.005053023807704449
0.025382030756806773 0.005042701028287411
0.025373626697346552 0.005032117944210768
0.02536652983462046 0.005020991433411837
0.025357954025630007 0.005009326618164778
0.025349942816051404 0.004997837357223034
epoch: 40 | iteration: 960 |   loss: 0.025350  |   KL divergence: 0.025351  |  JS divergence: 0.006420
('==== Found maximium gradient [0.002188481, 0.0019198509, 0.0019030151, '
 '0.0017460304, 0.001739416] of gate e^[Y8 Z5], e^[Y8 Z7], e^[Y3 Z9], e^[Y4 '
 'Z2], e^[Y5 Z8] ====')
learning rate =  0.0003812708712538607
0.02534147562748624 0.006560625042766333
0.025332909276462277 0.009986519813537598
0.025320752158555376 0.012277747504413128
0.025308727967541158 0.008643969893455505
0.025297838187249077 0.008096174336969852
0.02529030255454912 0.00905656348913908
0.025277690866455045 0.008064568042755127
0.02526546617277147 0.006431007292121649
0.025257935670897767 0.007388085592538118
0.025248816427677363 0.007638494484126568
0.0252378802086922 0.006359107326716185
0.02522758326902501 0.006028458476066589
0.025218302489953742 0.006478479597717524
0.0252085453957265 0.006449881475418806
0.025199301737264812 0.006140939425677061
0.025188658292888473 0.0058798035606741905
0.02517876009404736 0.005791193805634975
0.025168880799528795 0.0056997970677912235
0.025157372786386953 0.005339140072464943
0.025149198532321546 0.005199894774705172
0.0251400664791361 0.005483053158968687
0.02513107986324671 0.005575207527726889
0.025121382689576713 0.005388983059674501
0.02511074686432342 0.005183986388146877
0.025101503760751112 0.0049819014966487885
epoch: 41 | iteration: 985 |   loss: 0.025102  |   KL divergence: 0.025102  |  JS divergence: 0.006353
('==== Found maximium gradient [0.0019846987, 0.001956651, 0.0016752305, '
 '0.0015965232, 0.0015422188] of gate e^[Y10 Z0], e^[Y0 Z10], e^[Y6 Z8], e^[Y3 '
 'Z6], e^[Y0 Z9] ====')
learning rate =  0.00035215034926207723
0.02509193115907352 0.006323685869574547
0.025092260541748505 0.014051152393221855
0.02507173858051232 0.010549374856054783
0.025062893448711685 0.009786865673959255
0.025056533441165565 0.011219894513487816
0.025043096896209854 0.008857956156134605
0.025030726924399786 0.007009604480117559
0.02502159881928743 0.008374517783522606
0.025013116260321787 0.008397524245083332
0.025003660075429767 0.007198463659733534
0.02499274590804676 0.007092284969985485
0.024983136788399203 0.0074679916724562645
0.024972794224768655 0.006702740211039782
0.02496274659673434 0.005647202953696251
0.02495448861785528 0.0058823819272220135
0.02494505124023629 0.006572630722075701
0.024935982736951273 0.0064113326370716095
0.02492549969393751 0.005552481394261122
0.024916557106484463 0.005084280855953693
0.024907811769339774 0.005435578059405088
0.024899026860775282 0.005724905524402857
0.024889801310113334 0.005408302880823612
0.02488100622009947 0.004875611513853073
epoch: 42 | iteration: 1008 |   loss: 0.024881  |   KL divergence: 0.024882  |  JS divergence: 0.006295
('==== Found maximium gradient [0.0018877354, 0.001713158, 0.0015152505, '
 '0.0015129815, 0.0014593384] of gate e^[Y5 Z0], e^[Y0 Z5], e^[Y10 Z2], e^[Y3 '
 'Z5], e^[Y12 Z11] ====')
learning rate =  0.00032512421893445914
0.024872624080731275 0.005983079317957163
0.02487012731633564 0.012851881794631481
0.024852779318802393 0.007245501969009638
0.0248469652562366 0.009893356822431087
0.024837785679027318 0.009113128297030926
0.0248275207285482 0.006743183359503746
0.024817951401310948 0.0068034701980650425
0.02480981683743853 0.007647266145795584
0.024801965032940028 0.007257508113980293
0.02479153620545218 0.006378956139087677
0.024783154271294447 0.005878394935280085
0.024774279040910813 0.005675734486430883
0.024765560168056686 0.005786618683487177
0.02475820041112009 0.005909495986998081
0.024750177917476805 0.005610858555883169
0.02474131500752122 0.005141079425811768
0.02473383283503158 0.005030621774494648
0.024724450935463577 0.0050199138931930065
0.0247173403128935 0.004859240259975195
epoch: 43 | iteration: 1027 |   loss: 0.024717  |   KL divergence: 0.024718  |  JS divergence: 0.006250
('==== Found maximium gradient [0.0015549853, 0.0014642264, 0.0013866351, '
 '0.0013836966, 0.0013759434] of gate e^[Y3 Z11], e^[Y0 Z2], e^[X0 Y10], e^[X0 '
 'Y9], RY[4] ====')
learning rate =  0.0002869499215207925
0.024709247707262096 0.005856523755937815
0.02470742213070236 0.009922177530825138
0.024696909391036612 0.011163728311657906
0.024685748183370444 0.0069684977643191814
0.024680261384399684 0.008254947140812874
0.02467290131708736 0.009195901453495026
0.024663957544758613 0.007312307599931955
0.02465560609519155 0.005981698166579008
0.024649865112111223 0.006549709010869265
0.024642366315150134 0.006979853846132755
0.02463518721496529 0.006551110185682774
0.024626858224154766 0.0057440283708274364
0.024619558872220768 0.005231635645031929
0.02461266638667963 0.005359362345188856
0.024606164319260555 0.005629835184663534
0.024599158165249484 0.00551181472837925
0.02459163960583527 0.00498769199475646
epoch: 44 | iteration: 1044 |   loss: 0.024592  |   KL divergence: 0.024593  |  JS divergence: 0.006216
('==== Found maximium gradient [0.0018474716, 0.0018302501, 0.0012917628, '
 '0.0012286435, 0.0011914463] of gate e^[Y5 Z10], e^[Y10 Z5], e^[X0 Y9], e^[X1 '
 'Y2], e^[X1 Y10] ====')
learning rate =  0.00030147275998115706
0.024585468521915302 0.005639098584651947
0.024586495544924265 0.014382461085915565
0.02456969550327043 0.009749561548233032
0.02456432701249136 0.010187849402427673
0.02455796935617935 0.00959195289760828
0.024549857203791343 0.009620842523872852
0.024540391874040165 0.007856120355427265
0.024531587952031184 0.00642488244920969
0.024526273610442857 0.008052145130932331
0.024519209354162498 0.008869308978319168
0.024511104931914766 0.007222197484225035
0.02450235470311027 0.005152606870979071
0.024495548496224213 0.005881965160369873
0.024488939363313054 0.007187423296272755
0.02448197534724845 0.006843762472271919
0.024473984340202856 0.005566398147493601
0.024466855194024112 0.005169176030904055
0.024459934908102415 0.005680045112967491
0.02445327890670776 0.0058592394925653934
0.024446203697391564 0.005632041022181511
0.02443885111673932 0.00541864987462759
0.024431872520973133 0.005188381299376488
0.024424746891055997 0.004899539984762669
epoch: 45 | iteration: 1067 |   loss: 0.024425  |   KL divergence: 0.024425  |  JS divergence: 0.006170
('==== Found maximium gradient [0.0014180996, 0.0014102429, 0.001290142, '
 '0.0012323853, 0.0011835576] of gate e^[X0 Y9], e^[X2 Y0], e^[Y12 Z11], e^[Y3 '
 'Z7], e^[Y1 Z12] ====')
learning rate =  0.00026205098224156646
0.024417426044020883 0.00570079917088151
0.0244149908328895 0.011396597139537334
0.024405086662123474 0.010629088617861271
0.024395728223987657 0.008158370852470398
0.024389486178492063 0.00888060312718153
0.02438283509802186 0.009451583959162235
0.02437312088897408 0.007199238520115614
0.024365553883020308 0.006076359655708075
0.024359395296357344 0.0075287166982889175
0.024353140677091843 0.007849057205021381
0.0243441567681757 0.006470922846347094
0.02433564002210918 0.005435274913907051
0.02432940469501608 0.0060747223906219006
0.024320861998080756 0.006656728219240904
0.024314492070071785 0.006224436219781637
0.024307378470823947 0.005462133325636387
0.024299432366042418 0.005321943666785955
0.024292064092736435 0.005553603637963533
0.02428498916663143 0.005574318114668131
0.024277275587667665 0.005411882419139147
0.024270463932084783 0.005305799189954996
0.024263509116729035 0.005269412882626057
0.024255252478010893 0.005237662233412266
0.02424718712782392 0.005219369661062956
0.02424071322014262 0.0051732901483774185
0.02423292949571553 0.005039640702307224
0.024227097179792653 0.004911975935101509
epoch: 46 | iteration: 1094 |   loss: 0.024227  |   KL divergence: 0.024227  |  JS divergence: 0.006116
('==== Found maximium gradient [0.001238643, 0.0012300398, 0.0011658466, '
 '0.0010870857, 0.0010786076] of gate e^[Y14 Z8], e^[X0 Y9], e^[X1 Y2], e^[Y12 '
 'Z11], e^[Y4 Z1] ====')
learning rate =  0.00023240623237731452
0.024219440328997234 0.0055927373468875885
0.02421430155545317 0.009262059815227985
0.024205531977990018 0.008289400488138199
0.0241983872039557 0.007552787661552429
0.024191082505421364 0.006398607045412064
0.024184107863737925 0.007174563594162464
0.024175573878187688 0.006820133421570063
0.02416806169328595 0.005707673728466034
0.02416202185533947 0.005868038162589073
0.02415489654145718 0.006319204345345497
0.024147681302007465 0.005893990863114595
0.02413961675016796 0.00526793859899044
0.024132382555173727 0.005354755558073521
0.024125864040674617 0.005683907773345709
0.02411902099068619 0.0055396161042153835
0.024112610774013252 0.005170799791812897
0.02410498273832021 0.0050858622416853905
0.024097269903609664 0.005185719579458237
0.02409073823270398 0.0051396493799984455
0.024083474910131283 0.005030964035540819
0.024075377727528116 0.005083141848444939
0.024067833197371644 0.005160713568329811
0.024061100041124866 0.005071983672678471
0.02405359728643129 0.004924268927425146
epoch: 47 | iteration: 1118 |   loss: 0.024054  |   KL divergence: 0.024055  |  JS divergence: 0.006072
('==== Found maximium gradient [0.0010697773, 0.0010503227, 0.0010461163, '
 '0.0010321838, 0.0010232771] of gate e^[Y12 Z1], e^[X2 Y4], e^[Y1 Z12], e^[X9 '
 'Y4], e^[Y3 Z10] ====')
learning rate =  0.00020889155206248912
0.024047187470075466 0.005401191767305136
0.02404206135772215 0.008265732787549496
0.02403298852974435 0.007565716747194529
0.02402599771844384 0.0068503781221807
0.024019963221045257 0.005781775806099176
0.024013781797691286 0.006744245998561382
0.024006557854494938 0.00619113352149725
0.023999312691370657 0.005494393408298492
0.02399314003008828 0.0059090228751301765
0.02398753175714808 0.005879244301468134
0.023979458730889233 0.005237823352217674
0.023972533182177857 0.005038919858634472
0.023966766152266672 0.005189666524529457
0.023959034454597315 0.005101768299937248
0.02395270802308342 0.004993078764528036
epoch: 48 | iteration: 1133 |   loss: 0.023953  |   KL divergence: 0.023954  |  JS divergence: 0.006046
('==== Found maximium gradient [0.0011326403, 0.0011200128, 0.0010313729, '
 '0.0010199649, 0.001015377] of gate e^[X2 Y0], e^[X1 Y2], e^[Y1 Z3], e^[Y11 '
 'Z1], e^[Y4 Z1] ====')
learning rate =  0.00021302302497469805
0.02394611431834639 0.0056224106810987
0.023942139675709642 0.009050805121660233
0.023931767586860074 0.006807542406022549
0.023924488598121033 0.006698917597532272
0.02391748164511821 0.0071356818079948425
0.023909833306534234 0.006485683377832174
0.02390175200456733 0.005305005237460136
0.023895128897288582 0.005621078424155712
0.023887607116826713 0.0062074679881334305
0.023879871757971412 0.0057687764056026936
0.02387335799840592 0.005191200412809849
0.023865629720988005 0.005392430815845728
0.02385784546064231 0.005638104397803545
0.023851375399147647 0.005337012466043234
0.023843036880846415 0.004942111670970917
epoch: 49 | iteration: 1148 |   loss: 0.023843  |   KL divergence: 0.023844  |  JS divergence: 0.006017
('==== Found maximium gradient [0.0011898405, 0.0011679409, 0.0010738737, '
 '0.0010666923, 0.0010215938] of gate e^[X10 Y11], e^[X1 Y11], e^[Y11 Z0], '
 'e^[X3 Y4], RY[4] ====')
learning rate =  0.00022116957984137447
0.023835589546328768 0.0055269780568778515
0.02383332497334024 0.010261445306241512
0.0238198385593575 0.006409490015357733
0.02381383046077746 0.008014485239982605
0.023807574657896527 0.007116551045328379
0.0237983495362576 0.0065216016955673695
0.023789878538506753 0.006507854908704758
0.023782565692161358 0.006001576781272888
0.023775608349518557 0.0059338221326470375
0.023767560796267285 0.006177922710776329
0.023759824230079784 0.005839403718709946
0.023751595265303297 0.0052398680709302425
0.02374455818691888 0.005202454514801502
0.0237371023828624 0.005467720329761505
0.02372920969397844 0.0054290746338665485
0.023721521462131974 0.005227681249380112
0.023714122511586683 0.005149072501808405
0.02370553566337976 0.005054261535406113
0.023698077631923564 0.0048992023803293705
epoch: 50 | iteration: 1167 |   loss: 0.023698  |   KL divergence: 0.023699  |  JS divergence: 0.005980
('==== Found maximium gradient [0.0012682395, 0.0010181982, 0.0009942098, '
 '0.0009865422, 0.0009466718] of gate e^[X8 Y11], e^[X0 Y12], e^[Y9 Z12], '
 'e^[Y15 Z9], e^[Y9 Z11] ====')
learning rate =  0.00020982020154872397
0.023690265751511765 0.005435560829937458
0.02368504566909302 0.007776058744639158
0.023674888951390076 0.006893846206367016
0.023667644168842213 0.006018516141921282
0.023660857330916937 0.00664748577401042
0.023652325314394138 0.005641314201056957
0.02364448237903171 0.005584822501987219
0.02363647881555804 0.005998094100505114
0.023629856426018395 0.005626393482089043
0.02362178386899104 0.005503399297595024
0.023614601094552136 0.005615823902189732
0.023605767453971933 0.005274011753499508
0.023597617685307125 0.004980124998837709
epoch: 51 | iteration: 1180 |   loss: 0.023598  |   KL divergence: 0.023599  |  JS divergence: 0.005954
('==== Found maximium gradient [0.0011685828, 0.0011444114, 0.0010202583, '
 '0.0009920396, 0.0009147672] of gate e^[X8 Y11], e^[X11 Y12], e^[Y6 Z11], '
 'e^[Y11 Z6], e^[Y4 Z10] ====')
learning rate =  0.0002104686505811367
0.02359089982499542 0.005594564601778984
0.023587892862934817 0.012015973217785358
0.02357478253095137 0.005959993693977594
0.02356867649236776 0.008938227780163288
0.02356162231862883 0.008341653272509575
0.023552961867886045 0.006173973437398672
0.023545418865097936 0.006162724457681179
0.02353848864755469 0.006914228200912476
0.02352927335402627 0.006589121650904417
0.02352291750471145 0.005841797683387995
0.023514799520991295 0.005744680762290955
0.023508068173608187 0.005897898692637682
0.023500013064466842 0.005682041402906179
0.02349210638424904 0.0052315848879516125
0.023486093422597498 0.00499073788523674
epoch: 52 | iteration: 1195 |   loss: 0.023486  |   KL divergence: 0.023487  |  JS divergence: 0.005925
('==== Found maximium gradient [0.0012705429, 0.0012399452, 0.0012326273, '
 '0.00094159297, 0.0009317609] of gate e^[X3 Y1], e^[X2 Y1], e^[X0 Y1], e^[Y1 '
 'Z8], e^[X2 Y0] ====')
learning rate =  0.00022673135580593653
0.02347882169551645 0.005691340193152428
0.023478333470817816 0.012509136460721493
0.023462979239051947 0.006209051236510277
0.02345561836219631 0.0072102015838027
0.023451670715506787 0.009032030589878559
0.02344262636311995 0.007971459068357944
0.023434473965059318 0.005655788350850344
0.023425125932729145 0.00578588480129838
0.02341827335729792 0.0066008116118609905
0.023410189816368616 0.0065384963527321815
0.023403289094187117 0.005888630636036396
0.023394083765894774 0.005238112062215805
0.023386570883213154 0.005173929035663605
0.023379871247040697 0.005294364877045155
0.023371978711130354 0.005329112522304058
0.023365100274950784 0.005260456819087267
0.02335844856738668 0.005020130425691605
0.023350425572367463 0.004829928278923035
epoch: 53 | iteration: 1213 |   loss: 0.023350  |   KL divergence: 0.023351  |  JS divergence: 0.005891
('==== Found maximium gradient [0.0010744933, 0.001062699, 0.0009636733, '
 '0.0009159623, 0.0008945673] of gate e^[Y11 Z5], e^[Y5 Z11], e^[Y2 Z3], e^[X9 '
 'Y4], e^[Y14 Z3] ====')
learning rate =  0.0001970130728459992
0.02334271588890992 0.005237432196736336
0.023338253958113384 0.010659106075763702
0.023328665434370746 0.005777029786258936
0.023324225509913876 0.008627966977655888
0.02331670397672852 0.006608794908970594
0.023311481356399513 0.005288332235068083
0.023303944900080663 0.006706658285111189
0.023296784576499467 0.006470200605690479
0.023289435979945924 0.005076630972325802
0.023284045035553265 0.00508875260129571
0.0232773664541765 0.005856771487742662
0.02327226953430861 0.0055129677057266235
0.023264418200062045 0.004526322707533836
epoch: 54 | iteration: 1226 |   loss: 0.023264  |   KL divergence: 0.023266  |  JS divergence: 0.005869
('==== Found maximium gradient [0.00090361084, 0.0008879479, 0.0008796065, '
 '0.0008542265, 0.0008488161] of gate e^[Y12 Z0], e^[Y11 Z7], e^[Y7 Z11], '
 'e^[Y10 Z8], e^[Y11 Z2] ====')
Convergence criterion has reached, break the loop!
