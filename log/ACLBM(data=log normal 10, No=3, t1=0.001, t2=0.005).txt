nohup: ignoring input
('==== Found maximium gradient [0.68139344, 0.68139344, 0.68139344] of gate '
 'e^[X4 Y0], e^[X8 Y0], e^[X1 Y0] ====')
learning rate =  0.06813934567104411
0.37779086573540466 0.37779086573540466 1.4011963605880737
0.22116213281492952 0.22116213281492952 0.9048244953155518
0.11199905694310107 0.11199905694310107 0.44698670506477356
0.08071274168970559 0.08071274168970559 0.15401510894298553
0.1027559814845424 0.1027559814845424 0.49243712425231934
0.13629907872366623 0.13629907872366623 0.8463528156280518
0.1464624455505833 0.1464624455505833 0.9712528586387634
0.13032891364036528 0.13032891364036528 0.8301061391830444
0.10675046069499876 0.10675046069499876 0.5746936202049255
0.08845766649748273 0.08845766649748273 0.3248365521430969
0.07944840631169851 0.07944840631169851 0.15345370769500732
0.0795254237832326 0.0795254237832326 0.18925580382347107
0.08584942381186868 0.08584942381186868 0.3067769706249237
0.0939491141784701 0.0939491141784701 0.39750683307647705
0.09931638073445277 0.09931638073445277 0.4450107216835022
0.09921138336140485 0.09921138336140485 0.4473170340061188
0.09371252464333903 0.09371252464333903 0.4083130657672882
0.08525138639582214 0.08525138639582214 0.3355349600315094
0.07710626120617689 0.07710626120617689 0.23868627846240997
0.07191240335022353 0.07191240335022353 0.13082590699195862
0.0707462332744868 0.0707462332744868 0.06021863594651222
0.0729669055438608 0.0729669055438608 0.13270021975040436
0.07675366510179599 0.07675366510179599 0.22254207730293274
0.07998763821693529 0.07998763821693529 0.2857339680194855
0.08114095012745734 0.08114095012745734 0.3103885054588318
0.07982829024330881 0.07982829024330881 0.29435524344444275
0.0767427033419961 0.0767427033419961 0.24408376216888428
0.07313980847713282 0.07313980847713282 0.17116986215114594
0.0702923446431047 0.0702923446431047 0.08858820050954819
0.0690709271283928 0.0690709271283928 0.02146279625594616
0.06963453860790117 0.06963453860790117 0.07506441324949265
0.07135094208587918 0.07135094208587918 0.13208742439746857
0.07310394800704959 0.07310394800704959 0.16926400363445282
0.07391589469793827 0.07391589469793827 0.18367092311382294
0.07347257532948036 0.07347257532948036 0.17581309378147125
0.07216446628569842 0.07216446628569842 0.14889493584632874
0.07069483691308412 0.07069483691308412 0.10815984755754471
0.06963117331996194 0.06963117331996194 0.06104574352502823
0.06920755020991871 0.06920755020991871 0.02905558981001377
0.06937217182300734 0.06937217182300734 0.05640890821814537
0.0698915073477813 0.0698915073477813 0.09229058772325516
0.07043060151550523 0.07043060151550523 0.11571606993675232
0.07066492096150363 0.07066492096150363 0.12222125381231308
0.07044177122108211 0.07044177122108211 0.11155624687671661
0.06987771585923885 0.06987771585923885 0.08673474192619324
0.06928773080383636 0.06928773080383636 0.053459201008081436
0.06896976550778608 0.06896976550778608 0.022731980308890343
0.06901657826170413 0.06901657826170413 0.0307980477809906
0.06928797999442388 0.06928797999442388 0.055643144994974136
0.06954290134919275 0.06954290134919275 0.07263927161693573
0.06960869946425444 0.06960869946425444 0.07855028659105301
0.06946468349027446 0.06946468349027446 0.07345569133758545
0.06920844937720341 0.06920844937720341 0.05911112204194069
0.06896705423154596 0.06896705423154596 0.038518574088811874
0.06883154071040881 0.06883154071040881 0.01708025485277176
0.06883557159381477 0.06883557159381477 0.017905473709106445
0.06895022722841573 0.06895022722841573 0.03596455603837967
0.06909171067634771 0.06909171067634771 0.049412958323955536
0.06915844988668057 0.06915844988668057 0.05453258752822876
0.06909717867309464 0.06909717867309464 0.050655726343393326
0.06894622886538433 0.06894622886538433 0.03905132785439491
0.06880181256452955 0.06880181256452955 0.022481931373476982
0.06873970889895659 0.06873970889895659 0.005601133685559034
0.0687674335723264 0.0687674335723264 0.014112040400505066
0.06883884665400897 0.06883884665400897 0.026838188990950584
0.06889796664160086 0.06889796664160086 0.034344691783189774
0.06891219124882071 0.06891219124882071 0.03591728210449219
0.06887795567181965 0.06887795567181965 0.03186706453561783
0.06881567641742371 0.06881567641742371 0.023296765983104706
0.06875916699932769 0.06875916699932769 0.012117957696318626
0.06873533108062216 0.06873533108062216 0.004816161002963781
iteration: 1 | epoch: 72 |   loss: 0.068735  |   KL divergence: 0.068735  |  JS divergence: 0.020432
('==== Found maximium gradient [0.13770117, 0.12936772, 0.12460382] of gate '
 'e^[Y1 Z2], e^[Y2 Z1], e^[Y2 Z3] ====')
learning rate =  0.01306697232714636
0.06874991689718375 0.06874991689718375 0.22672006487846375
0.0644990373400944 0.0644990373400944 0.20221969485282898
0.06008349191221263 0.06008349191221263 0.16099277138710022
0.0569847789811629 0.0569847789811629 0.13327960669994354
0.0547156659766502 0.0547156659766502 0.11289466917514801
0.05285304711790821 0.05285304711790821 0.08752066642045975
0.05157047302932016 0.05157047302932016 0.06504204124212265
0.05094193036776686 0.05094193036776686 0.058891408145427704
0.050757387076626186 0.050757387076626186 0.06518151611089706
0.050715794426718516 0.050715794426718516 0.0694412961602211
0.0506920413571528 0.0506920413571528 0.06889662146568298
0.05069994996191035 0.05069994996191035 0.06749195605516434
0.050752417513588034 0.050752417513588034 0.06821274012327194
0.05079242685171684 0.05079242685171684 0.069060318171978
0.05074415131043936 0.05074415131043936 0.06618735194206238
0.05060926340050742 0.05060926340050742 0.05903018265962601
0.05045838169436161 0.05045838169436161 0.05079992115497589
0.05035749573683056 0.05035749573683056 0.04569112882018089
0.05031174666445981 0.05031174666445981 0.04440976306796074
0.0502883222528169 0.0502883222528169 0.043872471898794174
0.05026714386274765 0.05026714386274765 0.04234449937939644
0.05025807838682092 0.05025807838682092 0.04128964617848396
0.050272314323051105 0.050272314323051105 0.04263937473297119
0.05029079949047263 0.05029079949047263 0.04543907567858696
0.05027197682905302 0.05027197682905302 0.04681457206606865
0.050195101367713595 0.050195101367713595 0.045199550688266754
0.050073487997283936 0.050073487997283936 0.04132014140486717
0.049939375684533785 0.049939375684533785 0.036976829171180725
0.049811091455381214 0.049811091455381214 0.03298444300889969
0.04969145388444198 0.04969145388444198 0.028327565640211105
0.04958414402186914 0.04958414402186914 0.02171558141708374
0.04950491805032217 0.04950491805032217 0.013357765972614288
0.049469071418908064 0.049469071418908064 0.006295348051935434
0.049475764281522124 0.049475764281522124 0.008255861699581146
0.049506396357495784 0.049506396357495784 0.01294886413961649
0.04954292108981315 0.04954292108981315 0.015952445566654205
0.049579699660391253 0.049579699660391253 0.01824098266661167
0.04961411315980805 0.04961411315980805 0.020847689360380173
0.04964041566432914 0.04964041566432914 0.02314034476876259
0.04964814616975148 0.04964814616975148 0.023857878521084785
0.049634747876525054 0.049634747876525054 0.022636279463768005
0.04960900724593659 0.04960900724593659 0.020287970080971718
0.04957973281269239 0.04957973281269239 0.0179410632699728
0.049551909676792225 0.049551909676792225 0.015812736004590988
0.049525372010928576 0.049525372010928576 0.013273303396999836
0.04950234716305364 0.04950234716305364 0.010327572003006935
0.04948779457638375 0.04948779457638375 0.008509282022714615
0.04948264852757304 0.04948264852757304 0.009034278802573681
0.049482084116363685 0.049482084116363685 0.01023769099265337
0.04948116497401278 0.04948116497401278 0.010625578463077545
0.049479080354301846 0.049479080354301846 0.010378309525549412
0.04947740147679119 0.04947740147679119 0.01020019967108965
0.049474990368862305 0.049474990368862305 0.010000319220125675
0.04947142184509598 0.04947142184509598 0.009115109220147133
0.04946654481585798 0.04946654481585798 0.007502944674342871
0.049463342622431836 0.049463342622431836 0.006159444339573383
0.04946342931530798 0.04946342931530798 0.00604478782042861
0.04946469006468405 0.04946469006468405 0.006507656536996365
0.0494658393477227 0.0494658393477227 0.006754564121365547
0.0494664386275988 0.0494664386275988 0.00698684761300683
0.049466912274757434 0.049466912274757434 0.00745273195207119
0.049466046689657386 0.049466046689657386 0.007716956548392773
0.04946290486422848 0.04946290486422848 0.007300803903490305
0.04945795863843614 0.04945795863843614 0.006313585210591555
0.0494533102509989 0.0494533102509989 0.005261712707579136
0.04944899961851019 0.04944899961851019 0.004342448431998491
iteration: 2 | epoch: 138 |   loss: 0.049449  |   KL divergence: 0.049449  |  JS divergence: 0.014497
('==== Found maximium gradient [0.0969087, 0.09582023, 0.0756905] of gate '
 'e^[Y1 Z3], e^[Y3 Z1], e^[Y2 Z4] ====')
learning rate =  0.009000345342553286
0.049445241053495306 0.049445241053495306 0.155923992395401
0.047683344646532566 0.047683344646532566 0.14356744289398193
0.04541523009540139 0.04541523009540139 0.10665976256132126
0.04410190942008996 0.04410190942008996 0.08557718992233276
0.04321076376148898 0.04321076376148898 0.07240384817123413
0.042421676035186276 0.042421676035186276 0.05279083549976349
0.04189452900998453 0.04189452900998453 0.03005383536219597
0.04173706697944572 0.04173706697944572 0.02183917537331581
0.04186177791952976 0.04186177791952976 0.03593215346336365
0.04206177758306516 0.04206177758306516 0.047760993242263794
0.04220893879804208 0.04220893879804208 0.052451781928539276
0.042300685147312556 0.042300685147312556 0.0530797615647316
0.04237134791890609 0.04237134791890609 0.05345040559768677
0.042424407658121846 0.042424407658121846 0.05473550781607628
0.04242372629242723 0.04242372629242723 0.05501274764537811
0.0423407680451313 0.0423407680451313 0.052034102380275726
0.04219235207775633 0.04219235207775633 0.04550594091415405
0.0420268218000385 0.0420268218000385 0.03721471130847931
0.04189012714227709 0.04189012714227709 0.030177637934684753
0.041797430680806616 0.041797430680806616 0.02665643021464348
0.04173671613537223 0.04173671613537223 0.025498852133750916
0.0416925411374482 0.0416925411374482 0.023941228166222572
0.0416604168978874 0.0416604168978874 0.021390557289123535
0.04164777191708154 0.04164777191708154 0.01988021843135357
0.041655621796792906 0.041655621796792906 0.021362973377108574
0.04167271697689018 0.04167271697689018 0.024459177628159523
0.041679549765699264 0.041679549765699264 0.0265266802161932
0.04166646896320759 0.04166646896320759 0.026361992582678795
0.041637825198188774 0.041637825198188774 0.02439560554921627
0.04160702722280129 0.04160702722280129 0.021975772455334663
0.04158170787712638 0.04158170787712638 0.02015945129096508
0.0415598334385108 0.0415598334385108 0.01867859438061714
0.04153764702131023 0.04153764702131023 0.016525743529200554
0.04151605771087258 0.04151605771087258 0.013460333459079266
0.04150163501777135 0.04150163501777135 0.010808950290083885
0.04149739375119406 0.04149739375119406 0.010674475692212582
0.0415012237532623 0.0415012237532623 0.012575941160321236
0.04150440207455088 0.04150440207455088 0.01426259521394968
0.0415023393038623 0.0415023393038623 0.014793840236961842
0.04149557630854499 0.04149557630854499 0.014517003670334816
0.04148640923363942 0.04148640923363942 0.014170676469802856
0.04147570710085924 0.04147570710085924 0.013929557986557484
0.041461213074111034 0.041461213074111034 0.01323197316378355
0.04144411797550803 0.04144411797550803 0.01154344156384468
0.041426450666652424 0.041426450666652424 0.008992824703454971
0.04141341642435135 0.04141341642435135 0.006485641933977604
0.0414051760001245 0.0414051760001245 0.005318339914083481
0.041401110973107814 0.041401110973107814 0.005581889301538467
0.04139825789758252 0.04139825789758252 0.006119388621300459
0.04139667926561278 0.04139667926561278 0.006623491179198027
0.04139583686366462 0.04139583686366462 0.00737475510686636
0.04139475150941071 0.04139475150941071 0.008252318017184734
0.04139144855598374 0.04139144855598374 0.008736489340662956
0.04138521832545601 0.04138521832545601 0.00849070306867361
0.04137684451953195 0.04137684451953195 0.007627603132277727
0.04136750361885966 0.04136750361885966 0.006572984624654055
0.041357980656618436 0.041357980656618436 0.00566816283389926
0.04134937334717921 0.04134937334717921 0.004857902880758047
iteration: 3 | epoch: 196 |   loss: 0.041349  |   KL divergence: 0.041349  |  JS divergence: 0.011881
('==== Found maximium gradient [0.06331134, 0.056614093, 0.0543886] of gate '
 'e^[Y0 Z2], e^[Y2 Z0], e^[Y0 Z3] ====')
learning rate =  0.005822829164505025
0.04134134932673741 0.04134134932673741 0.10093134641647339
0.04052765591753057 0.04052765591753057 0.09292585402727127
0.0395944093691151 0.0395944093691151 0.0733710527420044
0.03894527657547243 0.03894527657547243 0.0614638552069664
0.03846958405966028 0.03846958405966028 0.05265171453356743
0.0380565680638341 0.0380565680638341 0.04083803668618202
0.03773642662578798 0.03773642662578798 0.02798481099307537
0.03755056954270684 0.03755056954270684 0.020559675991535187
0.03748342633805427 0.03748342633805427 0.022307192906737328
0.03747386167039772 0.03747386167039772 0.025448372587561607
0.037476794340974645 0.037476794340974645 0.026083648204803467
0.03748716829798161 0.03748716829798161 0.025824902579188347
0.03751003478417367 0.03751003478417367 0.026935728266835213
0.03753976662390171 0.03753976662390171 0.029544923454523087
0.03755689612078415 0.03755689612078415 0.03165249899029732
0.03754137198966957 0.03754137198966957 0.03160015866160393
0.03749523983176795 0.03749523983176795 0.029460979625582695
0.03743129003212677 0.03743129003212677 0.02648794651031494
0.0373642416140345 0.0373642416140345 0.024074887856841087
0.03729975758611628 0.03729975758611628 0.022562768310308456
0.03723686577345308 0.03723686577345308 0.021018413826823235
0.037174578371511724 0.037174578371511724 0.018549447879195213
0.03711734913590165 0.03711734913590165 0.015371940098702908
0.03707094531303124 0.03707094531303124 0.01285721268504858
0.037038262687942775 0.037038262687942775 0.01234168279916048
0.03701388170357169 0.03701388170357169 0.01315045915544033
0.036992157259954084 0.036992157259954084 0.013697389513254166
0.03696984737510847 0.03696984737510847 0.013458824716508389
0.03694640259667263 0.03694640259667263 0.012972203083336353
0.03692366403105679 0.03692366403105679 0.012997517362236977
0.03690154743641332 0.03690154743641332 0.013487442396581173
0.03687706999981068 0.03687706999981068 0.01365271769464016
0.03684990754118424 0.03684990754118424 0.012966255657374859
0.03682153198299894 0.03682153198299894 0.01162655744701624
0.03679405024655785 0.03679405024655785 0.01034555770456791
0.036768884361923215 0.036768884361923215 0.00969658698886633
0.0367457625912318 0.0367457625912318 0.009462455287575722
0.036723443719863025 0.036723443719863025 0.009062748402357101
0.036701647459102996 0.036701647459102996 0.008432702161371708
0.03668129237606268 0.03668129237606268 0.00808802992105484
0.03666235666913092 0.03666235666913092 0.008381471037864685
0.03664394162542696 0.03664394162542696 0.008921134285628796
0.036624589132854005 0.036624589132854005 0.009094201028347015
0.03660431764203259 0.03660431764203259 0.008735700510442257
0.0365824919597162 0.0365824919597162 0.00815514475107193
0.036561263584661496 0.036561263584661496 0.007685043383389711
0.03654032938466591 0.03654032938466591 0.007261228747665882
0.03651949503992957 0.03651949503992957 0.00657695671543479
0.03649837160908853 0.03649837160908853 0.0055664158426225185
0.0364789246072971 0.0364789246072971 0.004642335698008537
iteration: 4 | epoch: 246 |   loss: 0.036479  |   KL divergence: 0.036479  |  JS divergence: 0.010511
('==== Found maximium gradient [0.05198151, 0.05016373, 0.04603195] of gate '
 'e^[Y1 Z4], e^[Y4 Z1], e^[Y3 Z4] ====')
learning rate =  0.00494550902906924
0.03646122750358111 0.03646122750358111 0.08576889336109161
0.03588104585519846 0.03588104585519846 0.07730161398649216
0.03522143380624274 0.03522143380624274 0.05845298618078232
0.03479803000454863 0.03479803000454863 0.04687916114926338
0.03451864677899094 0.03451864677899094 0.03967103734612465
0.03427172595315596 0.03427172595315596 0.02866360917687416
0.03411314132732962 0.03411314132732962 0.018283214420080185
0.03406654421643617 0.03406654421643617 0.01805834472179413
0.034087080767656666 0.034087080767656666 0.02446811832487583
0.0341108397890103 0.0341108397890103 0.028695764020085335
0.03411320753382412 0.03411320753382412 0.02979946881532669
0.03410214766714344 0.03410214766714344 0.0294937901198864
0.03408834870322498 0.03408834870322498 0.029320063069462776
0.034071041584495254 0.034071041584495254 0.029472246766090393
0.03404280749973219 0.03404280749973219 0.028842216357588768
0.03399841680845962 0.03399841680845962 0.026466846466064453
0.033944627256635884 0.033944627256635884 0.02262183278799057
0.03389213808829207 0.03389213808829207 0.01867915317416191
0.03384934142879824 0.03384934142879824 0.016236331313848495
0.03381657888448079 0.03381657888448079 0.0155147360637784
0.033788893024686024 0.033788893024686024 0.015191081911325455
0.03376298010142603 0.03376298010142603 0.014409337192773819
0.03374017833584313 0.03374017833584313 0.01359026599675417
0.03372149898598533 0.03372149898598533 0.013611286878585815
0.03370752861287448 0.03370752861287448 0.014493548311293125
0.03369303252634867 0.03369303252634867 0.015268852934241295
0.033674366733181346 0.033674366733181346 0.015073506161570549
0.03365070008582084 0.03365070008582084 0.013792282901704311
0.03362378377663313 0.03362378377663313 0.0120070930570364
0.03359791454827532 0.03359791454827532 0.010561705566942692
0.03357503074967356 0.03357503074967356 0.00975362304598093
0.0335530730767163 0.0335530730767163 0.00898775551468134
0.033532250376521223 0.033532250376521223 0.00768725760281086
0.03351372535509029 0.03351372535509029 0.006215808447450399
0.03349919330785928 0.03349919330785928 0.005852643866091967
0.033488609474471416 0.033488609474471416 0.00687665119767189
0.0334795915102111 0.0334795915102111 0.007999819703400135
0.03346996025724059 0.03346996025724059 0.008499451912939548
0.03345925738383977 0.03345925738383977 0.008500407449901104
0.03344743385328998 0.03344743385328998 0.008401375263929367
0.033434899775298746 0.033434899775298746 0.008357949554920197
0.03342075669847015 0.03342075669847015 0.008161749690771103
0.03340494838010727 0.03340494838010727 0.007540464401245117
0.033388719616512755 0.033388719616512755 0.006506581790745258
0.033373509500313085 0.033373509500313085 0.0054670702666044235
0.03335916562752064 0.03335916562752064 0.004882871173322201
iteration: 5 | epoch: 292 |   loss: 0.033359  |   KL divergence: 0.033359  |  JS divergence: 0.009448
('==== Found maximium gradient [0.036118872, 0.030814203, 0.029995074] of gate '
 'e^[Y2 Z5], e^[X2 Y1], e^[Y1 Z5] ====')
learning rate =  0.0032423203476426247
0.033346812164549 0.033346812164549 0.05635029822587967
0.03310237738605792 0.03310237738605792 0.053045205771923065
0.032764105326005745 0.032764105326005745 0.04465311020612717
0.03252664306336581 0.03252664306336581 0.040773943066596985
0.03232786181491751 0.03232786181491751 0.0379456952214241
0.03213653878340389 0.03213653878340389 0.0338752344250679
0.03195998161408062 0.03195998161408062 0.029520148411393166
0.03181348180664557 0.03181348180664557 0.026760727167129517
0.03170000890653684 0.03170000890653684 0.026205401867628098
0.031603129475651276 0.031603129475651276 0.026304226368665695
0.031509227806763046 0.031509227806763046 0.025990350171923637
0.031417938011981256 0.031417938011981256 0.025677314028143883
0.03133325982428844 0.03133325982428844 0.02608245052397251
0.03125358263606757 0.03125358263606757 0.027172574773430824
0.031173050962545516 0.031173050962545516 0.028296053409576416
0.03108640816991228 0.03108640816991228 0.028961075469851494
0.030992369668481512 0.030992369668481512 0.02913058176636696
0.03089122533595736 0.03089122533595736 0.028999101370573044
0.03078437475915094 0.03078437475915094 0.028715016320347786
0.030673329298571694 0.030673329298571694 0.028276117518544197
0.03055915710094139 0.03055915710094139 0.02763109840452671
0.03044177556689841 0.03044177556689841 0.026826344430446625
0.030323815808896346 0.030323815808896346 0.026010379195213318
0.030204505375612506 0.030204505375612506 0.02531956136226654
0.03008705453662079 0.03008705453662079 0.02478070743381977
0.029971415839042066 0.029971415839042066 0.024339990690350533
0.029858714998072605 0.029858714998072605 0.023970231413841248
0.029748221736083363 0.029748221736083363 0.023689553141593933
0.029640298413970798 0.029640298413970798 0.02349204383790493
0.02953386625301235 0.02953386625301235 0.023329610005021095
0.029427324950430378 0.029427324950430378 0.023173470050096512
0.029322125906929015 0.029322125906929015 0.02305830828845501
0.029217040950302652 0.029217040950302652 0.02304151840507984
0.029112080446120063 0.029112080446120063 0.02312314882874489
0.029006786172833022 0.029006786172833022 0.02322850376367569
0.028899433420162587 0.028899433420162587 0.02327604778110981
0.02879220333655132 0.02879220333655132 0.023248855024576187
0.028684120831315642 0.028684120831315642 0.023180751129984856
0.028576900549725975 0.028576900549725975 0.023086151108145714
0.028469283641020585 0.028469283641020585 0.02293931134045124
0.02836191050015934 0.02836191050015934 0.02273125946521759
0.02825516529290069 0.02825516529290069 0.02250952646136284
0.02814932999600091 0.02814932999600091 0.022338084876537323
0.02804450457298222 0.02804450457298222 0.022232448682188988
0.02794045387412203 0.02794045387412203 0.02215545065701008
0.02783784034650935 0.02783784034650935 0.022070519626140594
0.027735513950367795 0.027735513950367795 0.021979808807373047
0.027634074528240078 0.027634074528240078 0.02190418727695942
0.027533760707988034 0.027533760707988034 0.02184547670185566
0.027433734795211155 0.027433734795211155 0.021786216646432877
0.02733424903998917 0.02733424903998917 0.021715382114052773
0.027235315302935374 0.027235315302935374 0.021632911637425423
0.027136937846293407 0.027136937846293407 0.021535130217671394
0.02703885335869462 0.02703885335869462 0.02141610160470009
0.02694152534603305 0.02694152534603305 0.02128196321427822
0.026845076710856695 0.026845076710856695 0.02114987187087536
0.026749113166943117 0.026749113166943117 0.02103244699537754
0.026654023526471612 0.026654023526471612 0.020927758887410164
0.02656005373992622 0.02656005373992622 0.020825978368520737
0.02646661015408651 0.02646661015408651 0.020721113309264183
0.02637454335565084 0.02637454335565084 0.020612461492419243
0.026283241107935108 0.026283241107935108 0.02049902081489563
0.02619301182455242 0.02619301182455242 0.020380252972245216
0.026103541949759855 0.026103541949759855 0.020259898155927658
0.026014496637961737 0.026014496637961737 0.02014276385307312
0.02592678571386901 0.02592678571386901 0.020028909668326378
0.025840009646917416 0.025840009646917416 0.01991434395313263
0.02575387236788294 0.02575387236788294 0.019796298816800117
0.02566882045222419 0.02566882045222419 0.019675247371196747
0.02558434309983814 0.02558434309983814 0.019551077857613564
0.025501084233360824 0.025501084233360824 0.019421815872192383
0.025418879870078306 0.025418879870078306 0.01928875222802162
0.025336661973619657 0.025336661973619657 0.0191578958183527
0.02525634967784339 0.02525634967784339 0.01903418079018593
0.02517666353369479 0.02517666353369479 0.01891673356294632
0.025097841017261105 0.025097841017261105 0.018800677731633186
0.025020151211796588 0.025020151211796588 0.018683774396777153
0.02494338632232483 0.02494338632232483 0.018568016588687897
0.024867240941077718 0.024867240941077718 0.018455980345606804
0.024791654671151502 0.024791654671151502 0.01834707148373127
0.024717561976553483 0.024717561976553483 0.018237851560115814
0.024643818691594606 0.024643818691594606 0.01812375895678997
0.02457095126371741 0.02457095126371741 0.01800253987312317
0.024499480831011795 0.024499480831011795 0.017876582220196724
0.024428557357575854 0.024428557357575854 0.017751015722751617
0.02435798561698228 0.02435798561698228 0.0176292285323143
0.02428890707681118 0.02428890707681118 0.01751057244837284
0.02421999816844516 0.02421999816844516 0.01739213615655899
0.02415205240842077 0.02415205240842077 0.017271973192691803
0.02408499716308038 0.02408499716308038 0.017149794846773148
0.02401873093487886 0.02401873093487886 0.017026657238602638
0.023953384754378117 0.023953384754378117 0.016903825104236603
0.023888539151612417 0.023888539151612417 0.016782747581601143
0.023824432218506008 0.023824432218506008 0.016664734110236168
0.023760588887160185 0.023760588887160185 0.01655004359781742
0.023698558045745968 0.023698558045745968 0.016437388956546783
0.0236364334136425 0.0236364334136425 0.016324209049344063
0.023574877171445668 0.023574877171445668 0.016208725050091743
0.023514474720688943 0.023514474720688943 0.016091400757431984
0.02345460200319785 0.02345460200319785 0.01597505994141102
0.023394692348671118 0.023394692348671118 0.01586177572607994
0.023336645669970707 0.023336645669970707 0.015751000493764877
0.023278781001975706 0.023278781001975706 0.01564016565680504
0.02322178611497509 0.02322178611497509 0.015527132898569107
0.023165035971525205 0.023165035971525205 0.015412342734634876
0.023108865419676657 0.023108865419676657 0.015297641046345234
0.0230537656141728 0.0230537656141728 0.015184519812464714
0.022999349654866795 0.022999349654866795 0.015072927810251713
0.02294535260975193 0.02294535260975193 0.014961782842874527
0.022891886792621392 0.022891886792621392 0.01485033892095089
0.022838956551017427 0.022838956551017427 0.014738427475094795
0.022787237538209743 0.022787237538209743 0.014626702293753624
0.02273552363084073 0.02273552363084073 0.014515433460474014
0.022684925991868173 0.022684925991868173 0.014405056834220886
0.02263478789819133 0.02263478789819133 0.014295932836830616
0.022584883525877696 0.022584883525877696 0.014188099652528763
0.022535586049058677 0.022535586049058677 0.01408056728541851
0.02248719372886855 0.02248719372886855 0.013972414657473564
0.022439662409496262 0.022439662409496262 0.013863535597920418
0.022392181134440043 0.022392181134440043 0.013755114749073982
0.02234546139117423 0.02234546139117423 0.013648063875734806
0.022299497642217517 0.022299497642217517 0.013542323373258114
0.022254037711051583 0.022254037711051583 0.013436819426715374
0.02220917834029948 0.02220917834029948 0.013330671004951
0.02216429906970863 0.02216429906970863 0.013224099762737751
0.022121025349601683 0.022121025349601683 0.013118107803165913
0.022077765184224354 0.022077765184224354 0.013013244606554508
0.022035317220355698 0.022035317220355698 0.012909331358969212
0.021992804838011613 0.021992804838011613 0.012805774807929993
0.0219515211643408 0.0219515211643408 0.01270242314785719
0.021910822367900828 0.021910822367900828 0.012599213048815727
0.021870152782601265 0.021870152782601265 0.012496269308030605
0.021830266076711832 0.021830266076711832 0.012393832206726074
0.02179114542811159 0.02179114542811159 0.012292062863707542
0.021752027561145762 0.021752027561145762 0.012191150337457657
0.02171385153995093 0.02171385153995093 0.012090840376913548
0.02167620984317361 0.02167620984317361 0.011990752071142197
0.021639083025453292 0.021639083025453292 0.011890624649822712
0.021602329532916267 0.021602329532916267 0.011790888383984566
0.021565905525550058 0.021565905525550058 0.011691874824464321
0.021530146266106633 0.021530146266106633 0.011593841947615147
0.021495183746604144 0.021495183746604144 0.011496497318148613
0.02146027280022053 0.02146027280022053 0.01139932218939066
0.02142595855570395 0.02142595855570395 0.011302486062049866
0.02139253710559232 0.02139253710559232 0.01120623666793108
0.021359099067854683 0.021359099067854683 0.011110743507742882
0.0213262880055909 0.0213262880055909 0.01101597398519516
0.02129372001887632 0.02129372001887632 0.01092180423438549
0.02126180047624069 0.02126180047624069 0.01082814484834671
0.021230277453202013 0.021230277453202013 0.01073522213846445
0.021199169927159575 0.021199169927159575 0.01064295507967472
0.02116863358382004 0.02116863358382004 0.010551289655268192
0.02113859249380108 0.02113859249380108 0.010460234247148037
0.021108580264690424 0.021108580264690424 0.01036992110311985
0.02107939650601166 0.02107939650601166 0.010280267335474491
0.02105069219403524 0.02105069219403524 0.010191133245825768
0.021021862944897777 0.021021862944897777 0.010102672502398491
0.020993732423681993 0.020993732423681993 0.010014764033257961
0.020966222026526145 0.020966222026526145 0.009927649982273579
0.0209386228784532 0.0209386228784532 0.009841074235737324
0.020911507035594145 0.020911507035594145 0.009755032137036324
0.020885003223092637 0.020885003223092637 0.00966972578316927
0.02085920294355686 0.02085920294355686 0.009585194289684296
0.02083293203766388 0.02083293203766388 0.009501439519226551
0.02080730920425133 0.02080730920425133 0.009418352507054806
0.020782559187637002 0.020782559187637002 0.009335903450846672
0.02075770747937343 0.02075770747937343 0.009254155680537224
0.02073335743479096 0.02073335743479096 0.00917319767177105
0.020709047943872808 0.020709047943872808 0.00909291673451662
0.020684919145278834 0.020684919145278834 0.009013448841869831
0.020661986532789427 0.020661986532789427 0.008934657089412212
0.020638813264479142 0.020638813264479142 0.008856465108692646
0.02061597173032661 0.02061597173032661 0.008778827264904976
0.020593600207512476 0.020593600207512476 0.008701934479176998
0.020571319276471576 0.020571319276471576 0.008625805377960205
0.02054954304059335 0.02054954304059335 0.008550427854061127
0.0205275576420079 0.0205275576420079 0.00847574695944786
0.02050694255091157 0.02050694255091157 0.008401751518249512
0.02048575455157518 0.02048575455157518 0.008328377269208431
0.02046489697415917 0.02046489697415917 0.008255676366388798
0.02044465272270388 0.02044465272270388 0.008183811791241169
0.020424454623878693 0.020424454623878693 0.00811267364770174
0.020404592976194607 0.020404592976194607 0.008042248897254467
0.020385183640607873 0.020385183640607873 0.00797242671251297
0.02036606232803127 0.02036606232803127 0.007903233170509338
0.02034673066918931 0.02034673066918931 0.007834789343178272
0.02032789648236722 0.02032789648236722 0.0077669923193752766
0.02030914438858284 0.02030914438858284 0.007699878420680761
0.02029095507213736 0.02029095507213736 0.007633455563336611
0.020272536954538237 0.020272536954538237 0.0075676655396819115
0.02025527072091828 0.02025527072091828 0.007502446416765451
0.02023762919973098 0.02023762919973098 0.007437894586473703
0.020220425665604214 0.020220425665604214 0.007374137174338102
0.0202031563943268 0.0202031563943268 0.007311022840440273
0.020186465447307646 0.020186465447307646 0.007248629815876484
0.020169616694764463 0.020169616694764463 0.007186766713857651
0.02015301151966303 0.02015301151966303 0.007125571370124817
0.02013641462690961 0.02013641462690961 0.0070649259723722935
0.020120877981704158 0.020120877981704158 0.007004960440099239
0.020105158961468993 0.020105158961468993 0.006945654284209013
0.020089195250108736 0.020089195250108736 0.006886952556669712
0.0200739718318577 0.0200739718318577 0.006828764453530312
0.020058858272727867 0.020058858272727867 0.0067711458541452885
0.020043667621740865 0.020043667621740865 0.006714198738336563
0.02002873436870685 0.02002873436870685 0.006657914724200964
0.020014271625566512 0.020014271625566512 0.006602139212191105
0.019999591195065523 0.019999591195065523 0.00654687499627471
0.019985612854953427 0.019985612854953427 0.00649228086695075
0.019971602248822627 0.019971602248822627 0.0064383093267679214
0.019957376474878327 0.019957376474878327 0.006384838838130236
0.019944036494738502 0.019944036494738502 0.006332007702440023
0.019929811074169627 0.019929811074169627 0.0062796203419566154
0.019916901500870166 0.019916901500870166 0.006227824371308088
0.019904167435368277 0.019904167435368277 0.006176530383527279
0.019890561124028337 0.019890561124028337 0.006125729996711016
0.019877586183720597 0.019877586183720597 0.006075509823858738
0.01986508885460007 0.01986508885460007 0.00602572038769722
0.019852333588155077 0.019852333588155077 0.005976484622806311
0.019840151495607805 0.019840151495607805 0.0059278286062181
0.01982792938306907 0.01982792938306907 0.0058797188103199005
0.01981552525753361 0.01981552525753361 0.00583201227709651
0.019803930029383052 0.019803930029383052 0.005784888751804829
0.019792148441393414 0.019792148441393414 0.005738153588026762
0.019780102618207087 0.019780102618207087 0.005691920407116413
0.019768581225451498 0.019768581225451498 0.005646240897476673
0.019757424846170026 0.019757424846170026 0.005600966978818178
0.019746250068599206 0.019746250068599206 0.00555604649707675
0.019735032388297463 0.019735032388297463 0.005511593539267778
0.019724190222693113 0.019724190222693113 0.005467671435326338
0.019713066334208863 0.019713066334208863 0.005424101371318102
0.019702157015695766 0.019702157015695766 0.005381041672080755
0.01969175052919096 0.01969175052919096 0.00533845741301775
0.019681344972936454 0.019681344972936454 0.005296316463500261
0.01967076310830869 0.01967076310830869 0.005254564806818962
0.019661045469494643 0.019661045469494643 0.005213163793087006
0.019651074831109182 0.019651074831109182 0.005172202363610268
0.01964113196968637 0.01964113196968637 0.005131683312356472
0.01963122130949228 0.01963122130949228 0.0050916001200675964
0.019621456376246987 0.019621456376246987 0.005051825661212206
0.019612060829931086 0.019612060829931086 0.005012347362935543
0.01960270990209746 0.01960270990209746 0.004973301663994789
iteration: 6 | epoch: 533 |   loss: 0.019603  |   KL divergence: 0.019603  |  JS divergence: 0.005449
('==== Found maximium gradient [0.027812332, 0.026096001, 0.025638115] of gate '
 'e^[X2 Y0], e^[X3 Y0], e^[X1 Y0] ====')
learning rate =  0.0026531993151243053
0.019593308552925015 0.019593308552925015 0.04621895030140877
0.01944433122519507 0.01944433122519507 0.036689642816782
0.019232263107986345 0.019232263107986345 0.03348978981375694
0.019055036780818036 0.019055036780818036 0.03313157334923744
0.018872237499936835 0.018872237499936835 0.03278080374002457
0.018676549317124612 0.018676549317124612 0.03169305995106697
0.018482822426646978 0.018482822426646978 0.03057938814163208
0.018298497536534383 0.018298497536534383 0.030108977109193802
0.018120700896228373 0.018120700896228373 0.03003847226500511
0.017944833503882988 0.017944833503882988 0.029928376898169518
0.0177691394369229 0.0177691394369229 0.029622245579957962
0.017598040838609705 0.017598040838609705 0.029228590428829193
0.0174344517475889 0.0174344517475889 0.028840119019150734
0.017276791933185955 0.017276791933185955 0.028397822752594948
0.017123374495898264 0.017123374495898264 0.027805915102362633
0.016972715891141806 0.016972715891141806 0.02704809606075287
0.01682605883609887 0.01682605883609887 0.026208214461803436
0.01668361268312558 0.01668361268312558 0.025415461510419846
0.016546288038858416 0.016546288038858416 0.024770839139819145
0.016414754683639298 0.016414754683639298 0.02429596334695816
0.01628648290291707 0.01628648290291707 0.023933585733175278
0.016161397611072544 0.016161397611072544 0.02360563538968563
0.016040112899951 0.016040112899951 0.023276761174201965
0.015921988277050693 0.015921988277050693 0.022952407598495483
0.01580849844314051 0.01580849844314051 0.0226270891726017
0.01569899870091134 0.01569899870091134 0.02226470597088337
0.015591888511580427 0.015591888511580427 0.021837016567587852
0.015487415203560288 0.015487415203560288 0.021359065547585487
0.015386161853034042 0.015386161853034042 0.02088523469865322
0.015287410906988626 0.015287410906988626 0.020470140501856804
0.015192272682325958 0.015192272682325958 0.02012099325656891
0.015099507531201067 0.015099507531201067 0.01979105919599533
0.015009087793066743 0.015009087793066743 0.01943521574139595
0.014920722107512876 0.014920722107512876 0.019059231504797935
0.014834916022251532 0.014834916022251532 0.01870196871459484
0.01475194257141773 0.01475194257141773 0.018385108560323715
0.014671205024442087 0.014671205024442087 0.018096325919032097
0.01459285037664336 0.01459285037664336 0.017811965197324753
0.014516266842613586 0.014516266842613586 0.017519719898700714
0.01444183619547631 0.01444183619547631 0.017221547663211823
0.014369034646185412 0.014369034646185412 0.016920771449804306
0.014299263651316323 0.014299263651316323 0.01660892926156521
0.014231278149397958 0.014231278149397958 0.01627197302877903
0.014165073782908164 0.014165073782908164 0.015912918373942375
0.014101119491991422 0.014101119491991422 0.015560660511255264
0.01403846013627134 0.01403846013627134 0.015245421789586544
0.01397756933494711 0.01397756933494711 0.014973603188991547
0.013919090350570235 0.013919090350570235 0.01473316177725792
0.01386195177543115 0.01386195177543115 0.014508504420518875
0.013806670327285784 0.013806670327285784 0.014285551384091377
0.013752713471255692 0.013752713471255692 0.014055565930902958
0.013700535469654562 0.013700535469654562 0.013816633261740208
0.013649316739202883 0.013649316739202883 0.013572092168033123
0.013599907768076881 0.013599907768076881 0.013329721987247467
0.013551757629123553 0.013551757629123553 0.013100211508572102
0.013504848972105295 0.013504848972105295 0.012889000587165356
0.013459469909203993 0.013459469909203993 0.012693339958786964
0.01341529245460121 0.01341529245460121 0.012506392784416676
0.013371880002522565 0.013371880002522565 0.01232131291180849
0.013330164244039053 0.013330164244039053 0.012134726159274578
0.013289157276541735 0.013289157276541735 0.01194598339498043
0.013249114730214506 0.013249114730214506 0.011754925362765789
0.013210149698211654 0.013210149698211654 0.011564383283257484
0.013172387544557997 0.013172387544557997 0.011380857788026333
0.013135324027011888 0.013135324027011888 0.011209212243556976
0.013099424957285822 0.013099424957285822 0.011047051288187504
0.013064696252029946 0.013064696252029946 0.010885162279009819
0.013030132407186402 0.013030132407186402 0.010715911164879799
0.012997024619259915 0.012997024619259915 0.010540831834077835
0.012964540916462014 0.012964540916462014 0.0103685911744833
0.012932932131439449 0.012932932131439449 0.010206704959273338
0.01290227069892574 0.01290227069892574 0.01005631685256958
0.012872308311970386 0.012872308311970386 0.009913676418364048
0.012842821346650442 0.012842821346650442 0.00977299828082323
0.012814612602103528 0.012814612602103528 0.009629114530980587
0.012786796638338326 0.012786796638338326 0.009480142034590244
0.012759336854649316 0.012759336854649316 0.009328216314315796
0.012733284842228968 0.012733284842228968 0.009178509935736656
0.012707926450956596 0.012707926450956596 0.009036260657012463
0.012683036666941705 0.012683036666941705 0.008902940899133682
0.012658710692164035 0.012658710692164035 0.008776911534368992
0.01263480404885415 0.01263480404885415 0.008654998615384102
0.012611745084627077 0.012611745084627077 0.008533807471394539
0.012589248596351825 0.012589248596351825 0.008409759029746056
0.012567386837554428 0.012567386837554428 0.008280792273581028
0.012545657121032934 0.012545657121032934 0.008148479275405407
0.012524915018536965 0.012524915018536965 0.00801763404160738
0.012504994955882611 0.012504994955882611 0.007893812842667103
0.01248509028234486 0.01248509028234486 0.007779787760227919
0.0124662502925261 0.0124662502925261 0.007674063555896282
0.012447320265405926 0.012447320265405926 0.007571800146251917
0.012429666942663222 0.012429666942663222 0.007467609364539385
0.012411690258966646 0.012411690258966646 0.007358694449067116
0.012394361977644746 0.012394361977644746 0.007246114779263735
0.012378000536341426 0.012378000536341426 0.0071334270760416985
0.012361617746090056 0.012361617746090056 0.007024308200925589
0.012345559977885731 0.012345559977885731 0.006920917890965939
0.01232989199075541 0.01232989199075541 0.006823874078691006
0.012315267406529657 0.012315267406529657 0.00673172902315855
0.01230046065916687 0.01230046065916687 0.006641244515776634
0.012286170731553383 0.012286170731553383 0.006548623088747263
0.01227170566344908 0.01227170566344908 0.00645217252895236
0.012258654796386614 0.012258654796386614 0.006353789009153843
0.012245634445297592 0.012245634445297592 0.006257247179746628
0.012232926825056296 0.012232926825056296 0.006165338680148125
0.012220310495302818 0.012220310495302818 0.006078091915696859
0.01220808309136383 0.01220808309136383 0.0059936996549367905
0.01219639651560285 0.01219639651560285 0.005910431034862995
0.012184624101099896 0.012184624101099896 0.00582762248814106
0.012173786445513889 0.012173786445513889 0.005745308473706245
0.012162588219149034 0.012162588219149034 0.0056635551154613495
0.012151870521563862 0.012151870521563862 0.005582424812018871
0.012141480362224396 0.012141480362224396 0.005502173211425543
0.012131435824962029 0.012131435824962029 0.005423347000032663
0.012122020492278023 0.012122020492278023 0.005346368532627821
0.012112160544676322 0.012112160544676322 0.005271369591355324
0.012103149619428061 0.012103149619428061 0.005197884049266577
0.012093932041841643 0.012093932041841643 0.005125322379171848
0.012085013134864571 0.012085013134864571 0.0050533064641058445
0.012076727812983419 0.012076727812983419 0.0049822055734694
iteration: 7 | epoch: 653 |   loss: 0.012077  |   KL divergence: 0.012077  |  JS divergence: 0.003407
('==== Found maximium gradient [0.023965534, 0.022214556, 0.021167735] of gate '
 'e^[X3 Y4], e^[X0 Y4], e^[Y2 Z6] ====')
learning rate =  0.0022478925223345624
0.01206856588568428 0.01206856588568428 0.03924329951405525
0.011938308570893372 0.011938308570893372 0.03686182573437691
0.011775184280748197 0.011775184280748197 0.03256751969456673
0.01165004349006799 0.01165004349006799 0.029519662261009216
0.011531758675328425 0.011531758675328425 0.02793154865503311
0.011404485613525746 0.011404485613525746 0.024881690740585327
0.011288874415452997 0.011288874415452997 0.024131322279572487
0.011178288215149384 0.011178288215149384 0.023711666464805603
0.011067470694285845 0.011067470694285845 0.02243313379585743
0.010961340498783634 0.010961340498783634 0.022108761593699455
0.010857794689791662 0.010857794689791662 0.02227294258773327
0.010755829038577375 0.010755829038577375 0.022316185757517815
0.010659499531011089 0.010659499531011089 0.023030364885926247
0.010568013371418867 0.010568013371418867 0.02421402931213379
0.010478693697703911 0.010478693697703911 0.024904385209083557
0.010391269826355824 0.010391269826355824 0.025279264897108078
0.010305303179072326 0.010305303179072326 0.025690119713544846
0.010218146128651639 0.010218146128651639 0.02567356824874878
0.010130211002502273 0.010130211002502273 0.025104619562625885
0.010043631073030235 0.010043631073030235 0.02448803372681141
0.009959457061169175 0.009959457061169175 0.023901157081127167
0.00987585074317113 0.00987585074317113 0.023023396730422974
0.009793097557714276 0.009793097557714276 0.022039487957954407
0.009711259077704246 0.009711259077704246 0.02125830575823784
0.00963087057630328 0.00963087057630328 0.020557047799229622
0.009552487482692143 0.009552487482692143 0.019937215372920036
0.009476585417336229 0.009476585417336229 0.0195882860571146
0.009401796237558676 0.009401796237558676 0.01933259516954422
0.009328637059691931 0.009328637059691931 0.018981343135237694
0.009256312948452326 0.009256312948452326 0.018754247575998306
0.009186067492164201 0.009186067492164201 0.018735093995928764
0.009117209865847213 0.009117209865847213 0.01876586116850376
0.009050011269940891 0.009050011269940891 0.01888371631503105
0.008984840905445626 0.008984840905445626 0.019102925434708595
0.008920483815118282 0.008920483815118282 0.019215313717722893
0.008857002940537814 0.008857002940537814 0.019175391644239426
0.008795330813374882 0.008795330813374882 0.019090944901108742
0.008734488310467565 0.008734488310467565 0.018924852833151817
0.008674048245294002 0.008674048245294002 0.01865401864051819
0.00861488706941365 0.00861488706941365 0.018345380201935768
0.008556723909130693 0.008556723909130693 0.017960935831069946
0.008499893441525543 0.008499893441525543 0.01748405583202839
0.008444073783531247 0.008444073783531247 0.017037123441696167
0.008389022959102045 0.008389022959102045 0.016665173694491386
0.008335410139128346 0.008335410139128346 0.016348853707313538
0.008282346277746877 0.008282346277746877 0.016123441979289055
0.008231012820041482 0.008231012820041482 0.015955686569213867
0.008180375494848029 0.008180375494848029 0.015787752345204353
0.00813144603812788 0.00813144603812788 0.01566413789987564
0.008082888500022598 0.008082888500022598 0.015597346238791943
0.008035690933125898 0.008035690933125898 0.015544301830232143
0.00798933973409097 0.00798933973409097 0.015498127788305283
0.007944451930181413 0.007944451930181413 0.015425946563482285
0.007900129033088791 0.007900129033088791 0.015292973257601261
0.007856559032545968 0.007856559032545968 0.015131141059100628
0.00781403092738718 0.00781403092738718 0.014955682680010796
0.007772370321449169 0.007772370321449169 0.014761552214622498
0.007731674213338975 0.007731674213338975 0.014560134150087833
0.007691274406310931 0.007691274406310931 0.014332148246467113
0.0076523168377883415 0.0076523168377883415 0.014072182588279247
0.007614130701071958 0.007614130701071958 0.013822011649608612
0.007576506221666753 0.007576506221666753 0.013599945232272148
0.007540093152789594 0.007540093152789594 0.013410542160272598
0.007504092744231609 0.007504092744231609 0.013255782425403595
0.007468914401716434 0.007468914401716434 0.013114490546286106
0.007434711103660105 0.007434711103660105 0.012985719367861748
0.007401085559157455 0.007401085559157455 0.012879855930805206
0.007368632945029266 0.007368632945029266 0.012790464796125889
0.0073365290056970085 0.0073365290056970085 0.012711641378700733
0.007305104212559279 0.007305104212559279 0.012624594382941723
0.007274124290340774 0.007274124290340774 0.01251195278018713
0.007244061661761508 0.007244061661761508 0.012384588830173016
0.007214170569977839 0.007214170569977839 0.012249025516211987
0.0071853448990518275 0.0071853448990518275 0.01210540160536766
0.007157239801882761 0.007157239801882761 0.01195280160754919
0.0071293568643873645 0.0071293568643873645 0.011787213385105133
0.007102097597179852 0.007102097597179852 0.011620200239121914
0.0070756859425123095 0.0070756859425123095 0.011466104537248611
0.007049227618475535 0.007049227618475535 0.01132779661566019
0.007023645273115381 0.007023645273115381 0.011203981004655361
0.006998851551982457 0.006998851551982457 0.011084677651524544
0.006974378241648259 0.006974378241648259 0.01096674706786871
0.006950591767163544 0.006950591767163544 0.010856128297746181
0.006927049385621924 0.006927049385621924 0.010754048824310303
0.006904197039286094 0.006904197039286094 0.010659064166247845
0.006881650716920092 0.006881650716920092 0.01056445948779583
0.006859307655767326 0.006859307655767326 0.010465512983500957
0.006837617552925902 0.006837617552925902 0.01036395225673914
0.0068160889942495435 0.0068160889942495435 0.010258717462420464
0.006794988417905516 0.006794988417905516 0.010147622786462307
0.006774940797560992 0.006774940797560992 0.010029640048742294
0.006755026468282745 0.006755026468282745 0.009906475432217121
0.0067352077999374305 0.0067352077999374305 0.009785261936485767
0.006716044870519307 0.006716044870519307 0.009670150466263294
0.006696990030904702 0.006696990030904702 0.00956109631806612
0.0066785089672550535 0.0066785089672550535 0.009455012157559395
0.0066599343547743065 0.0066599343547743065 0.00935046374797821
0.006642212679322562 0.006642212679322562 0.009250846691429615
0.006624617491367275 0.006624617491367275 0.009157994762063026
0.0066073671014994255 0.0066073671014994255 0.009070809930562973
0.0065905905840058345 0.0065905905840058345 0.008985981345176697
0.006574140748309032 0.006574140748309032 0.00890045054256916
0.0065580287534059796 0.0065580287534059796 0.00881440844386816
0.006541957701711254 0.006541957701711254 0.00872763805091381
0.006526337512460885 0.006526337512460885 0.008639320731163025
0.006510917789729181 0.006510917789729181 0.008547832258045673
0.006496164447495215 0.006496164447495215 0.00845316518098116
0.0064815035594661865 0.0064815035594661865 0.008358017541468143
0.006466569531049973 0.006466569531049973 0.008263909257948399
0.006453014833730472 0.006453014833730472 0.008172046393156052
0.006438126774083895 0.006438126774083895 0.008082584477961063
0.006424888768723408 0.006424888768723408 0.00799650140106678
0.00641168406731284 0.00641168406731284 0.007914574816823006
0.006398231732062663 0.006398231732062663 0.00783567875623703
0.0063851690486532355 0.0063851690486532355 0.007757888175547123
0.0063729118354663335 0.0063729118354663335 0.007679484318941832
0.00636025258638552 0.00636025258638552 0.007600921206176281
0.006347815530692555 0.006347815530692555 0.007523344364017248
0.006335798331314068 0.006335798331314068 0.007446476258337498
0.006323819765338866 0.006323819765338866 0.0073692696169018745
0.006312516902132345 0.006312516902132345 0.007290996145457029
0.006301300844040132 0.006301300844040132 0.007212525233626366
0.006289723358436781 0.006289723358436781 0.0071343532763421535
0.006279138247476826 0.006279138247476826 0.007056545931845903
0.006268577948494554 0.006268577948494554 0.006978990975767374
0.006257832834890799 0.006257832834890799 0.006902208086103201
0.00624752110766924 0.00624752110766924 0.006827143486589193
0.006237689984805326 0.006237689984805326 0.006754101254045963
0.006227602057020332 0.006227602057020332 0.006682754494249821
0.00621774503810211 0.00621774503810211 0.00661246944218874
0.006208267668862228 0.006208267668862228 0.006543474737554789
0.006198936421514657 0.006198936421514657 0.006475457455962896
0.00618950054485995 0.00618950054485995 0.006408027373254299
0.006180339847559623 0.006180339847559623 0.0063403015956282616
0.006172005302974437 0.006172005302974437 0.006272303871810436
0.006163072228828427 0.006163072228828427 0.006204256322234869
0.006154525861208793 0.006154525861208793 0.0061364686116576195
0.0061463672461446045 0.0061463672461446045 0.006068953312933445
0.006137886717867738 0.006137886717867738 0.006001819856464863
0.006129934118581791 0.006129934118581791 0.005935505498200655
0.006122049487354734 0.006122049487354734 0.005870329216122627
0.006114280606407712 0.006114280606407712 0.005806164816021919
0.006106837027829281 0.006106837027829281 0.005742785055190325
0.006099088621787865 0.006099088621787865 0.005680125672370195
0.006091961336367915 0.006091961336367915 0.005618581082671881
0.006084789802178454 0.006084789802178454 0.005558167118579149
0.00607729322619887 0.00607729322619887 0.0054981340654194355
0.006070825922087189 0.006070825922087189 0.0054383971728384495
0.006063749960032381 0.006063749960032381 0.005378779489547014
0.006057065986963249 0.006057065986963249 0.005319499876350164
0.00605077360097219 0.00605077360097219 0.005260528530925512
0.006044493009422156 0.006044493009422156 0.005201646592468023
0.006037923996644244 0.006037923996644244 0.005143255461007357
0.006031788654449134 0.006031788654449134 0.005085428711026907
0.006025876370821182 0.006025876370821182 0.005028386600315571
0.006019922290907469 0.006019922290907469 0.004971922375261784
iteration: 8 | epoch: 809 |   loss: 0.006020  |   KL divergence: 0.006020  |  JS divergence: 0.001673
('==== Found maximium gradient [0.021758102, 0.018738568, 0.017477022] of gate '
 'e^[Y3 Z5], e^[Y5 Z2], e^[X3 Y5] ====')
learning rate =  0.001940786190014465
0.006014475618305425 0.006014475618305425 0.03397301211953163
0.0059170122861147405 0.0059170122861147405 0.03316272050142288
0.005812917743848829 0.005812917743848829 0.031099533662199974
0.005704350844989757 0.005704350844989757 0.026458313688635826
0.005613706793347272 0.005613706793347272 0.023732544854283333
0.005537052605926247 0.005537052605926247 0.0232393816113472
0.005454472410375317 0.005454472410375317 0.02049400471150875
0.0053792868384628465 0.0053792868384628465 0.018294433131814003
0.005314906803579265 0.005314906803579265 0.018046440556645393
0.005252747079135504 0.005252747079135504 0.01693161576986313
0.005191521783688535 0.005191521783688535 0.015093988738954067
0.005138034455606962 0.005138034455606962 0.014657889492809772
0.005089302497423721 0.005089302497423721 0.014974278397858143
0.005041297438323068 0.005041297438323068 0.014375762082636356
0.004996076355212611 0.004996076355212611 0.013676299713551998
0.004956083510879598 0.004956083510879598 0.014087031595408916
0.004918339490545066 0.004918339490545066 0.014707404188811779
0.004879674168218863 0.004879674168218863 0.014594990760087967
0.0048426975576580066 0.0048426975576580066 0.01439790427684784
0.004807659393121585 0.004807659393121585 0.01475227065384388
0.004772411990262797 0.004772411990262797 0.015014407224953175
0.004736651439180955 0.004736651439180955 0.014626627787947655
0.004700934784462674 0.004700934784462674 0.014079977758228779
0.0046658762060483375 0.0046658762060483375 0.01385238766670227
0.004631007783223971 0.004631007783223971 0.013551969081163406
0.004596850021427185 0.004596850021427185 0.012846555560827255
0.004562936463774241 0.004562936463774241 0.012117642909288406
0.004531043954144897 0.004531043954144897 0.011665167286992073
0.004500051573407768 0.004500051573407768 0.011174412444233894
0.004469352237889998 0.004469352237889998 0.010494761168956757
0.004440108614175231 0.004440108614175231 0.00998866930603981
0.0044132360583495804 0.0044132360583495804 0.00976809673011303
0.0043864253912897794 0.0043864253912897794 0.009502552449703217
0.004360487484669792 0.004360487484669792 0.009150288067758083
0.004335536126922587 0.004335536126922587 0.008967405185103416
0.00431224298572887 0.00431224298572887 0.008904129266738892
0.004288987345244796 0.004288987345244796 0.008764559403061867
0.0042662516723744135 0.0042662516723744135 0.008673486299812794
0.004244891686217024 0.004244891686217024 0.008758330717682838
0.004223830822776335 0.004223830822776335 0.008825688622891903
0.004202723261898227 0.004202723261898227 0.008764070458710194
0.004182383782344442 0.004182383782344442 0.008729414083063602
0.004162586475651865 0.004162586475651865 0.008756994269788265
0.004142562973970967 0.004142562973970967 0.008705470710992813
0.00412324712066117 0.00412324712066117 0.008598756976425648
0.004104490573629259 0.004104490573629259 0.008544357493519783
0.004086327532614209 0.004086327532614209 0.008459934033453465
0.0040674346966315875 0.0040674346966315875 0.008257544599473476
0.0040494224714200866 0.0040494224714200866 0.00803317315876484
0.004032344361348656 0.004032344361348656 0.00784314051270485
0.004015011806552856 0.004015011806552856 0.0076220715418457985
0.003999376036658565 0.003999376036658565 0.0073983571492135525
0.003982929662740844 0.003982929662740844 0.007240186911076307
0.003967443047361972 0.003967443047361972 0.007086309138685465
0.003952425928429673 0.003952425928429673 0.006900612264871597
0.0039374397190670395 0.0039374397190670395 0.006753926165401936
0.003923164185558984 0.003923164185558984 0.006647950503975153
0.003909262471637128 0.003909262471637128 0.006540802773088217
0.0038955514473840657 0.0038955514473840657 0.006464063189923763
0.0038822989547703103 0.0038822989547703103 0.006412227638065815
0.0038691206429914086 0.0038691206429914086 0.006325567606836557
0.0038571468879469066 0.0038571468879469066 0.006225903984159231
0.0038447004205826463 0.0038447004205826463 0.006153206806629896
0.003832400666656392 0.003832400666656392 0.006078687030822039
0.003820415402482361 0.003820415402482361 0.006002125795930624
0.003809500025250889 0.003809500025250889 0.005945200566202402
0.003797967924109016 0.003797967924109016 0.005872230511158705
0.003787126730483567 0.003787126730483567 0.005773400422185659
0.0037765204374417124 0.0037765204374417124 0.005685298703610897
0.00376607702040511 0.00376607702040511 0.005602639634162188
0.0037563686932566183 0.0037563686932566183 0.00551234558224678
0.0037464526268198373 0.0037464526268198373 0.005428934469819069
0.003737400274720088 0.003737400274720088 0.0053396569564938545
0.00372789698276053 0.00372789698276053 0.005233146250247955
0.003718989880878273 0.003718989880878273 0.005132087040692568
0.003710381152858742 0.003710381152858742 0.005042895209044218
0.003701598249920457 0.003701598249920457 0.004956288728863001
iteration: 9 | epoch: 886 |   loss: 0.003702  |   KL divergence: 0.003702  |  JS divergence: 0.000992
('==== Found maximium gradient [0.015286293, 0.014838858, 0.011683922] of gate '
 'e^[Y1 Z6], e^[Y3 Z6], e^[Y2 Z7] ====')
learning rate =  0.0014028262817580876
0.003693033843059853 0.003693033843059853 0.024782096967101097
0.003640479819720945 0.003640479819720945 0.02288629114627838
0.003584765785916507 0.003584765785916507 0.021953510120511055
0.003526386122296781 0.003526386122296781 0.0177132710814476
0.003490422189581041 0.003490422189581041 0.01795630156993866
0.0034493983721470374 0.0034493983721470374 0.01480264775454998
0.003414038631779983 0.003414038631779983 0.01115894503891468
0.0033905781553966773 0.0033905781553966773 0.010521357879042625
0.0033723292839834026 0.0033723292839834026 0.009482812136411667
0.0033569680297690797 0.0033569680297690797 0.0070416685193777084
0.003345462565378237 0.003345462565378237 0.005931728053838015
0.0033375974878319574 0.0033375974878319574 0.006645806133747101
0.003333117456720886 0.003333117456720886 0.006613471079617739
0.003329232074431603 0.003329232074431603 0.006222303491085768
0.0033273392222919304 0.0033273392222919304 0.006863360293209553
0.0033248390944092014 0.0033248390944092014 0.007746719289571047
0.003321726886795328 0.003321726886795328 0.007797427475452423
0.003316621396473996 0.003316621396473996 0.007482783403247595
0.003312089300003428 0.003312089300003428 0.007686533499509096
0.003307111642540034 0.003307111642540034 0.008032790385186672
0.0033002245158029095 0.0033002245158029095 0.007769046816974878
0.0032921446553342646 0.0032921446553342646 0.0071069360710680485
0.0032842044262537244 0.0032842044262537244 0.006703391205519438
0.0032767530113353713 0.0032767530113353713 0.006488388404250145
0.0032689097327541225 0.0032689097327541225 0.00597069226205349
0.0032614012553907404 0.0032614012553907404 0.005261349957436323
0.003254541865426676 0.003254541865426676 0.00480648735538125
iteration: 10 | epoch: 913 |   loss: 0.003255  |   KL divergence: 0.003255  |  JS divergence: 0.000864
('==== Found maximium gradient [0.011197642, 0.010787095, 0.010443685] of gate '
 'e^[Y0 Z5], e^[X2 Y6], e^[X1 Y6] ====')
learning rate =  0.0010813867132338276
0.0032484667607251302 0.0032484667607251302 0.019260307773947716
0.003235920355032874 0.003235920355032874 0.021853351965546608
0.0031846678063127353 0.0031846678063127353 0.014307205565273762
0.0031647405577582615 0.0031647405577582615 0.014351051300764084
0.003150072201720066 0.003150072201720066 0.01548600010573864
0.0031270560999068437 0.0031270560999068437 0.013791829347610474
0.0031031198504143562 0.0031031198504143562 0.011737402528524399
0.003085408671223891 0.003085408671223891 0.011519397608935833
0.003070339327575301 0.003070339327575301 0.012456831522285938
0.0030541903898315065 0.0030541903898315065 0.01253928616642952
0.0030345052840771583 0.0030345052840771583 0.01137640979140997
0.0030137728064068073 0.0030137728064068073 0.009892131201922894
0.002995138073177057 0.002995138073177057 0.009209869429469109
0.0029782889634530924 0.0029782889634530924 0.00939514022320509
0.002962442548749126 0.002962442548749126 0.009585685096681118
0.0029467215833908263 0.0029467215833908263 0.009322038851678371
0.002930543518090068 0.002930543518090068 0.008852127008140087
0.002915104285595614 0.002915104285595614 0.008643577806651592
0.002899410834306658 0.002899410834306658 0.008779875002801418
0.002884689400356844 0.002884689400356844 0.008904709480702877
0.002869556774567716 0.002869556774567716 0.008730129338800907
0.0028541013893302854 0.0028541013893302854 0.008330394513905048
0.0028388431185756525 0.0028388431185756525 0.007986899465322495
0.0028234201763411293 0.0028234201763411293 0.007826271466910839
0.0028084889522420205 0.0028084889522420205 0.007692969404160976
0.002794195901745737 0.002794195901745737 0.007423144765198231
0.002779972069539108 0.002779972069539108 0.007077166344970465
0.0027665519156362586 0.0027665519156362586 0.006838017608970404
0.002753022826437753 0.002753022826437753 0.006751225795596838
0.0027399646009178356 0.0027399646009178356 0.006682677194476128
0.0027275403760584857 0.0027275403760584857 0.006536656524986029
0.0027159223072396087 0.0027159223072396087 0.006378293503075838
0.0027044007530682094 0.0027044007530682094 0.0063064219430089
0.0026933230036325258 0.0026933230036325258 0.006284987088292837
0.002682258631638279 0.002682258631638279 0.0061830622144043446
0.0026710961300717346 0.0026710961300717346 0.005957106128334999
0.002660539491435688 0.002660539491435688 0.005713791120797396
0.0026505046615770836 0.0026505046615770836 0.005570049863308668
0.0026408032869690715 0.0026408032869690715 0.005495065823197365
0.002631533829647629 0.002631533829647629 0.005375618115067482
0.0026224753807987887 0.0026224753807987887 0.005193765740841627
0.002613780158414572 0.002613780158414572 0.005047450307756662
0.002605069670607856 0.002605069670607856 0.004997411277145147
iteration: 11 | epoch: 956 |   loss: 0.002605  |   KL divergence: 0.002605  |  JS divergence: 0.000681
('==== Found maximium gradient [0.008616617, 0.008347092, 0.008088201] of gate '
 'e^[Y4 Z5], e^[Y3 Z4], e^[Y2 Z0] ====')
learning rate =  0.0008353423244173647
0.002596607239134255 0.002596607239134255 0.015299949795007706
0.0025896743305241048 0.0025896743305241048 0.017999906092882156
0.0025472260465673746 0.0025472260465673746 0.013027853332459927
0.0025255369409545765 0.0025255369409545765 0.013747317716479301
0.002507482111753258 0.002507482111753258 0.015184360556304455
0.0024819956327406466 0.0024819956327406466 0.014112615026533604
0.0024569795361905214 0.0024569795361905214 0.012206252664327621
0.0024352355918760595 0.0024352355918760595 0.01133142039179802
0.0024178455606219777 0.0024178455606219777 0.011693548411130905
0.0024005909199404573 0.0024005909199404573 0.011877045966684818
0.002381665384604983 0.002381665384604983 0.011151249520480633
0.0023625549426950464 0.0023625549426950464 0.009972685016691685
0.0023458006851539088 0.0023458006851539088 0.0092536099255085
0.0023301062927574764 0.0023301062927574764 0.009407183155417442
0.0023162976085466594 0.0023162976085466594 0.009868497960269451
0.0023014939710945246 0.0023014939710945246 0.009961262345314026
0.0022865330102379987 0.0022865330102379987 0.009595516137778759
0.002271394451379489 0.002271394451379489 0.009149194695055485
0.0022575335793445835 0.0022575335793445835 0.009035075083374977
0.0022439699468961138 0.0022439699468961138 0.009259115904569626
0.0022311159461296136 0.0022311159461296136 0.009450425393879414
0.00221817094375932 0.00221817094375932 0.009310927242040634
0.0022052266783339847 0.0022052266783339847 0.008864046074450016
0.002191301346468123 0.002191301346468123 0.008370310068130493
0.002178964556796728 0.002178964556796728 0.008067633025348186
0.0021674334591408415 0.0021674334591408415 0.007940671406686306
0.002155105654691524 0.002155105654691524 0.007792245130985975
0.0021436415852123703 0.0021436415852123703 0.0075136274099349976
0.002132115482757997 0.002132115482757997 0.007200161460787058
0.0021211841049964737 0.0021211841049964737 0.007024051155894995
0.0021102285771089696 0.0021102285771089696 0.007021510042250156
0.0021005136690878195 0.0021005136690878195 0.007047870196402073
0.0020902942576741562 0.0020902942576741562 0.0069527048617601395
0.0020807835696115004 0.0020807835696115004 0.006727953441441059
0.0020710260479189276 0.0020710260479189276 0.006485539488494396
0.002061626651551229 0.002061626651551229 0.006323499139398336
0.002053289907456072 0.002053289907456072 0.006230018101632595
0.002044742971239114 0.002044742971239114 0.0061335754580795765
0.0020359005124224363 0.0020359005124224363 0.006010929588228464
0.00202789786099863 0.00202789786099863 0.0059069073759019375
0.0020203822530538945 0.0020203822530538945 0.005858961492776871
0.002012652872620535 0.002012652872620535 0.0058351438492536545
0.0020049907740435635 0.0020049907740435635 0.00576791213825345
0.001997899470482015 0.001997899470482015 0.005628011655062437
0.0019902783494488664 0.0019902783494488664 0.005446314346045256
0.0019838068828766605 0.0019838068828766605 0.005273811984807253
0.0019770082282221367 0.0019770082282221367 0.005133319646120071
0.001970699754439361 0.001970699754439361 0.005019616801291704
0.0019645311533200214 0.0019645311533200214 0.004929236602038145
iteration: 12 | epoch: 1005 |   loss: 0.001965  |   KL divergence: 0.001965  |  JS divergence: 0.000510
('==== Found maximium gradient [0.0076398966, 0.007516959, 0.007170918] of '
 'gate e^[Y1 Z7], e^[Y3 Z7], e^[Y0 Z6] ====')
learning rate =  0.0007445239381750008
0.0019584324905411936 0.0019584324905411936 0.013784735463559628
0.0019411081327770096 0.0019411081327770096 0.014264191500842571
0.0019158551761584664 0.0019158551761584664 0.011693288572132587
0.001899558170914052 0.001899558170914052 0.010293658822774887
0.001883637348355234 0.001883637348355234 0.00900841224938631
0.0018681771861423948 0.0018681771861423948 0.008112041279673576
0.0018540166829131752 0.0018540166829131752 0.006851335987448692
0.0018428342906543233 0.0018428342906543233 0.0059926072135567665
0.0018345636182302357 0.0018345636182302357 0.005956689827144146
0.00182771919212992 0.00182771919212992 0.005651142913848162
0.0018203654752941612 0.0018203654752941612 0.00478988466784358
iteration: 13 | epoch: 1016 |   loss: 0.001820  |   KL divergence: 0.001820  |  JS divergence: 0.000471
('==== Found maximium gradient [0.0059352224, 0.005919393, 0.005379971] of '
 'gate e^[Y2 Z8], e^[Y5 Z3], e^[X2 Y7] ====')
learning rate =  0.0005750657331025669
0.0018148189212672304 0.0018148189212672304 0.010810218751430511
0.0018064179396856577 0.0018064179396856577 0.011340400204062462
0.001790674696462154 0.001790674696462154 0.008945186622440815
0.001779487309355483 0.001779487309355483 0.009057150222361088
0.0017686906049089594 0.0017686906049089594 0.008656922727823257
0.0017576556926247812 0.0017576556926247812 0.007799105253070593
0.0017473396121416226 0.0017473396121416226 0.0075105419382452965
0.0017381868746927714 0.0017381868746927714 0.007697540335357189
0.0017298144427031988 0.0017298144427031988 0.007638130336999893
0.0017207778998064626 0.0017207778998064626 0.007249253802001476
0.0017129588014170197 0.0017129588014170197 0.006922976579517126
0.001704668166922311 0.001704668166922311 0.006895001046359539
0.0016968436716552687 0.0016968436716552687 0.006996938027441502
0.0016887934708616531 0.0016887934708616531 0.006982003804296255
0.001681988890067649 0.001681988890067649 0.006848425138741732
0.0016738347793540335 0.0016738347793540335 0.006740225479006767
0.0016658757490490336 0.0016658757490490336 0.006716906558722258
0.001658982986664028 0.001658982986664028 0.006697576958686113
0.0016510444947603416 0.0016510444947603416 0.006599082611501217
0.001643915460310895 0.001643915460310895 0.006449575070291758
0.0016357032587026212 0.0016357032587026212 0.0063351658172905445
0.0016285510249402341 0.0016285510249402341 0.006280796602368355
0.0016209638665531686 0.0016209638665531686 0.006230637896806002
0.0016143661879574932 0.0016143661879574932 0.006141043733805418
0.0016066654300706806 0.0016066654300706806 0.006036931183189154
0.0015993735540332631 0.0015993735540332631 0.0059605613350868225
0.001592352526235104 0.001592352526235104 0.0059070708230137825
0.0015849204418214341 0.0015849204418214341 0.005839817691594362
0.0015784457904630127 0.0015784457904630127 0.005746013484895229
0.001571956381704001 0.001571956381704001 0.005650738719850779
0.0015650008185040956 0.0015650008185040956 0.0055809589102864265
0.0015581854752442265 0.0015581854752442265 0.005534795578569174
0.0015514508400108842 0.0015514508400108842 0.005497654899954796
0.0015450873630538592 0.0015450873630538592 0.005471954122185707
0.001538686536049797 0.001538686536049797 0.005467606242746115
0.0015321653569536264 0.0015321653569536264 0.005472480785101652
0.0015263673735638882 0.0015263673735638882 0.005458894185721874
0.0015197624038726853 0.0015197624038726853 0.005419171415269375
0.0015138794378688162 0.0015138794378688162 0.0053739119321107864
0.0015079105889416083 0.0015079105889416083 0.005342272575944662
0.0015020756444146886 0.0015020756444146886 0.005320614669471979
0.0014961401945978827 0.0014961401945978827 0.005295671988278627
0.0014896623340665013 0.0014896623340665013 0.005265249405056238
0.0014849213404789527 0.0014849213404789527 0.0052359094843268394
0.0014784158587602327 0.0014784158587602327 0.005206532310694456
0.001472607803244101 0.001472607803244101 0.005168204195797443
0.0014671450834555615 0.0014671450834555615 0.005120185669511557
0.0014613345650826806 0.0014613345650826806 0.005071679130196571
0.0014564391006745602 0.0014564391006745602 0.0050274888053536415
0.0014508628821414634 0.0014508628821414634 0.004984789062291384
iteration: 14 | epoch: 1066 |   loss: 0.001451  |   KL divergence: 0.001451  |  JS divergence: 0.000371
('==== Found maximium gradient [0.0048217075, 0.004413065, 0.004273267] of '
 'gate e^[Y4 Z6], e^[Y3 Z1], e^[Y6 Z4] ====')
learning rate =  0.000450868853833047
0.0014453446224482163 0.0014453446224482163 0.009242667816579342
0.0014373514232321972 0.0014373514232321972 0.008974838070571423
0.0014268432149257063 0.0014268432149257063 0.007599852047860622
0.0014196929716905706 0.0014196929716905706 0.006906644906848669
0.0014121466349771277 0.0014121466349771277 0.006522827316075563
0.001404877179604744 0.001404877179604744 0.006332073826342821
0.001397976413602236 0.001397976413602236 0.006265473552048206
0.0013927424729549157 0.0013927424729549157 0.006378896068781614
0.0013873582825751848 0.0013873582825751848 0.006631785072386265
0.0013819580861176317 0.0013819580861176317 0.006747341714799404
0.0013766054218580864 0.0013766054218580864 0.006595361977815628
0.0013705161315564754 0.0013705161315564754 0.006324262358248234
0.001364372347017129 0.001364372347017129 0.006092896685004234
0.0013584330781682295 0.0013584330781682295 0.005896400194615126
0.0013528275888276921 0.0013528275888276921 0.005678702611476183
0.001346964711488089 0.001346964711488089 0.005466924514621496
0.0013414641632414977 0.0013414641632414977 0.005310388747602701
0.0013353788757800573 0.0013353788757800573 0.00520151574164629
0.0013301019321912773 0.0013301019321912773 0.005115995649248362
0.001324751622674018 0.001324751622674018 0.00506220618262887
0.001319981809033924 0.001319981809033924 0.005049328785389662
0.0013149476702709823 0.0013149476702709823 0.005052480846643448
0.0013097730703196847 0.0013097730703196847 0.005046036094427109
0.0013048756570237662 0.0013048756570237662 0.005035749636590481
0.0013001191819033264 0.0013001191819033264 0.005029011517763138
0.001294626219019628 0.001294626219019628 0.005011015105992556
0.0012902693327655397 0.0012902693327655397 0.004966846201568842
iteration: 15 | epoch: 1093 |   loss: 0.001290  |   KL divergence: 0.001290  |  JS divergence: 0.000330
('==== Found maximium gradient [0.004158251, 0.0038428179, 0.0038019835] of '
 'gate e^[X2 Y8], e^[Y1 Z8], e^[Y3 Z8] ====')
learning rate =  0.00039375703786962557
0.0012851045695325982 0.0012851045695325982 0.008396057412028313
0.0012772899575984363 0.0012772899575984363 0.00795983336865902
0.0012689422452976382 0.0012689422452976382 0.0072339861653745174
0.0012609172331706359 0.0012609172331706359 0.00672773877158761
0.0012540707988045253 0.0012540707988045253 0.0062967268750071526
0.0012469387960134934 0.0012469387960134934 0.005879618227481842
0.001240705978079385 0.001240705978079385 0.00549268675968051
0.0012350827494069618 0.0012350827494069618 0.005233960226178169
0.0012301480481966846 0.0012301480481966846 0.0051225777715444565
0.0012249268580587166 0.0012249268580587166 0.005032298155128956
0.0012203427243282414 0.0012203427243282414 0.004929203074425459
iteration: 16 | epoch: 1104 |   loss: 0.001220  |   KL divergence: 0.001220  |  JS divergence: 0.000311
('==== Found maximium gradient [0.003691834, 0.0035872164, 0.0035468237] of '
 'gate e^[Y0 Z7], e^[Y4 Z3], e^[X4 Y5] ====')
learning rate =  0.0003609142009241373
0.00121590290421153 0.00121590290421153 0.007910010404884815
0.0012098855789138257 0.0012098855789138257 0.007517806254327297
0.0012012917735880967 0.0012012917735880967 0.007179595530033112
0.001193274271342227 0.001193274271342227 0.006897157058119774
0.0011865517323440004 0.0011865517323440004 0.006910393014550209
0.0011792865973020952 0.0011792865973020952 0.006764763034880161
0.001172801432682824 0.001172801432682824 0.0066970703192055225
0.0011660138907638965 0.0011660138907638965 0.00656524021178484
0.0011593612161696848 0.0011593612161696848 0.006367531139403582
0.0011532519855042569 0.0011532519855042569 0.00621472904458642
0.0011471156664146166 0.0011471156664146166 0.006072387099266052
0.001141227083557682 0.001141227083557682 0.005921804346144199
0.0011351568204936038 0.0011351568204936038 0.005830795504152775
0.0011295088462500364 0.0011295088462500364 0.005808072164654732
0.0011249757320080092 0.0011249757320080092 0.005785681772977114
0.0011192232334178397 0.0011192232334178397 0.005740918684750795
0.0011142812337391846 0.0011142812337391846 0.005702754016965628
0.0011085843775635934 0.0011085843775635934 0.005673359148204327
0.0011038329986995503 0.0011038329986995503 0.005631003528833389
0.0010980321347030123 0.0010980321347030123 0.005576268769800663
0.0010927084361917034 0.0010927084361917034 0.005516831763088703
0.0010880962486999133 0.0010880962486999133 0.005445638205856085
0.0010830331216078923 0.0010830331216078923 0.00536702573299408
0.00107822715326281 0.00107822715326281 0.00530124269425869
0.0010735545264732521 0.0010735545264732521 0.00525322649627924
0.001068726273305085 0.001068726273305085 0.005213710013777018
0.0010636057299986226 0.0010636057299986226 0.005183383356779814
0.0010583317057155902 0.0010583317057155902 0.005162587855011225
0.0010548995969720393 0.0010548995969720393 0.005136386025696993
0.0010496722603682085 0.0010496722603682085 0.005093802232295275
0.001045702531225205 0.001045702531225205 0.005042858421802521
0.0010402631302736994 0.0010402631302736994 0.004994500428438187
iteration: 17 | epoch: 1136 |   loss: 0.001040  |   KL divergence: 0.001040  |  JS divergence: 0.000264
('==== Found maximium gradient [0.0035313873, 0.0033259601, 0.003257205] of '
 'gate e^[X4 Y1], e^[X1 Y4], e^[Y8 Z0] ====')
learning rate =  0.0003373528880064681
0.0010364487610706676 0.0010364487610706676 0.007658591028302908
0.001029481998535942 0.001029481998535942 0.007889331318438053
0.0010217196040783114 0.0010217196040783114 0.0070503950119018555
0.001014594503813964 0.001014594503813964 0.006799620576202869
0.001007811131702723 0.001007811131702723 0.006694338750094175
0.0010010361026325555 0.0010010361026325555 0.00665406184270978
0.0009934605284030002 0.0009934605284030002 0.006551053840667009
0.0009864514998424354 0.0009864514998424354 0.006472583394497633
0.0009800357223808407 0.0009800357223808407 0.0064483266323804855
0.0009747880473766845 0.0009747880473766845 0.006372446194291115
0.0009675573403015229 0.0009675573403015229 0.006231814157217741
0.0009608070112269012 0.0009608070112269012 0.00611124187707901
0.0009544946661308976 0.0009544946661308976 0.006047671660780907
0.0009484606175695314 0.0009484606175695314 0.0060199834406375885
0.0009423643798823354 0.0009423643798823354 0.006016000639647245
0.0009365130282023504 0.0009365130282023504 0.0060197398997843266
0.0009302861369716265 0.0009302861369716265 0.006002037785947323
0.0009247562731724496 0.0009247562731724496 0.005961609538644552
0.000918623298856798 0.000918623298856798 0.005921030882745981
0.0009131646330249095 0.0009131646330249095 0.005884149577468634
0.0009075197702255195 0.0009075197702255195 0.00583646772429347
0.0009018097836726884 0.0009018097836726884 0.0057779839262366295
0.0008960224480275324 0.0008960224480275324 0.005725499242544174
0.000891061494404676 0.000891061494404676 0.005688298027962446
0.0008849143551828665 0.0008849143551828665 0.005663542076945305
0.0008799671868315593 0.0008799671868315593 0.005646341014653444
0.0008744356522021353 0.0008744356522021353 0.005627562757581472
0.0008698011892191051 0.0008698011892191051 0.005596021190285683
0.0008645785481827423 0.0008645785481827423 0.005549285560846329
0.000858510197819951 0.000858510197819951 0.005494061391800642
0.0008539967989998348 0.0008539967989998348 0.005436394363641739
0.0008489590141892058 0.0008489590141892058 0.0053789964877069
0.0008438454060199523 0.0008438454060199523 0.005324927624315023
0.0008394411315706785 0.0008394411315706785 0.005275969859212637
0.0008342457203117507 0.0008342457203117507 0.005229562520980835
0.000829515601663086 0.000829515601663086 0.005182537715882063
0.0008248937535018464 0.0008248937535018464 0.005133887752890587
0.000820260689167096 0.000820260689167096 0.005083759780973196
0.0008153574664176921 0.0008153574664176921 0.005033949855715036
0.0008111205433635566 0.0008111205433635566 0.004987337160855532
iteration: 18 | epoch: 1176 |   loss: 0.000811  |   KL divergence: 0.000811  |  JS divergence: 0.000205
('==== Found maximium gradient [0.002992339, 0.0029888614, 0.0026925327] of '
 'gate e^[Y4 Z7], e^[Y2 Z9], e^[Y2 Z5] ====')
learning rate =  0.0002894657074807828
0.0008064970131154844 0.0008064970131154844 0.007042675279080868
0.0008001408708827795 0.0008001408708827795 0.006996531970798969
0.0007943076298121501 0.0007943076298121501 0.0065661147236824036
0.0007886454468478582 0.0007886454468478582 0.006309028249233961
0.0007821422954905253 0.0007821422954905253 0.006128774955868721
0.0007762930507173148 0.0007762930507173148 0.005941756535321474
0.0007712731248027715 0.0007712731248027715 0.005679355468600988
0.0007661140540445059 0.0007661140540445059 0.005462256725877523
0.0007604360395563616 0.0007604360395563616 0.005322092212736607
0.0007559972280227819 0.0007559972280227819 0.00517547270283103
0.0007512136755307608 0.0007512136755307608 0.0050599100068211555
0.0007466699336772012 0.0007466699336772012 0.005003387574106455
0.0007430109317114371 0.0007430109317114371 0.004993274342268705
iteration: 19 | epoch: 1189 |   loss: 0.000743  |   KL divergence: 0.000743  |  JS divergence: 0.000187
('==== Found maximium gradient [0.002269282, 0.0022404795, 0.0019489274] of '
 'gate e^[Y2 Z5], e^[Y7 Z2], e^[X6 Y5] ====')
learning rate =  0.0002157754110676496
0.0007381005047498622 0.0007381005047498622 0.006251705810427666
0.0007343366247057961 0.0007343366247057961 0.00589600158855319
0.0007290779007876523 0.0007290779007876523 0.005501134786754847
0.000725242646800038 0.000725242646800038 0.005340686067938805
0.0007205093602351241 0.0007205093602351241 0.005291378125548363
0.0007158754143785368 0.0007158754143785368 0.005252246279269457
0.0007121290384826257 0.0007121290384826257 0.005226852837949991
0.000707960462885266 0.000707960462885266 0.005223449785262346
0.0007035962373966936 0.0007035962373966936 0.005219190381467342
0.0006993404354250356 0.0006993404354250356 0.00516075175255537
0.0006953149101127569 0.0006953149101127569 0.005057427100837231
0.0006913003725084699 0.0006913003725084699 0.00496060261502862
iteration: 20 | epoch: 1201 |   loss: 0.000691  |   KL divergence: 0.000691  |  JS divergence: 0.000174
('==== Found maximium gradient [0.0019679915, 0.0019587185, 0.0018588973] of '
 'gate e^[Y1 Z9], e^[Y3 Z9], e^[X3 Y6] ====')
learning rate =  0.0001929167905313572
0.0006875555680155377 0.0006875555680155377 0.005918620619922876
0.00068315395048766 0.00068315395048766 0.005803125910460949
0.0006782856346719434 0.0006782856346719434 0.005476129241287708
0.0006739644064930158 0.0006739644064930158 0.005343562923371792
0.0006701540354155632 0.0006701540354155632 0.005217885132879019
0.0006659951489702957 0.0006659951489702957 0.005142212845385075
0.0006618232935129808 0.0006618232935129808 0.005114331375807524
0.0006579926049539558 0.0006579926049539558 0.005064979661256075
0.0006545288657687286 0.0006545288657687286 0.004976615309715271
iteration: 21 | epoch: 1210 |   loss: 0.000655  |   KL divergence: 0.000655  |  JS divergence: 0.000165
('==== Found maximium gradient [0.0017211165, 0.0016962436, 0.0016473006] of '
 'gate e^[Y6 Z1], e^[X3 Y6], e^[X1 Y4] ====')
learning rate =  0.00016884986548259553
0.0006498209155896411 0.0006498209155896411 0.005688454955816269
0.0006463224125618902 0.0006463224125618902 0.005627910606563091
0.0006425560876657881 0.0006425560876657881 0.005258849356323481
0.0006387328690696724 0.0006387328690696724 0.005180293694138527
0.000634786915418279 0.000634786915418279 0.005155500490218401
0.0006305524205088208 0.0006305524205088208 0.005157852079719305
0.0006272735326240827 0.0006272735326240827 0.0051612863317132
0.000624084265730067 0.000624084265730067 0.005175701342523098
0.0006201664836599142 0.0006201664836599142 0.005133797414600849
0.0006158294560653356 0.0006158294560653356 0.005105067975819111
0.0006124645166317692 0.0006124645166317692 0.005059676710516214
0.0006094869217175114 0.0006094869217175114 0.0050003440119326115
0.0006061671843538969 0.0006061671843538969 0.004938451107591391
iteration: 22 | epoch: 1223 |   loss: 0.000606  |   KL divergence: 0.000606  |  JS divergence: 0.000152
('==== Found maximium gradient [0.0016580019, 0.001569178, 0.0015609192] of '
 'gate e^[X1 Y5], e^[Y6 Z1], e^[Y5 Z2] ====')
learning rate =  0.00015966379652996034
0.000602981393580981 0.000602981393580981 0.005604640580713749
0.0005986700789858555 0.0005986700789858555 0.005627645645290613
0.0005943890194467258 0.0005943890194467258 0.005388587713241577
0.0005907099470939065 0.0005907099470939065 0.005302933976054192
0.0005870893695141635 0.0005870893695141635 0.005202949047088623
0.0005831272559098936 0.0005831272559098936 0.005099622532725334
0.0005793624110445604 0.0005793624110445604 0.005006952211260796
0.000575864081528237 0.000575864081528237 0.00492352619767189
iteration: 23 | epoch: 1231 |   loss: 0.000576  |   KL divergence: 0.000576  |  JS divergence: 0.000145
('==== Found maximium gradient [0.0015707477, 0.0014968565, 0.001427892] of '
 'gate e^[Y2 Z4], e^[X1 Y5], e^[X2 Y9] ====')
learning rate =  0.0001499633643894879
0.0005720442612454178 0.0005720442612454178 0.005514667835086584
0.0005685442192251303 0.0005685442192251303 0.005469037219882011
0.0005647205765257592 0.0005647205765257592 0.005297966301441193
0.0005600417702945575 0.0005600417702945575 0.005215533543378115
0.0005567891540501447 0.0005567891540501447 0.00516570033505559
0.0005537885305803737 0.0005537885305803737 0.005105034913867712
0.0005495653527963478 0.0005495653527963478 0.005041693802922964
0.0005463190781666779 0.0005463190781666779 0.004984334111213684
iteration: 24 | epoch: 1239 |   loss: 0.000546  |   KL divergence: 0.000546  |  JS divergence: 0.000137
('==== Found maximium gradient [0.0015052698, 0.0014657291, 0.0013458189] of '
 'gate e^[X3 Y1], e^[Y6 Z0], e^[X2 Y1] ====')
learning rate =  0.0001440535512802679
0.0005426656574254339 0.0005426656574254339 0.005519680678844452
0.0005392049873551386 0.0005392049873551386 0.005258920136839151
0.0005350325907271606 0.0005350325907271606 0.00500112259760499
0.0005316559229464386 0.0005316559229464386 0.004890977870672941
iteration: 25 | epoch: 1243 |   loss: 0.000532  |   KL divergence: 0.000532  |  JS divergence: 0.000134
('==== Found maximium gradient [0.001429607, 0.0014101884, 0.0014070779] of '
 'gate e^[X6 Y9], e^[X7 Y9], e^[X5 Y9] ====')
learning rate =  0.00014156595250007717
0.0005280626030788134 0.0005280626030788134 0.005429605022072792
0.0005243515114093138 0.0005243515114093138 0.004996368661522865
iteration: 26 | epoch: 1245 |   loss: 0.000524  |   KL divergence: 0.000524  |  JS divergence: 0.000132
('==== Found maximium gradient [0.0013591229, 0.0013214477, 0.0011917306] of '
 'gate e^[X4 Y1], e^[X2 Y5], e^[X1 Y5] ====')
learning rate =  0.00012927569149255686
0.0005205159542919325 0.0005205159542919325 0.005238358397036791
0.0005167321064937643 0.0005167321064937643 0.005091955419629812
0.0005135245722999537 0.0005135245722999537 0.005103833507746458
0.0005096321936461523 0.0005096321936461523 0.0051291752606630325
0.000507150248556336 0.000507150248556336 0.005093548912554979
0.0005032093697887659 0.0005032093697887659 0.005024784244596958
0.0004995050468327843 0.0004995050468327843 0.004955240059643984
iteration: 27 | epoch: 1252 |   loss: 0.000500  |   KL divergence: 0.000500  |  JS divergence: 0.000126
('==== Found maximium gradient [0.0015742076, 0.0014340979, 0.0013931945] of '
 'gate e^[X6 Y5], e^[X7 Y5], e^[X8 Y5] ====')
learning rate =  0.00014692126316579192
0.0004959880464461543 0.0004959880464461543 0.005517158657312393
0.0004923537607255093 0.0004923537607255093 0.005298546049743891
0.0004880085067812686 0.0004880085067812686 0.005015259608626366
0.00048400645288920654 0.00048400645288920654 0.005015322007238865
0.00048078045934336 0.00048078045934336 0.005009638611227274
0.0004767847115540823 0.0004767847115540823 0.004907975904643536
iteration: 28 | epoch: 1258 |   loss: 0.000477  |   KL divergence: 0.000477  |  JS divergence: 0.000120
('==== Found maximium gradient [0.0014088406, 0.0013820227, 0.001233722] of '
 'gate e^[X2 Y5], e^[Y4 Z2], e^[X4 Y1] ====')
learning rate =  0.00013437371302448515
0.00047336559843089415 0.00047336559843089415 0.005304645746946335
0.0004700427891385912 0.0004700427891385912 0.005041651427745819
0.0004651040025766575 0.0004651040025766575 0.0047240788117051125
iteration: 29 | epoch: 1261 |   loss: 0.000465  |   KL divergence: 0.000465  |  JS divergence: 0.000117
('==== Found maximium gradient [0.0011775213, 0.0011202594, 0.0011104717] of '
 'gate e^[X1 Y7], e^[Y8 Z2], e^[Y3 Z0] ====')
learning rate =  0.00011364689561566356
0.0004617447022966169 0.0004617447022966169 0.004953843541443348
iteration: 30 | epoch: 1262 |   loss: 0.000462  |   KL divergence: 0.000462  |  JS divergence: 0.000116
('==== Found maximium gradient [0.0012370379, 0.0011774118, 0.0011661917] of '
 'gate e^[X1 Y9], e^[Y0 Z2], e^[X2 Y9] ====')
learning rate =  0.00011939521072836784
0.0004586328150228114 0.0004586328150228114 0.005277371499687433
0.0004548416688424882 0.0004548416688424882 0.004822212737053633
iteration: 31 | epoch: 1264 |   loss: 0.000455  |   KL divergence: 0.000455  |  JS divergence: 0.000114
('==== Found maximium gradient [0.0011585929, 0.0010982758, 0.0010371516] of '
 'gate e^[X0 Y3], e^[Y6 Z2], e^[X1 Y4] ====')
learning rate =  0.00010991254682025385
0.00045041283434551143 0.00045041283434551143 0.005148113239556551
0.00044734085994415864 0.00044734085994415864 0.004924980457872152
iteration: 32 | epoch: 1266 |   loss: 0.000447  |   KL divergence: 0.000447  |  JS divergence: 0.000112
('==== Found maximium gradient [0.0010456443, 0.0010407604, 0.0010378554] of '
 'gate RY[4], e^[X9 Y4], e^[X8 Y4] ====')
learning rate =  0.00010414250193300588
0.0004440210040760771 0.0004440210040760771 0.005165704991668463
0.00043983247492250115 0.00043983247492250115 0.004940231330692768
iteration: 33 | epoch: 1268 |   loss: 0.000440  |   KL divergence: 0.000440  |  JS divergence: 0.000111
('==== Found maximium gradient [0.001058533, 0.0010218193, 0.0009704786] of '
 'gate e^[X1 Y4], e^[Y2 Z3], e^[X1 Y7] ====')
learning rate =  0.00010175846404553673
0.0004356583933571083 0.0004356583933571083 0.005165996961295605
0.0004324154916669961 0.0004324154916669961 0.005006214138120413
0.00042901832652271444 0.00042901832652271444 0.004926268942654133
iteration: 34 | epoch: 1271 |   loss: 0.000429  |   KL divergence: 0.000429  |  JS divergence: 0.000108
('==== Found maximium gradient [0.0009861018, 0.00092764414, 0.00092318474] of '
 'gate e^[X5 Y7], e^[Y0 Z9], e^[X6 Y7] ====')
Convergence criterion has reached, break the loop!
