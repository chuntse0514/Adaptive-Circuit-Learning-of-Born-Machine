nohup: ignoring input
('==== Found maximium gradient [0.29810816, 0.29810813, 0.29810813] of gate '
 'e^[X1 Y0], e^[X6 Y0], e^[X13 Y0] ====')
learning rate =  0.05962163065212838
0.07780715339459152 0.07780715339459152 0.6273967623710632
0.039981999097603874 0.039981999097603874 0.2609078288078308
0.0239606249160198 0.0239606249160198 0.271937757730484
0.03900757947233128 0.03900757947233128 0.4376727044582367
0.04240255636769625 0.04240255636769625 0.4123087227344513
0.030062668403633815 0.030062668403633815 0.27291324734687805
0.019026815183296342 0.019026815183296342 0.1265263557434082
0.018552874697301585 0.018552874697301585 0.16317465901374817
0.02506567571425039 0.02506567571425039 0.26420995593070984
0.028745398891214715 0.028745398891214715 0.3016568422317505
0.025126749996178553 0.025126749996178553 0.2672556936740875
0.01780053696135927 0.01780053696135927 0.17981316149234772
0.012723902527665353 0.012723902527665353 0.07176610082387924
0.012911997812344282 0.012911997812344282 0.07960115373134613
0.01664368018550241 0.01664368018550241 0.16674081981182098
0.01964586309808003 0.01964586309808003 0.21447880566120148
0.019211860054647232 0.019211860054647232 0.21063435077667236
0.016073324755481424 0.016073324755481424 0.16290250420570374
0.012890267654350038 0.012890267654350038 0.0919947475194931
0.011716135950853565 0.011716135950853565 0.051521480083465576
0.01255508705633786 0.01255508705633786 0.0970267727971077
0.013805593882004825 0.013805593882004825 0.13869774341583252
0.01395063149867103 0.01395063149867103 0.1494312584400177
0.012827635591038116 0.012827635591038116 0.12854672968387604
0.011453197368367656 0.011453197368367656 0.08628329634666443
0.010885156796511515 0.010885156796511515 0.0497933067381382
0.011261903357949271 0.011261903357949271 0.06664066016674042
0.011820738115806972 0.011820738115806972 0.09906195849180222
0.01174901010996447 0.01174901010996447 0.11235080659389496
0.01095642467328813 0.01095642467328813 0.10069871693849564
0.010036705779884957 0.010036705779884957 0.06962711364030838
0.009603479023385136 0.009603479023385136 0.03603305295109749
0.009742729796707095 0.009742729796707095 0.04160270839929581
0.010051593837906747 0.010051593837906747 0.06775733083486557
0.010092829009216197 0.010092829009216197 0.0811925083398819
0.009769843536348924 0.009769843536348924 0.07654357701539993
0.009318316904398799 0.009318316904398799 0.057183969765901566
0.009015131970594364 0.009015131970594364 0.03434118628501892
0.00892911903576719 0.00892911903576719 0.03290953114628792
0.008923126146385595 0.008923126146385595 0.04922720044851303
0.008840162348944169 0.008840162348944169 0.058624785393476486
0.008657521551470614 0.008657521551470614 0.05495857074856758
0.008465122327977722 0.008465122327977722 0.040904171764850616
0.00834133434469669 0.00834133434469669 0.026699936017394066
0.008282795239947965 0.008282795239947965 0.02914702333509922
0.008232164061590507 0.008232164061590507 0.0402107834815979
0.008142164363781186 0.008142164363781186 0.04496891051530838
0.007999774439808614 0.007999774439808614 0.039792273193597794
0.007833985059872615 0.007833985059872615 0.02697713114321232
0.007704160800115335 0.007704160800115335 0.016202470287680626
0.0076493323328601145 0.0076493323328601145 0.022803334519267082
0.007641379905828695 0.007641379905828695 0.032502274960279465
0.007605227047855849 0.007605227047855849 0.03460186347365379
0.007500783287921045 0.007500783287921045 0.02805493026971817
0.007366795643686309 0.007366795643686309 0.01697700098156929
0.007271913678882414 0.007271913678882414 0.013660387136042118
0.00723458275827301 0.00723458275827301 0.021416714414954185
0.007211172365569096 0.007211172365569096 0.026136094704270363
0.0071557776453694925 0.0071557776453694925 0.023915380239486694
0.007071697589255902 0.007071697589255902 0.016359295696020126
0.006998355599255617 0.006998355599255617 0.010670310817658901
0.006961390364432319 0.006961390364432319 0.015254332683980465
0.006940616377033282 0.006940616377033282 0.02031089924275875
0.0068995653410789505 0.0068995653410789505 0.019993554800748825
0.006831938797531715 0.006831938797531715 0.014310541562736034
0.0067679663621269875 0.0067679663621269875 0.0074492390267550945
0.006735015049214589 0.006735015049214589 0.009802953340113163
0.00672316665638752 0.00672316665638752 0.015084123238921165
0.006701629520833032 0.006701629520833032 0.01616791822016239
0.006657323246021262 0.006657323246021262 0.012566379271447659
0.00660874329954464 0.00660874329954464 0.007018145639449358
0.006578224100056026 0.006578224100056026 0.007214710116386414
0.006563375774799063 0.006563375774799063 0.0112949563190341
0.006545631570221078 0.006545631570221078 0.01244404911994934
0.006515942519817368 0.006515942519817368 0.009803048335015774
0.006484919054095997 0.006484919054095997 0.005640437360852957
0.006466489089658535 0.006466489089658535 0.006135542411357164
0.006455722771280102 0.006455722771280102 0.009247079491615295
0.0064394390761463634 0.0064394390761463634 0.009828797541558743
0.006415575567159298 0.006415575567159298 0.007355480454862118
0.0063945983018190876 0.0063945983018190876 0.003925980534404516
0.006382913473650508 0.006382913473650508 0.004859225358814001
0.006375255731946313 0.006375255731946313 0.007307724561542273
0.006363490955069584 0.006363490955069584 0.007566966116428375
0.006348146246267463 0.006348146246267463 0.005612044129520655
0.00633561816433829 0.00633561816433829 0.003428176511079073
0.00632729506408574 0.00632729506408574 0.004276062827557325
0.006319677649343895 0.006319677649343895 0.005727427080273628
0.006311007099622942 0.006311007099622942 0.005543622653931379
0.006301661766072938 0.006301661766072938 0.0039140270091593266
0.00629484055142304 0.00629484055142304 0.00278706313110888
0.006289579589218827 0.006289579589218827 0.003842330537736416
0.006284443085356619 0.006284443085356619 0.004674965050071478
0.006278052960916219 0.006278052960916219 0.004135544877499342
0.0062719820543648535 0.0062719820543648535 0.0026510385796427727
0.006267595628224551 0.006267595628224551 0.0021081455051898956
0.006264475431475345 0.006264475431475345 0.003154188860207796
0.00626120163566939 0.00626120163566939 0.003643585601821542
0.0062572636613419325 0.0062572636613419325 0.0030254069715738297
0.0062543839016305095 0.0062543839016305095 0.0019004128407686949
iteration: 1 | epoch: 101 |   loss: 0.006254  |   KL divergence: 0.006254  |  JS divergence: 0.001685
('==== Found maximium gradient [0.07160322, 0.06637317, 0.036230892] of gate '
 'e^[Y0 Z2], e^[Y2 Z0], CRY[2, 0] ====')
learning rate =  0.012025028011237025
0.006251063111120905 0.006251063111120905 0.10415703803300858
0.004779645568821147 0.004779645568821147 0.06840561330318451
0.0038285169202004793 0.0038285169202004793 0.021392345428466797
0.00388240957256415 0.00388240957256415 0.03378687798976898
0.004166424840751028 0.004166424840751028 0.046194083988666534
0.004417243913969924 0.004417243913969924 0.056934505701065063
0.004479479021822504 0.004479479021822504 0.061706554144620895
0.004284833654149522 0.004284833654149522 0.053517863154411316
0.004001921113625706 0.004001921113625706 0.03681371733546257
0.0038182762363907796 0.0038182762363907796 0.023190323263406754
0.003753815555287913 0.003753815555287913 0.01886671781539917
0.0037687060479500373 0.0037687060479500373 0.01951267011463642
0.0038501870974012656 0.0038501870974012656 0.025831012055277824
0.003952752291731004 0.003952752291731004 0.03386911377310753
0.003990675096034877 0.003990675096034877 0.03671184927225113
0.003936790994664751 0.003936790994664751 0.03332900628447533
0.003845374878574475 0.003845374878574475 0.027357757091522217
0.0037640688162492884 0.0037640688162492884 0.02158096246421337
0.0037060156011900114 0.0037060156011900114 0.014548594132065773
0.0036833270342042225 0.0036833270342042225 0.007398292422294617
0.0037100799349840618 0.0037100799349840618 0.012854795902967453
0.00376105421808478 0.00376105421808478 0.02096802182495594
0.003792415628032274 0.003792415628032274 0.024257034063339233
0.0037889087109779767 0.0037889087109779767 0.023298654705286026
0.0037625841891164935 0.0037625841891164935 0.020783090963959694
0.0037244725964757763 0.0037244725964757763 0.017182789742946625
0.0036827319158740423 0.0036827319158740423 0.011035190895199776
0.0036578919406065283 0.0036578919406065283 0.0031887521035969257
0.0036619925964484442 0.0036619925964484442 0.006101206876337528
0.003681053979376452 0.003681053979376452 0.011172807775437832
0.003697699715085497 0.003697699715085497 0.013609777204692364
0.003704814398957226 0.003704814398957226 0.014989570714533329
0.0037010026736854604 0.0037010026736854604 0.01526031456887722
0.0036831832227810102 0.0036831832227810102 0.01287053618580103
0.003660979630960095 0.003660979630960095 0.008021938614547253
0.0036476526829805392 0.0036476526829805392 0.0042089903727173805
0.0036455923584735733 0.0036455923584735733 0.005318395793437958
0.003649385961933192 0.003649385961933192 0.007073163986206055
0.0036551532309398323 0.0036551532309398323 0.008879298344254494
0.0036605789006349553 0.0036605789006349553 0.010406587272882462
0.0036573263483888688 0.0036573263483888688 0.010117190890014172
0.0036481938586934853 0.0036481938586934853 0.00806080549955368
0.0036388987930065717 0.0036388987930065717 0.005890661850571632
0.003632828919724686 0.003632828919724686 0.004260061774402857
0.0036305925456375007 0.0036305925456375007 0.0031859821174293756
0.0036319978136541277 0.0036319978136541277 0.004838461987674236
0.0036350477487882586 0.0036350477487882586 0.006879888009279966
0.0036340377946140934 0.0036340377946140934 0.007165723480284214
0.003629773893835205 0.003629773893835205 0.006108434405177832
0.0036251018362102655 0.0036251018362102655 0.00487004779279232
0.003620104829323235 0.003620104829323235 0.0033440047409385443
0.0036166083285526767 0.0036166083285526767 0.0018361411057412624
iteration: 2 | epoch: 153 |   loss: 0.003617  |   KL divergence: 0.003617  |  JS divergence: 0.000977
('==== Found maximium gradient [0.036416933, 0.03165441, 0.018550739] of gate '
 'e^[Y0 Z3], e^[Y3 Z0], CRY[3, 0] ====')
learning rate =  0.0059691702769688335
0.0036160973811801118 0.0036160973811801118 0.051788050681352615
0.003437513792148402 0.003437513792148402 0.04621437191963196
0.0030729652488298022 0.0030729652488298022 0.017253588885068893
0.0030322908182665 0.0030322908182665 0.01472374889999628
0.003161419843447339 0.003161419843447339 0.02839837037026882
0.003243826335749377 0.003243826335749377 0.0332677997648716
0.0032223178885803627 0.0032223178885803627 0.031938061118125916
0.0031431257566937503 0.0031431257566937503 0.02658151090145111
0.0030665142276149453 0.0030665142276149453 0.019711989909410477
0.0030279821033550028 0.0030279821033550028 0.014766347594559193
0.003018847692603964 0.003018847692603964 0.013361402787268162
0.0030200208842686063 0.0030200208842686063 0.013907856307923794
0.0030254776564149115 0.0030254776564149115 0.015399000607430935
0.0030331970930329273 0.0030331970930329273 0.017247097566723824
0.0030377368921153227 0.0030377368921153227 0.018572164699435234
0.0030311164325441025 0.0030311164325441025 0.018494801595807076
0.0030105261218237277 0.0030105261218237277 0.01658502034842968
0.0029815318210801786 0.0029815318210801786 0.012961480766534805
0.0029551280537113925 0.0029551280537113925 0.008241229690611362
0.0029426789445013363 0.0029426789445013363 0.004921175539493561
0.002946917572788584 0.002946917572788584 0.0076770177111029625
0.0029595259918658583 0.0029595259918658583 0.011821526102721691
0.0029670252601629076 0.0029670252601629076 0.014094991609454155
0.00296141676241896 0.00296141676241896 0.013873171992599964
0.002945190484279121 0.002945190484279121 0.011630982160568237
0.0029262041494210254 0.0029262041494210254 0.008433962240815163
0.0029128394203122828 0.0029128394203122828 0.005640413612127304
0.0029067126576096712 0.0029067126576096712 0.004873736295849085
0.002905499499911461 0.002905499499911461 0.0060507371090352535
0.0029059018322165225 0.0029059018322165225 0.007330609485507011
0.002903770046467969 0.002903770046467969 0.007932025007903576
0.002899945846448391 0.002899945846448391 0.007924380712211132
0.0028942696048661304 0.0028942696048661304 0.007542736828327179
0.002886717466303574 0.002886717466303574 0.0067433761432766914
0.0028775666917638396 0.0028775666917638396 0.005407840013504028
0.0028692027092504855 0.0028692027092504855 0.0039069270715117455
0.0028631236599369544 0.0028631236599369544 0.0034047774970531464
0.0028599665536710407 0.0028599665536710407 0.004392166621983051
0.0028581340825918323 0.0028581340825918323 0.005663795862346888
0.0028556990317578014 0.0028556990317578014 0.006362095475196838
0.0028506943406492857 0.0028506943406492857 0.006119010038673878
0.0028426919168875273 0.0028426919168875273 0.00498799467459321
0.002835907295430683 0.002835907295430683 0.0035738355945795774
0.002829803276228931 0.002829803276228931 0.0029354803264141083
0.0028264487655272194 0.0028264487655272194 0.0033176825381815434
0.002822528366619932 0.002822528366619932 0.0038266226183623075
0.0028183098209818517 0.0028183098209818517 0.0040516615845263
0.0028138694028100137 0.0028138694028100137 0.0039726803079247475
0.002808486291189178 0.002808486291189178 0.00368583295494318
0.0028035860546098716 0.0028035860546098716 0.0033377930521965027
0.0027981507073385602 0.0027981507073385602 0.0030012575443834066
0.0027934482557001768 0.0027934482557001768 0.0027447135653346777
0.002788506304709584 0.002788506304709584 0.002799501409754157
0.0027847843415361086 0.0027847843415361086 0.0031836500857025385
0.0027804411026649324 0.0027804411026649324 0.003528632689267397
0.002775767019102211 0.002775767019102211 0.003543460974469781
0.002770958699711533 0.002770958699711533 0.003177545266225934
0.0027659707839318517 0.0027659707839318517 0.002594725461676717
0.0027609235729270662 0.0027609235729270662 0.002211354672908783
0.002756658270240739 0.002756658270240739 0.0023396944161504507
0.0027527595924061983 0.0027527595924061983 0.002626114059239626
0.0027486341085795575 0.0027486341085795575 0.0027055260725319386
0.0027440629179213204 0.0027440629179213204 0.002584001747891307
0.002739549776825369 0.002739549776825369 0.0024058367125689983
0.0027350898319557014 0.0027350898319557014 0.0022670268081128597
0.0027305208889542142 0.0027305208889542142 0.002212218241766095
0.002726213385845299 0.002726213385845299 0.0022439321037381887
0.002722404803815305 0.002722404803815305 0.002339232712984085
0.002718113560643217 0.002718113560643217 0.0024558657314628363
0.0027139975928459005 0.0027139975928459005 0.002497738925740123
0.002709835974257099 0.002709835974257099 0.0023904263507574797
0.0027060780568297967 0.0027060780568297967 0.002185503952205181
0.002701577701285913 0.002701577701285913 0.00202384265139699
0.0026971915420958446 0.0026971915420958446 0.0019985304679721594
iteration: 3 | epoch: 227 |   loss: 0.002697  |   KL divergence: 0.002697  |  JS divergence: 0.000720
('==== Found maximium gradient [0.018872717, 0.015991887, 0.009540856] of gate '
 'e^[Y0 Z4], e^[Y4 Z0], CRY[4, 0] ====')
learning rate =  0.0030614763590635493
0.0026931949045820632 0.0026931949045820632 0.026593225076794624
0.002584670405662772 0.002584670405662772 0.018482821062207222
0.002546470606977579 0.002546470606977579 0.016381988301873207
0.002531048829829905 0.002531048829829905 0.01238048356026411
0.0025329437043548246 0.0025329437043548246 0.011766205541789532
0.002550945584337998 0.002550945584337998 0.01585138961672783
0.0025529640544953154 0.0025529640544953154 0.016460763290524483
0.002533196579453648 0.002533196579453648 0.013612735085189342
0.0025102867516521715 0.0025102867516521715 0.01035365555435419
0.0024958001481525044 0.0024958001481525044 0.008650491945445538
0.002487648846769677 0.002487648846769677 0.007520016748458147
0.002484027752139112 0.002484027752139112 0.006622095592319965
0.0024828136709179167 0.0024828136709179167 0.0072266277857124805
0.002483302859591324 0.002483302859591324 0.008841232396662235
0.0024819067259727514 0.0024819067259727514 0.00976504571735859
0.0024762827105969543 0.0024762827105969543 0.009415006265044212
0.002466551289524511 0.002466551289524511 0.008059103041887283
0.0024548511127714338 0.0024548511127714338 0.006154712755233049
0.002445168906730313 0.002445168906730313 0.004211506340652704
0.0024396229580308753 0.0024396229580308753 0.0035574212670326233
0.0024374879945821175 0.0024374879945821175 0.004768354818224907
0.002436049204443883 0.002436049204443883 0.0060044885613024235
0.002432513900023476 0.002432513900023476 0.006478500552475452
0.002427697423459314 0.002427697423459314 0.00642368895933032
0.0024226240056447676 0.0024226240056447676 0.00622674822807312
0.0024165452954826114 0.0024165452954826114 0.005750930868089199
0.0024094577614246744 0.0024094577614246744 0.004669634159654379
0.002402742919889846 0.002402742919889846 0.0033305997494608164
0.002398034664383209 0.002398034664383209 0.003008668078109622
0.002394887252061155 0.002394887252061155 0.003823935054242611
0.0023918551422163685 0.0023918551422163685 0.004484077915549278
0.0023875303668144093 0.0023875303668144093 0.00462136697024107
0.002382973402596844 0.002382973402596844 0.0044050635769963264
0.002377666021124344 0.002377666021124344 0.003978220745921135
0.00237229907634095 0.00237229907634095 0.003410962177440524
0.00236729347584443 0.00236729347584443 0.0029015589971095324
0.0023625253183428073 0.0023625253183428073 0.0026965767610818148
0.0023583289111905282 0.0023583289111905282 0.0028386423364281654
0.002354405249030042 0.002354405249030042 0.0032386952079832554
0.0023507144695544694 0.0023507144695544694 0.0036647459492087364
0.0023463638682890585 0.0023463638682890585 0.003759651444852352
0.0023414464130011668 0.0023414464130011668 0.003373451065272093
0.002336728820945849 0.002336728820945849 0.0027952527161687613
0.0023321757607080262 0.0023321757607080262 0.0025240809191018343
0.002328323423626928 0.002328323423626928 0.002571325981989503
0.0023240008592445727 0.0023240008592445727 0.0026427952107042074
0.0023204638625001555 0.0023204638625001555 0.002764460863545537
0.0023161295866984464 0.0023161295866984464 0.0029488455038517714
0.0023123261381999428 0.0023123261381999428 0.0029772245325148106
0.002307861885748455 0.002307861885748455 0.0027670974377542734
0.0023033438646759205 0.0023033438646759205 0.0025092768482863903
0.0022995499778331566 0.0022995499778331566 0.0024069608189165592
0.002295727782576632 0.002295727782576632 0.00246826303191483
0.0022917487754423476 0.0022917487754423476 0.002605033339932561
0.002288012588085595 0.002288012588085595 0.0027035975363105536
0.002284060982398548 0.002284060982398548 0.002681936137378216
0.002279822857555967 0.002279822857555967 0.002568313153460622
0.00227616931045616 0.00227616931045616 0.002427070401608944
0.0022722406650489586 0.0022722406650489586 0.0022832376416772604
0.0022680702444848972 0.0022680702444848972 0.0022007389925420284
0.0022644226029410685 0.0022644226029410685 0.002236361149698496
0.0022607809331195803 0.0022607809331195803 0.0022986861877143383
0.0022572906689101698 0.0022572906689101698 0.002284606685861945
0.002253353758282497 0.002253353758282497 0.002225502859801054
0.0022493120609110404 0.0022493120609110404 0.0021916162222623825
0.0022455181201193374 0.0022455181201193374 0.0021955089177936316
0.0022420437823777797 0.0022420437823777797 0.0022290563210844994
0.0022382925115584946 0.0022382925115584946 0.0022762592416256666
0.0022348367959649914 0.0022348367959649914 0.0023016519844532013
0.002231040151541074 0.002231040151541074 0.002288641408085823
0.0022272346876817516 0.0022272346876817516 0.002246387768536806
0.0022235807356964983 0.0022235807356964983 0.002193914959207177
0.002219890261376945 0.002219890261376945 0.002163191791623831
0.0022166923038181717 0.0022166923038181717 0.0021623375359922647
0.0022128900276170748 0.0022128900276170748 0.002152117434889078
0.0022095120698680196 0.0022095120698680196 0.0021172971464693546
0.0022056396109712923 0.0022056396109712923 0.002086557913571596
0.002202414644690935 0.002202414644690935 0.00206907675601542
0.0021986605454895605 0.0021986605454895605 0.002060314640402794
0.002195108438987863 0.002195108438987863 0.0020722171757370234
0.002191297705466374 0.002191297705466374 0.0020967682357877493
0.0021877880065680564 0.0021877880065680564 0.002106858417391777
0.0021844707890428727 0.0021844707890428727 0.002097438322380185
0.0021809664333163636 0.0021809664333163636 0.002081342274323106
0.0021771837137613682 0.0021771837137613682 0.0020676106214523315
0.0021739187810326807 0.0021739187810326807 0.002058447105810046
0.002170370202141603 0.002170370202141603 0.0020483951084315777
0.0021673423119399782 0.0021673423119399782 0.002034274162724614
0.002163669049933896 0.002163669049933896 0.0020211038645356894
0.0021601534776384567 0.0021601534776384567 0.002010778523981571
0.0021567665846584988 0.0021567665846584988 0.002003228757530451
0.0021533787034937316 0.0021533787034937316 0.0020011498127132654
0.0021502571435756132 0.0021502571435756132 0.0020011093001812696
0.0021468225575049875 0.0021468225575049875 0.001998002640902996
iteration: 4 | epoch: 321 |   loss: 0.002147  |   KL divergence: 0.002147  |  JS divergence: 0.000559
('==== Found maximium gradient [0.012970529, 0.012574469, 0.012519366] of gate '
 'e^[Y3 Z1], e^[Y1 Z3], e^[Y2 Z1] ====')
learning rate =  0.0025379423863774054
0.002143298367578827 0.002143298367578827 0.022069619968533516
0.002076007955482663 0.002076007955482663 0.019336771219968796
0.002015845423572461 0.002015845423572461 0.014168266206979752
0.001997794400109472 0.001997794400109472 0.012922117486596107
0.001980262860271087 0.001980262860271087 0.00890621729195118
0.0019856243994868304 0.0019856243994868304 0.012628386728465557
0.0019876610106196895 0.0019876610106196895 0.014067068696022034
0.0019745935235708956 0.0019745935235708956 0.011557000689208508
0.0019621770385857876 0.0019621770385857876 0.009852742776274681
0.001955736052452931 0.001955736052452931 0.010509013198316097
0.0019472861525353345 0.0019472861525353345 0.009813735261559486
0.0019362547205763422 0.0019362547205763422 0.0074545843526721
0.0019289720422136854 0.0019289720422136854 0.006666200235486031
0.0019258408398145376 0.0019258408398145376 0.008406425826251507
0.001920435104181537 0.001920435104181537 0.009246116504073143
0.0019099660484302222 0.0019099660484302222 0.008190683089196682
0.0018977853381370166 0.0018977853381370166 0.006662096828222275
0.0018875423736750211 0.0018875423736750211 0.006356615107506514
0.001879672391780611 0.001879672391780611 0.006503747310489416
0.0018711561569539278 0.0018711561569539278 0.005763166584074497
0.0018637850615993727 0.0018637850615993727 0.004587778355926275
0.001857861035874546 0.001857861035874546 0.0046875327825546265
0.001853711115463689 0.001853711115463689 0.005859485827386379
0.0018488664753501406 0.0018488664753501406 0.006514779757708311
0.0018415757830794644 0.0018415757830794644 0.006283016409724951
0.0018322312947486811 0.0018322312947486811 0.00572602404281497
0.0018234183131339433 0.0018234183131339433 0.0054022520780563354
0.0018151684624914098 0.0018151684624914098 0.005211124662309885
0.0018064758980468403 0.0018064758980468403 0.00482230493798852
0.0017982120612189951 0.0017982120612189951 0.004371514078229666
0.0017909517903067571 0.0017909517903067571 0.004311230964958668
0.0017839710186496128 0.0017839710186496128 0.004621720407158136
0.0017777716975471162 0.0017777716975471162 0.004823651164770126
0.001770457936648908 0.001770457936648908 0.004698215052485466
0.0017625996493197762 0.0017625996493197762 0.004421068821102381
0.0017550659772047597 0.0017550659772047597 0.004229366779327393
0.0017473989806300223 0.0017473989806300223 0.004123886581510305
0.0017396246367513825 0.0017396246367513825 0.004013031721115112
0.0017318633975073653 0.0017318633975073653 0.003956852946430445
0.0017242896912301956 0.0017242896912301956 0.0040088132955133915
0.001716817843799774 0.001716817843799774 0.004047999158501625
0.0017095718311070586 0.0017095718311070586 0.0039733415469527245
0.0017019093428575355 0.0017019093428575355 0.0038501080125570297
0.001694463493782546 0.001694463493782546 0.0037787985056638718
0.001687046145007799 0.001687046145007799 0.0037775891833007336
0.0016791016778561095 0.0016791016778561095 0.0038471559528261423
0.0016718972565890758 0.0016718972565890758 0.003984504379332066
0.0016647029353054075 0.0016647029353054075 0.004111923277378082
0.001657305819983107 0.001657305819983107 0.004140415228903294
0.0016502191056565326 0.0016502191056565326 0.004079334903508425
0.001642422475863512 0.001642422475863512 0.003998108208179474
0.0016349120401186084 0.0016349120401186084 0.003933388274163008
0.0016274596731379455 0.0016274596731379455 0.0038949113804847
0.001619919649003433 0.001619919649003433 0.0039038374088704586
0.0016125881966323435 0.0016125881966323435 0.003955754451453686
0.0016050762778844147 0.0016050762778844147 0.003992915619164705
0.0015980018236631146 0.0015980018236631146 0.003961983602494001
0.0015909662867928088 0.0015909662867928088 0.0038746893405914307
0.0015834848395204254 0.0015834848395204254 0.003787797410041094
0.0015761990478530595 0.0015761990478530595 0.0037321923300623894
0.0015689971115040553 0.0015689971115040553 0.003700052388012409
0.0015616689561267706 0.0015616689561267706 0.00369496108032763
0.0015542494518742767 0.0015542494518742767 0.0037232893519103527
0.0015472240319997616 0.0015472240319997616 0.003751154523342848
0.0015398542342032356 0.0015398542342032356 0.0037415106780827045
0.0015325095315211138 0.0015325095315211138 0.0037136198952794075
0.0015257677342824193 0.0015257677342824193 0.0037021238822489977
0.001518376816054301 0.001518376816054301 0.003706548362970352
0.0015113482017636158 0.0015113482017636158 0.0037224756088107824
0.00150425876714084 0.00150425876714084 0.003759539918974042
0.0014972036610861447 0.0014972036610861447 0.0038020964711904526
0.0014899964729891552 0.0014899964729891552 0.003817290998995304
0.0014829974204630266 0.0014829974204630266 0.0037991872522979975
0.0014760627540334665 0.0014760627540334665 0.0037656608037650585
0.001468987685372566 0.001468987685372566 0.0037307054735720158
0.0014623343307864102 0.0014623343307864102 0.0037047904916107655
0.0014552135294022407 0.0014552135294022407 0.0036954341921955347
0.001448301146344558 0.001448301146344558 0.0036963806487619877
0.0014414343246493232 0.0014414343246493232 0.0036911943461745977
0.001434461332117235 0.001434461332117235 0.0036700728815048933
0.001427819878996613 0.001427819878996613 0.0036368651781231165
0.0014213775240705419 0.0014213775240705419 0.003604723373427987
0.001414256821527452 0.001414256821527452 0.0035862966906279325
0.0014076222511060148 0.0014076222511060148 0.0035867055412381887
0.0014009778775206782 0.0014009778775206782 0.00359992659650743
0.0013945312916529551 0.0013945312916529551 0.0036136270500719547
0.0013878125092214207 0.0013878125092214207 0.003618063172325492
0.0013813937285492768 0.0013813937285492768 0.003612036118283868
0.0013746699193862362 0.0013746699193862362 0.003601750358939171
0.0013682790936059186 0.0013682790936059186 0.0035946834832429886
0.0013617739895546064 0.0013617739895546064 0.003593654604628682
0.0013553107198919145 0.0013553107198919145 0.003594554029405117
0.0013487274822454997 0.0013487274822454997 0.0035909598227590322
0.0013426687548385538 0.0013426687548385538 0.0035798908211290836
0.0013362532199916808 0.0013362532199916808 0.003561729099601507
0.0013301268891468259 0.0013301268891468259 0.0035397156607359648
0.0013236753677770535 0.0013236753677770535 0.0035191921051591635
0.0013177374100470324 0.0013177374100470324 0.0035028907004743814
0.0013114194631650216 0.0013114194631650216 0.0034897730220109224
0.0013051332414785082 0.0013051332414785082 0.0034784937743097544
0.0012992952879344515 0.0012992952879344515 0.003467957489192486
0.0012928838621501057 0.0012928838621501057 0.0034570195712149143
0.001286894030151206 0.001286894030151206 0.0034455389250069857
0.0012810844273926463 0.0012810844273926463 0.003435367252677679
0.0012749528698729798 0.0012749528698729798 0.0034279751125723124
0.001269052079726099 0.001269052079726099 0.0034229650627821684
0.0012631774781341606 0.0012631774781341606 0.00341893476434052
0.0012576009515198622 0.0012576009515198622 0.0034141778014600277
0.001251625436007408 0.001251625436007408 0.0034055470023304224
0.0012458938304083396 0.0012458938304083396 0.003392565995454788
0.0012402712275557785 0.0012402712275557785 0.0033772685565054417
0.0012345175568512618 0.0012345175568512618 0.0033617799635976553
0.0012287454416252401 0.0012287454416252401 0.0033472042996436357
0.0012231307430427241 0.0012231307430427241 0.0033335762564092875
0.0012177257338365733 0.0012177257338365733 0.0033191819675266743
0.0012122618127683542 0.0012122618127683542 0.0033031050115823746
0.0012064269110453566 0.0012064269110453566 0.0032861509826034307
0.0012010852104869648 0.0012010852104869648 0.0032704249024391174
0.0011959933321275128 0.0011959933321275128 0.0032570676412433386
0.0011903458381897658 0.0011903458381897658 0.0032464212272316217
0.0011853082451827185 0.0011853082451827185 0.0032370565459132195
0.0011800767394589894 0.0011800767394589894 0.0032272213138639927
0.001174865175498407 0.001174865175498407 0.0032159145921468735
0.0011696689864124621 0.0011696689864124621 0.0032036355696618557
0.0011645655898742681 0.0011645655898742681 0.0031907670199871063
0.001159265444683474 0.001159265444683474 0.003177941543981433
0.0011545732763226166 0.0011545732763226166 0.0031651922035962343
0.0011494434620284793 0.0011494434620284793 0.0031517082825303078
0.00114440314565116 0.00114440314565116 0.00313702505081892
0.0011392363150432197 0.0011392363150432197 0.00312115834094584
0.0011345572953538898 0.0011345572953538898 0.0031047030352056026
0.001129641350724405 0.001129641350724405 0.0030886675231158733
0.001124914916543977 0.001124914916543977 0.0030737807974219322
0.0011201427439822753 0.0011201427439822753 0.0030599129386246204
0.0011153692655594266 0.0011153692655594266 0.0030466311145573854
0.0011103318771467636 0.0011103318771467636 0.0030330184381455183
0.0011058565205563189 0.0011058565205563189 0.0030188364908099174
0.0011013168988125927 0.0011013168988125927 0.003004580968990922
0.001096527525800819 0.001096527525800819 0.0029908569995313883
0.0010920451050777185 0.0010920451050777185 0.002977733500301838
0.0010873954221975648 0.0010873954221975648 0.0029645548202097416
0.0010833333532703424 0.0010833333532703424 0.002950717695057392
0.0010787535220632082 0.0010787535220632082 0.002935750875622034
0.001074386177140571 0.001074386177140571 0.0029198951087892056
0.0010700836563027234 0.0010700836563027234 0.0029043450485914946
0.0010657267715313448 0.0010657267715313448 0.00288930325768888
0.001061430418162721 0.001061430418162721 0.00287459883838892
0.0010571897428557128 0.0010571897428557128 0.0028598334174603224
0.001053122456942583 0.001053122456942583 0.002844581613317132
0.0010488440874431343 0.0010488440874431343 0.0028290345799177885
0.0010447320259682254 0.0010447320259682254 0.0028138754423707724
0.0010407125183547951 0.0010407125183547951 0.00279941875487566
0.0010366502993734545 0.0010366502993734545 0.0027852454222738743
0.0010328880253641717 0.0010328880253641717 0.0027711044531315565
0.0010288602653008303 0.0010288602653008303 0.0027562708128243685
0.001024769327323926 0.001024769327323926 0.002741251839324832
0.001020716321994741 0.001020716321994741 0.0027260908391326666
0.001017179926940318 0.001017179926940318 0.0027113002724945545
0.0010135237931331235 0.0010135237931331235 0.002696408424526453
0.0010097241161353403 0.0010097241161353403 0.0026814669836312532
0.00100585545813997 0.00100585545813997 0.0026662256568670273
0.001001912923635212 0.001001912923635212 0.002650855341926217
0.0009984997645318323 0.0009984997645318323 0.002635485492646694
0.0009947858786261265 0.0009947858786261265 0.0026202541776001453
0.0009916046464633291 0.0009916046464633291 0.0026054102927446365
0.0009876931257842203 0.0009876931257842203 0.0025906888768076897
0.0009842115910292568 0.0009842115910292568 0.0025760100688785315
0.0009804625687748222 0.0009804625687748222 0.0025610062293708324
0.0009774528374404546 0.0009774528374404546 0.0025461374316364527
0.0009742660295099913 0.0009742660295099913 0.0025310511700809
0.0009705749363575478 0.0009705749363575478 0.0025162959937006235
0.0009674761675986477 0.0009674761675986477 0.002501479582861066
0.0009636199219237847 0.0009636199219237847 0.002486526733264327
0.0009605654174017673 0.0009605654174017673 0.002471497980877757
0.0009571485920825916 0.0009571485920825916 0.0024563854094594717
0.0009543542047199449 0.0009543542047199449 0.0024414327926933765
0.0009513647816539882 0.0009513647816539882 0.0024266166146844625
0.0009478800842140618 0.0009478800842140618 0.002412118948996067
0.0009448892742323645 0.0009448892742323645 0.002397530945017934
0.0009415931236386292 0.0009415931236386292 0.002382764359936118
0.0009387481971738198 0.0009387481971738198 0.0023678625002503395
0.0009355566851948804 0.0009355566851948804 0.002353101270273328
0.000932538830088612 0.000932538830088612 0.002338571473956108
0.0009298000552955261 0.0009298000552955261 0.0023240067530423403
0.000926791857020132 0.000926791857020132 0.0023094071075320244
0.0009239639492870789 0.0009239639492870789 0.002294675214216113
0.0009208594599607008 0.0009208594599607008 0.0022800315637141466
0.0009180721075251115 0.0009180721075251115 0.002265492221340537
0.0009150737418668134 0.0009150737418668134 0.002251164987683296
0.0009125357366928228 0.0009125357366928228 0.002236898522824049
0.0009095288926917566 0.0009095288926917566 0.002222668845206499
0.0009069456763863016 0.0009069456763863016 0.0022083118092268705
0.0009041118986106204 0.0009041118986106204 0.0021939461585134268
0.0009015238737095382 0.0009015238737095382 0.0021796547807753086
0.0008988655406995149 0.0008988655406995149 0.0021654656156897545
0.0008962159749092573 0.0008962159749092573 0.002151440130546689
0.0008936816397828804 0.0008936816397828804 0.0021373124327510595
0.0008911791972546357 0.0008911791972546357 0.0021231609862297773
0.0008885490986589139 0.0008885490986589139 0.0021090845111757517
0.0008858467381170423 0.0008858467381170423 0.002095162170007825
0.0008836812968326386 0.0008836812968326386 0.00208113226108253
0.0008811020167420651 0.0008811020167420651 0.002067290712147951
0.0008785737951568667 0.0008785737951568667 0.0020535914227366447
0.000876561496971702 0.000876561496971702 0.0020399040076881647
0.0008737541406771309 0.0008737541406771309 0.0020261667668819427
0.0008715030205703239 0.0008715030205703239 0.0020125648006796837
0.0008691787443352306 0.0008691787443352306 0.001998898573219776
iteration: 5 | epoch: 528 |   loss: 0.000869  |   KL divergence: 0.000869  |  JS divergence: 0.000223
('==== Found maximium gradient [0.013462826, 0.013273789, 0.012183119] of gate '
 'e^[Y2 Z3], e^[Y3 Z2], e^[Y4 Z1] ====')
learning rate =  0.0025970996375119454
0.0008667953964553994 0.0008667953964553994 0.022578997537493706
0.0008168631705069698 0.0008168631705069698 0.022462215274572372
0.0007337233781576564 0.0007337233781576564 0.012131008319556713
0.0007266399709614764 0.0007266399709614764 0.015382783487439156
0.0007145691444157161 0.0007145691444157161 0.012890229932963848
0.0007093759449038049 0.0007093759449038049 0.010409072041511536
0.0007176622169419865 0.0007176622169419865 0.012916683219373226
0.0007218255967159843 0.0007218255967159843 0.014364315196871758
0.0007115386715300172 0.0007115386715300172 0.012230769731104374
0.0006975752226861522 0.0006975752226861522 0.008860781788825989
0.0006892387519746134 0.0006892387519746134 0.008249489590525627
0.0006854397339322623 0.0006854397339322623 0.009623746387660503
0.0006797777845161243 0.0006797777845161243 0.009394032880663872
0.0006722995609952532 0.0006722995609952532 0.007573151029646397
0.0006684897300011047 0.0006684897300011047 0.006739404052495956
0.0006669416060221753 0.0006669416060221753 0.00809159129858017
0.0006643699658323292 0.0006643699658323292 0.009038864634931087
0.0006576369919810246 0.0006576369919810246 0.00808149203658104
0.0006497366397405714 0.0006497366397405714 0.005802276078611612
0.000644440654199234 0.000644440654199234 0.004394816234707832
0.0006421216217646892 0.0006421216217646892 0.005185435526072979
0.0006403288467881958 0.0006403288467881958 0.005848117172718048
0.0006372669328321419 0.0006372669328321419 0.005290321074426174
0.0006341238544120153 0.0006341238544120153 0.004370995331555605
0.0006320981280674205 0.0006320981280674205 0.004638167098164558
0.000629857057215034 0.000629857057215034 0.00555183831602335
0.0006261119124114575 0.0006261119124114575 0.005640304181724787
0.0006211674111431402 0.0006211674111431402 0.004633162170648575
0.0006162664366096487 0.0006162664366096487 0.003462956054136157
0.0006125003777761762 0.0006125003777761762 0.0034748688340187073
0.000609698808569812 0.000609698808569812 0.003979042172431946
0.0006071043281628186 0.0006071043281628186 0.0037859862204641104
0.0006042185623855026 0.0006042185623855026 0.0031240175012499094
0.000602312404090694 0.000602312404090694 0.0031614918261766434
0.0006001350909807103 0.0006001350909807103 0.0038143969140946865
0.0005979892817832054 0.0005979892817832054 0.003910723142325878
0.0005948302601502031 0.0005948302601502031 0.0031576757319271564
0.0005914027604256065 0.0005914027604256065 0.0023187289480119944
0.0005883316496415707 0.0005883316496415707 0.002425918821245432
0.0005859140065130682 0.0005859140065130682 0.00271566747687757
0.0005828540556560616 0.0005828540556560616 0.002369908383116126
0.0005803893656967534 0.0005803893656967534 0.0018401138950139284
iteration: 6 | epoch: 570 |   loss: 0.000580  |   KL divergence: 0.000580  |  JS divergence: 0.000150
('==== Found maximium gradient [0.0096888235, 0.0077698333, 0.007207661] of '
 'gate e^[Y0 Z5], e^[Y5 Z0], e^[Y4 Z2] ====')
learning rate =  0.0016580872136372324
0.0005777667239026973 0.0005777667239026973 0.01452296320348978
0.0005705098349398411 0.0005705098349398411 0.017674263566732407
0.0005234535987932982 0.0005234535987932982 0.007788599468767643
0.0005180916887741629 0.0005180916887741629 0.009075623005628586
0.0005215108526561849 0.0005215108526561849 0.011504482477903366
0.0005185080992628787 0.0005185080992628787 0.010228147730231285
0.0005129828698734473 0.0005129828698734473 0.0080375075340271
0.0005105333378040128 0.0005105333378040128 0.00776219367980957
0.000510033782906726 0.000510033782906726 0.008978349156677723
0.0005070897712527055 0.0005070897712527055 0.009175442159175873
0.0005008141008778458 0.0005008141008778458 0.007657128386199474
0.0004940963401124246 0.0004940963401124246 0.005344924982637167
0.0004900163649945189 0.0004900163649945189 0.004370634909719229
0.0004884776625483593 0.0004884776625483593 0.0056354510597884655
0.0004878713262214123 0.0004878713262214123 0.006756308488547802
0.00048472279930889363 0.00048472279930889363 0.006626536138355732
0.0004797987244175868 0.0004797987244175868 0.0055387900210917
0.0004761410989109957 0.0004761410989109957 0.004452666267752647
0.0004732763728392057 0.0004732763728392057 0.004314504563808441
0.00047049697344412114 0.00047049697344412114 0.004661381710320711
0.00046826824079322844 0.00046826824079322844 0.004608102608472109
0.00046522035393894653 0.00046522035393894653 0.004032041411846876
0.0004626343300294519 0.0004626343300294519 0.003473557299003005
0.0004604008462212812 0.0004604008462212812 0.003579831449314952
0.0004587225500168814 0.0004587225500168814 0.0040602064691483974
0.00045633149467081254 0.00045633149467081254 0.004218628164380789
0.000453380584847207 0.000453380584847207 0.0037717220839112997
0.0004496725732238265 0.0004496725732238265 0.0029291126411408186
0.0004466272201508291 0.0004466272201508291 0.00236072507686913
0.0004441421039676791 0.0004441421039676791 0.002511207712814212
0.0004421923359986365 0.0004421923359986365 0.0028251868207007647
0.00043979963148701084 0.00043979963148701084 0.002807409269735217
0.000437055214715315 0.000437055214715315 0.002569071250036359
0.0004353163736201107 0.0004353163736201107 0.002530427649617195
0.0004328555559282368 0.0004328555559282368 0.0027789087034761906
0.00043099448894537125 0.00043099448894537125 0.0029545980505645275
0.00042854650115223654 0.00042854650115223654 0.0027962615713477135
0.00042542219333607594 0.00042542219333607594 0.002389652421697974
0.0004232098324740545 0.0004232098324740545 0.0020718572195619345
0.0004211261610406759 0.0004211261610406759 0.002112826332449913
0.000419140572307675 0.000419140572307675 0.0023122276179492474
0.0004168540668738381 0.0004168540668738381 0.0023664585314691067
0.00041477119053234877 0.00041477119053234877 0.002236003754660487
0.00041272816707536473 0.00041272816707536473 0.002089999383315444
0.0004107230911563905 0.0004107230911563905 0.002071667928248644
0.00040823394372136725 0.00040823394372136725 0.002085430547595024
0.0004064475331385716 0.0004064475331385716 0.001991705037653446
iteration: 7 | epoch: 617 |   loss: 0.000406  |   KL divergence: 0.000406  |  JS divergence: 0.000104
('==== Found maximium gradient [0.0046775835, 0.0037435342, 0.003476874] of '
 'gate e^[Y0 Z6], e^[Y6 Z0], e^[Y2 Z0] ====')
learning rate =  0.0007998540604931599
0.00040410569645841913 0.00040410569645841913 0.007163616828620434
0.00039671018934878273 0.00039671018934878273 0.006932687945663929
0.00038687556454965785 0.00038687556454965785 0.004743815399706364
0.00038275727045963175 0.00038275727045963175 0.005702846217900515
0.00037913225044533983 0.00037913225044533983 0.005318249575793743
0.00037504094708188274 0.00037504094708188274 0.004841298330575228
0.0003713989262404523 0.0003713989262404523 0.005113380961120129
0.00036735821695318743 0.00036735821695318743 0.0051651522517204285
0.0003625096472954549 0.0003625096472954549 0.00483042374253273
0.00035749002768493406 0.00035749002768493406 0.0043908278457820415
0.0003528947923898386 0.0003528947923898386 0.004024609923362732
0.00034842814263108096 0.00034842814263108096 0.003906531259417534
0.0003449074503206998 0.0003449074503206998 0.003966691438108683
0.000341237933970874 0.000341237933970874 0.0040168254636228085
0.00033811366264142786 0.00033811366264142786 0.004078499972820282
0.0003342302380319721 0.0003342302380319721 0.004141700454056263
0.0003310349099943144 0.0003310349099943144 0.004085291177034378
0.00032732864696117885 0.00032732864696117885 0.003876467002555728
0.0003238381066556177 0.0003238381066556177 0.003592761931940913
0.00031992113862787006 0.00031992113862787006 0.0033403397537767887
0.0003166925352346888 0.0003166925352346888 0.003193984040990472
0.00031383516108115 0.00031383516108115 0.003174073528498411
0.00031046028786666825 0.00031046028786666825 0.003191074589267373
0.00030769889666362895 0.00030769889666362895 0.003136926330626011
0.0003048762778754833 0.0003048762778754833 0.003039357718080282
0.00030244544489898704 0.00030244544489898704 0.002946043387055397
0.0002996544037192605 0.0002996544037192605 0.002857106737792492
0.00029707623986249376 0.00029707623986249376 0.002767360070720315
0.0002942155607218133 0.0002942155607218133 0.0026766881346702576
0.00029175441416774353 0.00029175441416774353 0.0025907910894602537
0.00028888987355218476 0.00028888987355218476 0.0025326195172965527
0.00028718239354075806 0.00028718239354075806 0.0025267719756811857
0.00028504790809308914 0.00028504790809308914 0.0025382922030985355
0.0002828974493831132 0.0002828974493831132 0.002530966652557254
0.00028068099574618825 0.00028068099574618825 0.002487202174961567
0.0002787265038730138 0.0002787265038730138 0.0023873241152614355
0.0002771587558374253 0.0002771587558374253 0.0022591904271394014
0.0002748194923883791 0.0002748194923883791 0.0021498925052583218
0.00027328647366880733 0.00027328647366880733 0.002075982978567481
0.00027146173804216224 0.00027146173804216224 0.002036048099398613
0.0002698650326069667 0.0002698650326069667 0.0020318112801760435
0.0002679327959492394 0.0002679327959492394 0.002030955860391259
0.0002665523794938032 0.0002665523794938032 0.0020000964868813753
0.0002656048294854255 0.0002656048294854255 0.0019444840727373958
iteration: 8 | epoch: 661 |   loss: 0.000266  |   KL divergence: 0.000266  |  JS divergence: 0.000068
('==== Found maximium gradient [0.0038921414, 0.0037214586, 0.0036881396] of '
 'gate e^[Y4 Z3], e^[Y3 Z4], e^[Y5 Z1] ====')
learning rate =  0.000753661224355091
0.00026389777735520405 0.00026389777735520405 0.006793043576180935
0.000257174687723955 0.000257174687723955 0.006415204145014286
0.0002506732869483926 0.0002506732869483926 0.004444983322173357
0.00024862025247621985 0.00024862025247621985 0.004986225627362728
0.0002457062674318223 0.0002457062674318223 0.0038645511958748102
0.0002442975819319508 0.0002442975819319508 0.0042913309298455715
0.00024325272756383167 0.00024325272756383167 0.004294666927307844
0.00024125776689140244 0.00024125776689140244 0.003884453559294343
0.00023953127379710464 0.00023953127379710464 0.0037840635050088167
0.00023778017892489166 0.00023778017892489166 0.003597587114199996
0.0002361311754754144 0.0002361311754754144 0.0033046468161046505
0.00023447762161324175 0.00023447762161324175 0.00315802707336843
0.0002327615194856792 0.0002327615194856792 0.0029764147475361824
0.00023139537864856657 0.00023139537864856657 0.002719257492572069
0.00023046006578223042 0.00023046006578223042 0.0027805068530142307
0.0002293293638546169 0.0002293293638546169 0.0030083893798291683
0.00022800165375142135 0.00022800165375142135 0.002883750945329666
0.0002258047545110662 0.0002258047545110662 0.002480909461155534
0.00022514699126036818 0.00022514699126036818 0.0022984615061432123
0.00022390696125123262 0.00022390696125123262 0.0023367577232420444
0.00022328488980115325 0.00022328488980115325 0.0022113174200057983
0.00022206697665605864 0.00022206697665605864 0.001990304794162512
iteration: 9 | epoch: 683 |   loss: 0.000222  |   KL divergence: 0.000222  |  JS divergence: 0.000057
('==== Found maximium gradient [0.0047372705, 0.0043296767, 0.0024565656] of '
 'gate e^[Y5 Z2], e^[Y2 Z5], e^[Y0 Z7] ====')
learning rate =  0.0007934947979488223
0.0002212782258094769 0.0002212782258094769 0.007152668200433254
0.00022299287454085687 0.00022299287454085687 0.009408822283148766
0.00020827307590754599 0.00020827307590754599 0.004002842586487532
0.00020718929271081325 0.00020718929271081325 0.004336774814873934
0.00020930269815543876 0.00020930269815543876 0.006155367940664291
0.00020836879301151196 0.00020836879301151196 0.0056949700228869915
0.00020566973499083332 0.00020566973499083332 0.004337097518146038
0.00020422352686559663 0.00020422352686559663 0.0038103589322417974
0.00020351170044605846 0.00020351170044605846 0.00457056425511837
0.00020262569162869865 0.00020262569162869865 0.004983482416719198
0.0001997459071230852 0.0001997459071230852 0.004358247853815556
0.00019679725780197895 0.00019679725780197895 0.0029547715093940496
0.00019506273808783797 0.00019506273808783797 0.0018330879975110292
iteration: 10 | epoch: 696 |   loss: 0.000195  |   KL divergence: 0.000195  |  JS divergence: 0.000050
('==== Found maximium gradient [0.0012761621, 0.0012013367, 0.0011885957] of '
 'gate e^[Y3 Z0], e^[Y0 Z8], e^[Y0 Z3] ====')
learning rate =  0.00024452837241467775
0.00019431536685077946 0.00019431536685077946 0.003315978217869997
0.00019344988645517586 0.00019344988645517586 0.002404511207714677
0.0001926812337197464 0.0001926812337197464 0.00254407268948853
0.0001918952102444182 0.0001918952102444182 0.0023410313297063112
0.00019096471312289316 0.00019096471312289316 0.0020603782031685114
0.00019029003840148097 0.00019029003840148097 0.0019817808642983437
iteration: 11 | epoch: 702 |   loss: 0.000190  |   KL divergence: 0.000190  |  JS divergence: 0.000048
('==== Found maximium gradient [0.0012858718, 0.0010843123, 0.0010568525] of '
 'gate e^[Y5 Z3], e^[Y6 Z1], e^[Y6 Z2] ====')
learning rate =  0.00022937993024242
0.00018920014550687794 0.00018920014550687794 0.0028820408042520285
0.00018841714829720557 0.00018841714829720557 0.0029815793968737125
0.0001864378240353989 0.0001864378240353989 0.0025140484794974327
0.0001855038292428017 0.0001855038292428017 0.0021723806858062744
0.0001840406764057346 0.0001840406764057346 0.0022406287025660276
0.00018295401973202844 0.00018295401973202844 0.002314105397090316
0.00018211849409526012 0.00018211849409526012 0.002272202167659998
0.0001819348363243952 0.0001819348363243952 0.002273269696161151
0.00018050804167135703 0.00018050804167135703 0.0023849213030189276
0.00017996829546134373 0.00017996829546134373 0.002511455910280347
0.00017939784145968712 0.00017939784145968712 0.002545140916481614
0.00017872853562306209 0.00017872853562306209 0.0024883181322366
0.00017728598562254187 0.00017728598562254187 0.0024254736490547657
0.00017707988659309954 0.00017707988659309954 0.0024067051708698273
0.00017555509635748371 0.00017555509635748371 0.002404704922810197
0.00017498619665322937 0.00017498619665322937 0.0023840710055083036
0.0001738987429161607 0.0001738987429161607 0.002346024615690112
0.00017290301655175383 0.00017290301655175383 0.002315907971933484
0.00017205780917614578 0.00017205780917614578 0.0023118399549275637
0.0001715678847921221 0.0001715678847921221 0.0023215278051793575
0.0001707851633537588 0.0001707851633537588 0.0023211492225527763
0.00016997804348846456 0.00016997804348846456 0.002306693233549595
0.00016870716846503986 0.00016870716846503986 0.0022885657381266356
0.00016854091591783654 0.00016854091591783654 0.0022749528288841248
0.00016773001455556383 0.00016773001455556383 0.0022653853520751
0.00016695108745711475 0.00016695108745711475 0.002252858830615878
0.000165741519727508 0.000165741519727508 0.0022380908485502005
0.00016545119663702882 0.00016545119663702882 0.002228404860943556
0.0001645582523324891 0.0001645582523324891 0.0022224285639822483
0.0001638680305349868 0.0001638680305349868 0.0022132142912596464
0.0001634881033784902 0.0001634881033784902 0.0021991103421896696
0.0001619343556661047 0.0001619343556661047 0.0021825525909662247
0.00016152715769606897 0.00016152715769606897 0.002166920341551304
0.00016087241225583873 0.00016087241225583873 0.002152075292542577
0.00015996247023064908 0.00015996247023064908 0.0021354793570935726
0.0001593407096516686 0.0001593407096516686 0.002119465032592416
0.00015867893072976094 0.00015867893072976094 0.002108595333993435
0.00015802013295546986 0.00015802013295546986 0.0021034597884863615
0.00015719710470059838 0.00015719710470059838 0.0020994972437620163
0.00015688066213548173 0.00015688066213548173 0.0020903872791677713
0.00015577247779600896 0.00015577247779600896 0.0020756979938596487
0.0001552903501864921 0.0001552903501864921 0.0020599698182195425
0.00015441895081268542 0.00015441895081268542 0.0020452202297747135
0.00015443781114505824 0.00015443781114505824 0.0020309912506490946
0.00015348675675200496 0.00015348675675200496 0.0020157499238848686
0.00015248798682706148 0.00015248798682706148 0.002001031069085002
0.00015178152000240298 0.00015178152000240298 0.001989227021113038
iteration: 12 | epoch: 749 |   loss: 0.000152  |   KL divergence: 0.000152  |  JS divergence: 0.000039
('==== Found maximium gradient [0.0012437206, 0.0011246077, 0.0011094167] of '
 'gate e^[Y5 Z4], e^[X4 Y5], e^[X10 Y5] ====')
learning rate =  0.0002321605617199676
0.00015163480272027002 0.00015163480272027002 0.0028217253275215626
0.00015031962160945339 0.00015031962160945339 0.002759171649813652
0.00014864244711757383 0.00014864244711757383 0.002145894570276141
0.00014806764966210546 0.00014806764966210546 0.0021033112425357103
0.0001472445868528001 0.0001472445868528001 0.0022750648204237223
0.00014712841886969019 0.00014712841886969019 0.0022029930260032415
0.0001462258764455356 0.0001462258764455356 0.002095084870234132
0.0001452433560784472 0.0001452433560784472 0.0020551481284201145
0.0001445644343665208 0.0001445644343665208 0.002012787386775017
0.00014401810481538802 0.00014401810481538802 0.0019607667345553637
iteration: 13 | epoch: 759 |   loss: 0.000144  |   KL divergence: 0.000144  |  JS divergence: 0.000037
('==== Found maximium gradient [0.0011168191, 0.0010528862, 0.0010528585] of '
 'gate e^[Y6 Z3], RY[6], e^[X14 Y6] ====')
learning rate =  0.00021492216287130893
0.00014353246737576367 0.00014353246737576367 0.0026783121284097433
0.00014281779833116197 0.00014281779833116197 0.0029260010924190283
0.00014156757376355955 0.00014156757376355955 0.001976442988961935
iteration: 14 | epoch: 762 |   loss: 0.000142  |   KL divergence: 0.000142  |  JS divergence: 0.000036
('==== Found maximium gradient [0.00086040003, 0.0007388998, 0.00073889963] of '
 'gate e^[X0 Y6], e^[X15 Y2], e^[X14 Y2] ====')
Convergence criterion has reached, break the loop!
