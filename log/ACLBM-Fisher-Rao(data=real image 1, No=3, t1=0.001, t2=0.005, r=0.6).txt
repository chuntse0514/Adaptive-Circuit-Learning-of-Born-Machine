nohup: ignoring input
('==== Found maximium gradient [0.18926477, 0.18926477, 0.18926477] of gate '
 'RY[1], e^[X2 Y1], e^[X0 Y1] ====')
learning rate =  0.03785295635730998
0.0597238943306861 0.17714886732512347 0.44898778200149536
0.04852484063300022 0.15807379185442139 0.23459257185459137
0.04610940564895698 0.1531223066655739 0.3509112596511841
0.04496939410565379 0.15111397174168395 0.3115726113319397
0.043962103679646626 0.14975628552052414 0.19882339239120483
0.04327344516124157 0.1491672516499712 0.18548277020454407
0.04345609228479541 0.1499507926175801 0.25979578495025635
0.042989904176109456 0.14932289259392556 0.27068838477134705
0.04186222895610828 0.1472825514773924 0.21362818777561188
0.040849351283007124 0.14525492318793568 0.136093407869339
0.040552294210706025 0.1444156770642564 0.13536836206912994
0.04075032625977654 0.1445376995055342 0.18658924102783203
0.040682120481996875 0.14441430513527284 0.1998271942138672
0.04015792688854747 0.14371374416426752 0.1646258682012558
0.03954229441632292 0.1429635260254691 0.10894253849983215
0.03921332435191723 0.14268489104530824 0.0982508510351181
0.03922784499857176 0.1428580795054718 0.1364305317401886
0.03931680185224253 0.14297184525826326 0.1559995710849762
0.03927452726034088 0.14271960890543095 0.13923029601573944
0.0391452047991883 0.1422663969596802 0.10011320561170578
0.039048621284951825 0.14188475158761754 0.07811001688241959
0.03899867873696479 0.1416371805635823 0.09647712111473083
0.0388895868275036 0.14137219139298968 0.11202937364578247
0.03867675922598683 0.14104293447763314 0.10107175260782242
0.03847628663523308 0.1408541309626261 0.07069630920886993
0.038415362771672366 0.14097718428577444 0.05674950033426285
0.03846134223585431 0.14126548523915547 0.0789203867316246
0.038451627654976554 0.14135210009904456 0.09565947204828262
0.03829955167459561 0.14105805279992922 0.08792942762374878
0.03810820181766486 0.14059112951814617 0.0591488778591156
0.038047510173809626 0.14031231491681526 0.03482731431722641
0.03814650119568405 0.14033543412932503 0.05099460855126381
0.03826264404011706 0.14045139090971479 0.06811457872390747
0.03826231121696706 0.14044798823284824 0.0651814267039299
0.038160160919127856 0.14034060330759385 0.04713769629597664
0.03806185381030687 0.14028151369607098 0.037545979022979736
0.038011026731246234 0.14030171387494134 0.049789298325777054
0.03795769538663657 0.1402679253118289 0.057392995804548264
0.03787555883263384 0.14011603905043232 0.048258889466524124
0.03782321235075424 0.13996088437953325 0.028005795553326607
0.037858160201998406 0.13993647422413436 0.024408165365457535
0.03793855714537954 0.14000987848552338 0.0401320718228817
0.03796261726289271 0.14002983078693673 0.045483581721782684
0.03789844149140328 0.13994617985657423 0.036099016666412354
0.03781259027023098 0.1398526920473895 0.022007068619132042
0.037775570809439926 0.13984040976564932 0.02543574385344982
0.037778432543695686 0.1398626664765269 0.0349566787481308
0.03777673966570205 0.13983448374555799 0.03382999077439308
0.03776364604912506 0.1397573808914626 0.02251039445400238
0.03776592892794364 0.1397051008257043 0.01488974504172802
0.03778500932618758 0.13970835466712425 0.022960349917411804
0.03778408398341691 0.1397151366442395 0.027597246691584587
0.03774439779070188 0.13969134641344386 0.023158304393291473
0.03768905629739299 0.13965730413338373 0.01610621064901352
0.03765012106208095 0.1396400170962802 0.018055453896522522
0.03763391761727337 0.13962618086458697 0.0220940001308918
0.03763254556260362 0.1395965142826073 0.019400984048843384
0.03764456053891231 0.13956153866239393 0.011689748615026474
0.03766938236170905 0.13954526398426303 0.011084734462201595
0.037692303746546155 0.13954748220526755 0.017036952078342438
0.037691806437338424 0.1395413913724778 0.018057525157928467
0.037665532938378606 0.1395203551663669 0.013706088997423649
0.03762930320485363 0.13949467699356535 0.010363662615418434
0.03760166499827426 0.13947938659705753 0.012567685917019844
0.037586885375537796 0.13946453291467314 0.013376186601817608
0.037584911291395386 0.1394501201829431 0.01034563034772873
0.03759160569290037 0.1394389086034471 0.008306246250867844
0.037598770710429615 0.1394314621862539 0.010937475599348545
0.037596389808797856 0.13941955690199487 0.01215639989823103
0.037583534181678 0.13940464326816496 0.00965786725282669
0.037566730727010875 0.1393891938455159 0.006734889466315508
0.03755471732046097 0.13937741610300228 0.00809086300432682
0.03755161199025313 0.13937011366556643 0.009409490041434765
0.03755431169625395 0.13935894502656415 0.007877337746322155
0.03756015184639565 0.1393487031749352 0.005948907695710659
0.037563673022601725 0.13934032307387056 0.007084082346409559
0.037558905716086 0.13932988262252122 0.008067470975220203
0.03754619995080665 0.13932066600879822 0.0067395600490272045
0.037529725783200955 0.1393111222233906 0.005023695062845945
0.03751640406034898 0.1393026548756709 0.005704274866729975
0.03751013927978658 0.13929392675902325 0.006313716061413288
0.0375115326734669 0.13928605946647757 0.0052075511775910854
0.03751699489629653 0.13927758838240947 0.004299338441342115
iteration: 1 | epoch: 84 |   loss: 0.139278  |   KL divergence: 0.037517  |  JS divergence: 0.009605
('==== Found maximium gradient [0.12892854, 0.12810892, 0.07931094] of gate '
 'e^[Y8 Z1], e^[Y1 Z8], e^[Y8 Z0] ====')
learning rate =  0.022898235212485157
0.03752197190459546 0.1392705442926097 0.1983741819858551
0.03485225160885604 0.13426676826796802 0.11602712422609329
0.03500838679849356 0.13357499797560396 0.10582741349935532
0.03572851299753845 0.1347257850931547 0.12672176957130432
0.03589409153893614 0.13521694286635128 0.13275635242462158
0.035653176668769423 0.13494089689766942 0.13482844829559326
0.03497251869418263 0.1336655491572673 0.08444004505872726
0.03462882071074082 0.13294893800626378 0.0383586622774601
0.03474669095979577 0.13320259966530618 0.07522416114807129
0.03479055792371221 0.13347095784764193 0.08481490612030029
0.034718528335828225 0.13358507104492753 0.08223060518503189
0.034658734829314045 0.1336581398525786 0.08977196365594864
0.03451040443229583 0.13340667659470024 0.08018028736114502
0.034344242212208276 0.1329648722035094 0.045331500470638275
0.034383566920145325 0.1328363487214203 0.033878911286592484
0.03454971502018906 0.13298698522853378 0.056253839284181595
0.034611588930667354 0.13304391679859717 0.05887122079730034
0.034581280732932235 0.13301159153520886 0.05473034456372261
0.03455276841197936 0.13300082656501155 0.05956524237990379
0.03450175690036627 0.132905060937212 0.05447080731391907
0.03444337458107846 0.13274364337429556 0.03183186426758766
0.03446074992392625 0.1327197558033309 0.02568306401371956
0.034505828528722186 0.13280537450686997 0.04207896068692207
0.03446503391400199 0.13280985734021952 0.04314718768000603
0.03436650823778713 0.13275313089037705 0.0368967279791832
0.034293183236430956 0.13272384040923998 0.03860824927687645
0.03425067489570792 0.13267719437821063 0.03516390919685364
0.034244669187927415 0.13261678414406228 0.0200419332832098
0.03430012665678695 0.13262973596940048 0.020539984107017517
0.03436558459893602 0.13267968255636056 0.03174273669719696
0.034369490026365246 0.13266389558015804 0.030194595456123352
0.034336922712664496 0.13262016354712827 0.025036804378032684
0.03431505371303113 0.13259502864668968 0.026490941643714905
0.03430736226802518 0.13256616908842217 0.02197949029505253
0.03431864265213141 0.13254595302574013 0.011444146744906902
0.034349441517831134 0.13256984818498974 0.018499230965971947
0.034356294337228345 0.13259090867990053 0.024305837228894234
0.03431753008914625 0.13257059894020318 0.0200786292552948
0.03427036531741827 0.13254634267228718 0.01723998598754406
0.03424318016282559 0.13252959617605697 0.017583679407835007
0.03423964922527354 0.1325102392192568 0.011117816902697086
0.034262699285291735 0.13251138823628514 0.00934260617941618
0.034291238550792885 0.13252906401935005 0.016699325293302536
0.03429324499584524 0.13252796096885144 0.01627035066485405
0.03427500314194554 0.1325129786816527 0.012442998588085175
0.03426098132921859 0.1325020070781406 0.013047035783529282
0.034258842609499386 0.13248943661958051 0.010201549157500267
0.0342702443681428 0.13248313297866243 0.005536361131817102
0.03428626664194952 0.1324890761009966 0.011132948100566864
0.03428679418749983 0.13249214988749602 0.01243130024522543
0.03427000185144308 0.13248526630659743 0.009181099012494087
0.03425396803741816 0.1324788910165026 0.00934882927685976
0.034248521911784964 0.13247164731773725 0.008319210261106491
0.034254718580347975 0.13246570713874037 0.00448154890909791
iteration: 2 | epoch: 138 |   loss: 0.132466  |   KL divergence: 0.034255  |  JS divergence: 0.008684
('==== Found maximium gradient [0.07173404, 0.07140977, 0.06753477] of gate '
 'e^[Y10 Z0], e^[Y0 Z10], e^[Y9 Z8] ====')
learning rate =  0.014050420116869106
0.03426577100003752 0.13246645274236854 0.1219237819314003
0.033948621418952024 0.1327249639431426 0.17146530747413635
0.03286993501538234 0.1301806713873834 0.05228700861334801
0.0336351651652747 0.13109886198407322 0.11372318118810654
0.03418780706099138 0.13195002599224895 0.1470576822757721
0.03375596656697696 0.1312417592823364 0.11348109692335129
0.03315241517184871 0.13034543417173416 0.052777208387851715
0.032976235448887455 0.13027538996112448 0.05490630120038986
0.033134727256092955 0.13075229527200005 0.09606794267892838
0.03319450379495153 0.13089643071277496 0.10436676442623138
0.033044786951329896 0.1305176967315142 0.0808379054069519
0.03290117819403422 0.1300753796303664 0.0434357188642025
0.032946758562677196 0.12998231895654688 0.038764677941799164
0.03312192044124153 0.13018829149506922 0.06393782794475555
0.033229522481018195 0.13035879077703755 0.07389826327562332
0.03317379611951738 0.1303159214129758 0.06462156027555466
0.033021637952545875 0.1301534588159776 0.046606168150901794
0.03289122465657857 0.1300508108114361 0.039975814521312714
0.0328277266559433 0.13004256716275414 0.04809723049402237
0.032804673266956366 0.13004809531292538 0.05157502740621567
0.032793553414710415 0.13000335225930054 0.04390401020646095
0.032805673903459495 0.1299457605557897 0.031708814203739166
0.03285812120741161 0.12993979752134388 0.030355315655469894
0.03292970782421585 0.12997962344820446 0.03875752538442612
0.03297265322266652 0.1300026013486458 0.04215133190155029
0.0329599944384645 0.12997228169853567 0.03640303760766983
0.03290698325283886 0.12991435532012305 0.026003994047641754
0.03284994791480026 0.12987881388248168 0.022006366401910782
0.03281092030382343 0.12987760927740652 0.02688683196902275
0.0327908041860686 0.12988678461163236 0.029678694903850555
0.032785225392612805 0.12988663262303965 0.026799393817782402
0.0327923978617809 0.12987556474346068 0.021729854866862297
0.03280984696752744 0.12986241140037255 0.020164858549833298
0.032830925148388375 0.12985537461439864 0.021605508401989937
0.03284628190379053 0.12985310388015509 0.021399326622486115
0.032849512242643764 0.1298496337901493 0.019151344895362854
0.03284099444051638 0.12984794200018498 0.017851468175649643
0.0328216907789118 0.12984048626931388 0.018074428662657738
0.032797173708725355 0.12982345973912457 0.016774944961071014
0.03278010307273221 0.12981098210077954 0.013005400076508522
0.03277982062998263 0.12981565757184607 0.011193248443305492
0.032791749145172314 0.1298283999561284 0.014584074728190899
0.032803339331902305 0.12983401601035754 0.017138147726655006
0.03280483377503844 0.1298199389533986 0.01499839499592781
0.032800602494314574 0.1298001640508272 0.008702115155756474
0.032800127561509344 0.12979609258696664 0.005328011233359575
0.032803179661204815 0.1298048117573102 0.010609319433569908
0.032802522839001994 0.1298087940340871 0.013321301899850368
0.03279626534377156 0.1298026839445682 0.0112602012231946
0.03278960886379693 0.12979381523541636 0.006659292615950108
0.03278801059229082 0.1297930122134269 0.006467476021498442
0.03278890714211426 0.12979597851751293 0.009613264352083206
0.03278747817390505 0.1297952137671971 0.0099074337631464
0.03278297806802273 0.12978761194484842 0.0070893126539886
0.0327807963595277 0.12978363169826018 0.004835737403482199
iteration: 3 | epoch: 193 |   loss: 0.129784  |   KL divergence: 0.032781  |  JS divergence: 0.008331
('==== Found maximium gradient [0.069729924, 0.06587036, 0.058333464] of gate '
 'e^[Y1 Z3], e^[Y3 Z1], e^[Y10 Z9] ====')
learning rate =  0.012963517253654739
0.03278300497405431 0.1297858470610107 0.11246435344219208
0.033580436093939306 0.13096162865536545 0.18488284945487976
0.03189922368521692 0.12796975350734474 0.05032302066683769
0.0323245890743806 0.1290721850593382 0.12229223549365997
0.03280479744711852 0.1300846157552082 0.15749981999397278
0.03239243704180265 0.12922294081528501 0.11971365660429001
0.03190451342731282 0.1281309707480546 0.051950931549072266
0.03192395911465438 0.12802673747729204 0.057533007115125656
0.032243487532631995 0.1285750893151377 0.1025162786245346
0.032339278126626805 0.1287743249850335 0.11020250618457794
0.032106378343987024 0.12839901349600133 0.08417622745037079
0.031821930552970085 0.12794997060157334 0.04643280804157257
0.031731385130621466 0.12786389488273822 0.0470571368932724
0.031817170953253315 0.1280674688706417 0.07214976847171783
0.031906952320307186 0.12821167519825652 0.07969578355550766
0.03190692734939139 0.12812823039439536 0.0667613074183464
0.03186572835978886 0.12794294198440326 0.04582711681723595
0.03186103975106943 0.1278441055741438 0.042043253779411316
0.03188939642441708 0.12785773461414054 0.054511114954948425
0.03188669256472512 0.12787259135867737 0.058762334287166595
0.031824660479462266 0.12782364713707098 0.04882337152957916
0.03174265785283306 0.1277628236255563 0.03305526822805405
0.031693699247485135 0.12776240899371416 0.03244596719741821
0.03168456452054975 0.12780460040863273 0.04465343430638313
0.03168383652134385 0.1278104771289932 0.04931408166885376
0.031674434384165895 0.1277473668922304 0.041158419102430344
0.03167466314313326 0.12766764839379874 0.02511775679886341
0.03170649186002612 0.1276426510817317 0.01963443122804165
0.03175567933163277 0.1276720230717856 0.03136919438838959
0.031782994324535255 0.12770198333809335 0.038145504891872406
0.03176325123553644 0.12768380378758573 0.03418945521116257
0.03171453794656678 0.12764383449725064 0.023134440183639526
0.03166928690824518 0.12762146605470986 0.017628874629735947
0.03164404922116302 0.12762548623133915 0.024520711973309517
0.03163358288929922 0.12762955759756414 0.02901379019021988
0.031629627031266344 0.12761020065305737 0.02546260878443718
0.03163761444266343 0.12758870227358549 0.017010126262903214
0.03165911647524129 0.12758216790448956 0.014787060208618641
0.03168357714482073 0.12759169802940254 0.020840898156166077
0.03169093075659188 0.12759016805758894 0.02335079200565815
0.03167569789086188 0.12757115276983763 0.019092874601483345
0.03165109705684084 0.12755446085147792 0.011840698309242725
0.031631737363827545 0.12755325220291186 0.012305004522204399
0.03162046112034075 0.12755647397802938 0.01766701228916645
0.03161467557247282 0.12755160365344362 0.018346184864640236
0.031614042753127784 0.1275354135269534 0.01309045497328043
0.0316231453146138 0.12752466534565093 0.006851998623460531
0.03163938626713371 0.1275266364485349 0.01078001968562603
0.03165069292172263 0.12753051096593168 0.01552310585975647
0.03164635850446112 0.1275214096557289 0.01479276828467846
0.03163025312456831 0.12750753119831135 0.008841329254209995
0.03161269782707025 0.12749783083794555 0.003299592062830925
iteration: 4 | epoch: 245 |   loss: 0.127498  |   KL divergence: 0.031613  |  JS divergence: 0.008043
('==== Found maximium gradient [0.039249517, 0.03830977, 0.025524303] of gate '
 'e^[Y2 Z1], e^[Y1 Z2], e^[Y0 Z2] ====')
learning rate =  0.006985368688200404
0.031602682099114605 0.12750090127473204 0.06116585433483124
0.03204058877722455 0.12795265249150428 0.0985894501209259
0.031470742789449606 0.12701649630419917 0.02871710993349552
0.031540907688833525 0.12734556033441083 0.06343402713537216
0.03167629244217604 0.1276655187410617 0.08306148648262024
0.031563866717075985 0.1273924051511466 0.06359443068504333
0.03144111254959133 0.1270488701899206 0.028514280915260315
0.031471850202552366 0.1270093247201778 0.027827000245451927
0.031581619037446156 0.12717025632613524 0.051006220281124115
0.03161009853095562 0.12723873803571598 0.056362126022577286
0.031524966468828325 0.12713386013913572 0.0445767380297184
0.03141584542084218 0.12700249639545785 0.0260786060243845
0.03136557767605203 0.12697971339903708 0.023354146629571915
0.03137485863518359 0.12704008379793408 0.03514861315488815
0.03139497726626831 0.12708108714828917 0.040127214044332504
0.031392686756625064 0.1270391800693295 0.03493925929069519
0.03138306657297283 0.12695944862108755 0.02394239418208599
0.031394579065753214 0.12691826111284368 0.017898885533213615
0.03142806307688154 0.12693645522391592 0.022878417745232582
0.031456392132517864 0.12697363755538618 0.027643995359539986
0.031454142148829 0.12698182380032813 0.027154717594385147
0.0314209915270038 0.1269521340955999 0.02265198528766632
0.03137842496431036 0.1269116190944639 0.018119757995009422
0.031348949884162355 0.1268888832960913 0.01681966334581375
0.03134178611842267 0.12689496017516805 0.017481166869401932
0.03134869587824931 0.12690854918585925 0.017915913835167885
0.03135807294927173 0.12691122992821371 0.017899347469210625
0.03136348302336936 0.1269013505077893 0.01746976561844349
0.03136298164168763 0.12688272447197374 0.015949996188282967
0.03135986833063939 0.12686824332862123 0.013202143833041191
0.0313571668881886 0.126864338200655 0.011242403648793697
0.03135525699867294 0.12686865491697838 0.012325349263846874
0.031351750599562446 0.12687018765449545 0.01418197900056839
0.03134598085298774 0.12686186955772163 0.013806920498609543
0.03134200895591114 0.12685110970562824 0.010882566682994366
0.031342546815603216 0.12684363355151476 0.00825799722224474
0.031346607958325855 0.12684273789866823 0.009519750252366066
0.0313486154165861 0.12684295933383175 0.011537108570337296
0.031343600452711694 0.1268362639467059 0.010934530757367611
0.031334158257165186 0.12682862874830728 0.007823520340025425
0.03132489390134182 0.12682310343485742 0.005883578676730394
0.031319731193873476 0.1268226959290421 0.00813677255064249
0.031318498582216414 0.12682344990094485 0.009861390106379986
0.03131934406656498 0.12681967184992596 0.008669133298099041
0.03132123507806926 0.12680936328731918 0.00533847464248538
0.031325943047264604 0.1268046363315201 0.004222773481160402
iteration: 5 | epoch: 291 |   loss: 0.126805  |   KL divergence: 0.031326  |  JS divergence: 0.007956
('==== Found maximium gradient [0.014479857, 0.014213484, 0.013500344] of gate '
 'e^[Y1 Z9], e^[Y9 Z1], e^[Y0 Z9] ====')
learning rate =  0.002814127780499962
0.031330598899431024 0.1268054512460838 0.0252990759909153
0.031307856475581916 0.1269016217008885 0.04367097094655037
0.03123957086502934 0.12672422612243794 0.015125865116715431
0.03128388838652511 0.12675380063191516 0.022508835420012474
0.031330878053794996 0.12682203535439085 0.03411535918712616
0.03130836375957038 0.12678768830775808 0.02865459956228733
0.03126257257081593 0.1267255225248452 0.014838404022157192
0.03123802976733087 0.12670888906043273 0.009456395171582699
0.031240379485972282 0.12673355310010923 0.01988632045686245
0.031248208633951464 0.12675117829624205 0.024364395067095757
0.031246726898867774 0.12673288725845244 0.02092744968831539
0.031244076770754706 0.12670435094948432 0.012396755628287792
0.031249619290491366 0.12669051428509912 0.006324382498860359
0.031262577517701874 0.1266995098025388 0.012312793172895908
0.031270901397692924 0.126713086285117 0.017222756519913673
0.031265241787559385 0.12671179027980817 0.017264707013964653
0.03124889888328743 0.1266988488323515 0.013203666545450687
0.03123102932830501 0.12668467728572097 0.008076976984739304
0.031220156261105733 0.12668035931678862 0.007766922004520893
0.031217368805140786 0.12668177729578825 0.010949677787721157
0.031219888794364485 0.1266816917714777 0.012215159833431244
0.031225532491385696 0.12667911596668646 0.010716780088841915
0.031232197349621082 0.12667301418263846 0.007968242280185223
0.031239707294603767 0.1266712454868713 0.007045754697173834
0.031243998432221178 0.12666896513862053 0.008497613482177258
0.031243288662067013 0.12666826499650966 0.009340967051684856
0.03123601551069255 0.1266633901137917 0.008314797654747963
0.031225898633243626 0.12665968486594223 0.006176121067255735
0.031215761854337845 0.12665512304871998 0.00525797950103879
0.031209543591251453 0.12665471414180157 0.006433256436139345
0.031207260663542978 0.1266534649635667 0.007309016305953264
0.031208493162832196 0.12664947803660404 0.006669085472822189
0.031212937361545838 0.12664520185132375 0.0050030844286084175
0.031219607349019518 0.12664426988175648 0.0042159971781075
iteration: 6 | epoch: 325 |   loss: 0.126644  |   KL divergence: 0.031220  |  JS divergence: 0.007935
('==== Found maximium gradient [0.011859893, 0.011038662, 0.008425423] of gate '
 'e^[Y2 Z9], e^[Y9 Z2], e^[Y2 Z3] ====')
learning rate =  0.0021087021658423295
0.031224363697936235 0.12664078878445642 0.018987858667969704
0.031183581761821563 0.12669017029310117 0.03164166957139969
0.031198687626385203 0.12659038163046968 0.010227923281490803
0.03126983975986218 0.12661284714574153 0.0181871484965086
0.03130916085088996 0.1266471696417559 0.025884579867124557
0.03128257653520207 0.12661861056287244 0.020929479971528053
0.03123135045634527 0.1265762781650064 0.009838164784014225
0.031191181064425734 0.12656534946190062 0.006509837228804827
0.031171384413906007 0.12657802128275136 0.014946728013455868
0.031164484552446425 0.1265854997922076 0.018105603754520416
0.031163392022481536 0.12657270925858982 0.01545872911810875
0.03117045391385733 0.12655525764615713 0.009522221982479095
0.03118581033549927 0.12654414969465824 0.006083235610276461
0.03120451453522794 0.12654498172874798 0.009606261737644672
0.031216058905153457 0.12654686889774464 0.012368456460535526
0.031214484550760882 0.12654174067845647 0.01187825296074152
0.03120195675767956 0.12653105192020145 0.008893202058970928
0.031185810773751637 0.12652359753871453 0.00603205943480134
0.0311712053935017 0.12651952948469927 0.0066865007393062115
0.0311616144519055 0.12651955311040364 0.00858933012932539
0.031156385102896745 0.12651562254492757 0.008903424255549908
0.031156155051031274 0.12651000248992517 0.007423938252031803
0.0311605491364121 0.12650552994662062 0.005496501456946135
0.031166504694718225 0.12649946538812012 0.0052797794342041016
0.031172471890351452 0.12649806293575028 0.006419102195650339
0.03117457379930639 0.1264963761102088 0.006866435520350933
0.031171273212964798 0.12649174775922736 0.005987957585602999
0.03116379761029436 0.12648468555989958 0.004412902984768152
iteration: 7 | epoch: 353 |   loss: 0.126485  |   KL divergence: 0.031164  |  JS divergence: 0.007916
('==== Found maximium gradient [0.0052312105, 0.0047268677, 0.003968918] of '
 'gate e^[X8 Y0], e^[Y8 Z1], e^[X0 Y1] ====')
learning rate =  0.0009342458267729572
0.031155919328869432 0.1264813970858226 0.00893424078822136
0.0311407000907457 0.1264863021361858 0.013242077082395554
0.031136713239243267 0.12646403210201768 0.007914687506854534
0.03113890570783821 0.12645569929157577 0.009148227982223034
0.03113797732678468 0.12645247238604268 0.011264721862971783
0.031130598392467505 0.1264432308681592 0.011003968305885792
0.031122431029944875 0.12643198991317872 0.01031409204006195
0.031117924974251816 0.12642334297317068 0.009686300531029701
0.03111642223097273 0.1264170119048446 0.009228607639670372
0.03111411508534856 0.12640570067514834 0.008922368288040161
0.031111948248325506 0.12639914020330512 0.008482172153890133
0.031107198420274276 0.1263897194795367 0.0076203555800020695
0.031101547156420953 0.12638181752180955 0.006710178218781948
0.031095411963418335 0.1263714178467219 0.006498643662780523
0.031091418395820393 0.12636425711858695 0.006731944624334574
0.031088746022881572 0.12635581198270354 0.006685967557132244
0.031087026454449097 0.12634639299255204 0.006375272758305073
0.031086217700263548 0.1263397663657439 0.006286470219492912
0.03108374526818978 0.12633077228214196 0.006471916567534208
0.03107947228507097 0.12632218194710731 0.006523267365992069
0.031073291755402625 0.12631272500077198 0.0063636694103479385
0.031067135842041783 0.12630564575453213 0.006289393175393343
0.03106147810231401 0.12629782450794763 0.006406550761312246
0.03105700186077099 0.12628900270596863 0.00653872499242425
0.031054377621935813 0.12628182151140446 0.006610864773392677
0.03105220736536836 0.12627317847562936 0.006676217541098595
0.031050211118953317 0.1262654715373484 0.006674543023109436
0.031047577413326324 0.12625823892721239 0.0064727989956736565
0.031043635121855154 0.12624927564896252 0.006101420149207115
0.031039951447615954 0.12624311096910307 0.005725192371755838
0.031036264440813283 0.12623646965122887 0.0054384260438382626
0.03103283790870244 0.1262290791567181 0.005252421367913485
0.031029487525426322 0.12622040882605137 0.005196333862841129
0.031026656377926082 0.12621350880277726 0.005240298807621002
0.031024127584391343 0.1262089168967187 0.0052537498995661736
0.03102091980232355 0.12620311957449645 0.005184882320463657
0.031016925446206024 0.12619472094462567 0.005140641238540411
0.03101371358100145 0.12618847358661409 0.0051918537355959415
0.031010164059651256 0.12617915287866194 0.005272020120173693
0.031008751684373746 0.12617685091557881 0.005331302527338266
0.03100601409755807 0.1261692056442397 0.005399287212640047
0.031003106058452745 0.12616220669849598 0.005463996436446905
0.03099984662567218 0.12615577885746157 0.00545113068073988
0.030996345207615413 0.12614960485146762 0.005340729374438524
0.030993330096362307 0.12614482223954449 0.005191346164792776
0.0309908024806283 0.12613988510635651 0.00505937822163105
0.03098869554448836 0.12613419006696272 0.00496713537722826
iteration: 8 | epoch: 400 |   loss: 0.126134  |   KL divergence: 0.030989  |  JS divergence: 0.007872
('==== Found maximium gradient [0.0069863554, 0.006923531, 0.006130448] of '
 'gate e^[X2 Y0], e^[X10 Y0], e^[X1 Y0] ====')
learning rate =  0.0013382916070725098
0.030986351788685917 0.12612623397841263 0.012589204125106335
0.03099193514843573 0.1261110888221498 0.011404440738260746
0.03098919531724969 0.12609932645532299 0.019109001383185387
0.030956555490835876 0.12607779060315058 0.01531151495873928
0.030951764286519023 0.12606809250263684 0.013824508525431156
0.03094973107066478 0.12605425434846076 0.012127459049224854
0.030952102168317508 0.1260375274140697 0.011482791043817997
0.030949548960234177 0.12601892070785606 0.011029011569917202
0.030940478829735264 0.1260041030635264 0.009783869609236717
0.030929716554819492 0.12599305460516547 0.010306436568498611
0.030919420151737532 0.12597925660363773 0.011748936027288437
0.030911647419644722 0.12596379466646745 0.011907422915101051
0.030906143961556054 0.12594778810274734 0.010467746295034885
0.0309009579567145 0.1259308006851656 0.008739539422094822
0.030896535281261364 0.12591910936575648 0.008476929739117622
0.03089023305236014 0.12590548073598878 0.009019210003316402
0.030882608932271877 0.1258926967651239 0.008597861044108868
0.030873008792672626 0.12587451772763875 0.007454936392605305
0.03086522204731796 0.12586077849010455 0.007304262835532427
0.03085929777204676 0.12584877610235085 0.008379751816391945
0.030854133939182543 0.12583463387908772 0.009167294017970562
0.03084921226984163 0.12581922751461175 0.008957401849329472
0.030844465543581463 0.12580587360372114 0.00820118561387062
0.030838227887932064 0.1257918561275271 0.007659110240638256
0.030830418544126673 0.12577926717622462 0.007308623753488064
0.030820519495680373 0.12576378287922033 0.006849958561360836
0.03081175429007609 0.12575125756286534 0.006551133468747139
0.030805378181233863 0.125739875315624 0.006579673383384943
0.03080094769165183 0.12572617460814461 0.006684040185064077
0.030798176496040684 0.1257132696461087 0.006956894416362047
0.030794593597292697 0.12569899778000485 0.007450444158166647
0.030789595360253278 0.12568777685367502 0.007592861540615559
0.030781739774346176 0.12567522258937117 0.007009195163846016
0.030772850191999115 0.1256632301316601 0.006202894728630781
0.03076413950004202 0.1256490501717651 0.005913968663662672
0.030757805003742283 0.12563697747949934 0.005955054424703121
0.03075334393531086 0.12562548972169008 0.0058183674700558186
0.030749557435604664 0.12561308502902957 0.005719579290598631
0.03074614583070749 0.1256022021349807 0.006030130200088024
0.030741607415162672 0.12558987560937776 0.006373419426381588
0.030736585553429563 0.12558007331339827 0.006279075518250465
0.030729937577530828 0.12556745604260747 0.005870926659554243
0.030723830567434673 0.1255581557653984 0.0055058919824659824
0.0307176692045668 0.1255469356618552 0.005293822381645441
0.03071243597075795 0.12553572680560998 0.0051982104778289795
0.030708090870263396 0.12552454376777095 0.005216103047132492
0.030704615329638432 0.12551552244962164 0.005298456642776728
0.030700293959159984 0.1255045286450438 0.005342461168766022
0.030695140185649797 0.12549271754461488 0.005316898226737976
0.030690682117315835 0.12548499939312693 0.00523824617266655
0.03068565704463047 0.12547424879757504 0.005074534565210342
0.03068168624465869 0.12546572856638297 0.0048709772527217865
iteration: 9 | epoch: 452 |   loss: 0.125466  |   KL divergence: 0.030682  |  JS divergence: 0.007789
('==== Found maximium gradient [0.0075435336, 0.006598748, 0.0053421585] of '
 'gate e^[Y8 Z9], e^[Y9 Z8], e^[Y9 Z0] ====')
learning rate =  0.001311421803236043
0.030677797439245865 0.1254563016831778 0.012318327091634274
0.030701463587031356 0.1254603143301631 0.024523206055164337
0.03063441808789051 0.1254002859583863 0.013475939631462097
0.030618918669365412 0.12538932468356304 0.019445493817329407
0.03061694713976351 0.12537329760184662 0.01960504613816738
0.030612202362940932 0.12534207382666399 0.016299467533826828
0.030608699897857153 0.12530985341113654 0.014811169356107712
0.03059861616248797 0.12528179757320004 0.014115431345999241
0.03058555232536533 0.1252609017355146 0.013116766698658466
0.030570943014530977 0.12523903626319147 0.01284089870750904
0.030555279970609233 0.12521586657708633 0.013541517779231071
0.030538857722636856 0.12518884293387056 0.013533595018088818
0.030523542897341684 0.1251566687170141 0.012030541896820068
0.030512682479362827 0.12512755512617196 0.010492483153939247
0.030505272454523998 0.1251035378182053 0.011248103342950344
0.0304958423102951 0.1250777632115589 0.013179688714444637
0.030482049785195652 0.12505041899060973 0.013838502578437328
0.030465013806751737 0.12502122387654832 0.01283018384128809
0.030447637493894245 0.12498976443400461 0.011327936314046383
0.030433386064417235 0.12496172889577449 0.010808379389345646
0.030422004151678672 0.1249360706839935 0.011255118064582348
0.03041127739793353 0.12490831391518192 0.011537784710526466
0.030400609996175693 0.12487990536743722 0.01118684932589531
0.03038862745002119 0.12484822806044807 0.010660182684659958
0.030375667240735565 0.12481804718152381 0.010590659454464912
0.030360690014542103 0.12478801521330503 0.010913215577602386
0.03034434809792725 0.12475941097603267 0.011249112896621227
0.030327426061971197 0.12472969592549091 0.011473050341010094
0.030311631100311605 0.12470019390110708 0.011581983417272568
0.030296770144683273 0.12466818494327195 0.011533111333847046
0.030283815135345067 0.12463825671447487 0.011314364150166512
0.0302714269362915 0.12460637616015566 0.01106411125510931
0.030259563971563003 0.1245748618652984 0.01092746015638113
0.03024723363823385 0.12454431240827618 0.010904994793236256
0.030233266423094568 0.12451418884831186 0.01084042713046074
0.030217322727105443 0.12448302765807148 0.010683928616344929
0.030200982642155965 0.12445273644114387 0.010594264604151249
0.03018439594932433 0.12441944240926768 0.010692635551095009
0.030169406417616004 0.12438881625435161 0.010891134850680828
0.030155457503657387 0.12435858537401785 0.011033096350729465
0.030141978723078455 0.12432701801351731 0.011067288927733898
0.03012900683896603 0.12429618945785594 0.011021653190255165
0.03011538903289072 0.12426436971202051 0.010946406051516533
0.030101779140831772 0.12423540205142025 0.01085083931684494
0.030087302814117728 0.12420435146235034 0.010732586495578289
0.03007298216177781 0.12417375248732394 0.010604836978018284
0.030058475669949014 0.12414231321728635 0.010504285804927349
0.03004390844742799 0.1241106362026867 0.010463910177350044
0.030030273061030097 0.12408148615210293 0.010496588423848152
0.030017109286407415 0.12405248997743783 0.010559223592281342
0.030003346644527966 0.12402070480355477 0.010600019246339798
0.029989992793398312 0.12399128255108154 0.010602259077131748
0.02997694465541086 0.1239630694525523 0.010572634637355804
0.029963553639294545 0.12393248373743236 0.010506408289074898
0.029950510148067398 0.12390254385862391 0.010399793274700642
0.029938232837903967 0.12387542441652492 0.010268167592585087
0.02992585669655181 0.12384757883035216 0.010146241635084152
0.029912752424273485 0.12381695095005538 0.010053087025880814
0.02990033766777448 0.12379008284435014 0.009990239515900612
0.029887683319512588 0.12376285205618563 0.009963520802557468
0.02987548735746909 0.12373652764449306 0.009965184144675732
0.029863635749684876 0.12370994600092511 0.009965401142835617
0.02985181637413074 0.12368231865701915 0.009939233772456646
0.02984048325319241 0.12365575635459311 0.00987967848777771
0.02982933562875714 0.12362922462876458 0.009784906171262264
0.029819000681871672 0.12360614115070985 0.009655163623392582
0.029807478151235467 0.12357922239487626 0.009511876851320267
0.029797053736591146 0.1235572122613362 0.009391543455421925
0.029785909551565196 0.12353187492131755 0.009309155866503716
0.029775117821380655 0.12350709059227757 0.009252848103642464
0.029765214977942687 0.12348465841508405 0.009208652190864086
0.029755358647319124 0.12346079126003476 0.009165623225271702
0.029745950746338932 0.12343768736025555 0.009105086326599121
0.029737128496727005 0.12341708432301689 0.00901199970394373
0.02972797109874422 0.12339563131604685 0.00889152754098177
0.02971917765696999 0.12337568980352427 0.008759834803640842
0.029709963181649 0.12335377317907137 0.008629247546195984
0.02970149478425711 0.12333431514694461 0.008510040119290352
0.029692806576945993 0.1233129362463987 0.008409632369875908
0.029684474005575473 0.12329192101508532 0.008323614485561848
0.029677144481129524 0.12327439600471768 0.008239911869168282
0.029669390858416286 0.12325484563129559 0.008152543567121029
0.029662147436802448 0.12323704176209112 0.008059254847466946
0.029655045796144152 0.12321968286674706 0.007953950203955173
0.029647993876772125 0.12320230537587681 0.007833042182028294
0.02964128626602207 0.12318561374909144 0.007702193688601255
0.029634340920702065 0.1231672375194019 0.00757054565474391
0.029628978245553134 0.12315493876770278 0.0074423435144126415
0.02962207799933813 0.12313618387681745 0.007322306744754314
0.02961657484188357 0.1231226328152425 0.007212128024548292
0.029610457327679564 0.12310613162164334 0.007109272293746471
0.029605578903064162 0.12309407735051611 0.007006342988461256
0.02960033266956431 0.12307991713650361 0.00689656799659133
0.02959529804182353 0.12306629825414739 0.006775846239179373
0.02959072866773542 0.12305449790878314 0.006643918342888355
0.029585243670665506 0.12303882192425122 0.006506596226245165
0.029580753157023482 0.12302693922501198 0.006372177507728338
0.029576156443779963 0.12301432792712512 0.006246152799576521
0.02957240860339387 0.12300450466138813 0.006128362379968166
0.02956807040704832 0.12299159168857562 0.006017373409122229
0.029564383343458338 0.12298096669184111 0.005908531602472067
0.0295607696161072 0.12297055174372568 0.005796349141746759
0.02955717554870985 0.1229602234923974 0.005676992237567902
0.029553214138113477 0.12294838879268878 0.005551817826926708
0.02955065353421013 0.12294193566614034 0.005424212198704481
0.029547315793440658 0.12293180758796853 0.0052978177554905415
0.0295443853976872 0.12292290850336324 0.005176321603357792
0.029541207828833002 0.12291272061492486 0.005061390809714794
0.029538995186026526 0.12290622165491977 0.004950988572090864
iteration: 10 | epoch: 561 |   loss: 0.122906  |   KL divergence: 0.029539  |  JS divergence: 0.007477
('==== Found maximium gradient [0.011431953, 0.009511973, 0.0075764046] of '
 'gate e^[Y0 Z1], e^[Y1 Z0], e^[Y2 Z0] ====')
learning rate =  0.00192724003810296
0.02953619524083816 0.12289729707491616 0.01737891137599945
0.02955645422505206 0.12288906088720822 0.026153480634093285
0.02953872589531304 0.12285645843085398 0.020804231986403465
0.029525398463092427 0.12283488852171806 0.025639545172452927
0.029508969738352542 0.12280851874554521 0.022156165912747383
0.02949874063991727 0.12277603369491673 0.016480473801493645
0.02949430065824562 0.12274509159006958 0.01745358668267727
0.029487438022378135 0.12271756403254977 0.017417926341295242
0.029479350318102927 0.122697859831245 0.014928403310477734
0.029467080181208596 0.12267981806827379 0.014372024685144424
0.02944697521304307 0.1226575736210848 0.014576852321624756
0.029426147091171678 0.12263195232411381 0.014121823012828827
0.029413801915314404 0.12260719658287753 0.012504461221396923
0.02941198042443542 0.12258726064098323 0.010042662732303143
0.029416192514950527 0.12257177944411742 0.010239736177027225
0.029419186819159386 0.12255606123924279 0.012540408410131931
0.029415560416696067 0.12253829202439606 0.012540671043097973
0.029404481981737052 0.12251939538304854 0.010025030933320522
0.029388134107282887 0.12249859510156046 0.0077553545124828815
0.029372562005235185 0.12248449553499106 0.007975790649652481
0.029360464390599122 0.12247153838964277 0.009403332136571407
0.029353296793846316 0.12245799442222088 0.009591711685061455
0.02934969002864035 0.1224423478643641 0.007852648384869099
0.02934796359093783 0.12242554929016498 0.006463144905865192
0.029347901651911118 0.12241431200641284 0.007321154698729515
0.029346021139002778 0.1224028868282569 0.007806723937392235
0.02934023712063087 0.12238892539920468 0.007137612905353308
0.029331837823050287 0.1223775528725238 0.006574706174433231
0.02932228230191141 0.12236692141448688 0.006599773187190294
0.029313956105167325 0.12235533798868789 0.006736834533512592
0.029308645668249457 0.12234477377847373 0.006202229298651218
0.029305135316253964 0.12233384610866757 0.005017624702304602
0.029302027246065877 0.12232316915917624 0.004901296459138393
iteration: 11 | epoch: 594 |   loss: 0.122323  |   KL divergence: 0.029302  |  JS divergence: 0.007406
('==== Found maximium gradient [0.009664091, 0.006775765, 0.0057077473] of '
 'gate e^[Y10 Z0], e^[Y0 Z10], e^[Y9 Z10] ====')
learning rate =  0.0015138649591893041
0.029297832633147093 0.12231231649451685 0.014301163144409657
0.029326518321400166 0.12241862566782843 0.041576970368623734
0.029298868638074384 0.12229813252162748 0.020031515508890152
0.029300643903912457 0.12227368344286356 0.021601589396595955
0.029304698246664283 0.12228280025690232 0.029075143858790398
0.029280498539243464 0.12225296174227754 0.02703986130654812
0.0292422504522473 0.12219671160942794 0.018489956855773926
0.029214742572787313 0.12215633169869103 0.011743289418518543
0.02920685138364606 0.12214348189727117 0.016881084069609642
0.029207278482730657 0.12213594683185246 0.021718887612223625
0.029202170398475415 0.12211005326819425 0.020434370264410973
0.029192096888504174 0.12207314747195827 0.014814800582826138
0.029183188492522556 0.12204243022745284 0.010394292883574963
0.02917612811074549 0.12202093407542419 0.011831706389784813
0.029168492437915992 0.12200653200992877 0.01449751015752554
0.02915687081035341 0.12198952698649744 0.015173944644629955
0.02914050483164842 0.12196311051101817 0.013907232321798801
0.029124810742196968 0.12194065443635894 0.011511453427374363
0.029110905557109157 0.1219165118682554 0.0094477329403162
0.029102436076872965 0.12189872552532516 0.00956689566373825
0.02909857021280293 0.12188537392859124 0.010965264402329922
0.02909539855155435 0.12186839986221115 0.01127663441002369
0.029091202651226125 0.12184806133937318 0.009940152056515217
0.029086397862349726 0.12182980173142992 0.00824421364814043
0.029080272843554394 0.12181268915806831 0.007801238913089037
0.0290731549675474 0.12179910902496377 0.008336765691637993
0.029064910990365185 0.12178716161163186 0.008753826841711998
0.02905603188893574 0.12177461527595351 0.008697914890944958
0.029046763843886617 0.12175710850177712 0.00804694090038538
0.029040524610352073 0.12174424322168595 0.006829781923443079
0.029035839654256077 0.12172849938225 0.0059411111287772655
0.029033666099598045 0.12171662683278958 0.006452005356550217
0.02903184780150553 0.12170617945519499 0.007364274933934212
0.02902771164083812 0.12169228669857994 0.007298205513507128
0.029021976996732698 0.12167977886146042 0.006222967524081469
0.029014850883811453 0.12166711594471838 0.00525788264349103
0.02900768161820338 0.12165582143784377 0.005381659604609013
0.029001645182401073 0.12164730273775602 0.005968607030808926
0.02899605895174814 0.12163658418690988 0.006153962109237909
0.028991341790837916 0.12162454845860876 0.005784908309578896
0.028987481907567662 0.12161190026469641 0.00518440967425704
0.028984698189225 0.12160181369567291 0.00492640258744359
iteration: 12 | epoch: 636 |   loss: 0.121602  |   KL divergence: 0.028985  |  JS divergence: 0.007320
('==== Found maximium gradient [0.00422598, 0.0037457107, 0.0032009583] of '
 'gate e^[Y3 Z1], e^[X2 Y3], e^[Y0 Z8] ====')
learning rate =  0.0007495366402642884
0.028981435937546776 0.12159113977649996 0.008315006271004677
0.0289695212857691 0.12159552191718118 0.017530707642436028
0.028973604199026518 0.12156681050950391 0.008883125148713589
0.02897778982834977 0.12155785917330254 0.012485140934586525
0.02897140235705263 0.1215495863421368 0.01298364158719778
0.028954882959125204 0.12153194751407323 0.010653768666088581
0.02893869895382705 0.12151612027118767 0.010234634391963482
0.028929420272980497 0.12150739544952043 0.010367821902036667
0.028924318845462604 0.1214943417693595 0.009600503370165825
0.02892260431057595 0.12148203959718706 0.008689584210515022
0.028920972835268066 0.12146759791099235 0.008454999886453152
0.02891819384104448 0.12145667898888773 0.008406585082411766
0.028911088263784485 0.12144136710620211 0.007729686331003904
0.02890235012681485 0.12143021259465196 0.007170727476477623
0.028891970870145774 0.12141682233011855 0.007659541442990303
0.02888267067537581 0.12140519452440204 0.008282379247248173
0.028875091464418988 0.1213927043016075 0.00796748511493206
0.028869053472255133 0.12137716811062042 0.007015412673354149
0.028865531109540106 0.12136537383933686 0.00663917837664485
0.028861940655256935 0.121352798658853 0.007194312755018473
0.028857741328587243 0.12134327766420933 0.007684521377086639
0.028850063613667414 0.12132735174109709 0.007366491947323084
0.02884200609037439 0.12131549410619896 0.006576827727258205
0.028833352250081684 0.12130256697290169 0.006339884363114834
0.02882537038115629 0.12129025074058859 0.006776550784707069
0.028818540842282588 0.12127824734395215 0.007026521489024162
0.028812954869801746 0.12126573072481064 0.006702795159071684
0.028808598121860048 0.12125346794836307 0.006146648433059454
0.02880406429671446 0.12123949096084469 0.00594374630600214
0.028798900080019993 0.12122697665906397 0.006139127537608147
0.02879257049799682 0.1212162498779058 0.0062567442655563354
0.028784528409286463 0.12120340980825124 0.006123672239482403
0.028775998710376276 0.12118970404403974 0.005983182229101658
0.028768414294939648 0.12117764971960451 0.006008058320730925
0.028762096398957278 0.12116648859419808 0.006091387011110783
0.02875670354122146 0.12115435798565681 0.0061029656790196896
0.028752386486865976 0.12114364802821553 0.006030402146279812
0.028747245141391382 0.12113003523707914 0.005961206741631031
0.028741862306017156 0.12111899112910435 0.005914091598242521
0.028735171882031594 0.12110680028950478 0.005857624113559723
0.02872779965528706 0.12109461625735303 0.005813978612422943
0.028720661146078463 0.12108413194040676 0.005794195923954248
0.02871347112998698 0.12107219708731866 0.00577066233381629
0.028707388029322815 0.12106187989856881 0.0057351430878043175
0.028701711430221155 0.12104984057666228 0.005709435325115919
0.02869674060359624 0.12103876780403793 0.0057041235268116
0.02869127562186404 0.12102625509352101 0.0056855338625609875
0.028685756333517005 0.12101588324076672 0.005620317067950964
0.02867907967112416 0.12100313723951976 0.005552524700760841
0.028672267044472892 0.1209909912856585 0.005526254884898663
0.028665809860238433 0.12098010416769413 0.005526024382561445
0.02865915458010618 0.12096739073699245 0.005512857344001532
0.028653574709665793 0.12095770056769632 0.005485576577484608
0.028647845759814473 0.12094600856926786 0.005479123443365097
0.028642211995642382 0.12093405195468578 0.0054924217984080315
0.028637218946788986 0.12092532835363701 0.005489149130880833
0.028631076004441917 0.12091312642833398 0.005459512118250132
0.028625149838323108 0.12090267833956797 0.005420539062470198
0.028618884532750938 0.12089099203410955 0.005385179538279772
0.02861300498128584 0.12088057065576362 0.005346985999494791
0.028607298686463938 0.12087014046384675 0.005305136553943157
0.028602085297260986 0.12086088634489242 0.005276931449770927
0.02859591500378674 0.12084741794344771 0.005265561398118734
0.028590228273553103 0.12083641482419834 0.005258202087134123
0.02858436944471866 0.12082516323530786 0.005250102840363979
0.028579022310763688 0.12081602335978284 0.005242733284831047
0.028573357707554127 0.12080540494269976 0.005235372576862574
0.02856787630764152 0.12079540449189022 0.005217361729592085
0.02856168590566717 0.12078220530994842 0.005189346149563789
0.028556618706501703 0.12077340002868794 0.005162869114428759
0.02855136422777111 0.1207640094715119 0.0051444293931126595
0.02854588649408337 0.12075412565847171 0.005130970850586891
0.028540160166734944 0.12074333764310989 0.005118568427860737
0.028534683592166377 0.12073327346267367 0.005108969286084175
0.02852900929704509 0.12072197945882597 0.005102495662868023
0.028523720716583538 0.12071194843594658 0.005094990599900484
0.02851860178312103 0.12070251197855783 0.005080490838736296
0.02851331600418914 0.12069265065443589 0.0050598918460309505
0.02850725689161015 0.12068006506357716 0.005038948729634285
0.02850207162356394 0.120671280821478 0.005022668279707432
0.028496851052168905 0.12066208987995909 0.005012554116547108
0.028491163407449456 0.12065052367499782 0.005006710533052683
0.028486120106978118 0.12064123974449877 0.005001095123589039
0.02848128370847252 0.1206325442547549 0.00499464338645339
iteration: 13 | epoch: 720 |   loss: 0.120633  |   KL divergence: 0.028481  |  JS divergence: 0.007203
('==== Found maximium gradient [0.0032508702, 0.003243639, 0.0029613562] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y2 Z9] ====')
learning rate =  0.0006309673222783817
0.028476144784753007 0.12062262634149863 0.007397632580250502
0.028476545712787807 0.1206121974389424 0.009714541956782341
0.02845329649390749 0.12059884875741107 0.008404872380197048
0.02844679703167834 0.12058382952500851 0.009027642197906971
0.028446431758962873 0.1205679981421822 0.007653817068785429
0.02844658201402363 0.12055385299668628 0.007286941632628441
0.028443764856841403 0.12054111834490411 0.007920872420072556
0.028434740124254256 0.12052654237555999 0.007779630366712809
0.02842365658385 0.12051437941945009 0.007353925611823797
0.02841246355933006 0.12049981560864802 0.007482058834284544
0.02840362161053195 0.12048673833023058 0.007739828433841467
0.02839654570422602 0.12046930664475203 0.007571520283818245
0.02839262182454486 0.12045584454497583 0.007102416828274727
0.028389338934329218 0.12044382680449943 0.006809081416577101
0.02838347870005135 0.12042614734065929 0.006913305725902319
0.028377463066604932 0.12041458394118044 0.00718082906678319
0.02836959234426279 0.12040142240284775 0.007228371687233448
0.028360388029321313 0.1203865294096886 0.007041976787149906
0.02835126294326707 0.12037173998541861 0.006899088155478239
0.028342853041177736 0.12035607904909738 0.006925365887582302
0.028336097240422284 0.12034339271041149 0.006941166240721941
0.028329764947707725 0.1203308214461311 0.006815367378294468
0.028322630793340766 0.12031416288877224 0.0067305308766663074
0.02831620230373367 0.12029976204706697 0.006846447475254536
0.02830977787903172 0.1202860537655034 0.007000595331192017
0.028302289574413476 0.12027024673299114 0.00697596138343215
0.028294551201748168 0.12025568111279587 0.006855321582406759
0.02828685347892949 0.12024249700018567 0.0068144057877361774
0.028279149185965424 0.120229684791254 0.006837299093604088
0.028271142494928164 0.12021484517246839 0.006834034342318773
0.028263606545337078 0.12019962792133992 0.00683868071064353
0.02825704325820285 0.12018599430929736 0.006886986084282398
0.02825084566896598 0.12017323922332387 0.00691584637388587
0.028243479600642187 0.12015667234686961 0.006882797926664352
0.02823610508613254 0.12014172133452151 0.0068220701068639755
0.02822858949530055 0.12012789077701333 0.006789030972868204
0.028220632338340754 0.12011319713031254 0.0068137189373373985
0.028212721077822904 0.12009804992169315 0.006867891643196344
0.028205750485622568 0.1200849226305236 0.006881737150251865
0.0281990262660377 0.12007091112956016 0.006846451200544834
0.02819250400771254 0.12005675718163218 0.006808442063629627
0.02818570401903544 0.12004195854897741 0.00678496016189456
0.02817856711804284 0.12002762086922718 0.00676222937181592
0.028171154724793764 0.12001407743312904 0.006749339401721954
0.02816350093954178 0.11999992511708252 0.006755180656909943
0.028156673577198393 0.11998776189906267 0.006758630275726318
0.028149471109563763 0.11997203758424736 0.006739297416061163
0.028143027594374776 0.11995815811446121 0.006704946979880333
0.028136838979728372 0.11994520722760235 0.006686410866677761
0.028129704177983245 0.11992941781112106 0.006689727772027254
0.028122603789115394 0.1199153818616118 0.00668368861079216
0.028115431068528866 0.11990189547898586 0.0066662197932600975
0.028108541740291225 0.11988929752507879 0.0066502573899924755
0.028101704180324857 0.11987599929097045 0.00662460969761014
0.02809515387018128 0.11986273524638706 0.006592976860702038
0.02808863523655729 0.11984868725311228 0.006582324858754873
0.02808250903494324 0.11983637250482408 0.006585545837879181
0.028075364135504793 0.11982064877218672 0.006580985616892576
0.02806916297004814 0.11980950902656294 0.0065665231086313725
0.028062285362315427 0.11979588572208763 0.006531760562211275
0.028055629071655423 0.11978313366475202 0.006486687809228897
0.028049212961501882 0.11977093994395827 0.006458358373492956
0.02804262077902596 0.11975753187919887 0.00643905671313405
0.02803620587836291 0.11974438375041593 0.006422001402825117
0.028030237462447604 0.11973268060870491 0.006403752136975527
0.02802383169478538 0.11971915383918975 0.00637370441108942
0.02801705509468267 0.11970453754874531 0.0063368286937475204
0.028011704727198057 0.11969635760809492 0.00629714410752058
0.028004753365918685 0.11968164012337819 0.006260247435420752
0.027998603145428874 0.11966990430612251 0.006231950595974922
0.027992366973549326 0.11965718882855579 0.0062001049518585205
0.027986740303859677 0.11964642798674265 0.006164942402392626
0.02798086846793877 0.11963443407687752 0.0061293356120586395
0.02797536082431786 0.11962415125254633 0.006088668946176767
0.027969038258652212 0.11961081034415284 0.006052148062735796
0.0279634661344796 0.11960076666797248 0.006016373634338379
0.02795764948905609 0.11958934292620453 0.0059805517084896564
0.027951970876392777 0.11957784440206647 0.0059427665546536446
0.027946612577379393 0.11956726224881556 0.005896280519664288
0.027940822643094446 0.11955477895223858 0.00585571676492691
0.027935464461059076 0.11954424404444583 0.005816214252263308
0.02792998700213705 0.11953335404731408 0.005773994605988264
0.02792479648515767 0.11952349779078333 0.005733720492571592
0.02791977016076749 0.11951394492740368 0.005689604207873344
0.027914344341964027 0.11950231919243164 0.0056449417024850845
0.02791012013621621 0.11949540671481969 0.005598393734544516
0.02790434322452942 0.11948196231343139 0.005555528216063976
0.027899663571355184 0.11947322424303418 0.00551175931468606
0.02789505121473539 0.11946480112034526 0.005464276764541864
0.027889322185476587 0.11945152529935857 0.005418369080871344
0.02788498824804104 0.11944380341335031 0.005366047844290733
0.027880338007526238 0.1194344706403825 0.005320457275956869
0.02787607028927329 0.11942652832580128 0.00527511490508914
0.027871376038380382 0.11941670697436824 0.005230689886957407
0.027866851479120526 0.11940753137799247 0.005183085799217224
0.02786249096343938 0.11939903281992184 0.005132289603352547
0.027858470546226165 0.11939189616458268 0.005083119962364435
0.027853317536745813 0.1193798548078592 0.0050331000238657
0.027849498351187385 0.11937308191444619 0.004991082940250635
iteration: 14 | epoch: 819 |   loss: 0.119373  |   KL divergence: 0.027849  |  JS divergence: 0.007052
('==== Found maximium gradient [0.0025753942, 0.002433171, 0.0023167313] of '
 'gate e^[X0 Y8], e^[Y2 Z0], e^[Y0 Z2] ====')
learning rate =  0.0004888110700012948
0.027845168332382125 0.11936392041706302 0.006507441867142916
0.027835078371725164 0.11935761033891239 0.008968482725322247
0.027840183562071134 0.11934635178590142 0.007794130593538284
0.027835503165467644 0.11933891953774284 0.008510671555995941
0.027824245046751794 0.11933043037447556 0.007613566238433123
0.02781386615468729 0.11931925047512312 0.007255923002958298
0.027807694214031113 0.11931146985158257 0.0075743007473647594
0.027805141383348178 0.11930426336241988 0.007146674208343029
0.027804336308347357 0.11929496367252868 0.006578108761459589
0.02780471757033952 0.11928824955858675 0.006556778214871883
0.02780332310802234 0.11927822025185167 0.006278177257627249
0.027801276536714138 0.11927302606268081 0.005703368689864874
0.027796839725136344 0.11926538781440305 0.005427289288491011
0.027790695983845808 0.11925517547617084 0.005377267021685839
0.02778595718270438 0.11925040538384742 0.005363275296986103
0.027782025586994753 0.11924411294728471 0.0053903572261333466
0.02777870989344417 0.11923433679804768 0.005347942002117634
0.027776938445777784 0.11922738548308726 0.005245467647910118
0.027774792532008645 0.11921934425521948 0.005258919205516577
0.027772319361639396 0.11921358970939003 0.005332121159881353
0.027768025981191907 0.11920471676509449 0.0052451384253799915
0.02776391312875575 0.11919959959256238 0.005089918151497841
0.027758827101959354 0.1191908551835304 0.005147826392203569
0.027754538439356116 0.11918353771026008 0.005283829290419817
0.027751297423297044 0.1191771093764774 0.0051788752898573875
0.0277490724390097 0.1191709740689414 0.004894429352134466
iteration: 15 | epoch: 845 |   loss: 0.119171  |   KL divergence: 0.027749  |  JS divergence: 0.007028
('==== Found maximium gradient [0.0029531135, 0.0025030598, 0.0024670819] of '
 'gate e^[X1 Y8], e^[Y1 Z3], e^[X1 Y0] ====')
learning rate =  0.0005300651377092101
0.027747836216810623 0.1191660887727155 0.006586016621440649
0.02774168394142456 0.1191621153062708 0.012562623247504234
0.02774307599705192 0.11914441287633575 0.006877748295664787
0.027744875799290962 0.11913671073745105 0.009895424358546734
0.02773997922517025 0.11913033415933935 0.009245066903531551
0.02773285741733563 0.11911934171955227 0.006923108361661434
0.02772686611977151 0.11910934423959721 0.007178910542279482
0.02772316718395042 0.11910248338621635 0.008560103364288807
0.027719205746671523 0.11909283353058985 0.008225622586905956
0.027714850131812404 0.11908095093670337 0.006615550257265568
0.027711765449731016 0.11907244788471327 0.005850036628544331
0.027708775635511766 0.11906442682136445 0.00643721129745245
0.027704987591559753 0.11905739734861041 0.006809981074184179
0.027698706745816832 0.11904612736884536 0.006398668512701988
0.02769256211584285 0.11903905926727955 0.005836835131049156
0.02768613037350024 0.11902896547553378 0.0058482373133301735
0.02768190178033103 0.11902151950320193 0.006183184217661619
0.027678866910079696 0.11901158258772374 0.006236135959625244
0.027678015920275564 0.11900638368203706 0.005920697934925556
0.027675674113639578 0.11899539495268023 0.00563693605363369
0.027672697087975914 0.11898633520041099 0.005650648847222328
0.027668873651217882 0.11897991114602524 0.005747749004513025
0.02766344519855224 0.11897144595232904 0.005707310978323221
0.027657167149483457 0.11896068819037513 0.005576866213232279
0.027652366470414892 0.11895388559897442 0.005520530976355076
0.027647601085131136 0.11894331628507607 0.005573381204158068
0.027644680604645692 0.1189372937123898 0.005620981566607952
0.027641501345881204 0.11892918688743648 0.005555517505854368
0.0276377097692977 0.11891930470740764 0.005423178896307945
0.027633433313151427 0.11890884158655961 0.005339326802641153
0.027630136557575576 0.11890403543357872 0.005292179528623819
0.027625169503440346 0.11889375660454359 0.005248554050922394
0.02762043723206221 0.118885452703963 0.005226279608905315
0.027615721699117586 0.11887687178742645 0.005222397390753031
0.027612054009025576 0.11887084094812513 0.005216365214437246
0.027607329524407982 0.11885796109482935 0.005236825440078974
0.027604694810574162 0.11885221041290478 0.005289248190820217
0.027600631407531488 0.11884050653482697 0.005326095502823591
0.027597627369616427 0.11883482747588621 0.005300926975905895
0.027593323328085537 0.11882599449128643 0.0052225301042199135
0.0275886848395947 0.11881749724548582 0.005154110956937075
0.02758428114838901 0.11881011045308548 0.005129355005919933
0.027579540460623875 0.11879994123329428 0.00512291444465518
0.027575701856191966 0.11879190157912961 0.005131369922310114
0.02757195545273918 0.11878346251454405 0.005163941066712141
0.027568261995260877 0.11877540988265813 0.005181403364986181
0.02756422842912017 0.11876642302338633 0.005151718854904175
0.027560000328361173 0.1187570552171817 0.005099658854305744
0.027556302007017867 0.11875027224160647 0.00507461978122592
0.0275517440036298 0.11874012249502616 0.0050836713053286076
0.027547340936133424 0.11873063035788577 0.0050867157988250256
0.027543671743817666 0.11872394674424565 0.005073977168649435
0.02753966400378914 0.11871521761612489 0.005082988180220127
0.027535703147202648 0.11870585093494193 0.005116135347634554
0.027532423064779613 0.11869893959353667 0.005132337566465139
0.027528784764156593 0.1186911332087258 0.005115319974720478
0.02752408894456713 0.11868011387073957 0.00508759543299675
0.027519658576067776 0.11867102480782069 0.005066697020083666
0.0275157591268049 0.11866400524884037 0.005049888510257006
0.027511321992288847 0.11865387055295436 0.005042023491114378
0.02750772057272939 0.11864631757684983 0.005058265756815672
0.027503607734800286 0.11863626117599871 0.005087273195385933
0.027499614327689707 0.11862712930347534 0.005096742417663336
0.02749562243505812 0.11861875183193128 0.005079190246760845
0.027491228515228262 0.11860905209860857 0.005055771209299564
0.02748775089384542 0.11860300446511031 0.005042788106948137
0.027483576809612078 0.118593616793455 0.00503927655518055
0.027479281528615403 0.11858332862185868 0.005044848658144474
0.027475910264179976 0.11857671005494642 0.005063311662524939
0.02747182500787948 0.11856723120053404 0.00508543336763978
0.027467684437044664 0.11855795786825872 0.005094022490084171
0.027463673282228342 0.1185496276344962 0.00508486432954669
0.027459591144317442 0.11854109618810087 0.005066079553216696
0.027455460094416753 0.11853211035727626 0.005048505961894989
0.027451561338198524 0.11852362768157093 0.005041640251874924
0.027447692260016344 0.11851490950774098 0.0050499457865953445
0.027443626827235557 0.1185054774445793 0.0050667282193899155
0.027439612612915873 0.11849673193795168 0.005080054048448801
0.02743559365657801 0.11848834714410622 0.0050822715274989605
0.02743165397757028 0.11848033305108356 0.005073753651231527
0.027427387827393877 0.11847066750472864 0.005061585456132889
0.02742375173168093 0.11846324057132912 0.0050556291826069355
0.027418672917452383 0.11844951079125024 0.005059331189841032
0.027415511808631055 0.1184439364172938 0.005068657454103231
0.027411408136900708 0.11843468892966241 0.00507871201261878
0.02740757549637279 0.11842685419499659 0.005083970259875059
0.027403234156555812 0.11841703225457292 0.005081596318632364
0.027399226121668185 0.11840854507832715 0.0050741443410515785
0.02739484046878285 0.11839821473265791 0.005068492144346237
0.02739063213050494 0.1183884243475945 0.005068215075880289
0.027386868650829406 0.11838047216031068 0.005071868188679218
0.027383037957615528 0.11837234259382863 0.005077814683318138
0.027378517563065304 0.11836148660059585 0.005082050338387489
0.027374553691033317 0.11835308529261677 0.005081597715616226
0.027370540391433055 0.11834445831051273 0.005078533198684454
0.02736642599767895 0.11833531962407949 0.005076143890619278
0.02736213529126418 0.11832534435452859 0.005076447501778603
0.027358317464437128 0.11831728019201178 0.0050794221460819244
0.02735429443314512 0.11830833949897591 0.005084095988422632
0.027350245823386236 0.11829937591396404 0.0050871288403868675
0.0273457147587265 0.11828850221319628 0.005086633842438459
0.027341987796793164 0.11828108187668346 0.005084379576146603
0.027337874118252538 0.11827200351464792 0.005082657095044851
0.027333734905882485 0.11826271157094598 0.0050825756043195724
0.027329595527048528 0.11825334087076189 0.005084384698420763
0.027325040687286056 0.11824224826832468 0.0050866431556642056
0.02732123722705159 0.11823438298728435 0.005087646655738354
0.027316654303814053 0.11822328458734206 0.005088194739073515
0.027313373966381338 0.11821769345959801 0.005087919533252716
0.027309446669442315 0.11820934028132762 0.00508721312507987
0.027304360698937883 0.11819605548739613 0.005087218247354031
0.027299894292230162 0.11818534455612686 0.005087652243673801
0.027296481353257497 0.11817908363569311 0.005088547710329294
0.027292005881896536 0.11816840725794965 0.005089771933853626
0.02728798601133573 0.11815970338850969 0.0050905728712677956
0.027283997528924703 0.11815113980628571 0.005090666934847832
0.02727925152946658 0.11813932125210862 0.00509011372923851
0.02727499450900166 0.118129507299997 0.005089460872113705
0.027271498982249648 0.11812290007614011 0.0050887963734567165
0.027267096149230445 0.11811251422192341 0.00508880615234375
0.02726324063332336 0.11810448858391254 0.005089216399937868
0.02725898127207791 0.11809476482803798 0.005089441314339638
0.027255113246591894 0.1180866561834191 0.005089459475129843
0.02725042318277676 0.11807503942643909 0.0050894697196781635
0.02724706985339523 0.11806902083870906 0.005088724661618471
0.02724196976256659 0.11805564876708306 0.005088014528155327
0.027237992720963177 0.11804704516196748 0.0050873770378530025
0.027234438884887614 0.11804025327991047 0.005086860153824091
0.027229427130517563 0.11802731995269143 0.005086961202323437
0.027224954786483322 0.11801663055984024 0.005087125115096569
0.027220949391196764 0.11800786556696993 0.005086550954729319
0.02721755288279056 0.11800165324955615 0.005085343960672617
0.027212847535140906 0.11798992637164936 0.005083940923213959
0.02720931875116899 0.11798318259672266 0.005082597956061363
0.027204669464495915 0.11797172289328105 0.005081836134195328
0.027200501282307693 0.11796227969879025 0.0050817751325666904
0.027196306774508253 0.11795270720077243 0.005081193521618843
0.02719256050369945 0.11794499037821013 0.005080041009932756
0.027188756642319907 0.11793701432720742 0.005078429356217384
0.027184014679862624 0.11792507286380001 0.0050770132802426815
0.02717965735421612 0.11791476214057955 0.005076026543974876
0.027175857433571975 0.11790681403385525 0.005075089167803526
0.02717151439114112 0.11789655447798797 0.005074082873761654
0.027167560721667254 0.11788791313051286 0.005073005799204111
0.02716332575547884 0.1178780609951248 0.005071424879133701
0.027159219885768533 0.11786874946679227 0.005069789942353964
0.02715489401746947 0.117858491299188 0.0050684185698628426
0.027151132505969254 0.11785061352983937 0.0050666965544223785
0.02714701147582015 0.11784120589877978 0.005065334029495716
0.027142896425702005 0.11783180893659956 0.005064112599939108
0.027138770020127642 0.11782234042404514 0.005062701180577278
0.0271345160092323 0.11781230205594075 0.0050610643811523914
0.027130171010011105 0.11780186595776758 0.005059417802840471
0.027127163425160822 0.11779707049813648 0.005057455040514469
0.0271229034589052 0.11778696853728542 0.005055802408605814
0.027118708417490048 0.11777712179322819 0.005054211709648371
0.027114808188692482 0.11776849116702152 0.005052739288657904
0.027110100385108027 0.11775643363664626 0.005051374435424805
0.027106837469264324 0.11775046318393206 0.005049215629696846
0.02710297432818111 0.1177419293541987 0.005047328304499388
0.027098049931265595 0.11772889005314292 0.005045562516897917
0.02709431723355267 0.11772086723817421 0.005043779034167528
0.02709042488534856 0.11771214252041426 0.005042361095547676
0.027086411023580524 0.11770288432967538 0.005040861200541258
0.027082325949056324 0.11769329349308189 0.00503910006955266
0.027078606187929295 0.11768522513251087 0.005037026014178991
0.027074533385767215 0.1176756395379554 0.005035219248384237
0.027070115744819847 0.11766457136585913 0.00503339059650898
0.027066490343030224 0.11765683002389739 0.005031940992921591
0.0270632229251405 0.11765056661295134 0.005030522588640451
0.027059044506985437 0.11764042790661461 0.005028655286878347
0.02705487190620829 0.11763027453089321 0.005026848055422306
0.027051244432193828 0.11762240290452702 0.0050249663181602955
0.027046978791317414 0.11761180296943699 0.00502372719347477
0.02704332042669192 0.11760375160488445 0.005021912511438131
0.027039884861508302 0.11759660801627997 0.005020292475819588
0.027035842471680185 0.1175868591399527 0.005018923431634903
0.027032117160236187 0.11757841755667381 0.005017314571887255
0.027028369613852462 0.11756984682781214 0.005015817936509848
0.02702475027293769 0.11756179032683509 0.0050137583166360855
0.02702027145785453 0.11755006367238349 0.005012490786612034
0.02701713721746004 0.117544004930253 0.005010940134525299
0.027013349411664847 0.11753512850818647 0.005009584128856659
0.027009830318770058 0.11752736024334129 0.005008100997656584
0.027006097098304944 0.1175186427207878 0.00500660901889205
0.02700203502655506 0.11750849991588239 0.005005127750337124
0.026998367171590584 0.11749999433006708 0.00500384159386158
0.02699495422032884 0.11749253235979167 0.005002422258257866
0.026991307997001203 0.11748404140984255 0.005001026205718517
0.02698780623532926 0.1174761152587958 0.004999833647161722
iteration: 16 | epoch: 1035 |   loss: 0.117476  |   KL divergence: 0.026988  |  JS divergence: 0.006829
('==== Found maximium gradient [0.0073293136, 0.006286761, 0.0032880413] of '
 'gate e^[Y9 Z1], e^[Y1 Z9], e^[X9 Y0] ====')
learning rate =  0.0011778704072534134
0.026984020426792158 0.11746696146959719 0.011359485797584057
0.026950084541581106 0.11745041142883626 0.016400285065174103
0.026977100828176927 0.11744533003223442 0.02732778899371624
0.026948377111601862 0.11739769726904949 0.01662283018231392
0.026929490659812587 0.11738850395749059 0.02237473987042904
0.026912335395876244 0.11735715534262293 0.017527377232909203
0.026902628885363926 0.11732831500603372 0.016135647892951965
0.02689897881814358 0.11731043006899519 0.017692629247903824
0.0268906453872423 0.11728631304895508 0.015284662134945393
0.02687915688858596 0.1172618735678906 0.013772751204669476
0.02686618613193198 0.11723983756400763 0.014202014543116093
0.0268519874155436 0.11721916508108209 0.012138010933995247
0.026837984816875902 0.11719513661778723 0.010965616442263126
0.026827331223292707 0.1171764761156602 0.013161391951143742
0.02681706691692982 0.11715485739132175 0.01362064853310585
0.02680825239759954 0.11713424048536679 0.010778923518955708
0.026801342767099855 0.11711316921283563 0.008879312314093113
0.026796572176629015 0.11709740814739637 0.010263901203870773
0.026789135555342673 0.11707679796941008 0.010619521141052246
0.026778899116748432 0.11705602502578853 0.008662822656333447
0.02676685452204943 0.1170370693164835 0.007524698041379452
0.02675375960559622 0.11701832295448289 0.00914041232317686
0.026740719057446544 0.11699856586507855 0.010252891108393669
0.026730036947808983 0.11698030281813375 0.00931583996862173
0.02672255558680627 0.11696177933715947 0.0075707146897912025
0.026718068375273248 0.11694426729598505 0.007065299898386002
0.02671323931757083 0.116923421868694 0.007706302218139172
0.02670677312693118 0.11690524060137851 0.007830082438886166
0.02669746732425944 0.11688989383404345 0.007138428743928671
0.02668477233341917 0.11687037605759908 0.006957199890166521
0.026672291869465185 0.11685178042920688 0.007626108825206757
0.026661861865994826 0.11683320148781534 0.007732721511274576
0.026654585908575966 0.11681598135083868 0.006951966788619757
0.02664834228206954 0.11679411201402738 0.006284472998231649
0.026643631375612417 0.11677764020157327 0.006331589072942734
0.026637140818281273 0.11676044341112228 0.006560515146702528
0.02662755157090029 0.11673974431930206 0.006554283667355776
0.026617297158115116 0.11672230679441792 0.006475694011896849
0.026606931540706338 0.11670375259506126 0.006455015391111374
0.026597951888548334 0.11668491932501805 0.006363027263432741
0.026591377702084106 0.11666868528846266 0.00615977868437767
0.026585357342260824 0.1166501973044819 0.00594331044703722
0.026578891098832075 0.11663071871006271 0.005871668457984924
0.026572167918731144 0.11661560311519518 0.005981431342661381
0.026562508141140445 0.11659420269714124 0.006086144596338272
0.02655332198114159 0.11657766405243052 0.006071303505450487
0.026544558168510538 0.1165606279492436 0.005922077223658562
0.026536553466475266 0.11654124106481513 0.00571542838588357
0.02653060199865309 0.11652560347850985 0.005649158731102943
0.02652439474709877 0.11650744363902361 0.005695090629160404
0.026517481169052153 0.11648857197491727 0.0057007623836398125
0.026510174492654612 0.11647191998621446 0.005689017474651337
0.02650106758009849 0.11645058794205525 0.005685755517333746
0.026493287829442966 0.11643564642853996 0.005609287414699793
0.02648509713758431 0.11641724901845252 0.005463216919451952
0.026478102538173863 0.11640098997464715 0.0053881690837442875
0.02647095711031536 0.11638166539934448 0.005403602495789528
0.026464455151178914 0.11636454378060258 0.005417113658040762
0.026457768485007582 0.11634791614169078 0.005407893098890781
0.02645022281923617 0.11632949825165298 0.005375951528549194
0.026443068438032194 0.1163137638734655 0.005311835091561079
0.026435593312186336 0.11629628742218091 0.00522078899666667
0.02642841151309463 0.11627905142701497 0.005161967594176531
0.026421454710801984 0.11626209037375611 0.005168448202311993
0.026415080312289542 0.11624750897577323 0.005172856617718935
0.026407682247085982 0.11622849180537051 0.005134934093803167
0.026401401262048377 0.1162138872549715 0.005097796209156513
0.026394725188742515 0.11619711500393332 0.005074523855000734
0.0263879406884173 0.1161797259078613 0.005021446384489536
0.02638134494364161 0.11616336707076669 0.004975509364157915
iteration: 17 | epoch: 1105 |   loss: 0.116163  |   KL divergence: 0.026381  |  JS divergence: 0.006678
('==== Found maximium gradient [0.0037792197, 0.002865517, 0.00249807] of gate '
 'e^[X9 Y2], e^[X8 Y9], e^[X9 Y0] ====')
learning rate =  0.0006189673248166216
0.02637489349141743 0.1161480119755669 0.007304069586098194
0.026366428214587154 0.11613850891224484 0.015781095251441002
0.026363858148113362 0.11612377016182568 0.011660470627248287
0.02637059238792963 0.11611420594031735 0.015096723102033138
0.026366614418926328 0.11609933413122168 0.011336524039506912
0.026357629722640358 0.11608563373426575 0.009448627009987831
0.026347059286131645 0.11607395197946084 0.011765850707888603
0.02633784482047789 0.11606399074329601 0.011666353791952133
0.026331020942159666 0.11604938291702453 0.009113776497542858
0.02632851568513388 0.11603701375316702 0.0075029791332781315
0.026328840621099834 0.11602783873739363 0.008025306276977062
0.026327572224390118 0.11601389942548611 0.008464399725198746
0.026324048839160577 0.11599989487935204 0.008110428228974342
0.026318705822180183 0.1159889127968219 0.0076143634505569935
0.02631077478078995 0.11597538699964717 0.007579561322927475
0.026301629729596758 0.11596040236124981 0.007754244841635227
0.026294219403970268 0.11595038880504609 0.007708435412496328
0.026287849377014172 0.11593831307201347 0.007371575105935335
0.02628306749476879 0.11592572907843593 0.007015736773610115
0.026278978799236817 0.11591029648408788 0.00678904727101326
0.026276499310383627 0.1158983355291583 0.006660024635493755
0.026274377659104172 0.11588792420384143 0.006665298715233803
0.02627058859701789 0.11587476391379048 0.006759985815733671
0.02626547160851623 0.11586299603697857 0.006672379560768604
0.026258485579482526 0.11584897077379241 0.006364616099745035
0.026251145508763764 0.11583515000995144 0.006182865705341101
0.026245029097416894 0.11582468155539219 0.006257323548197746
0.026239481791425226 0.11581266335261421 0.006181584671139717
0.026234087666463526 0.11579641646493416 0.005828189663589001
0.02623130324259513 0.11578754908603703 0.005660724826157093
0.026227544060266436 0.11577418442902074 0.005913991946727037
0.026223201951502975 0.11576197391919159 0.006151234265416861
0.02621745089626465 0.11574858820263245 0.006088580936193466
0.026211217606457123 0.11573626392397786 0.005926323588937521
0.026204978429891453 0.11572402184874063 0.005888213403522968
0.026199395208851207 0.11571197658277299 0.005900031421333551
0.026194216960625936 0.11569782232841352 0.0058314683847129345
0.02619055301950108 0.11568725033381058 0.005715675186365843
0.026186732712975305 0.11567518702495572 0.005677000619471073
0.026182937588388543 0.11566428369889525 0.005732548423111439
0.026178189793464 0.11565144115460474 0.00573263643309474
0.02617338368690971 0.11564053754579355 0.005604633595794439
0.026168576341306447 0.11563048754646515 0.005483677610754967
0.026162457413937544 0.11561411309397819 0.0054731667041778564
0.026157996102450405 0.11560379865179997 0.005483738146722317
0.026153427532496606 0.11559211177321588 0.005465005524456501
0.026149169762650047 0.11558084338671504 0.0054783811792731285
0.026144982072649824 0.11556951776820862 0.00550753204151988
0.026140661479360495 0.11555832495795884 0.0054939440451562405
0.026136160028260233 0.1155473952823107 0.0054495250806212425
0.026130758940184795 0.11553321472743695 0.0054059638641774654
0.02612601958197362 0.11552208128451816 0.00538030406460166
0.026121838236562042 0.11551285082896211 0.005387424491345882
0.026116742858367025 0.11549844022047419 0.005400830879807472
0.02611336891718125 0.11549032416395731 0.005376361310482025
0.02610964332940442 0.11548036285450602 0.005322221200913191
0.026105689075662013 0.11546987478107276 0.005262784659862518
0.026100610050345266 0.115455433638405 0.005209134891629219
0.026096273823417702 0.11544489377939156 0.005174545105546713
0.026091768421518276 0.11543361551434905 0.005166848190128803
0.02608760376994401 0.1154234054099204 0.005184960085898638
0.026083830142933348 0.11541434425401528 0.0052074831910431385
0.026079325601239746 0.11540165597311022 0.0051964460872113705
0.02607575352398934 0.11539297738935979 0.005152404773980379
0.026071608797733407 0.1153820943404697 0.00511410366743803
0.026067512309179412 0.11537152857184438 0.005089391954243183
0.026063309558249287 0.11536067442108233 0.005072347354143858
0.02605937782147645 0.11535116896668755 0.005071335472166538
0.026055400945621858 0.11534130547272856 0.0050756013952195644
0.026050979450191275 0.11532917098503527 0.005059088580310345
0.02604738782396253 0.11532020420584349 0.005017738323658705
0.026044363849323106 0.11531330920680456 0.004970215726643801
iteration: 18 | epoch: 1177 |   loss: 0.115313  |   KL divergence: 0.026044  |  JS divergence: 0.006581
('==== Found maximium gradient [0.0022633118, 0.001997241, 0.0019355487] of '
 'gate e^[X10 Y9], e^[X9 Y2], e^[Y10 Z9] ====')
learning rate =  0.0004140515315672817
0.026039832261673116 0.11529985908637269 0.006101955194026232
0.02603439822276291 0.11529137271703664 0.010146801359951496
0.026038652757970866 0.11528331039601909 0.009298985823988914
0.026034337891541963 0.11527744797168225 0.009442199021577835
0.02603091030008929 0.1152663123638997 0.008134962059557438
0.026028574949995262 0.11525865843714125 0.007691350765526295
0.026025436435244905 0.11525017060518551 0.008740972727537155
0.026019842238088262 0.11523943714315694 0.008125029504299164
0.026014791168212082 0.11523309090196918 0.006559712812304497
0.026010268185050783 0.1152233628883273 0.006388117093592882
0.026008015732490303 0.11521632978542926 0.006738794501870871
0.02600643825365467 0.11520784826213784 0.006241103634238243
0.02600499555252018 0.11519811518232366 0.005842824466526508
0.026003830506430615 0.11519243464084933 0.006300588138401508
0.026000176899021343 0.11518319621100448 0.006689323578029871
0.02599510902160436 0.11517429488237323 0.006439907476305962
0.02598982633233705 0.1151661120450418 0.006046693306416273
0.025985155271839352 0.11515689610709245 0.0059426529332995415
0.025981825715489345 0.11514756102658905 0.005863255355507135
0.025979862270320515 0.1151395276999162 0.0056640082038939
0.02597815607192313 0.11513138586407151 0.005578556098043919
0.025976263908739267 0.11512501245684076 0.005679348483681679
0.025972723743295734 0.11511593326795483 0.005758455954492092
0.025968709282719365 0.1151082600910646 0.005741978995501995
0.025964468291969474 0.11510040246554053 0.005685176234692335
0.025959991228682637 0.11508980618152032 0.005561416503041983
0.02595690666710103 0.11508248511896083 0.005359409376978874
0.025954039213021432 0.11507372401788366 0.005209829192608595
0.02595173158512824 0.1150665941211873 0.005199392791837454
0.025948324991648675 0.11505589390617814 0.0052446043118834496
0.02594589208283086 0.11505140117409351 0.005279841832816601
0.025941890084473992 0.11504116162332252 0.005334851797670126
0.025938363153326524 0.11503228232541743 0.005386638920754194
0.02593547107877471 0.11502452446376843 0.005364377051591873
0.02593281499779382 0.11501681775108165 0.00528322160243988
0.025929637960468314 0.1150073582170908 0.005198314785957336
0.025927017483972005 0.11500173578693659 0.005116143263876438
0.025923778371320406 0.11499451807540864 0.005048336926847696
0.02592015526842869 0.11498558124573391 0.005032944958657026
0.025917177255984348 0.11497839692306763 0.005047634709626436
0.025913652958943198 0.11496745246683236 0.005039882380515337
0.025911662885025125 0.11496211397504363 0.0050192056223750114
0.025908845505835165 0.11495308692350673 0.005011001136153936
0.025905919826127204 0.1149445752393317 0.00498634297400713
iteration: 19 | epoch: 1221 |   loss: 0.114945  |   KL divergence: 0.025906  |  JS divergence: 0.006540
('==== Found maximium gradient [0.0025486138, 0.0021613208, 0.0021332563] of '
 'gate e^[Y1 Z2], e^[X8 Y9], e^[X1 Y0] ====')
learning rate =  0.0004577848502731473
0.025902899462799358 0.11493705918015601 0.006329820957034826
0.025892482596203754 0.11492813355698246 0.013637606054544449
0.0258948204235953 0.11491865836340986 0.008476361632347107
0.025899925500599316 0.11491076873905656 0.01259530521929264
0.025893942564656474 0.11490008110612872 0.008936954662203789
0.0258845722036708 0.11488999731065898 0.00698092533275485
0.025878193905723844 0.1148842859455362 0.009497874416410923
0.0258742325582427 0.11487610142776525 0.009163141250610352
0.02587166076896115 0.11486405913252262 0.006887027528136969
0.025871545542265846 0.11485650029202775 0.00642795953899622
0.025870404517218032 0.11484617963943905 0.007453327067196369
0.025868741568274064 0.11484058790639193 0.007327035069465637
0.0258643385759599 0.11482972879696476 0.00614053662866354
0.025860190354090186 0.114822247132694 0.005751363467425108
0.025855695887366685 0.11481312325804635 0.0066667054779827595
0.02585131484869737 0.11480393635132527 0.007210868876427412
0.025847819396220204 0.11479663603858425 0.006612182129174471
0.025844617106527377 0.11478690509505915 0.005671344697475433
0.025842406697847674 0.11477808135167768 0.005573994014412165
0.025840565499393148 0.11477057793874557 0.005945506040006876
0.02583819011433971 0.11476375051979915 0.0058160200715065
0.02583487882588834 0.1147559958907221 0.005359101574867964
0.02583045293210616 0.11474434112466313 0.005303545854985714
0.025827289664908038 0.11473760456506864 0.005650822538882494
0.02582388382720492 0.11472850695568584 0.0058062318712472916
0.02582145834343562 0.11472157650719951 0.005587947089225054
0.025818730555708942 0.11471164382515958 0.005279012490063906
0.025816382489767923 0.11470365797918516 0.005214635282754898
0.025813568024031633 0.11469542774283548 0.005295004695653915
0.02581031795690745 0.11468703958098801 0.0052333613857626915
0.025806651787504208 0.11467795540437344 0.005081201437860727
0.025803477208992516 0.11467159274918666 0.005101724527776241
0.0257999267703171 0.1146630410615099 0.005211072973906994
0.025796758969551244 0.11465392977831022 0.005145767703652382
0.02579476025253772 0.11464741268571628 0.004939445294439793
iteration: 20 | epoch: 1256 |   loss: 0.114647  |   KL divergence: 0.025795  |  JS divergence: 0.006507
('==== Found maximium gradient [0.0025481565, 0.0020061245, 0.0017285424] of '
 'gate e^[Y1 Z3], e^[Y8 Z9], e^[X1 Y0] ====')
learning rate =  0.000424350409629752
0.025791998433043174 0.11463672569358992 0.006068396382033825
0.02579838434765114 0.1146342319256903 0.011798937804996967
0.025776603130756068 0.11462006450763 0.009584642015397549
0.025770635427649846 0.1146116130899264 0.01051254477351904
0.025770482309659237 0.11460008167200134 0.010170161724090576
0.025770575815290818 0.11459125215183763 0.008254261687397957
0.025768672711204976 0.11457971075908213 0.006967410445213318
0.025765257264718372 0.11456945522022338 0.0073718419298529625
0.02576082399547428 0.11456248463193017 0.0077395448461174965
0.025755098455407837 0.1145537182861679 0.007307557389140129
0.025748999740048014 0.11454193710535589 0.006538664922118187
0.025744811013430915 0.1145341690813304 0.006610210053622723
0.0257415269727607 0.11452591431636736 0.007239168975502253
0.025738321616391155 0.11451548068636637 0.007314841262996197
0.02573567147834076 0.11450715318444232 0.006599395535886288
0.02573207341029737 0.11449537371846782 0.005804914981126785
0.025728835964061746 0.11448601224864756 0.00565230380743742
0.025725830518929547 0.11447894131540994 0.005883160978555679
0.02572209017532212 0.11447074270855562 0.005953526124358177
0.025717184827657287 0.11445955217935734 0.005783691070973873
0.025712892090526136 0.11445158223811805 0.005724220536649227
0.025708866442285858 0.1144435605450407 0.005852927453815937
0.02570522022406818 0.11443540948095489 0.005960828624665737
0.02570143244842301 0.11442525851702946 0.0058719622902572155
0.025698105049624064 0.1144161887118996 0.005648251157253981
0.025694898524660812 0.11440702117895975 0.005405515898019075
0.025692237880205922 0.1144000139942934 0.005279742646962404
0.025688687734358454 0.1143894098216565 0.005282148718833923
0.02568510986194593 0.11437947465284656 0.005372707732021809
0.02568200772569718 0.11437299527608018 0.0054484158754348755
0.025677423328238913 0.11436163368236849 0.005463751498609781
0.025673599335028302 0.11435423592304965 0.005415845662355423
0.02566994747596757 0.11434683418246382 0.005363669712096453
0.025666158914516277 0.11433750066773642 0.005331825464963913
0.025662658494908314 0.11432852000951564 0.005261336453258991
0.025659303225518737 0.11431976740378884 0.005132907070219517
0.025656048089248238 0.11431117465324568 0.00503514101728797
0.025652886841074467 0.11430292715843023 0.0050659445114433765
0.025649341682787784 0.11429330600388789 0.005140737164765596
0.0256458448477682 0.11428442531067207 0.005131055135279894
0.025642156689221908 0.11427523932345948 0.005070731975138187
0.025638625432035534 0.11426688019620679 0.0050694504752755165
0.025635016260594 0.11425768718272576 0.005104593466967344
0.025631583164138907 0.11424859000505662 0.005094527266919613
0.025628253799280847 0.1142398377710107 0.005052582360804081
0.02562569740238403 0.11423487799861597 0.005028597079217434
0.025621874622604637 0.1142247342531359 0.005009895656257868
0.02561856136892772 0.1142167829692348 0.0049669332802295685
iteration: 21 | epoch: 1304 |   loss: 0.114217  |   KL divergence: 0.025619  |  JS divergence: 0.006458
('==== Found maximium gradient [0.0020296043, 0.0019937146, 0.001924514] of '
 'gate e^[Y1 Z9], e^[X3 Y1], e^[X8 Y1] ====')
learning rate =  0.0003966181360532779
0.025615334852790196 0.11420903034058384 0.006001332774758339
0.025618258514244686 0.11420021544493064 0.010489785112440586
0.02560134129379397 0.11418887846924029 0.010819628834724426
0.025595947566698547 0.11417950337963251 0.010792835615575314
0.025595935819908974 0.11417173172868268 0.008257361128926277
0.02559666751773522 0.11416198454365357 0.006837686989456415
0.025596456532443045 0.11415569376177286 0.00813447218388319
0.025592308556109493 0.11414629224005422 0.0076608723029494286
0.02558586806397023 0.1141355688081731 0.00686561269685626
0.025580550008110887 0.11413026589308894 0.006529676262289286
0.02557428104864475 0.1141169859482656 0.006719023920595646
0.025570388248204484 0.11410888591051212 0.0070948819629848
0.025567387083177878 0.11410085650468205 0.006770099978893995
0.025565081706574268 0.11409397050498403 0.006329972762614489
0.025561781197908348 0.11408264328241217 0.006138392724096775
0.025559008293139698 0.11407470628291133 0.005929999053478241
0.025555303600954156 0.11406408895011005 0.005949833896011114
0.025552161318011038 0.11405747462518538 0.005926191806793213
0.025548204047085576 0.11404883860002907 0.0057224552147090435
0.025543977472209958 0.11404001595084898 0.005708765704184771
0.025539015639151993 0.11402805797036153 0.005761243868619204
0.025535443525666217 0.1140214047179477 0.005741108674556017
0.025531497141006592 0.11401202558418842 0.005763935390859842
0.025528057184118186 0.11400393877357261 0.005670951213687658
0.02552470901584508 0.11399542577551632 0.00551595026627183
0.025521208450864287 0.11398534987413368 0.005485265050083399
0.025517264001793164 0.11397285174919931 0.005475187208503485
0.02551510012059302 0.11396881512166541 0.00545235350728035
0.02551089147510284 0.1139577518791241 0.005405591335147619
0.02550605328133719 0.11394594239630003 0.00534709682688117
0.02550176805257439 0.1139372427870718 0.005411743186414242
0.025497326078905275 0.11392685822692974 0.005457868333905935
0.02549450851622876 0.11392168398536263 0.005370588973164558
0.025491177552746908 0.11391271695320805 0.005294419825077057
0.025487487878924027 0.11390172487797508 0.005266324616968632
0.02548424708254405 0.11389316229911799 0.0052667176350951195
0.025480797421258264 0.11388459488435755 0.00526181235909462
0.02547754451626632 0.11387782192531096 0.005228134803473949
0.025473053995612442 0.11386618989469388 0.005226786248385906
0.02546966030446727 0.11385915365031112 0.005234492011368275
0.025465863292775552 0.11384941367433353 0.005212650168687105
0.02546193523788908 0.11383802089510191 0.005190934054553509
0.025459097864074097 0.11383095566069754 0.005166677758097649
0.025455286240739776 0.11382006360653013 0.005155328195542097
0.025451771168404858 0.11381130015214269 0.005159756168723106
0.025448310911656957 0.11380334284399697 0.005152090918272734
0.025445006571385223 0.11379606190531535 0.005133654456585646
0.025441276956115633 0.11378645267606524 0.005093028303235769
0.025437406725886343 0.11377560709005378 0.005060131195932627
0.02543412502596543 0.1137670039931079 0.00505330553278327
0.02543126118403815 0.11376041088104269 0.0050439233891665936
0.025427416973063825 0.11374996209956222 0.005037561058998108
0.025423760976294982 0.11374057234589126 0.00504152150824666
0.025419856297257036 0.11372994488512644 0.005047223996371031
0.025417195744180183 0.113724510527863 0.00502708088606596
0.02541357583561838 0.11371479214572412 0.004980307072401047
iteration: 22 | epoch: 1360 |   loss: 0.113715  |   KL divergence: 0.025414  |  JS divergence: 0.006402
('==== Found maximium gradient [0.0027091594, 0.0023978336, 0.0023496833] of '
 'gate e^[Y10 Z0], e^[Y0 Z10], e^[Y2 Z3] ====')
learning rate =  0.0004981320342756409
0.02541018678723779 0.11370611134023832 0.006563536822795868
0.025404362811121062 0.11369424435085927 0.012376104481518269
0.025400952062626894 0.11368213921299661 0.012959479354321957
0.025397123179918123 0.1136683080785068 0.010770702734589577
0.025387978200568276 0.11365328728152678 0.0077808271162211895
0.025381856508687562 0.11364627595457732 0.010167562402784824
0.025377617577311485 0.11363306164379977 0.009054894559085369
0.025375473476671063 0.11361959381833156 0.0062776426784694195
0.025374960365950595 0.11361087452256746 0.007483357563614845
0.025371630014253313 0.11360097614424226 0.008383801206946373
0.025365150927889015 0.11359070291871941 0.006652183830738068
0.02535721325064325 0.11357658735574486 0.005948351696133614
0.025352255958123453 0.11356804996546331 0.007355746813118458
0.025348135182304252 0.11355499089389207 0.007146467454731464
0.025346044856247398 0.11354682030278034 0.005595169961452484
0.025342736235660652 0.11353369461378972 0.005523875821381807
0.02533947459383891 0.11352493061441235 0.006331226322799921
0.025334923848417044 0.11351527180653398 0.005983978509902954
0.025329457985111686 0.11350277192211282 0.00524756358936429
0.025325409064711753 0.1134941969361413 0.005536303855478764
0.025321673868469056 0.11348462726214877 0.005987612530589104
0.025317665036099356 0.11347319305614635 0.0057378364726901054
0.025312869933365647 0.11345876693909775 0.005249110050499439
0.025310126982351144 0.11345341502533565 0.0051438831724226475
0.0253060571979776 0.11344158854085416 0.005253722425550222
0.02530232479582431 0.11343092431372301 0.005180929321795702
0.025298893117692303 0.11342225318101781 0.005058050621300936
0.025294724150377874 0.11341157831546103 0.005172012373805046
0.025289532963441212 0.11339743374960946 0.005301456432789564
0.025285896851043467 0.11338997439421944 0.005157757084816694
0.02528195056736382 0.11337949655448173 0.004929327871650457
iteration: 23 | epoch: 1391 |   loss: 0.113379  |   KL divergence: 0.025282  |  JS divergence: 0.006365
('==== Found maximium gradient [0.0021521947, 0.0018016805, 0.0016558839] of '
 'gate e^[Y1 Z8], e^[Y2 Z3], e^[Y9 Z2] ====')
learning rate =  0.0003762967842736308
0.025278775384406926 0.11337012785963367 0.005867329426109791
0.025286580062626914 0.11336737175488258 0.014675830490887165
0.025272244478083027 0.11334988980368327 0.008015747182071209
0.025272692411792575 0.11334688448341834 0.011428123340010643
0.02526894009595221 0.11333564192651634 0.009736591950058937
0.02526678162302748 0.11332796379930901 0.008341708220541477
0.025265997080813826 0.11332037778187558 0.00785801187157631
0.02526527578872302 0.1133142528194343 0.007968497462570667
0.025261905236487994 0.11330322399709275 0.007976879365742207
0.02525798986871624 0.11329710751391064 0.0069281188771128654
0.025252760374977323 0.11328764658232092 0.006102611776441336
0.025249015825259902 0.11328048100008062 0.006723746191710234
0.02524648602834543 0.11327146777777149 0.007104962132871151
0.025245038651531746 0.11326234089059338 0.006509323138743639
0.025244449154151458 0.11325742589886993 0.006012176163494587
0.025241722194535448 0.11324823968534603 0.006011941935867071
0.025238415193740135 0.1132418056756902 0.005876912269741297
0.02523433792813578 0.113233514010199 0.005644817836582661
0.025230588619784874 0.1132245019062201 0.00561837712302804
0.025228223873007674 0.11321880252495245 0.005577674135565758
0.02522514815247988 0.11320893140370132 0.005420169793069363
0.025223162427958662 0.11320437951797507 0.0053526307456195354
0.025219952577177514 0.11319483949374143 0.005336211994290352
0.025216884633389426 0.11318501501035834 0.005173052195459604
0.025215455580015443 0.11318079506755319 0.005047996062785387
0.025212475549482888 0.11316953946097734 0.0051599349826574326
0.025209901681714896 0.11316241507167182 0.005173717625439167
0.025207121215875282 0.11315745696077027 0.0049179792404174805
iteration: 24 | epoch: 1419 |   loss: 0.113157  |   KL divergence: 0.025207  |  JS divergence: 0.006341
('==== Found maximium gradient [0.002097183, 0.0016799265, 0.0015887439] of '
 'gate e^[Y0 Z1], e^[Y8 Z0], e^[Y0 Z9] ====')
learning rate =  0.0003604522365369009
0.025203353206293865 0.1131492595851897 0.00566026009619236
0.025207584376482257 0.11314250920185077 0.010090302675962448
0.025198059872916442 0.113136561527775 0.012087088078260422
0.025190049355269188 0.11312729310044757 0.008623212575912476
0.025187532845093015 0.11311916528533987 0.008425924926996231
0.02518720819940297 0.11311206616260756 0.008799273520708084
0.02518610922867324 0.1131041344516057 0.007450832054018974
0.025184118769899354 0.11309654568768654 0.006949994713068008
0.025182132698233797 0.11309114926138843 0.007244030945003033
0.025179466064923307 0.11308420742888632 0.007156109903007746
0.025176003740364855 0.11307605702420026 0.006870317738503218
0.025171518018073158 0.11306637632503042 0.006563536357134581
0.02516742379855093 0.11306071633429025 0.006186333950608969
0.025162733833831333 0.11305197242241702 0.005940352100878954
0.025159915082439054 0.11304760637372792 0.005896310321986675
0.025157195992191708 0.11303878954600532 0.005857669748365879
0.025155100367832882 0.11302995830363176 0.005825632717460394
0.025152537491475502 0.11301956070373667 0.005745315458625555
0.025150692851623614 0.11301536102054686 0.005616826470941305
0.025146791569318303 0.11300561162013319 0.0056080943904817104
0.025143066404080372 0.11299844401391056 0.005594195332378149
0.02513904875622615 0.11298953238620127 0.005314562004059553
0.025135589201514923 0.11298125316673287 0.005098750349134207
0.02513332916765039 0.1129767134247727 0.005315725225955248
0.025130190387911394 0.11296821761997715 0.005482248496264219
0.025126905485838867 0.11295987199273219 0.005228893365710974
0.025123533461531233 0.11295147433655232 0.004985963460057974
iteration: 25 | epoch: 1446 |   loss: 0.112951  |   KL divergence: 0.025124  |  JS divergence: 0.006318
('==== Found maximium gradient [0.0015266122, 0.0013655147, 0.001316602] of '
 'gate e^[X1 Y2], e^[Y0 Z1], e^[Y8 Z0] ====')
learning rate =  0.0002811551340346459
0.025120755275303098 0.11294516272120848 0.005646985024213791
0.025120293205053556 0.11293785168083696 0.010385842062532902
0.0251139180212555 0.11293011425360336 0.007141734939068556
0.025111635184723625 0.1129267011406402 0.007885390892624855
0.02510946180882706 0.11291485833213737 0.007348423358052969
0.025109495298276004 0.11291154850510486 0.007343397941440344
0.025107632516935312 0.1129051720488656 0.007111807819455862
0.02510359237040572 0.11289631744098377 0.0066660623997449875
0.02509917694178865 0.11289124545698828 0.0064519187435507774
0.025094390053376315 0.11288434293585854 0.0061694481410086155
0.025091312533248755 0.1128792338570325 0.005894968286156654
0.025088890469845068 0.1128700229604184 0.005888143554329872
0.02508747754836382 0.11286090759491714 0.005877950228750706
0.02508697608724154 0.11285552234106423 0.005741620436310768
0.025085692791217994 0.11285001267288454 0.005761678330600262
0.0250822854601724 0.11284064455135465 0.005886676721274853
0.025078696210436822 0.11283542139063558 0.005777033045887947
0.02507439994952048 0.11282865265349727 0.005464673042297363
0.02507086902120969 0.11282312963837841 0.005237219389528036
0.025068121257133293 0.11281725221553307 0.005291484761983156
0.025065073002094276 0.11280713028253234 0.005527770612388849
0.025063430135489746 0.1128024449050801 0.005623070057481527
0.02506131968805815 0.11279658124507635 0.005444083362817764
0.025057962282094955 0.11278652742933036 0.0052425148896873
0.025055095097818482 0.11277938716314892 0.005260024219751358
0.02505296936699327 0.11277544744350299 0.005327911581844091
0.025049604457816572 0.1127655491168702 0.005255462136119604
0.025047478477600506 0.11276092299141707 0.005152957513928413
0.02504461036894443 0.1127535214243248 0.005162685178220272
0.02504158301816714 0.1127464010310564 0.00521641131490469
0.02503846474578771 0.1127396697930616 0.005212280433624983
0.025035977966946628 0.11273567167993218 0.00517633743584156
0.025032688420689432 0.11272714204192019 0.005175099708139896
0.025029704222470084 0.11271852698482888 0.005191289819777012
0.025027025882596234 0.1127101875006721 0.0051671178080141544
0.025025552756328923 0.11270705673992662 0.005112019367516041
0.025022705586889057 0.11269873786727683 0.005081020761281252
0.02502000559958701 0.11269236246262544 0.005079020746052265
0.025017270316310666 0.1126867132870936 0.0050695426762104034
0.02501451992289022 0.1126809212052121 0.005044125020503998
0.02501104319973716 0.1126710446364225 0.00502520427107811
0.025008357156174957 0.11266364700852828 0.005026631988584995
0.025006501076693187 0.11265945750129948 0.005032221786677837
0.025004227611936228 0.11265368425752784 0.005022134631872177
0.025001895358614218 0.1126482873520643 0.005001169629395008
0.024998406723204268 0.1126382592603151 0.004987954627722502
iteration: 26 | epoch: 1492 |   loss: 0.112638  |   KL divergence: 0.024998  |  JS divergence: 0.006283
('==== Found maximium gradient [0.0016538638, 0.0013501017, 0.0012554557] of '
 'gate e^[Y0 Z9], e^[Y8 Z1], e^[X0 Y1] ====')
learning rate =  0.0002859885402792918
0.02499574270939296 0.11263183825651306 0.005566751584410667
0.024994067074929724 0.11262576659902301 0.007569623179733753
0.024987705902482872 0.11261895580487301 0.007759456522762775
0.024987689427046204 0.1126104993778354 0.006694018375128508
0.02498655758857301 0.11260480846329157 0.005818238947540522
0.024983633561303772 0.11259903659423574 0.006042778957635164
0.024979013810335935 0.11258970534839234 0.005731737241148949
0.02497493846272339 0.11258117143643803 0.005604020319879055
0.024972358350249146 0.11257482576499647 0.005596593953669071
0.024970217290533697 0.11256738525890332 0.005362074356526136
0.024968583377609963 0.11256301646724638 0.00532902218401432
0.024964833851779576 0.1125530764414605 0.005403878167271614
0.024961040066128364 0.11254632084234162 0.005210658069700003
0.02495683996487536 0.11253812909346458 0.005073722451925278
0.024953831858376463 0.11253230162366107 0.0051142447628080845
0.02495080308079274 0.11252232614932285 0.005053775850683451
0.02494948434276987 0.11251741933863817 0.0049705225974321365
iteration: 27 | epoch: 1509 |   loss: 0.112517  |   KL divergence: 0.024949  |  JS divergence: 0.006269
('==== Found maximium gradient [0.0014629907, 0.0010939264, 0.0009984034] of '
 'gate e^[Y9 Z0], e^[X9 Y0], e^[X1 Y3] ====')
learning rate =  0.00024038375902349157
0.024947933064721484 0.11251171856898882 0.005378209054470062
0.02494659959779251 0.11250723958919423 0.009592566639184952
0.024942959877030838 0.11249794321741576 0.007727218791842461
0.02493818338313722 0.11249274675234196 0.007529253605753183
0.024936112246127587 0.11248949646046194 0.006451289169490337
0.024934605081656062 0.11248136486137773 0.007081762887537479
0.02493390069783343 0.11247661585776754 0.006556824315339327
0.02493231885218656 0.1124715111706212 0.005684073083102703
0.02492901788621386 0.11246318150404663 0.005761748645454645
0.024926060271826853 0.11245935571254198 0.005911630112677813
0.024923028051697237 0.11245556031356475 0.005564446095377207
0.024919804148664317 0.11244828507619892 0.005453319288790226
0.02491750464846374 0.11244148321216237 0.005680600646883249
0.024916669970035457 0.11243905228745263 0.005651987157762051
0.024914097839384322 0.11242887053754866 0.0054252552799880505
0.024912741781266366 0.11242540960741827 0.00532354973256588
0.024909808036116116 0.11241676740821112 0.005293979309499264
0.02490741846429813 0.11241185409600792 0.005189497489482164
0.024903786283048 0.11240157414537119 0.005119632463902235
0.024901238298902048 0.11239536902760362 0.005167065653949976
0.024899002091554198 0.11238979271077511 0.005229506641626358
0.024897088951792073 0.11238514007645127 0.005231141112744808
0.024895528410120715 0.1123818625552619 0.005184834823012352
0.024893572309716137 0.11237696156823437 0.005109145771712065
0.024890209121550752 0.11236616919589641 0.005019270349293947
0.024887775936242404 0.11235964021372495 0.0049722688272595406
iteration: 28 | epoch: 1535 |   loss: 0.112360  |   KL divergence: 0.024888  |  JS divergence: 0.006252
('==== Found maximium gradient [0.0013233232, 0.0011948271, 0.0011757195] of '
 'gate e^[Y1 Z8], e^[X9 Y10], e^[Y9 Z0] ====')
learning rate =  0.000246606634130452
0.02488549974080412 0.11235342212377382 0.005432534031569958
0.024886180535034476 0.11234760475848361 0.008378826081752777
0.024884420863187002 0.11234268935753554 0.007094284985214472
0.024876890130769647 0.11233533588196544 0.00729405740275979
0.024874895880877886 0.11233130206757057 0.0068483115173876286
0.024872867712656847 0.11231995386043533 0.005991317331790924
0.024872810776416898 0.1123157015527342 0.006206979975104332
0.024871554745080432 0.1123073099358691 0.006289289798587561
0.02487127906512782 0.11230643799414064 0.0061505744233727455
0.024867830596211983 0.11229612142377622 0.005848877597600222
0.024864278980675867 0.11228933781436304 0.005564842373132706
0.024860983304420173 0.11228505518198266 0.005567668471485376
0.02485687394387748 0.11227548600301025 0.00559197086840868
0.02485456736265316 0.11227087276664384 0.0055150799453258514
0.024852495189004183 0.11226477800434682 0.005390006583184004
0.024850424725182993 0.11225727274817772 0.005234892945736647
0.024848420677239205 0.11224965210030874 0.005285960156470537
0.024846923004998946 0.11224457423576151 0.005467087030410767
0.02484483778068478 0.11223773792392153 0.005414071958512068
0.024842436095829507 0.11223076177144123 0.005263098981231451
0.024840474402266957 0.11222725986181124 0.005263409577310085
0.02483734098021652 0.11221989586596133 0.0052986303344368935
0.024834060966460257 0.11221221840100204 0.00526785384863615
0.024830966951924112 0.11220445418139226 0.005177860148251057
0.02482862794130516 0.1121984125624779 0.005058834794908762
0.02482633702534687 0.11219107642542306 0.004999860189855099
iteration: 29 | epoch: 1561 |   loss: 0.112191  |   KL divergence: 0.024826  |  JS divergence: 0.006233
('==== Found maximium gradient [0.0011614644, 0.0011324013, 0.00103809] of '
 'gate e^[Y0 Z9], e^[Y1 Z0], e^[X1 Y0] ====')
learning rate =  0.00022237994516554344
0.02482483195807581 0.11218643906275341 0.005366715136915445
0.024825373417642245 0.11217754818770594 0.007667898666113615
0.024816896380854 0.11217384645208567 0.008525166660547256
0.024814119262546938 0.11216641036951423 0.006572582758963108
0.024814252254393813 0.11216269995095787 0.006902053486555815
0.024813144853665217 0.11215620869319713 0.006774274166673422
0.02480945735735965 0.1121450338731844 0.00605076365172863
0.024807250684245455 0.11214242315496527 0.005782672669738531
0.02480557812004036 0.11214005739823663 0.006160813383758068
0.024803342840237195 0.11213304886318486 0.006199310999363661
0.0248006319566108 0.11212351214137602 0.00584842124953866
0.024799106559998004 0.11212065405996462 0.005650742910802364
0.024795851208499885 0.11211231403796756 0.005507775582373142
0.024792709752921922 0.11210633238163512 0.005392806138843298
0.02479069415307918 0.11210587375302956 0.005404973402619362
0.024786220493565825 0.11209307581349189 0.005333297420293093
0.02478379555326756 0.11208642941532124 0.00517043424770236
0.0247823025474252 0.11208101242346868 0.005204563029110432
0.024781166089001522 0.11207596090459072 0.0053552123717963696
0.024779982483914848 0.1120717139565091 0.005364678334444761
0.024777710296119436 0.11206501897650742 0.005270897410809994
0.024774736304449856 0.11205762177485322 0.005211524199694395
0.024771565552470412 0.11205071501803564 0.005167393013834953
0.024769544822062575 0.11204882006135836 0.005079002119600773
0.02476595090077035 0.11203870251248056 0.005008800886571407
0.024763797115675952 0.11203334791864775 0.005019144155085087
0.02476143157871278 0.11202573954946579 0.005052986554801464
0.024759714039788175 0.11202048162084562 0.005044673569500446
0.024757263289540067 0.11201232724895448 0.005033421330153942
0.024755440757626625 0.11200790224024876 0.005068738013505936
0.024752608138121537 0.11199992399336 0.005094165913760662
0.02475026816338713 0.11199456477986246 0.0050422558560967445
0.02474787629549028 0.1119888158077465 0.004961064551025629
iteration: 30 | epoch: 1594 |   loss: 0.111989  |   KL divergence: 0.024748  |  JS divergence: 0.006211
('==== Found maximium gradient [0.0012081359, 0.00092721154, 0.00087642774] of '
 'gate e^[Y9 Z0], e^[X1 Y2], e^[X1 Y3] ====')
learning rate =  0.00020289370767202398
0.024746608459555876 0.11198771194077663 0.005232281517237425
0.024744310876521944 0.11197485546224763 0.0071921395137906075
0.024738037700835602 0.11197261358988865 0.00800028070807457
0.024737455038380998 0.11196818370911135 0.00687172869220376
0.02473654212322384 0.1119612621418142 0.006181028205901384
0.024734106883676107 0.11195676509035483 0.006237454246729612
0.02473228184467406 0.1119494464673393 0.006189207546412945
0.024731282077950844 0.11194640637165347 0.005786272697150707
0.024727913359071294 0.11193875845849709 0.005715291015803814
0.02472450875167629 0.1119345271834595 0.0059284185990691185
0.024721023870169678 0.11192705280864136 0.005933772772550583
0.024719431846422838 0.11192180543429933 0.005704570561647415
0.024718679636530856 0.11191731381605129 0.005734384059906006
0.024717059744174607 0.11191160542114875 0.005857354961335659
0.024714429507756763 0.11190591168134165 0.005676368251442909
0.024711238166940555 0.11189934830346025 0.005398306995630264
0.024708099214501247 0.11189122851743406 0.005343115422874689
0.024706607456638774 0.11188800212116244 0.00542046083137393
0.024704431963307794 0.11188106906551967 0.005408985074609518
0.024702098039055043 0.11187436682682286 0.005385397467762232
0.024700363353978422 0.11187149847032682 0.005467812065035105
0.024697633592528433 0.11186471319846451 0.005566542502492666
0.024694692219580226 0.11185692660890555 0.005557578057050705
0.024692155567731106 0.11185055847645 0.00543560367077589
0.024690467065951058 0.11184709085505373 0.005358127411454916
0.024688156076898123 0.11183974419578982 0.0053780036978423595
0.024686499061374406 0.11183494838939936 0.005365883931517601
0.024684178146116564 0.11182821345983036 0.005310956854373217
0.024681889191276635 0.111823257175341 0.005288973916321993
0.02467923549181201 0.11181728097103419 0.005307485349476337
0.024676680444111764 0.11181066555856568 0.0053002252243459225
0.02467468596241184 0.11180504813482314 0.005264854524284601
0.024672249428740793 0.11179713729600872 0.005263113882392645
0.024670267958856937 0.11179217114189621 0.005285228136926889
0.024667902640936712 0.11178628223776055 0.005306823179125786
0.024665915959356903 0.11178190443946599 0.005314638838171959
0.024663661720437623 0.11177576250117506 0.005307225976139307
0.024661443169762015 0.11176974974135748 0.005287962034344673
0.024659328969016847 0.11176465502619645 0.005249922163784504
0.024656859408748844 0.11175820338935 0.005200117360800505
0.02465386553247115 0.11174923514463195 0.005163147579878569
0.02465211937215432 0.1117456443078445 0.005163578316569328
0.024650392354314633 0.11174206245133941 0.005189049988985062
0.024648227702701198 0.11173630805010529 0.005218189675360918
0.024645573198098958 0.11172816086774853 0.005235584918409586
0.024644034500863936 0.11172529176980392 0.005236626602709293
0.02464128608323289 0.11171772505794694 0.005219791550189257
0.02463819442463549 0.11170880132648522 0.005187633913010359
0.024636968517149208 0.11170744437290914 0.005156796891242266
0.024635056230042224 0.11170227053308052 0.005140114575624466
0.024632584066578943 0.11169477937149479 0.005135346204042435
0.024629435998606508 0.11168499869014241 0.005132024176418781
0.024627633127021317 0.11168148796327407 0.005130937322974205
0.024625734303375106 0.11167720229857302 0.005137490574270487
0.024623888595287996 0.11167282995520958 0.0051464601419866085
0.02462088291051223 0.11166332582921173 0.005148675292730331
0.02461835787590048 0.11165609980060832 0.005140544846653938
0.024616947152697924 0.11165388697230302 0.0051238699816167355
0.024614586364778743 0.11164751619383569 0.005104550626128912
0.024612360224581353 0.1116417964643001 0.005087492521852255
0.024610462563577386 0.11163735894225267 0.005078312009572983
0.024608412706741682 0.11163201771454531 0.005079315043985844
0.024606317760768343 0.11162662259875175 0.005082468502223492
0.024603594379913045 0.11161873171015979 0.005081151146441698
0.024601584760116386 0.11161398146785823 0.0050766183994710445
0.024599779159418318 0.11160980345285525 0.005069826263934374
0.024597005655880105 0.11160124382938036 0.005060999188572168
0.02459490056003137 0.11159588600262635 0.005050287116318941
0.024591999354822234 0.11158705914887095 0.005039064679294825
0.024591078920402926 0.11158695641256491 0.005028971470892429
0.024587628281935232 0.1115755140929395 0.005023323930799961
0.024586429379128326 0.11157412846517721 0.005020469892770052
0.024583858944197446 0.11156656475806097 0.005018156953155994
0.02458195410049225 0.11156195489285226 0.005012648645788431
0.024579864938100993 0.11155666797360109 0.005004180129617453
0.0245777631012246 0.11155136102487088 0.0049950783140957355
iteration: 31 | epoch: 1670 |   loss: 0.111551  |   KL divergence: 0.024578  |  JS divergence: 0.006163
('==== Found maximium gradient [0.0014379025, 0.000978465, 0.00091487664] of '
 'gate RY[3], e^[Y0 Z9], e^[X9 Y2] ====')
learning rate =  0.00022692014396054718
0.024575093982566347 0.11154333210501484 0.005360709968954325
0.02457338946561246 0.11153934099323365 0.00660652806982398
0.02457259195214448 0.11153584829075404 0.008978495374321938
0.024567891382963072 0.11152612033964561 0.005803311709314585
0.024565625483181287 0.11152217345777217 0.007595747709274292
0.02456367927875543 0.1115144164614104 0.006219293922185898
0.024562710615414443 0.11151121865841448 0.006031295750290155
0.024559730441916755 0.11150440050320717 0.007056050002574921
0.024556009765185453 0.11149839206305155 0.006110545713454485
0.024552781775297332 0.11149266665780312 0.0051588877104222775
0.024550233412293357 0.11148498914682226 0.0056880442425608635
0.02454980603919111 0.11148341841763221 0.005623922683298588
0.024548552034254663 0.11147772579110539 0.005000157747417688
0.024546723236827606 0.11147137876964955 0.005088966339826584
0.0245441434646982 0.11146537903138823 0.005441082641482353
0.02454072049967953 0.11145873641383132 0.005377940833568573
0.02453769037814154 0.1114537210844824 0.005247349850833416
0.024535628202113247 0.1114498830558954 0.005117738153785467
0.02453362233874179 0.111442902705779 0.004843871109187603
iteration: 32 | epoch: 1689 |   loss: 0.111443  |   KL divergence: 0.024534  |  JS divergence: 0.006151
('==== Found maximium gradient [0.0010103793, 0.0010099863, 0.00096435635] of '
 'gate e^[X1 Y3], e^[Y9 Z1], e^[Y3 Z2] ====')
learning rate =  0.00019902836187511223
0.024531968092017017 0.11143634536341823 0.00502148550003767
0.02452854689213784 0.11143234800346756 0.008828173391520977
0.024530563296379954 0.11142850034452345 0.006815831642597914
0.02452808226361447 0.11142004052617036 0.0063663567416369915
0.024524887146978876 0.1114127331669746 0.006741351447999477
0.02452098281696009 0.11140832604746932 0.006266473326832056
0.024518785778265512 0.11140486490316616 0.005713541526347399
0.024517880371052455 0.11140045946127847 0.005570434965193272
0.024516342230574716 0.11139400818941118 0.005982734728604555
0.024513978651127488 0.11138926341021961 0.006045876070857048
0.02451004207293801 0.1113783487170274 0.005580832250416279
0.024508871438178016 0.1113762865633607 0.005063408985733986
0.024506679338695676 0.11136750739621544 0.005044739693403244
0.024505693833243764 0.111365638509139 0.005176928360015154
0.024503135272552448 0.11135931063589061 0.0051927207969129086
0.02450023029609475 0.1113526930791484 0.005144569091498852
0.02449812974977913 0.1113497386380855 0.005122433882206678
0.02449596329008734 0.11134625402117962 0.005217901896685362
0.024492979500599615 0.11133859809409632 0.00526564521715045
0.02449045674060736 0.11133107590763057 0.005215531215071678
0.02448954532184163 0.11132821054453687 0.005127416457980871
0.024487605634107228 0.11132012464540136 0.005027279257774353
0.024485948059461148 0.111315434814078 0.004894852172583342
iteration: 33 | epoch: 1712 |   loss: 0.111315  |   KL divergence: 0.024486  |  JS divergence: 0.006137
('==== Found maximium gradient [0.0011837482, 0.0009976884, 0.0008446017] of '
 'gate RY[3], e^[Y9 Z0], e^[Y8 Z1] ====')
learning rate =  0.0002036334609803522
0.024484256399931327 0.11131343442433886 0.005104075651615858
0.024481495688389913 0.111303422320234 0.00700675044208765
0.024471971355957658 0.11129785032720153 0.009065098129212856
0.024475134010483464 0.11129119488007096 0.00601013982668519
0.024476488045647442 0.11128560503983241 0.007330709602683783
0.024473912775709712 0.11127863601087014 0.0064152940176427364
0.02447059738902313 0.11127591796414289 0.005629224702715874
0.024465998674239826 0.11126882657462053 0.006422665435820818
0.024462538843030592 0.11126422557869478 0.006010270677506924
0.02446037707270496 0.11126022188872794 0.005316291470080614
0.024458401796048867 0.11125189857324155 0.005575826857239008
0.024458029374889646 0.1112486339001787 0.0055322120897471905
0.024456737489592286 0.11124327604784934 0.005223629996180534
0.024454955837929032 0.1112397439091712 0.005317938048392534
0.02445129702171988 0.11123102095032056 0.005356759298592806
0.02444819071003958 0.11122506694914461 0.005158029496669769
0.024445179746919912 0.11121722923815461 0.005108744837343693
0.024443985696242936 0.11121488719633975 0.005104265175759792
0.024442492009531858 0.1112102513985014 0.004892752040177584
iteration: 34 | epoch: 1731 |   loss: 0.111210  |   KL divergence: 0.024442  |  JS divergence: 0.006125
('==== Found maximium gradient [0.0008529514, 0.0008109409, 0.0007983982] of '
 'gate e^[Y1 Z0], e^[Y2 Z1], e^[Y1 Z3] ====')
Convergence criterion has reached, break the loop!
