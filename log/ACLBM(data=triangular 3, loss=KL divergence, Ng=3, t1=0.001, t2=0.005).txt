('==== Found maximium gradient [0.5500768, 0.5500768, 0.42502356] of gate '
 'e^[Y0 Z1], e^[Y1 Z0], CRY[1, 0] ====')
learning rate =  0.10235975670914586
0.29252454625339136 0.9420994520187378
0.15032363219670897 0.5058925151824951
0.09217772974490887 0.15234018862247467
0.10225176516233651 0.28120413422584534
0.14355004596965593 0.6489747762680054
0.15205939672415617 0.7471694946289062
0.12455098330037591 0.5270627737045288
0.09813509120330513 0.2762438654899597
0.08685319125793525 0.09254495799541473
0.08871779694137366 0.11650101840496063
0.09726763522086737 0.21904246509075165
0.1061553424684224 0.28863799571990967
0.1109692064118178 0.31925439834594727
0.10994177455774401 0.312360018491745
0.10379882440582039 0.2724197804927826
0.09520947427714382 0.20573711395263672
0.08771249164557778 0.11972685903310776
0.08419644563904638 0.024333715438842773
0.08556378916116308 0.07914918661117554
0.09015466395347231 0.1671576350927353
0.09451741708055132 0.22663116455078125
0.09564438539850895 0.24220724403858185
0.09314455973458156 0.2132127583026886
0.08905985404594649 0.15444055199623108
0.0857635380726945 0.08507125824689865
0.08444042438369331 0.02959105372428894
0.08499806585549306 0.05801280960440636
0.08661081779898104 0.10195779800415039
0.08823194096606311 0.13112987577915192
0.0889810038508414 0.1418531835079193
0.08846711130931924 0.13346731662750244
0.08696369393342056 0.10765211284160614
0.0852685808274016 0.0685754045844078
0.08423897639117706 0.024378126487135887
0.08427039657686825 0.03134627267718315
0.0850802752682627 0.06967966258525848
0.08595531114716512 0.0954265370965004
0.08626937718983968 0.10326427966356277
0.0858725971482887 0.09297626465559006
0.08508934006593621 0.068544901907444
0.08440485401506113 0.03709641844034195
0.08414196006811456 0.01600944809615612
0.0843217354577247 0.035495832562446594
0.08472069113546407 0.056078147143125534
0.08503177807625828 0.06682126969099045
0.08504300739495647 0.06626422703266144
0.0847549194982799 0.05524994805455208
0.08435986413295461 0.03636334463953972
0.08409757239668354 0.014402810484170914
0.08409241047008562 0.014910110272467136
0.0842817307472013 0.033284079283475876
0.08448444752760667 0.04544448107481003
0.08454275844201958 0.04849618673324585
0.0844251099299502 0.04244579002261162
0.08422428560135878 0.02931324578821659
0.08407323505370964 0.012587754055857658
0.08405060047374689 0.007384017575532198
0.08413804946688869 0.021200504153966904
0.08424712145471439 0.030701417475938797
0.08428847706382045 0.03378530964255333
0.08423526886590282 0.03031683899462223
0.0841326260166525 0.02147127315402031
0.08405400776638527 0.009599784389138222
0.08404256254482911 0.005337955430150032
0.08408670094270526 0.015422997996211052
0.08413922292995893 0.02230694890022278
0.08415668029226209 0.024169212207198143
0.08412724504866555 0.02096187137067318
0.08407537083363183 0.01379470620304346
0.08403974381630011 0.004882314242422581
epoch: 1 | iteration: 71 |   loss: 0.084040  |   KL divergence: 0.084040  |  JS divergence: 0.022877
('==== Found maximium gradient [0.33429632, 0.31364706, 0.20387861] of gate '
 'e^[Y0 Z2], e^[Y1 Z2], e^[Y2 Z0] ====')
learning rate =  0.05793041567466585
0.08404193709570726 0.5017250776290894
0.04885172775165249 0.4198589324951172
0.019208891651661134 0.19387860596179962
0.014386830138749546 0.1684236079454422
0.01481158173607348 0.18031619489192963
0.018649809250018162 0.24535973370075226
0.02504427236280344 0.4278862178325653
0.020188461259984303 0.286379873752594
0.01571734441061499 0.19411230087280273
0.013201645346630628 0.16977597773075104
0.01052882760745957 0.1453503668308258
0.008189985696826892 0.10737691074609756
0.007713020754128169 0.08052501082420349
0.009551517360379024 0.10505864769220352
0.012047980533887422 0.14523673057556152
0.012789091055359985 0.1602744460105896
0.011319792178950164 0.14804904162883759
0.009002749345723426 0.12421529740095139
0.007149859407991132 0.10415077209472656
0.006081309507571588 0.09266908466815948
0.005405100312274526 0.08198632299900055
0.004841448857015389 0.06552059948444366
0.004618790853550334 0.05286787450313568
0.005096077285872134 0.0688854306936264
0.006102494781823797 0.10175734758377075
0.006767429439496436 0.12131454795598984
0.0064021538969508615 0.11258674412965775
0.005370214452942004 0.08403132110834122
0.004474321101581377 0.05596474930644035
0.004038536681458148 0.04489206150174141
0.0038863682065672723 0.04691001772880554
0.0037838553520061404 0.0481615886092186
0.0037038603017516204 0.04683736711740494
0.0037400929748630735 0.04818636178970337
0.0038782212710966714 0.0531875304877758
0.0039331956972973965 0.05546952039003372
0.003748667040410234 0.04950902983546257
0.003398728205257203 0.03596800938248634
0.0031127244193436612 0.0236629880964756
0.0030238814218078295 0.02589990943670273
0.0030597935940442056 0.03420082479715347
0.003075690550571905 0.03807782009243965
0.0030168332064473375 0.03788326680660248
0.0029226120898280267 0.037578217685222626
0.0028222765125252695 0.037757597863674164
0.0026970862114122055 0.03462037071585655
0.00254818049748078 0.02607487142086029
0.002432013868417359 0.015519091859459877
0.0023976062868053816 0.014170240610837936
0.0024248234937933886 0.02169833891093731
0.0024461588751485373 0.026936931535601616
0.0024168269542527215 0.027568671852350235
0.0023416219437178854 0.02485005185008049
0.0022491391464230254 0.021010393276810646
0.002157304421729686 0.017251279205083847
0.002072888783593256 0.01324524451047182
0.0020089517008881376 0.009852513670921326
0.001979753452892168 0.011153960600495338
0.001978088765425234 0.01575649343430996
0.001972748259493822 0.018871475011110306
0.0019395177844345108 0.018781008198857307
0.0018843803871281457 0.01618763990700245
0.0018279615680129938 0.013116512447595596
0.00178165014598644 0.011018498800694942
0.001742566265555105 0.009514489211142063
0.001707325298252813 0.008501365780830383
0.0016791220944312388 0.009255481883883476
0.0016565485140153527 0.011097582057118416
0.0016304683804060976 0.01181329321116209
0.0015955090133952807 0.010464344173669815
0.0015575652741008925 0.007974980399012566
0.0015259963025956239 0.0068742502480745316
0.0015022052078027936 0.007999144494533539
0.001479649579424586 0.0090784365311265
0.0014548905283213467 0.009202612563967705
0.0014291090930969893 0.008901383727788925
0.0014028616691064894 0.008516383357346058
0.0013757179394979172 0.007639406714588404
0.001348691592322428 0.006134526338428259
0.001325357204555168 0.004965693689882755
epoch: 2 | iteration: 151 |   loss: 0.001325  |   KL divergence: 0.001325  |  JS divergence: 0.000326
('==== Found maximium gradient [0.02710364, 0.022911869, 0.020961134] of gate '
 'e^[X1 Y2], e^[X0 Y2], e^[X1 Y0] ====')
learning rate =  0.004759453873574794
0.001306014308736763 0.041538968682289124
0.001067699972815788 0.029899217188358307
0.0008855132893871593 0.02185123972594738
0.000878994214573164 0.030478104948997498
0.0008803975247180552 0.03633899614214897
0.0008196291878051175 0.03612165525555611
0.0007258662300425375 0.03258316591382027
0.0006298971440572079 0.027969537302851677
0.0005409788299227929 0.02308085560798645
0.0004657124055530209 0.018799327313899994
0.0004096868864056531 0.016780460253357887
0.0003687651253544179 0.017263442277908325
0.0003313186293367439 0.018269946798682213
0.0002871816096864481 0.017947925254702568
0.00023414583476706434 0.015765663236379623
0.00017911212393542566 0.012317651882767677
0.0001314661768273438 0.00899785477668047
9.724684688496195e-05 0.007854092866182327
7.71740461587905e-05 0.009312799200415611
6.621993046986713e-05 0.011324919760227203
5.731933958154009e-05 0.01245152112096548
4.538731476877965e-05 0.012137963436543941
2.9979239370302082e-05 0.010382105596363544
1.623096380509899e-05 0.007595081813633442
6.907060610998432e-06 0.004542814567685127
epoch: 3 | iteration: 176 |   loss: 0.000007  |   KL divergence: 0.000007  |  JS divergence: 0.000002
('==== Found maximium gradient [0.002073171, 0.0015381415, 0.00145944] of gate '
 'e^[Y0 Z1], e^[Y1 Z0], e^[Y0 Z2] ====')
learning rate =  0.0003424204623133166
4.03263093386727e-06 0.004160300828516483
epoch: 4 | iteration: 177 |   loss: 0.000004  |   KL divergence: 0.000004  |  JS divergence: 0.000001
('==== Found maximium gradient [0.0010033548, 0.0009351671, 0.0008945018] of '
 'gate RY[0], RY[2], CRY[0, 2] ====')
learning rate =  0.00018908170376475653
1.4766840645164415e-06 0.002605754416435957
epoch: 5 | iteration: 178 |   loss: 0.000001  |   KL divergence: 0.000002  |  JS divergence: 0.000000
('==== Found maximium gradient [0.00048470497, 0.00048156106, 0.00040803946] '
 'of gate RY[1], e^[X1 Y2], e^[Y0 Z1] ====')
Convergence criterion has reached, break the loop!
