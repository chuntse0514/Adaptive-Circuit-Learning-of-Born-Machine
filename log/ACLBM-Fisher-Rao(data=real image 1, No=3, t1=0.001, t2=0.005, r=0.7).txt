nohup: ignoring input
('==== Found maximium gradient [0.18926477, 0.18926477, 0.18926477] of gate '
 'RY[1], e^[X2 Y1], e^[X0 Y1] ====')
learning rate =  0.03785295635730998
0.0597238943306861 0.17714886732512347 0.44898778200149536
0.04852484063300022 0.15807379185442139 0.23459257185459137
0.04610940564895698 0.1531223066655739 0.3509112596511841
0.04496939410565379 0.15111397174168395 0.3115726113319397
0.043962103679646626 0.14975628552052414 0.19882339239120483
0.04327344516124157 0.1491672516499712 0.18548277020454407
0.04345609228479541 0.1499507926175801 0.25979578495025635
0.042989904176109456 0.14932289259392556 0.27068838477134705
0.04186222895610828 0.1472825514773924 0.21362818777561188
0.040849351283007124 0.14525492318793568 0.136093407869339
0.040552294210706025 0.1444156770642564 0.13536836206912994
0.04075032625977654 0.1445376995055342 0.18658924102783203
0.040682120481996875 0.14441430513527284 0.1998271942138672
0.04015792688854747 0.14371374416426752 0.1646258682012558
0.03954229441632292 0.1429635260254691 0.10894253849983215
0.03921332435191723 0.14268489104530824 0.0982508510351181
0.03922784499857176 0.1428580795054718 0.1364305317401886
0.03931680185224253 0.14297184525826326 0.1559995710849762
0.03927452726034088 0.14271960890543095 0.13923029601573944
0.0391452047991883 0.1422663969596802 0.10011320561170578
0.039048621284951825 0.14188475158761754 0.07811001688241959
0.03899867873696479 0.1416371805635823 0.09647712111473083
0.0388895868275036 0.14137219139298968 0.11202937364578247
0.03867675922598683 0.14104293447763314 0.10107175260782242
0.03847628663523308 0.1408541309626261 0.07069630920886993
0.038415362771672366 0.14097718428577444 0.05674950033426285
0.03846134223585431 0.14126548523915547 0.0789203867316246
0.038451627654976554 0.14135210009904456 0.09565947204828262
0.03829955167459561 0.14105805279992922 0.08792942762374878
0.03810820181766486 0.14059112951814617 0.0591488778591156
0.038047510173809626 0.14031231491681526 0.03482731431722641
0.03814650119568405 0.14033543412932503 0.05099460855126381
0.03826264404011706 0.14045139090971479 0.06811457872390747
0.03826231121696706 0.14044798823284824 0.0651814267039299
0.038160160919127856 0.14034060330759385 0.04713769629597664
0.03806185381030687 0.14028151369607098 0.037545979022979736
0.038011026731246234 0.14030171387494134 0.049789298325777054
0.03795769538663657 0.1402679253118289 0.057392995804548264
0.03787555883263384 0.14011603905043232 0.048258889466524124
0.03782321235075424 0.13996088437953325 0.028005795553326607
0.037858160201998406 0.13993647422413436 0.024408165365457535
0.03793855714537954 0.14000987848552338 0.0401320718228817
0.03796261726289271 0.14002983078693673 0.045483581721782684
0.03789844149140328 0.13994617985657423 0.036099016666412354
0.03781259027023098 0.1398526920473895 0.022007068619132042
0.037775570809439926 0.13984040976564932 0.02543574385344982
0.037778432543695686 0.1398626664765269 0.0349566787481308
0.03777673966570205 0.13983448374555799 0.03382999077439308
0.03776364604912506 0.1397573808914626 0.02251039445400238
0.03776592892794364 0.1397051008257043 0.01488974504172802
0.03778500932618758 0.13970835466712425 0.022960349917411804
0.03778408398341691 0.1397151366442395 0.027597246691584587
0.03774439779070188 0.13969134641344386 0.023158304393291473
0.03768905629739299 0.13965730413338373 0.01610621064901352
0.03765012106208095 0.1396400170962802 0.018055453896522522
0.03763391761727337 0.13962618086458697 0.0220940001308918
0.03763254556260362 0.1395965142826073 0.019400984048843384
0.03764456053891231 0.13956153866239393 0.011689748615026474
0.03766938236170905 0.13954526398426303 0.011084734462201595
0.037692303746546155 0.13954748220526755 0.017036952078342438
0.037691806437338424 0.1395413913724778 0.018057525157928467
0.037665532938378606 0.1395203551663669 0.013706088997423649
0.03762930320485363 0.13949467699356535 0.010363662615418434
0.03760166499827426 0.13947938659705753 0.012567685917019844
0.037586885375537796 0.13946453291467314 0.013376186601817608
0.037584911291395386 0.1394501201829431 0.01034563034772873
0.03759160569290037 0.1394389086034471 0.008306246250867844
0.037598770710429615 0.1394314621862539 0.010937475599348545
0.037596389808797856 0.13941955690199487 0.01215639989823103
0.037583534181678 0.13940464326816496 0.00965786725282669
0.037566730727010875 0.1393891938455159 0.006734889466315508
0.03755471732046097 0.13937741610300228 0.00809086300432682
0.03755161199025313 0.13937011366556643 0.009409490041434765
0.03755431169625395 0.13935894502656415 0.007877337746322155
0.03756015184639565 0.1393487031749352 0.005948907695710659
0.037563673022601725 0.13934032307387056 0.007084082346409559
0.037558905716086 0.13932988262252122 0.008067470975220203
0.03754619995080665 0.13932066600879822 0.0067395600490272045
0.037529725783200955 0.1393111222233906 0.005023695062845945
0.03751640406034898 0.1393026548756709 0.005704274866729975
0.03751013927978658 0.13929392675902325 0.006313716061413288
0.0375115326734669 0.13928605946647757 0.0052075511775910854
0.03751699489629653 0.13927758838240947 0.004299338441342115
iteration: 1 | epoch: 84 |   loss: 0.139278  |   KL divergence: 0.037517  |  JS divergence: 0.009605
('==== Found maximium gradient [0.12892854, 0.12810892, 0.07931094] of gate '
 'e^[Y8 Z1], e^[Y1 Z8], e^[Y8 Z0] ====')
learning rate =  0.022898235212485157
0.03752197190459546 0.1392705442926097 0.1983741819858551
0.03485225160885604 0.13426676826796802 0.11602712422609329
0.03500838679849356 0.13357499797560396 0.10582741349935532
0.03572851299753845 0.1347257850931547 0.12672176957130432
0.03589409153893614 0.13521694286635128 0.13275635242462158
0.035653176668769423 0.13494089689766942 0.13482844829559326
0.03497251869418263 0.1336655491572673 0.08444004505872726
0.03462882071074082 0.13294893800626378 0.0383586622774601
0.03474669095979577 0.13320259966530618 0.07522416114807129
0.03479055792371221 0.13347095784764193 0.08481490612030029
0.034718528335828225 0.13358507104492753 0.08223060518503189
0.034658734829314045 0.1336581398525786 0.08977196365594864
0.03451040443229583 0.13340667659470024 0.08018028736114502
0.034344242212208276 0.1329648722035094 0.045331500470638275
0.034383566920145325 0.1328363487214203 0.033878911286592484
0.03454971502018906 0.13298698522853378 0.056253839284181595
0.034611588930667354 0.13304391679859717 0.05887122079730034
0.034581280732932235 0.13301159153520886 0.05473034456372261
0.03455276841197936 0.13300082656501155 0.05956524237990379
0.03450175690036627 0.132905060937212 0.05447080731391907
0.03444337458107846 0.13274364337429556 0.03183186426758766
0.03446074992392625 0.1327197558033309 0.02568306401371956
0.034505828528722186 0.13280537450686997 0.04207896068692207
0.03446503391400199 0.13280985734021952 0.04314718768000603
0.03436650823778713 0.13275313089037705 0.0368967279791832
0.034293183236430956 0.13272384040923998 0.03860824927687645
0.03425067489570792 0.13267719437821063 0.03516390919685364
0.034244669187927415 0.13261678414406228 0.0200419332832098
0.03430012665678695 0.13262973596940048 0.020539984107017517
0.03436558459893602 0.13267968255636056 0.03174273669719696
0.034369490026365246 0.13266389558015804 0.030194595456123352
0.034336922712664496 0.13262016354712827 0.025036804378032684
0.03431505371303113 0.13259502864668968 0.026490941643714905
0.03430736226802518 0.13256616908842217 0.02197949029505253
0.03431864265213141 0.13254595302574013 0.011444146744906902
0.034349441517831134 0.13256984818498974 0.018499230965971947
0.034356294337228345 0.13259090867990053 0.024305837228894234
0.03431753008914625 0.13257059894020318 0.0200786292552948
0.03427036531741827 0.13254634267228718 0.01723998598754406
0.03424318016282559 0.13252959617605697 0.017583679407835007
0.03423964922527354 0.1325102392192568 0.011117816902697086
0.034262699285291735 0.13251138823628514 0.00934260617941618
0.034291238550792885 0.13252906401935005 0.016699325293302536
0.03429324499584524 0.13252796096885144 0.01627035066485405
0.03427500314194554 0.1325129786816527 0.012442998588085175
0.03426098132921859 0.1325020070781406 0.013047035783529282
0.034258842609499386 0.13248943661958051 0.010201549157500267
0.0342702443681428 0.13248313297866243 0.005536361131817102
0.03428626664194952 0.1324890761009966 0.011132948100566864
0.03428679418749983 0.13249214988749602 0.01243130024522543
0.03427000185144308 0.13248526630659743 0.009181099012494087
0.03425396803741816 0.1324788910165026 0.00934882927685976
0.034248521911784964 0.13247164731773725 0.008319210261106491
0.034254718580347975 0.13246570713874037 0.00448154890909791
iteration: 2 | epoch: 138 |   loss: 0.132466  |   KL divergence: 0.034255  |  JS divergence: 0.008684
('==== Found maximium gradient [0.07173404, 0.07140977, 0.06753477] of gate '
 'e^[Y10 Z0], e^[Y0 Z10], e^[Y9 Z8] ====')
learning rate =  0.014050420116869106
0.03426577100003752 0.13246645274236854 0.1219237819314003
0.033948621418952024 0.1327249639431426 0.17146530747413635
0.03286993501538234 0.1301806713873834 0.05228700861334801
0.0336351651652747 0.13109886198407322 0.11372318118810654
0.03418780706099138 0.13195002599224895 0.1470576822757721
0.03375596656697696 0.1312417592823364 0.11348109692335129
0.03315241517184871 0.13034543417173416 0.052777208387851715
0.032976235448887455 0.13027538996112448 0.05490630120038986
0.033134727256092955 0.13075229527200005 0.09606794267892838
0.03319450379495153 0.13089643071277496 0.10436676442623138
0.033044786951329896 0.1305176967315142 0.0808379054069519
0.03290117819403422 0.1300753796303664 0.0434357188642025
0.032946758562677196 0.12998231895654688 0.038764677941799164
0.03312192044124153 0.13018829149506922 0.06393782794475555
0.033229522481018195 0.13035879077703755 0.07389826327562332
0.03317379611951738 0.1303159214129758 0.06462156027555466
0.033021637952545875 0.1301534588159776 0.046606168150901794
0.03289122465657857 0.1300508108114361 0.039975814521312714
0.0328277266559433 0.13004256716275414 0.04809723049402237
0.032804673266956366 0.13004809531292538 0.05157502740621567
0.032793553414710415 0.13000335225930054 0.04390401020646095
0.032805673903459495 0.1299457605557897 0.031708814203739166
0.03285812120741161 0.12993979752134388 0.030355315655469894
0.03292970782421585 0.12997962344820446 0.03875752538442612
0.03297265322266652 0.1300026013486458 0.04215133190155029
0.0329599944384645 0.12997228169853567 0.03640303760766983
0.03290698325283886 0.12991435532012305 0.026003994047641754
0.03284994791480026 0.12987881388248168 0.022006366401910782
0.03281092030382343 0.12987760927740652 0.02688683196902275
0.0327908041860686 0.12988678461163236 0.029678694903850555
0.032785225392612805 0.12988663262303965 0.026799393817782402
0.0327923978617809 0.12987556474346068 0.021729854866862297
0.03280984696752744 0.12986241140037255 0.020164858549833298
0.032830925148388375 0.12985537461439864 0.021605508401989937
0.03284628190379053 0.12985310388015509 0.021399326622486115
0.032849512242643764 0.1298496337901493 0.019151344895362854
0.03284099444051638 0.12984794200018498 0.017851468175649643
0.0328216907789118 0.12984048626931388 0.018074428662657738
0.032797173708725355 0.12982345973912457 0.016774944961071014
0.03278010307273221 0.12981098210077954 0.013005400076508522
0.03277982062998263 0.12981565757184607 0.011193248443305492
0.032791749145172314 0.1298283999561284 0.014584074728190899
0.032803339331902305 0.12983401601035754 0.017138147726655006
0.03280483377503844 0.1298199389533986 0.01499839499592781
0.032800602494314574 0.1298001640508272 0.008702115155756474
0.032800127561509344 0.12979609258696664 0.005328011233359575
0.032803179661204815 0.1298048117573102 0.010609319433569908
0.032802522839001994 0.1298087940340871 0.013321301899850368
0.03279626534377156 0.1298026839445682 0.0112602012231946
0.03278960886379693 0.12979381523541636 0.006659292615950108
0.03278801059229082 0.1297930122134269 0.006467476021498442
0.03278890714211426 0.12979597851751293 0.009613264352083206
0.03278747817390505 0.1297952137671971 0.0099074337631464
0.03278297806802273 0.12978761194484842 0.0070893126539886
0.0327807963595277 0.12978363169826018 0.004835737403482199
iteration: 3 | epoch: 193 |   loss: 0.129784  |   KL divergence: 0.032781  |  JS divergence: 0.008331
('==== Found maximium gradient [0.069729924, 0.06587036, 0.058333464] of gate '
 'e^[Y1 Z3], e^[Y3 Z1], e^[Y10 Z9] ====')
learning rate =  0.012963517253654739
0.03278300497405431 0.1297858470610107 0.11246435344219208
0.033580436093939306 0.13096162865536545 0.18488284945487976
0.03189922368521692 0.12796975350734474 0.05032302066683769
0.0323245890743806 0.1290721850593382 0.12229223549365997
0.03280479744711852 0.1300846157552082 0.15749981999397278
0.03239243704180265 0.12922294081528501 0.11971365660429001
0.03190451342731282 0.1281309707480546 0.051950931549072266
0.03192395911465438 0.12802673747729204 0.057533007115125656
0.032243487532631995 0.1285750893151377 0.1025162786245346
0.032339278126626805 0.1287743249850335 0.11020250618457794
0.032106378343987024 0.12839901349600133 0.08417622745037079
0.031821930552970085 0.12794997060157334 0.04643280804157257
0.031731385130621466 0.12786389488273822 0.0470571368932724
0.031817170953253315 0.1280674688706417 0.07214976847171783
0.031906952320307186 0.12821167519825652 0.07969578355550766
0.03190692734939139 0.12812823039439536 0.0667613074183464
0.03186572835978886 0.12794294198440326 0.04582711681723595
0.03186103975106943 0.1278441055741438 0.042043253779411316
0.03188939642441708 0.12785773461414054 0.054511114954948425
0.03188669256472512 0.12787259135867737 0.058762334287166595
0.031824660479462266 0.12782364713707098 0.04882337152957916
0.03174265785283306 0.1277628236255563 0.03305526822805405
0.031693699247485135 0.12776240899371416 0.03244596719741821
0.03168456452054975 0.12780460040863273 0.04465343430638313
0.03168383652134385 0.1278104771289932 0.04931408166885376
0.031674434384165895 0.1277473668922304 0.041158419102430344
0.03167466314313326 0.12766764839379874 0.02511775679886341
0.03170649186002612 0.1276426510817317 0.01963443122804165
0.03175567933163277 0.1276720230717856 0.03136919438838959
0.031782994324535255 0.12770198333809335 0.038145504891872406
0.03176325123553644 0.12768380378758573 0.03418945521116257
0.03171453794656678 0.12764383449725064 0.023134440183639526
0.03166928690824518 0.12762146605470986 0.017628874629735947
0.03164404922116302 0.12762548623133915 0.024520711973309517
0.03163358288929922 0.12762955759756414 0.02901379019021988
0.031629627031266344 0.12761020065305737 0.02546260878443718
0.03163761444266343 0.12758870227358549 0.017010126262903214
0.03165911647524129 0.12758216790448956 0.014787060208618641
0.03168357714482073 0.12759169802940254 0.020840898156166077
0.03169093075659188 0.12759016805758894 0.02335079200565815
0.03167569789086188 0.12757115276983763 0.019092874601483345
0.03165109705684084 0.12755446085147792 0.011840698309242725
0.031631737363827545 0.12755325220291186 0.012305004522204399
0.03162046112034075 0.12755647397802938 0.01766701228916645
0.03161467557247282 0.12755160365344362 0.018346184864640236
0.031614042753127784 0.1275354135269534 0.01309045497328043
0.0316231453146138 0.12752466534565093 0.006851998623460531
0.03163938626713371 0.1275266364485349 0.01078001968562603
0.03165069292172263 0.12753051096593168 0.01552310585975647
0.03164635850446112 0.1275214096557289 0.01479276828467846
0.03163025312456831 0.12750753119831135 0.008841329254209995
0.03161269782707025 0.12749783083794555 0.003299592062830925
iteration: 4 | epoch: 245 |   loss: 0.127498  |   KL divergence: 0.031613  |  JS divergence: 0.008043
('==== Found maximium gradient [0.039249517, 0.03830977, 0.014313788] of gate '
 'e^[Y2 Z1], e^[Y1 Z2], e^[Y1 Z9] ====')
learning rate =  0.006545275544203791
0.03160268209911459 0.12750090127473204 0.057399094104766846
0.0319706760462612 0.12791645800209447 0.0913102775812149
0.03145494650321819 0.12712499227319096 0.026320680975914
0.03149740605169037 0.12739928559094296 0.05916452780365944
0.03160715548930884 0.1276567619171784 0.07637213915586472
0.03151743904395596 0.12741513940463925 0.05788576230406761
0.03143019312097433 0.12713154368169127 0.026622574776411057
0.031472685601990284 0.12710741609695198 0.027438389137387276
0.03157288951671722 0.12724842498852826 0.04659911245107651
0.031596379121608634 0.12730331549190116 0.05056881159543991
0.031521145477207316 0.12721523242959093 0.04052602872252464
0.03142258255789945 0.12710152129739646 0.02644859254360199
0.031371375165943044 0.12707061582024326 0.02421901933848858
0.031373603713318925 0.12711215413452803 0.03116035647690296
0.03139344795394107 0.12715034466949832 0.03399612382054329
0.03140179126054893 0.1271334694397869 0.030755402520298958
0.03140055720155765 0.1270817177952615 0.02510135993361473
0.03140341191958804 0.1270397726892942 0.021877512335777283
0.031414203521977026 0.12703031287369262 0.02154328115284443
0.031425356233233115 0.12704642308384245 0.021596310660243034
0.03142493293986377 0.12705981665811722 0.021611006930470467
0.03140981830087568 0.12705732355528013 0.021897269412875175
0.03138518834491942 0.12703554855262802 0.02126036398112774
0.03136290501780756 0.1270070325192339 0.01817328669130802
0.03135469928711073 0.12699284641137445 0.01360444724559784
0.03136129669519341 0.12699549908030405 0.012495525181293488
0.03137460583252251 0.12700918616439655 0.01605224609375
0.03137993487657541 0.1270103994436935 0.018379423767328262
0.03137239592682016 0.12699579363582514 0.016460230574011803
0.03135823753282387 0.12697708826062068 0.011179400607943535
0.03134762582775797 0.12696875375161773 0.008055418729782104
0.03134464939802395 0.1269716752811641 0.01146082766354084
0.03134596026557724 0.12697366597320298 0.01415511779487133
0.03134865831308627 0.12696926651192156 0.01288597472012043
0.03135213204187434 0.12695886666166528 0.008839765563607216
0.031357869433094515 0.12695360617139154 0.0071120792999863625
0.0313618954449569 0.1269522210196545 0.009791841730475426
0.03135907025378692 0.12695013773440084 0.01115528866648674
0.031348010521538114 0.1269433861649506 0.009318271651864052
0.03133417773910478 0.12693709784950494 0.006056696642190218
0.031323891576901436 0.12693468253182125 0.006102610379457474
0.031319580754698075 0.1269332834418965 0.008365906774997711
0.03132098596896252 0.12693124194801692 0.00872544851154089
0.03132547813535309 0.12692421696264894 0.006901474203914404
0.03133226317824828 0.12691881806849156 0.005136201158165932
0.031338554405550494 0.12691746747814733 0.005704020150005817
0.03133975952509066 0.1269148910313673 0.0065098232589662075
0.031335448157714614 0.12691355614362484 0.006018355488777161
0.03132635717446915 0.12690869285094014 0.005124203860759735
0.03131720872933691 0.12690463032300978 0.005168593022972345
0.031311483992198796 0.1269026934679844 0.005401304457336664
0.031309094558568513 0.12689700748461957 0.004797108471393585
iteration: 5 | epoch: 297 |   loss: 0.126897  |   KL divergence: 0.031309  |  JS divergence: 0.007968
('==== Found maximium gradient [0.013759362, 0.013223493, 0.007985219] of gate '
 'e^[Y0 Z9], e^[Y9 Z0], e^[Y3 Z2] ====')
learning rate =  0.002388708236389198
0.03131125887304969 0.12689450547241116 0.02107088826596737
0.03143949164023495 0.12697138356276283 0.03727439418435097
0.031313345261048724 0.12684297300613556 0.01100722886621952
0.03127201116974984 0.126877769435996 0.021594729274511337
0.03127479701707357 0.1269290743549733 0.030816683545708656
0.03126826062119235 0.12689490431404307 0.02530571073293686
0.031268538658629996 0.12684049552118304 0.012199108488857746
0.031293081184333243 0.12682672869485898 0.0048921313136816025
iteration: 6 | epoch: 305 |   loss: 0.126827  |   KL divergence: 0.031293  |  JS divergence: 0.007959
('==== Found maximium gradient [0.008743542, 0.006725815, 0.0062734135] of '
 'gate e^[X0 Y1], e^[Y8 Z1], e^[X2 Y1] ====')
learning rate =  0.0014653411426460575
0.031329103839641506 0.12684807987610097 0.02050316147506237
0.03125070716247565 0.12684548503522688 0.02204357087612152
0.031250048841784665 0.12683485865937216 0.018442900851368904
0.031264558977388064 0.1268093852217124 0.006259356625378132
0.03128995221426214 0.12680831407000473 0.012685208581387997
0.031300034416516256 0.12680949032111652 0.016182459890842438
0.03128737451886357 0.12679878031782668 0.011974595487117767
0.03126438969155197 0.12678323851455042 0.006462397053837776
0.031246602227914255 0.1267785718859997 0.009243985638022423
0.031237877500579832 0.12677703681770514 0.0120956189930439
0.031235677867619924 0.12676837958392917 0.010752396658062935
0.03123947171261749 0.12675918580893833 0.007074266672134399
0.03124580897251062 0.12674888532113504 0.006227363366633654
0.031251361253176964 0.1267423274059166 0.008530175313353539
0.031251675322948744 0.12673736967370983 0.009195467457175255
0.031244723169133994 0.12672926460121833 0.007694878615438938
0.03123297516358821 0.12671836822586624 0.006142512429505587
0.031221885569116238 0.12671108644268822 0.006611448246985674
0.03121411894634312 0.12670561706485847 0.007393686566501856
0.031209936158389975 0.12669794485784733 0.006869983859360218
0.031209024249697803 0.12668882784005556 0.005593208596110344
0.03121054978688334 0.12668204517236448 0.005242753308266401
0.031211038206481988 0.12667330700337098 0.005874821916222572
0.031209004254096548 0.12666434967395712 0.005985825322568417
0.031204337344579468 0.12665696081848465 0.0053403726778924465
0.03119771808271296 0.1266504040973985 0.0049729119054973125
iteration: 7 | epoch: 331 |   loss: 0.126650  |   KL divergence: 0.031198  |  JS divergence: 0.007937
('==== Found maximium gradient [0.00431083, 0.0036829223, 0.0033334952] of '
 'gate e^[X8 Y0], e^[X0 Y9], e^[Y0 Z1] ====')
learning rate =  0.0007594679470585113
0.031189848770375575 0.12664092533924892 0.008477915078401566
0.03119458678554488 0.12663908915246785 0.013736261986196041
0.031170762939041436 0.12662215468331864 0.00741801830008626
0.031159900550173737 0.12661982252759396 0.010926486924290657
0.031159111664507508 0.12661640926720708 0.012198974378407001
0.03116168268361231 0.1266091887817833 0.011395681649446487
0.031165306282286556 0.12660355434961487 0.011006061919033527
0.031165488355176248 0.12659568301308927 0.010927645489573479
0.03116127206274591 0.12658784996560588 0.009782865643501282
0.03115475464107964 0.12658264241623426 0.00807279534637928
0.031147469959572897 0.126575470481918 0.007359587587416172
0.03114259640402866 0.12656971018649482 0.007494277320802212
0.03114028112948218 0.12656270778779566 0.007120863068848848
0.031140677876463324 0.12655733940345498 0.006345147732645273
0.031141154162526552 0.12654888355152158 0.006293419748544693
0.031141434759321115 0.12654373346263395 0.007020880002528429
0.03113853048500128 0.1265361869877691 0.007445756811648607
0.03113261368147539 0.1265278065498955 0.007265125401318073
0.03112573576498015 0.12652250331025336 0.007132188882678747
0.031118523885460624 0.12651640702219455 0.007532175164669752
0.031112106951325522 0.12650835677063796 0.008046334609389305
0.0311083918802246 0.12650295216110227 0.008144877851009369
0.031106621947528435 0.12649742474211545 0.00785639975219965
0.03110496188249258 0.1264871772990927 0.007566699758172035
0.03110470227079834 0.12648135966273538 0.0074544381350278854
0.031103917487899247 0.12647638778472511 0.007288732100278139
0.031101281253710762 0.12646909186665248 0.006894965190440416
0.031097583457297143 0.12646201526764925 0.006471717264503241
0.03109384164425169 0.12645692744927234 0.0062797158025205135
0.031089810549346415 0.1264504306848985 0.00624031713232398
0.031086326536076212 0.1264442723479858 0.006162434350699186
0.031083028732783256 0.12643676367998766 0.006106966640800238
0.03108019991581539 0.12642995735592613 0.006224219221621752
0.031077117644784484 0.1264226276131233 0.0064494977705180645
0.03107411186768723 0.12641727837928132 0.00661685923114419
0.03107032299369652 0.12641054271311286 0.0067099230363965034
0.031066732661113254 0.12640515077301104 0.0068075694143772125
0.03106299810892053 0.12639821377085694 0.006898193620145321
0.03105996848258126 0.12639197595543777 0.006891193799674511
0.03105745542730324 0.12638560423696274 0.006775073241442442
0.031056092181878957 0.12638253963303606 0.006635631434619427
0.031053580982382756 0.12637523595499292 0.006520414259284735
0.031050810373267713 0.12636838547979792 0.0063826036639511585
0.03104750292503666 0.12636105146940568 0.006208004429936409
0.031044782776270388 0.12635675655733958 0.00607392517849803
0.031042234339279128 0.12635259302973464 0.006035614293068647
0.03103910234803883 0.1263448579257695 0.0060577127151191235
0.031036626112917364 0.1263386584130555 0.006109468173235655
0.03103466457584609 0.12633444682083067 0.006203416269272566
0.031031870703735663 0.1263280792831808 0.006321188528090715
0.031028783398269744 0.12632221772763783 0.006406344473361969
0.031025761980872167 0.1263177540820742 0.00643230089917779
0.03102230569106786 0.1263113755845918 0.006419151555746794
0.03101975953320687 0.1263070172988525 0.006381966173648834
0.031017552672194443 0.12630184621728427 0.006318805273622274
0.0310156139880126 0.1262960433040473 0.00624033622443676
0.031013616506982946 0.12628957648429082 0.006169371772557497
0.03101172635116017 0.12628445286271558 0.006109917536377907
0.03100996558210961 0.1262815213454112 0.006049355026334524
0.031006896694646333 0.12627493721716923 0.005997071508318186
0.031004373853082808 0.12627106685207795 0.005975666455924511
0.03100153021320486 0.12626540337170813 0.0059889452531933784
0.030999154908542874 0.126260418174469 0.006025490816682577
0.03099699314850029 0.12625518933291152 0.006076814141124487
0.030995355417286548 0.12625162384162636 0.006129646208137274
0.030992612203694016 0.12624409953451035 0.006160989869385958
0.030990458857076367 0.12623970955735128 0.006157931871712208
0.03098825166692036 0.12623570966700892 0.0061289421282708645
0.030986069980136477 0.1262317694072721 0.006086150649935007
0.030983617991547863 0.12622611375532838 0.00603866670280695
0.030981797372967457 0.1262221012310344 0.005993242841213942
0.030979624692769325 0.1262161908110404 0.005958394147455692
0.030977344678798722 0.12620993633653751 0.005932722706347704
0.0309757105412715 0.12620675884827806 0.005912720691412687
0.030973447935276253 0.12620168278543306 0.005903556011617184
0.030971416272410172 0.12619779010709237 0.005910573527216911
0.030968653244823188 0.12619090524592025 0.005930380430072546
0.03096681860510269 0.12618738006028235 0.005955787841230631
0.030964662970869784 0.12618234061449837 0.005978339817374945
0.030962543675368374 0.1261773840448579 0.005988191347569227
0.0309603981258506 0.12617235553941927 0.005978348199278116
0.030958694220486062 0.12616903999511242 0.0059515186585485935
0.030956325460502317 0.12616294780173012 0.005917794536799192
0.03095480533417011 0.12615998004309006 0.00588553911074996
0.030952795084202477 0.12615495957710834 0.00586025370284915
0.030950726078345564 0.12614980309594295 0.005843633785843849
0.030948697709071445 0.12614506575893858 0.005835210904479027
0.030946578979246922 0.12614024162278892 0.005830650683492422
0.030944416173709452 0.12613534233474702 0.00582924485206604
0.030942334524625876 0.12613062606546266 0.00583194475620985
0.030941079251704286 0.12612887034688755 0.005837664008140564
0.03093887685572573 0.12612311704523954 0.00584418885409832
0.03093668174383553 0.12611733603908357 0.005847003776580095
0.03093502391560626 0.1261138266372703 0.0058418926782906055
0.030932853865693645 0.1261085319615069 0.0058273919858038425
0.03093073868243676 0.12610356286380253 0.00580592779442668
0.030929089714395064 0.12610031511085423 0.005782756954431534
0.030927112124635434 0.12609551077744513 0.005763224791735411
0.030924828406022654 0.12608928388729204 0.005751145537942648
0.03092289823762699 0.12608443997554886 0.0057452828623354435
0.030921042657946596 0.12608008631842876 0.005743127781897783
0.0309196757903007 0.12607791924398742 0.005741745233535767
0.030916709629590713 0.1260695793057212 0.005740305874496698
0.030915645470339398 0.12606866792001728 0.005738029256463051
0.030913241611048532 0.1260622390421588 0.005734845995903015
0.030911298703167323 0.12605741277570504 0.005730102304369211
0.030909711656997768 0.12605389093987698 0.0057227108627557755
0.03090783693044713 0.12604931070143718 0.0057112714275717735
0.030906338009756146 0.12604635860117785 0.005697426851838827
0.030904077560162384 0.12604050557869942 0.005682865157723427
0.030902153978623167 0.12603597749359857 0.005670104641467333
0.030900367039195242 0.12603190141490217 0.005660631228238344
0.03089839120766733 0.12602698004766963 0.005654980428516865
0.03089679440650164 0.12602352456899987 0.005650906357914209
0.030894381306822455 0.1260168998164538 0.005647783167660236
0.03089239534027757 0.12601202689714097 0.005643266718834639
0.03089084988145821 0.12600891716865503 0.005637200549244881
0.03088920227044699 0.1260053547344187 0.00563020771369338
0.03088754613698013 0.12600166916023392 0.005622091703116894
0.03088558251154755 0.1259967043944604 0.0056128851138055325
0.030883640713172032 0.12599182905160297 0.0056027681566774845
0.030881615709012725 0.12598666711818074 0.005591928958892822
0.03088001581045382 0.12598323440688539 0.005581235978752375
0.030878311651536462 0.12597939087851748 0.005572451278567314
0.030876406000809875 0.12597472256758346 0.0055651175789535046
0.03087456232327857 0.12597026620355697 0.005559244193136692
0.030872556980756673 0.12596515831357596 0.005553561262786388
0.030871288465864934 0.12596296920072794 0.00554725993424654
0.030868921126363958 0.12595645411554482 0.005539859179407358
0.030866998132770457 0.12595167368696222 0.00553178833797574
0.030865502972473972 0.1259485504066678 0.005523165222257376
0.030863539598398285 0.12594354087493073 0.0055145034566521645
0.030862267066142285 0.1259412534556992 0.0055056349374353886
0.030860244111454077 0.1259360143234673 0.005496419966220856
0.030858488865166695 0.1259318517761406 0.005487640388309956
0.030856963334095763 0.12592860492958027 0.005479153245687485
0.030855095889005354 0.12592399533091625 0.005471133626997471
0.03085327095681442 0.12591952582339686 0.005464084446430206
0.03085146764915709 0.1259151132210608 0.005456964951008558
0.030849618566573533 0.12591051531544248 0.005449796561151743
0.03084803900463086 0.12590699329652186 0.005441706627607346
0.03084630161656192 0.1259028416067954 0.005432643927633762
0.030844589385759416 0.1258987751426715 0.005423393100500107
0.03084325683673146 0.1258961827816645 0.00541474437341094
0.030840863269678123 0.12588937628237998 0.005406347569078207
0.03083930875073971 0.12588588423747524 0.005397998262196779
0.03083776288197273 0.12588243839725707 0.0053897700272500515
0.030835880968116666 0.12587767563698665 0.005381305702030659
0.03083424828230781 0.12587388595255883 0.0053728800266981125
0.030832734337014507 0.1258705439587702 0.0053650266490876675
0.030830755583319304 0.12586533509949757 0.005356918554753065
0.030828908466601967 0.12586063094079666 0.005348525010049343
0.030827697692518596 0.12585844154020212 0.005339987576007843
0.030825804742297135 0.12585356487242644 0.005331358872354031
0.030824250614154475 0.12585002488149385 0.005322409328073263
0.030822673372942533 0.12584637320283198 0.005313368514180183
0.030820825668071844 0.12584162973089014 0.005304876249283552
0.030818657025312394 0.12583560519473092 0.0052965604700148106
0.030817342780998187 0.1258329571161399 0.00528805423527956
0.030815737166977917 0.12582915910188364 0.005279533565044403
0.03081424139873186 0.12582579056868173 0.005270903930068016
0.03081267110465325 0.12582212120983452 0.005262286402285099
0.03081099295933369 0.12581799093791537 0.005253857001662254
0.030809537094373864 0.12581472931207985 0.00524528743699193
0.03080791154082485 0.1258107861329927 0.005236639641225338
0.03080646658339759 0.12580755714559866 0.0052278232760727406
0.03080429132402673 0.12580143895293427 0.0052186269313097
0.030802544196499873 0.12579700533166577 0.005210075527429581
0.030801592927597897 0.12579570262902104 0.005201062187552452
0.030799735468265674 0.1257908002897446 0.0051925210282206535
0.030798155730450624 0.12578698213483977 0.00518402736634016
0.030796473825727266 0.12578275928275465 0.005175488069653511
0.030795275543063202 0.1257804454048231 0.005166518967598677
0.03079367691481932 0.12577653831739752 0.005157677922397852
0.030792055029271417 0.12577252751550602 0.005148860160261393
0.030790600280260615 0.12576915456383858 0.005140354856848717
0.030789283088332023 0.12576631034418317 0.005131371319293976
0.030787669559421096 0.12576229353131024 0.005122830625623465
0.030785534089802325 0.1257562139112479 0.005113711580634117
0.030784403962037576 0.1257541026936539 0.00510453199967742
0.030783226703846155 0.125751783409665 0.005095517262816429
0.030781327883191375 0.12574659633845744 0.005086952354758978
0.030779998771100138 0.12574365252507036 0.005078318528831005
0.03077815018906299 0.12573864862184986 0.005069673527032137
0.03077721809611335 0.12573726951683153 0.005060767289251089
0.030774859637885853 0.12573023662358515 0.005052181892096996
0.030773478465717527 0.125727057348893 0.00504315597936511
0.030772259073905676 0.12572449666492092 0.0050341119058430195
0.030770713800801534 0.1257206395874964 0.005025183781981468
0.030769218165402602 0.1257169751163828 0.005016331095248461
0.030767952016523388 0.1257142125874645 0.005007321015000343
0.030766197031083343 0.12570950483906984 0.0049985540099442005
iteration: 8 | epoch: 523 |   loss: 0.125710  |   KL divergence: 0.030766  |  JS divergence: 0.007820
('==== Found maximium gradient [0.006003534, 0.0058338656, 0.005554985] of '
 'gate e^[Y0 Z8], e^[Y8 Z0], e^[X10 Y9] ====')
learning rate =  0.0011600819150958308
0.030764815402243656 0.12570625657187037 0.011217372491955757
0.030767479223815373 0.12569493100137524 0.014228271320462227
0.030727879408393482 0.12567742744915147 0.01710359752178192
0.030731145595219774 0.1256581289735801 0.0117607107385993
0.03074826476977358 0.12564765909453696 0.013430830091238022
0.030749725021028476 0.12563669983861114 0.015293871983885765
0.030733553996120284 0.1256145622224093 0.010896448977291584
0.030714361922112243 0.12559698601316469 0.008325732313096523
0.030700704930956425 0.1255868574150693 0.011582465842366219
0.030694059198395865 0.12557624084858748 0.012817312963306904
0.030690824188304613 0.12555681750140846 0.010507890954613686
0.030690647248081057 0.12553697008181686 0.008255302906036377
0.030691306365223377 0.12552226223804527 0.00928789284080267
0.03068792597422181 0.12551014423231205 0.01012437418103218
0.030678476712295056 0.12549605603245306 0.009219941683113575
0.030664722450550227 0.12547630630053838 0.008638646453619003
0.03065325592738011 0.1254628035962123 0.009360653348267078
0.030644865714841887 0.12544823243246772 0.009538495913147926
0.03064018549728683 0.12543189692041445 0.008602830581367016
0.030638578292917967 0.12541580088834228 0.008029636926949024
0.030637482662806925 0.1254009162312297 0.008612513542175293
0.030633432839230333 0.12538511877780714 0.009010875597596169
0.030625429195921344 0.12536847060247938 0.008411046117544174
0.030615081265593633 0.12535156262299038 0.0076319375075399876
0.030605615191103767 0.12533683370680307 0.007754141930490732
0.03059766372495551 0.1253190607392002 0.008227838203310966
0.03059240807307172 0.12530179779724943 0.008182679302990437
0.030589219247377297 0.12528725925965223 0.007920613512396812
0.030584852667489504 0.12527003529459174 0.008006175048649311
0.03057907866245583 0.12525519734742174 0.008125748485326767
0.03057053173572271 0.12523781747568358 0.007887658663094044
0.03056181718062036 0.12522321404942793 0.007655343506485224
0.03055337394170224 0.12520660026915484 0.007776954211294651
0.03054685405010716 0.1251907338625928 0.007850945927202702
0.030541363228921363 0.12517244249190385 0.007584249600768089
0.030537310356960674 0.12515697977937 0.007395396940410137
0.030532346078795018 0.12514008891967152 0.007592193782329559
0.030525937759954165 0.12512357968405258 0.007776177488267422
0.030518042517068262 0.1251075918967143 0.007693282328546047
0.030509109926310236 0.12509044789064644 0.007617260795086622
0.030501571012699902 0.12507686479651303 0.007693572901189327
0.03049446628516073 0.12505935648943628 0.007693369407206774
0.030489550438381422 0.12504455414668383 0.007545992266386747
0.030484633480117096 0.12502701472852576 0.007466098293662071
0.030479674728259805 0.1250115558850363 0.007499136496335268
0.030473316282112167 0.12499618589012754 0.007462718989700079
0.030465306959859308 0.12497922264002279 0.007387961260974407
0.030457214859032973 0.12496277099907722 0.007444255519658327
0.030449833171543674 0.12494579688643002 0.0075262682512402534
0.030443606226841925 0.12492885046632085 0.007487269584089518
0.03043810870698141 0.12491245846557603 0.007440642453730106
0.030432127386367254 0.12489545154326906 0.00745429378002882
0.030425659648223455 0.12487996467744994 0.007424599956721067
0.030418701514633488 0.12486512257446852 0.007359114941209555
0.030410813736563392 0.12484650861117158 0.007349758874624968
0.03040422373701529 0.12483099008627327 0.007358414586633444
0.030397848352213055 0.12481422344772966 0.007334514986723661
0.03039099273819796 0.12479498814234657 0.00734105845913291
0.030385427580616062 0.1247821126836334 0.007386346347630024
0.030377769625985193 0.12476293430907719 0.007392683532088995
0.030370748240484538 0.12474776662387647 0.007369480561465025
0.03036355334481615 0.12473193923730896 0.007367909885942936
0.030356189758304373 0.12471416568665122 0.007356585469096899
0.03034911554102275 0.12469595101834162 0.00731715327128768
0.030342476670787093 0.12467877606356652 0.007296730298548937
0.03033594276269201 0.12466288219576191 0.007302463985979557
0.03032811338998788 0.12464366043280949 0.007303176913410425
0.030320618455837056 0.12462714831472059 0.007310981396585703
0.030313386130881963 0.12461156880096694 0.007331885397434235
0.030305667426552274 0.12459274927523041 0.007331728935241699
0.03029840420862178 0.12457453036863694 0.007309682667255402
0.030291866775656442 0.1245591055172551 0.007289627566933632
0.030284377109331233 0.12454089342932519 0.007269570138305426
0.030276921056705982 0.12452402083180657 0.007248914334923029
0.03026862733782871 0.12450430659808366 0.007242182269692421
0.030261367118283162 0.12448828371343146 0.007244706619530916
0.03025390541250158 0.12447051508641543 0.007241637911647558
0.030246329032686765 0.12445161556835868 0.007234471384435892
0.030239269867879035 0.12443493789267797 0.007224116940051317
0.030231869205436822 0.12441784294016249 0.007204798050224781
0.030223920986122033 0.12439958759111698 0.007181952241808176
0.030215741251836833 0.12438062068501385 0.0071625239215791225
0.030208604331466195 0.12436500425075789 0.007142327725887299
0.030200898312150955 0.12434599831169149 0.007120982278138399
0.030193225812050042 0.12432676793890608 0.00710438983514905
0.030185760979330404 0.12430907422694228 0.007089854683727026
0.030178162224087337 0.12429186681361996 0.007071672938764095
0.030170090727349923 0.12427313601021273 0.007050343323498964
0.03016280214992661 0.12425700284047093 0.007023027632385492
0.030154950129660733 0.12423777210178899 0.006988196168094873
0.030147684753265534 0.12422046778840336 0.006951618939638138
0.030140260927675196 0.12420272921374272 0.0069180866703391075
0.0301330835242823 0.12418643390902016 0.006886712275445461
0.03012534911934496 0.12416814640374503 0.0068568699061870575
0.03011797951168937 0.12415110607904772 0.006824831943958998
0.03011061356317729 0.12413354568542033 0.006785337347537279
0.030103789321909366 0.12411770793947675 0.006739215925335884
0.030096087203633652 0.1240982875336194 0.006691135000437498
0.03008932321636385 0.12408286148312545 0.006643231958150864
0.030082195934039074 0.12406609100439799 0.006596254650503397
0.030074720564854284 0.12404765598014678 0.00654944684356451
0.03006856774394319 0.1240340132762649 0.006499409209936857
0.030061076685867757 0.12401462226670727 0.006444958969950676
0.030054861697194665 0.12400025701483913 0.006387284956872463
0.030048222676504758 0.12398422253541555 0.00632792804390192
0.03004160868204338 0.12396822360839682 0.006267284043133259
0.030035381357694436 0.12395355875718868 0.006205576937645674
0.03002883455222114 0.1239372601493487 0.006141378078609705
0.03002323324071668 0.12392437008584695 0.006073827389627695
0.03001694168842898 0.12390839214483013 0.006004605907946825
0.030010451802616918 0.12389146047928545 0.005934712942689657
0.030005511027186287 0.1238806902954832 0.00586335826665163
0.029999073310640903 0.1238637862894138 0.00579052185639739
0.029993817696206 0.12385128999744 0.00571454968303442
0.029988268040044067 0.12383716938545455 0.0056356205604970455
0.029982464480215583 0.1238216836328438 0.005555417854338884
0.029977683846844915 0.12381012452877556 0.005475078709423542
0.029972698908708517 0.12379761654303265 0.005394932348281145
0.029967472858568767 0.12378395355445955 0.005314304027706385
0.029962702453120417 0.12377179530738937 0.005231253802776337
0.029958458803961936 0.12376136232665906 0.005145295988768339
0.02995418226943139 0.12375045176052066 0.005057692527770996
0.02994939744091773 0.12373729602854112 0.004970552399754524
iteration: 9 | epoch: 646 |   loss: 0.123737  |   KL divergence: 0.029949  |  JS divergence: 0.007578
('==== Found maximium gradient [0.0066915522, 0.0065228688, 0.0036981094] of '
 'gate e^[Y2 Z3], e^[Y3 Z2], e^[X8 Y1] ====')
learning rate =  0.001160463681626632
0.029944771341480457 0.12372465489792608 0.011173957958817482
0.02995295053668512 0.12371019489152892 0.016860906034708023
0.02993044838377111 0.12368403624589122 0.014044314622879028
0.029903756207246557 0.1236629499767857 0.015347999520599842
0.02989535459098983 0.12364431324426466 0.012175523675978184
0.029891415616044494 0.12362383475276525 0.013578354381024837
0.029887425936637874 0.12360620997457863 0.013515923172235489
0.029880723129291614 0.12358225040600553 0.010043490678071976
0.029876089124959437 0.1235646712135675 0.00960573647171259
0.02987274449863858 0.12354712096240293 0.011451927945017815
0.02986884157867143 0.12353030539608797 0.01066043321043253
0.029861965702445183 0.12351036740551498 0.008805402554571629
0.02985220105860026 0.12348989456373687 0.008964401669800282
0.029840466674089593 0.12347347857504587 0.00947983842343092
0.02982673168994772 0.12345393315839251 0.00909383874386549
0.02981506264112377 0.12343571429309315 0.00915393978357315
0.029807806180572993 0.12341949727981215 0.009840925224125385
0.029803811115627445 0.1234004202272632 0.009699375368654728
0.029801861933625984 0.12338121545334711 0.00876905769109726
0.029800003690713915 0.1233650096391756 0.008339355699717999
0.0297952196308705 0.12334908441279867 0.008388622663915157
0.02978643999892034 0.12333162973656235 0.007989123463630676
0.02977588890906963 0.12331605848017316 0.007477428764104843
0.029764155510460362 0.12329539072729245 0.00765664828941226
0.02975546537923017 0.12327931720032699 0.008004792965948582
0.029749271677196876 0.12326397931943132 0.007819732651114464
0.02974466142972408 0.12324940504578279 0.007573180366307497
0.02973912419490693 0.12323161406879965 0.007850917987525463
0.029732875094631628 0.12321653018857703 0.008128328248858452
0.029724865170293508 0.1232005022714645 0.00792425125837326
0.029716396189339522 0.12318462271011542 0.00765969417989254
0.029708262458276926 0.12316685555905947 0.007700984366238117
0.029702284797355254 0.12315228302988618 0.007644394412636757
0.02969706750883206 0.123136924380687 0.007309815846383572
0.029691055438669012 0.12311857591069858 0.0071294899098575115
0.029685132884575 0.12310515292555983 0.0072103459388017654
0.02967680598206353 0.12308850339419587 0.0072263856418430805
0.029668468254446405 0.12307621282916073 0.007216970901936293
0.029659077892537536 0.1230593344197274 0.007377441041171551
0.02965088252030071 0.12304267311032889 0.007518508937209845
0.029644951026044555 0.12302919513144095 0.007449953816831112
0.029639407515725545 0.12301346165728651 0.007308408617973328
0.029634361093410007 0.12300012776969402 0.007217508740723133
0.029627286784604412 0.12298258929803074 0.007115552201867104
0.02962009789216488 0.12296942045664369 0.007007004227489233
0.029611316040784885 0.12295244972299078 0.006970989052206278
0.029603848968108436 0.12294018821812205 0.006961111910641193
0.029595988881747762 0.12292371142507068 0.006922309752553701
0.029589415505782923 0.12291006577036327 0.006911951117217541
0.029582894446083856 0.1228960508282426 0.006935749668627977
0.02957599856288671 0.12288151727197619 0.006932140793651342
0.029568809144602304 0.12286685471051897 0.006911776028573513
0.029561752749583874 0.12285264439017926 0.006877067498862743
0.029554848181058697 0.12283801229723053 0.006785676348954439
0.029548438154466318 0.12282451630038765 0.006673686672002077
0.029541989670862443 0.12281107252996983 0.006595202721655369
0.02953467604704562 0.1227952485610305 0.006537317298352718
0.02952813238168872 0.12278354954792801 0.006504686549305916
0.02952124160890497 0.12277044991389068 0.006506072822958231
0.02951416026617167 0.12275561485446154 0.00649060495197773
0.029507808277970025 0.12274254047296423 0.006437037605792284
0.02950165048816144 0.12272955146999126 0.006383602041751146
0.029495286895936654 0.12271568061397801 0.006333326455205679
0.029489306734658043 0.12270356349403029 0.006266059819608927
0.029483338531741028 0.12269149585109089 0.006203898694366217
0.029476899592610985 0.12267726393786087 0.006148270796984434
0.029470962577944262 0.12266488703789895 0.006068824324756861
0.02946471296794588 0.12265128969943627 0.005986390169709921
0.029459009801729205 0.12264008965850126 0.005932399537414312
0.029453184645384822 0.12262839750763174 0.005890801548957825
0.02944727180449573 0.12261587428538243 0.005851098336279392
0.02944240260554346 0.12260668665125843 0.005811629816889763
0.029436677604293977 0.1225931533294123 0.00575078884139657
0.029431193698696366 0.12258026616589672 0.005664227996021509
0.029426087286486928 0.12256926313841104 0.005575064569711685
0.02942124855324533 0.12255998034610216 0.005498581100255251
0.029415533571135636 0.12254745905550772 0.005436820909380913
0.02941065561846955 0.12253794878197005 0.005385484080761671
0.029405781860923835 0.1225276349042728 0.005329199135303497
0.029401026088160025 0.12251715772151744 0.005261790938675404
0.02939564598854419 0.12250403522119069 0.005192408803850412
0.029391627793974296 0.1224966381823733 0.005125740077346563
0.029386392346607622 0.12248430587721296 0.005064290948212147
0.02938188051880812 0.12247447845554216 0.005002992693334818
0.02937737603338884 0.12246418676667128 0.004933108575642109
iteration: 10 | epoch: 731 |   loss: 0.122464  |   KL divergence: 0.029377  |  JS divergence: 0.007423
('==== Found maximium gradient [0.003964644, 0.0031784798, 0.0029523468] of '
 'gate e^[Y8 Z9], e^[X1 Y0], e^[X1 Y8] ====')
learning rate =  0.0006786014077251258
0.02937345247443951 0.12245616911422955 0.007624824997037649
0.029362420066972567 0.12244705658157608 0.009937283582985401
0.02937142159592805 0.12243477336373301 0.008037571795284748
0.02937169031150206 0.12242266888750694 0.008228238672018051
0.029366878238542303 0.12241174077836915 0.008513416163623333
0.029360056566039704 0.12240120175054932 0.008844033814966679
0.029352059998456134 0.12238751150861692 0.008127995766699314
0.02934483594185332 0.12237326443485533 0.00736693711951375
0.029338668969778804 0.12236045093327362 0.007287964224815369
0.029333319334522445 0.12235242969181989 0.0071463813073933125
0.029326543388289147 0.12234034769807987 0.006713011767715216
0.029320006005860197 0.12232880380115603 0.006518659181892872
0.02931424436158947 0.122316732259014 0.006619561463594437
0.029310176299848268 0.12230557466139884 0.006646662950515747
0.02930667017646102 0.12229186159955041 0.006531734485179186
0.029303534889295865 0.12227946364343686 0.00648814532905817
0.029300108268595387 0.1222703488772808 0.006529980804771185
0.029294483298928108 0.12225767558016708 0.006571880541741848
0.02928833416171115 0.12224549572707052 0.006631338968873024
0.029282669974982984 0.12223449850193914 0.00666324608027935
0.029277630796439993 0.12222392289788316 0.0065935286693274975
0.029272196426316354 0.12221070176040877 0.006454932037740946
0.029266786655985914 0.12219861464502998 0.006311759352684021
0.029261025797626038 0.1221871869578899 0.00619161082431674
0.029255467298623168 0.12217784947981868 0.006113333161920309
0.029248932227227353 0.12216417362811637 0.006092557683587074
0.029243705907356837 0.12215457301484273 0.0061142113991081715
0.029237844716175784 0.12214138807205664 0.006116609089076519
0.02923269059104118 0.1221306188492124 0.006062451750040054
0.02922781897354417 0.12212068329873216 0.005997999105602503
0.02922248352970702 0.1221086126314402 0.005969729274511337
0.029217551654367013 0.12209835344423282 0.005971689708530903
0.029212591679103433 0.12208859359089248 0.0059891208074986935
0.029206408450577873 0.1220742374360293 0.006019983906298876
0.029201349195801092 0.12206395477605995 0.006057091057300568
0.029196580233148816 0.12205363606493075 0.006068861577659845
0.0291923298345778 0.12204467598887052 0.006038350518792868
0.02918668751004541 0.12203067919259482 0.005985301453620195
0.029181730796249413 0.12202117419448948 0.005929221864789724
0.029175894642276046 0.12200952243671732 0.005875455681234598
0.029170604131956136 0.12200036707233257 0.005830388981848955
0.029164583548107973 0.12198760690627572 0.0058074346743524075
0.02915978215461223 0.12197911041244902 0.00579826720058918
0.02915435633356083 0.12196760865940083 0.005776217672973871
0.02914929394755434 0.12195710828493875 0.005741146858781576
0.0291443759711874 0.1219465930857825 0.005713898688554764
0.029139495314490317 0.12193586766745672 0.005703084170818329
0.029133962546161782 0.12192266882338945 0.005709050688892603
0.029129923364760203 0.1219160250345447 0.005730642471462488
0.02912454584329382 0.12190408552276823 0.00574919069185853
0.029119643139970064 0.12189387720893681 0.0057390425354242325
0.0291148979640055 0.12188410348775061 0.005709506571292877
0.029110251621006653 0.12187478105575371 0.005685769021511078
0.02910517278035537 0.12186388438273613 0.0056708152405917645
0.029100748782994096 0.12185576539235266 0.00565033545717597
0.02909548674323572 0.12184432527140916 0.005618471652269363
0.02909053404395754 0.12183441038691292 0.005583723075687885
0.02908550590856091 0.12182443305187483 0.00555401062592864
0.029080575605320576 0.1218146540919575 0.005531544331461191
0.029076034716558778 0.12180580333171226 0.005510861054062843
0.029071189085671374 0.12179503589239209 0.005490715149790049
0.029066507524745325 0.12178469221053971 0.0054804799146950245
0.029061621677124477 0.12177366868836968 0.005482133943587542
0.029057085765078962 0.12176429014097699 0.005479390732944012
0.02905300097043315 0.1217569328340213 0.005461191758513451
0.029048061757936505 0.1217462915121144 0.00543344859033823
0.029043977886235674 0.12173929102276783 0.0054071457125246525
0.029038776842796175 0.12172764355846041 0.005384792573750019
0.029034271515832738 0.12171856685943408 0.005362899508327246
0.029029822937600373 0.12170953965244938 0.005339475814253092
0.029025010859124036 0.12169901417120929 0.005314075853675604
0.029020511102907057 0.12168981380839203 0.005286324303597212
0.029016040444616316 0.12168074641026462 0.005256859119981527
0.029012123404036146 0.12167393680833412 0.005229777656495571
0.029007795997187648 0.12166548137844455 0.005209560506045818
0.029002820268385493 0.12165429990617035 0.005193667020648718
0.02899861335751365 0.12164597703655487 0.005175987258553505
0.028994575704782918 0.12163797244157735 0.0051545132882893085
0.028990242082742965 0.12162863303816304 0.005132331978529692
0.028986120956314053 0.1216203179304261 0.0051121641881763935
0.02898171384179056 0.12161105457165235 0.005093093495815992
0.02897776618228908 0.1216037373938962 0.005071921739727259
0.02897343557491727 0.12159475905716385 0.005047587677836418
0.02896889361679563 0.12158476687242081 0.00502166710793972
0.028965633014478874 0.12157982062146974 0.004994199611246586
iteration: 11 | epoch: 816 |   loss: 0.121580  |   KL divergence: 0.028966  |  JS divergence: 0.007315
('==== Found maximium gradient [0.004192133, 0.0040395213, 0.0031858901] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[X9 Y8] ====')
learning rate =  0.0007663037725271432
0.02896131564035257 0.12157042536203481 0.008288787677884102
0.028952244172404298 0.1215576356489518 0.009003916755318642
0.028943053332291538 0.12154362143764048 0.011623839847743511
0.028942153282153285 0.1215292340673938 0.012708378955721855
0.028921225427565443 0.12151273153263069 0.008568118326365948
0.02890677917709278 0.12150022513138305 0.00961749255657196
0.028901117491365695 0.12148600318779257 0.010792414657771587
0.028900882703944933 0.12147000654349557 0.008330904878675938
0.028901112713204734 0.12145021234318311 0.008649297058582306
0.02889948107663661 0.12144070717999726 0.010185872204601765
0.02888927158310276 0.12142184984772045 0.009107068181037903
0.028876296365774164 0.12140549594268343 0.007682269439101219
0.028864311065951952 0.12139056109162824 0.008334278129041195
0.02885506114522993 0.12137485611350168 0.008658611215651035
0.028848825210275812 0.1213597363034899 0.007872520945966244
0.028843915662117938 0.12134408549224222 0.007766351103782654
0.028837402469706213 0.12132521678914256 0.008357695303857327
0.028829379974008 0.12130963091004501 0.008243342861533165
0.028819628165856325 0.12129461845806022 0.007827564142644405
0.028808877641557776 0.12127665235629245 0.008052346296608448
0.02879998862927184 0.12126130304869026 0.008260073140263557
0.028792548172162015 0.1212450686077224 0.007878161035478115
0.028786017198328337 0.12122864975917944 0.007690635044127703
0.028778431900161324 0.12120963388338261 0.008047962561249733
0.028769991458129626 0.12119335597480553 0.008151891641318798
0.028760056752318547 0.12117655743718934 0.007908503524959087
0.02875003179777605 0.12116018984749094 0.007961590774357319
0.0287407542397277 0.12114287962146873 0.008186482824385166
0.02873288440845107 0.12112576796044117 0.008050749078392982
0.028725881391476738 0.1211089332334663 0.007814113050699234
0.028717778857529193 0.12108893039272972 0.007889773696660995
0.028709521873744134 0.12107349164425672 0.007987448945641518
0.028699975283213913 0.1210577114222968 0.007907278835773468
0.028689433529825243 0.12103865382677735 0.007934928871691227
0.028680182012020914 0.12102116463525296 0.008087997324764729
0.02867246975578172 0.12100485227668685 0.008112531155347824
0.028664669347478643 0.12098556866229218 0.008081110194325447
0.02865685434508028 0.12096819482901118 0.008115950040519238
0.028647900854179936 0.12095126403025032 0.008078341372311115
0.0286375310292447 0.12093275065348816 0.007986505515873432
0.02862741766098011 0.12091535358730465 0.00802153442054987
0.028617982147218265 0.12089672781097419 0.008092512376606464
0.02861034692944149 0.12088054590554807 0.008069214411079884
0.028602915558854667 0.12086299359968311 0.008069629780948162
0.02859441974843957 0.12084325002246647 0.00811175350099802
0.02858569473812244 0.12082729520918348 0.00806296057999134
0.028575957241895735 0.12081045067386291 0.007988856174051762
0.028566323575093686 0.12079331974537566 0.008002293296158314
0.028557479541900806 0.12077555286050773 0.00801963172852993
0.02854932285204375 0.12075676771369667 0.00799989327788353
0.028542296138018522 0.1207418227364911 0.008005660958588123
0.028533754158862674 0.12072338161651791 0.008001944981515408
0.02852457033979083 0.12070620714385226 0.007950055412948132
0.02851467597792147 0.12068798687258453 0.007905871607363224
0.028505490042667447 0.12067128049426837 0.007879683747887611
0.028496894297843522 0.12065374634286402 0.007850795984268188
0.028488981013576047 0.12063657851557208 0.007840510457754135
0.028481865361525055 0.12062265763556328 0.00782941747456789
0.028472930467740177 0.12060297581728734 0.007788428571075201
0.02846481894583685 0.12058823379066977 0.007746449206024408
0.028456094213993997 0.12057094669678033 0.007706127595156431
0.028448140129886678 0.12055563146148865 0.007643533870577812
0.028439957817386438 0.12053836150998973 0.0075832270085811615
0.028432328391144235 0.1205235194754205 0.007532081101089716
0.02842416153569595 0.12050732191522763 0.007468643132597208
0.028416163975847477 0.12049214532774606 0.007408691104501486
0.02840822763708884 0.12047635211974525 0.007363060023635626
0.028400871518046558 0.12046153194324284 0.007315313909202814
0.028393872648114764 0.1204474213554167 0.007264066953212023
0.028386054684137997 0.12043037875379614 0.007204648572951555
0.028379092004401942 0.12041790032096421 0.007128691300749779
0.02837185871702962 0.12040470548291032 0.007050164509564638
0.028364544815552326 0.12039045550573763 0.006974458694458008
0.028357552872315023 0.12037629664331123 0.006899628788232803
0.028350736782392676 0.12036215913245779 0.006830289028584957
0.028344043209059554 0.12034868628135051 0.0067565045319497585
0.028336979742892482 0.12033414563096248 0.006673708092421293
0.02833074460386366 0.12032290116939182 0.006592500489205122
0.028324997471859514 0.12031283476520443 0.006514218635857105
0.028318303691124234 0.12029798149964498 0.006436241324990988
0.028312930210651448 0.12028839572137952 0.00635918602347374
0.02830699597715003 0.12027693474192423 0.006275539752095938
0.028300567262149617 0.12026376875782221 0.006183627061545849
0.0282950983470404 0.12025420424163528 0.006091079208999872
0.028288793291323604 0.12024024179785694 0.006001668982207775
0.028284347623330243 0.12023316498463323 0.005917650647461414
0.028278816057595732 0.12022140817298514 0.005837702192366123
0.02827397885333636 0.12021273970539663 0.005755078513175249
0.028268925920168886 0.12020320832674493 0.005669795908033848
0.028263792537344467 0.12019291956533311 0.005582108162343502
0.028259102703518543 0.12018391291794778 0.0054925307631492615
0.028253838287368556 0.12017221636414534 0.0054056234657764435
0.028249624160624313 0.12016485470744914 0.005319917108863592
0.02824525192353113 0.12015674392502801 0.0052348594181239605
0.02824108392056418 0.12014905725373598 0.005152808967977762
0.028237152410853558 0.1201417639830861 0.005072179716080427
0.028233044404518477 0.12013340917358908 0.004993072245270014
iteration: 12 | epoch: 913 |   loss: 0.120133  |   KL divergence: 0.028233  |  JS divergence: 0.007141
('==== Found maximium gradient [0.0052773, 0.004830218, 0.00477482] of gate '
 'e^[Y10 Z0], e^[X8 Y9], e^[X1 Y9] ====')
learning rate =  0.0009931754160072985
0.0282293117086899 0.12012667461487235 0.00990658812224865
0.028233183180198247 0.12011763742865372 0.017130285501480103
0.02819694563100315 0.12009488867578735 0.018206166103482246
0.028192948246701457 0.12006749501314674 0.01358303427696228
0.02819984175414106 0.12004628142513178 0.011803391389548779
0.02819844026807935 0.12002992012358359 0.015478165820240974
0.028181815517934413 0.1200051218575911 0.012315311469137669
0.028161306907497526 0.11998083689587385 0.008288214914500713
0.028145621433538038 0.11996351589246333 0.01154398825019598
0.02813340638923888 0.11994229596752665 0.012519566342234612
0.028123514386424027 0.1199170002224158 0.00986324343830347
0.028117618719584993 0.11989759282063073 0.00963215995579958
0.02811045892160598 0.11987370894485502 0.011339564807713032
0.028101254997335404 0.11985400662741677 0.010560761205852032
0.028087441849732324 0.11982660949994065 0.00878759566694498
0.02807533150695006 0.11980867098549204 0.009333503432571888
0.028064103007038495 0.11978840711209851 0.010503995232284069
0.02805448296775869 0.11976566655049281 0.009954855777323246
0.028046623450791428 0.11974264610236092 0.008892296813428402
0.028038497749389414 0.11971774424167825 0.009348394349217415
0.028029454094105732 0.11969814998327531 0.010028865188360214
0.028016411377965324 0.11967540223136769 0.009485929273068905
0.028001404741817247 0.11965213387766203 0.008837425149977207
0.027987782462890236 0.1196317765493717 0.009174478240311146
0.027975804446973757 0.11960823216583258 0.00936032272875309
0.027966769834827383 0.1195861015654476 0.008932693861424923
0.027958798032564257 0.11956226680745513 0.008922469802200794
0.02795063582801408 0.11953950571968194 0.009374013170599937
0.027940693966121272 0.11951717883229596 0.009364238940179348
0.02792870250079201 0.1194938505930262 0.008986474946141243
0.027915861304193795 0.11946952753109882 0.008915591984987259
0.027904199871884652 0.11944776507961079 0.009030945599079132
0.027892843187657106 0.11942324562510916 0.008929017931222916
0.027882600016648336 0.11940072030440638 0.008848339319229126
0.027872030391923285 0.11937699476288119 0.009005485102534294
0.027861226686709917 0.11935467448558952 0.009040712378919125
0.027849777513942454 0.11933189981832919 0.008860778994858265
0.027837778146531725 0.11930686760606556 0.008828661404550076
0.02782699220013557 0.11928480734483944 0.008919049054384232
0.027816463277973352 0.11926111041288341 0.008883526548743248
0.027805913277349548 0.11923564766630594 0.008853293024003506
0.027796122239004288 0.11921393898036013 0.008900530636310577
0.027785266495090572 0.11919048699439153 0.008842546492815018
0.027773744904330055 0.119167139299588 0.008719881065189838
0.027762698532722528 0.11914674285313541 0.008681307546794415
0.0277509707707042 0.11912190060125974 0.00865277647972107
0.02774064452111585 0.11910000728257862 0.008582955226302147
0.027730779993323747 0.11907812568737629 0.008575557731091976
0.027719795032762423 0.1190521283004517 0.00860660057514906
0.027709423294160707 0.1190308841174067 0.008566866628825665
0.0276983800374549 0.1190082144023569 0.008511792868375778
0.02768759358810021 0.11898572827460958 0.008474789559841156
0.02767774287379445 0.11896486125975411 0.008385713212192059
0.027667636289774592 0.11894141148100873 0.008303193375468254
0.027657976474627442 0.11892052291044715 0.0082766804844141
0.027646780194724815 0.11889533562803581 0.008221830241382122
0.027636543402232636 0.1188754991929649 0.008140083402395248
0.027625799807354856 0.11885272604184785 0.008085690438747406
0.027616458206398298 0.11883364885674084 0.008023208007216454
0.027606730702944518 0.1188112655203649 0.007952000014483929
0.027597671463255927 0.11879169891739388 0.007914228364825249
0.027587882151597867 0.11877045721268685 0.007862536236643791
0.02757800247593062 0.11875012832659607 0.007763422094285488
0.027568157084257992 0.11872992619704413 0.007670591119676828
0.02755865785860312 0.11870981081074498 0.007580670993775129
0.027549803744095155 0.11869073395264146 0.007478902582079172
0.027541330366545533 0.11867243680977227 0.00740145705640316
0.027531936242245793 0.11865080513638775 0.007329497020691633
0.027523195827547822 0.118633037012277 0.0072369929403066635
0.027514117987477625 0.1186142554706128 0.007152722682803869
0.02750598792019239 0.11859852614369701 0.007072935346513987
0.02749718138801311 0.11857844487114674 0.006977425888180733
0.027489426693165484 0.11856201684108073 0.006883690599352121
0.02748075864211085 0.11854224384362327 0.006788458209484816
0.02747290131697431 0.1185267128235286 0.006677763536572456
0.027464785391628617 0.11851000695031767 0.006572251673787832
0.027456608120212896 0.11849183004315562 0.006469888146966696
0.02744919080433443 0.11847554868186394 0.00636375742033124
0.027441417454177313 0.1184574709011097 0.006268284283578396
0.02743427796826882 0.1184426707244125 0.006174045614898205
0.027427328997200903 0.11842919749587338 0.006071221549063921
0.027419763097569137 0.11841276188988258 0.005969232879579067
0.02741338331031222 0.11840027018438001 0.005863521713763475
0.027406701863873808 0.11838562232568711 0.005754300393164158
0.02740025723393502 0.11837177292265638 0.005650567356497049
0.027393609176631833 0.11835738694960786 0.005544443614780903
0.027387566045542877 0.11834571683102113 0.005437573418021202
0.027380855451304476 0.11833079266029392 0.005338896065950394
0.027375436152679965 0.11832038483997628 0.005241892766207457
0.02736930159467258 0.11830623568880107 0.005146086681634188
0.027363039374531998 0.1182915123499908 0.005051438231021166
0.027358054789853137 0.11828258514537804 0.004952409770339727
iteration: 13 | epoch: 1005 |   loss: 0.118283  |   KL divergence: 0.027358  |  JS divergence: 0.006922
('==== Found maximium gradient [0.0041826875, 0.003961658, 0.003617403] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y1 Z3] ====')
learning rate =  0.0007854952835703874
0.027352401865608715 0.11827099497929734 0.008357071317732334
0.02734345804172931 0.1182568762649162 0.013833258301019669
0.02734913791379661 0.11824035298884583 0.014690758660435677
0.027332825110113458 0.11821749517456456 0.012854069471359253
0.027315531779886923 0.11819847788907344 0.009665682911872864
0.02730637774788714 0.11818331541686002 0.011895009316504002
0.027302804503481083 0.11816642149598448 0.010554303415119648
0.02730064242581922 0.1181486672843084 0.007741848006844521
0.027297320702189053 0.11813307533646424 0.009150252677500248
0.02728958656094043 0.11811759886182556 0.01035699900239706
0.02727800600032935 0.11809991213203977 0.008980100043118
0.027267072628930696 0.11808402585471812 0.007797989062964916
0.027259347942302052 0.11807011842059739 0.008603171445429325
0.027253750085111685 0.11805388858685503 0.008761432953178883
0.027248617217149346 0.11803474006892244 0.007609148509800434
0.02724498829388232 0.118023291536762 0.007172028534114361
0.027239608484784534 0.11801039398205238 0.00794362835586071
0.027231873539121515 0.11799478540041777 0.00810173898935318
0.0272229314577249 0.11797814383324706 0.007365466561168432
0.027214779388538557 0.11796363047173704 0.006972429342567921
0.027207958057294146 0.1179496702906202 0.007244675420224667
0.027201996908986094 0.11793420826523923 0.007238354068249464
0.02719762831807192 0.11792313019404334 0.006901969201862812
0.027192350979395607 0.11790945951368437 0.006904103793203831
0.027185480969633004 0.11789322184691241 0.007093355059623718
0.02717818928553047 0.11787972416090227 0.006909274496138096
0.02717067437354865 0.11786722753730204 0.006547304801642895
0.02716225199453925 0.11784903731448339 0.0064725931733846664
0.027156811210260257 0.11783894975895617 0.006551201455295086
0.027151110706341408 0.11782367509295326 0.006565649062395096
0.027145935219583417 0.117809818535935 0.006649341434240341
0.027140032703884542 0.11779610913491782 0.006749028339982033
0.027132898156611383 0.11778219708147279 0.006599693093448877
0.02712490509954426 0.11776770879411878 0.006302166730165482
0.027117655536430536 0.11775502728914211 0.00618990371003747
0.027110967385533362 0.11773983869718554 0.006227094680070877
0.027106023698568453 0.11772708576323222 0.006264670751988888
0.027101369106694324 0.1177142522185026 0.0064025018364191055
0.02709596554599203 0.11770168178124882 0.006554509047418833
0.027089153360463063 0.1176887247256649 0.006460048723965883
0.027081512957626962 0.11767558345303 0.006208499893546104
0.027073913930119473 0.11766125058666077 0.00607715779915452
0.027068349739218303 0.1176507215540573 0.00605324050411582
0.027062869293334853 0.11763578389069129 0.006059581413865089
0.02705806355447025 0.11762215687195923 0.006182123441249132
0.02705302567196738 0.11760996048488044 0.006323773879557848
0.027046858277414418 0.11759718511296587 0.0062623582780361176
0.02703971381945052 0.11758295363465952 0.006066786590963602
0.027033562073092605 0.11757225631217814 0.005951718892902136
0.02702754912383492 0.11755895399760409 0.005918421782553196
0.027022245299230786 0.11754530878337235 0.005929903127253056
0.02701804379074016 0.11753509039325785 0.006014061626046896
0.027012914924401527 0.11752239626940209 0.006063549313694239
0.027007474888304794 0.11751103185830658 0.005976462736725807
0.027001188172619726 0.11749752539687758 0.0058504631742835045
0.02699543050388109 0.11748532447891005 0.005785943474620581
0.02699069060392102 0.11747501398031958 0.005756324622780085
0.026986146934683947 0.1174636550547338 0.005752934142947197
0.026981090170655198 0.11745021889059985 0.005769016221165657
0.026975768574879967 0.11743729206900592 0.00573433144018054
0.026970766168991855 0.11742709164293338 0.00564143992960453
0.026966133020696004 0.11741819287881622 0.00556044140830636
0.026960832313829397 0.11740483804036715 0.00551495049148798
0.026956393412797285 0.11739366339299227 0.005493135191500187
0.02695238790579895 0.11738409969987226 0.005481045227497816
0.026947310011933172 0.11737088884019524 0.0054420712403953075
0.026942731071640674 0.11736070610881738 0.005363107193261385
0.0269382459412019 0.11735092052707095 0.0052789561450481415
0.02693429799752589 0.11734249312491106 0.005219609942287207
0.026929446768449983 0.117329150853827 0.005191364325582981
0.02692598299461807 0.11732123587331987 0.005172325298190117
0.02692147252996649 0.11730924584774102 0.005127215292304754
0.02691764635194077 0.11730085537163333 0.005054698325693607
0.02691341372016938 0.1172910306143051 0.004979455377906561
iteration: 14 | epoch: 1079 |   loss: 0.117291  |   KL divergence: 0.026913  |  JS divergence: 0.006807
('==== Found maximium gradient [0.0037156912, 0.0032015606, 0.003101828] of '
 'gate e^[Y0 Z9], e^[Y9 Z10], e^[Y1 Z0] ====')
learning rate =  0.0006701014028018042
0.02690948516390638 0.11728202341923183 0.0076039633713662624
0.02690400306357572 0.11727255960719199 0.010928678326308727
0.02688870692898282 0.11726268548603551 0.014261029660701752
0.02689312022779 0.11724442296115034 0.009853850118815899
0.0268942651737398 0.11723431534258937 0.013214061968028545
0.026883629264123937 0.1172221631243751 0.01011693011969328
0.026868916085682475 0.11720490131280178 0.007844146341085434
0.0268601396332853 0.11719561645033252 0.01000886969268322
0.026857352316774306 0.11718493487803239 0.009961946867406368
0.026857809762637366 0.11717196846359043 0.00788408238440752
0.026859294706292006 0.11716147047456918 0.007647732272744179
0.026857585938375957 0.11715212765154825 0.008928186260163784
0.026849941256272436 0.11713983964708082 0.008046489208936691
0.02683888993546921 0.11712639707548178 0.005864887963980436
0.0268296145980813 0.11711806486996379 0.006164090242236853
0.026823798402629054 0.11711021444661261 0.007400429807603359
0.026820784724177968 0.11709826802709661 0.006851754151284695
0.026820573851880324 0.11708873095713325 0.005563829094171524
0.026820995365098785 0.11708248512609896 0.005624739453196526
0.02681855130694219 0.11707346765902726 0.006287854630500078
0.026813353868851766 0.11706437371135828 0.005875354167073965
0.026806847366891533 0.11705604228093425 0.00480881379917264
iteration: 15 | epoch: 1101 |   loss: 0.117056  |   KL divergence: 0.026807  |  JS divergence: 0.006781
('==== Found maximium gradient [0.0025049788, 0.0023354127, 0.0023222582] of '
 'gate e^[X2 Y3], e^[X1 Y3], e^[X1 Y2] ====')
learning rate =  0.0004777999016242438
0.026800772913545448 0.11704802442092423 0.00641368143260479
0.02682497751454073 0.1170537944989077 0.018912939354777336
0.026798909221762382 0.11703469701610378 0.007381490431725979
0.026782656332510382 0.11703197471938213 0.01177202258259058
0.026778123999067732 0.11703037258784701 0.014501622878015041
0.02678039112057099 0.11702062226402943 0.011253838427364826
0.02678324128054132 0.11700687395623842 0.006774502340704203
0.026788169768620092 0.11700647587490078 0.007205304689705372
0.02678940250183889 0.11700191640304353 0.009693769738078117
0.02678586965241299 0.11699322069650096 0.010113357566297054
0.02677979543805304 0.11698854822357707 0.008422876708209515
0.026771020998321265 0.11698003113879 0.0061467415653169155
0.02676288406719049 0.11697178657228108 0.005961980205029249
0.02675799938556843 0.11696752556782639 0.007211445830762386
0.026755225558507748 0.11696098932558496 0.007927770726382732
0.026754593941666908 0.11695621881387164 0.007393797859549522
0.02675424540187219 0.11694962843712568 0.006113301031291485
0.02675362410161853 0.11694125125800112 0.005430546123534441
0.026753335164316452 0.11693573619434579 0.005751308519393206
0.026752160352226294 0.11693086710480437 0.006283813621848822
0.02674920228010503 0.11692547278918461 0.006156764924526215
0.026744357472512102 0.11691880911328414 0.005379288457334042
0.026739310139813642 0.11691423997626339 0.004745908081531525
iteration: 16 | epoch: 1124 |   loss: 0.116914  |   KL divergence: 0.026739  |  JS divergence: 0.006764
('==== Found maximium gradient [0.0022534705, 0.0019539162, 0.0016931886] of '
 'gate e^[X9 Y10], e^[Y0 Z1], e^[X8 Y9] ====')
learning rate =  0.00039602701628477607
0.026734032833827772 0.11690664976654833 0.005916198715567589
0.026754700448539448 0.11691082674380794 0.014232849702239037
0.026736587858176716 0.11689501495906467 0.008012522011995316
0.026723648159393907 0.11689087420304792 0.009502170607447624
0.026717841369041886 0.11688739689981612 0.010592113249003887
0.02671435158490309 0.1168778522965784 0.008997778408229351
0.02671393218176232 0.11687014860818178 0.0068579185754060745
0.02671577758630693 0.11686447061730695 0.007291655987501144
0.026717042825652067 0.11685746997300385 0.008263856172561646
0.026716761374606185 0.11685159547446912 0.007615262642502785
0.02671428348814682 0.11684542863288748 0.006437008269131184
0.026709636318192675 0.11683727265857416 0.006342720706015825
0.026705329867994378 0.11683449747065124 0.0066524688154459
0.02669954071552602 0.11682513099483477 0.006380959879606962
0.026694738030614742 0.11681631326864231 0.005931070540100336
0.02669231608672104 0.11681284758583506 0.005850574467331171
0.026690093840829578 0.11680659110179482 0.005903285462409258
0.02668835259885277 0.11680122316663942 0.005804203916341066
0.026685820138984906 0.11679372785769762 0.00563478097319603
0.026682813742337632 0.11678678364961885 0.005536866374313831
0.026679264384371338 0.11677972706516926 0.005573356989771128
0.02667637131709661 0.11677586767455685 0.00573811586946249
0.02667297036881885 0.11676813358729585 0.005796929355710745
0.026670875691303837 0.11676306039080873 0.00552118057385087
0.026668396567251274 0.11675386059356987 0.00513471057638526
0.026666582458713006 0.11674693276165339 0.005101038608700037
0.026664621371370666 0.11674142345742938 0.0053187208250164986
0.026661554576869702 0.11673501851422773 0.0053269388154149055
0.02665763462438108 0.11672851631465786 0.005113555584102869
0.026652895665311337 0.11672002588031004 0.005021160002797842
0.026649224803938953 0.11671506213905936 0.0051269023679196835
0.026645478496027566 0.11670697596039908 0.005220509599894285
0.026643026361765725 0.11670123554176823 0.005213878117501736
0.026640528663580163 0.11669313481720221 0.005150213371962309
0.026639046429867384 0.1166889387688495 0.005068093538284302
0.02663651220626574 0.11668133273230823 0.005030242260545492
0.02663372164139064 0.1166744231969189 0.005063501186668873
0.02663046518939946 0.11666716105358474 0.005090227350592613
0.026627620580058325 0.11666255620341706 0.005070777144283056
0.026624509678481803 0.11665682799368367 0.005056253168731928
0.0266214801801557 0.11665083277742114 0.005044304300099611
0.02661871336495122 0.11664513922869345 0.005002354271709919
0.026615837787977163 0.1166383033940099 0.004983958788216114
iteration: 17 | epoch: 1167 |   loss: 0.116638  |   KL divergence: 0.026616  |  JS divergence: 0.006732
('==== Found maximium gradient [0.002505212, 0.0018796917, 0.0017774105] of '
 'gate e^[Y3 Z1], e^[X0 Y9], RY[9] ====')
learning rate =  0.0004158287623080292
0.026612769374105155 0.11663031660190211 0.00617996184155345
0.026611616184174354 0.11662594733268604 0.009898670017719269
0.0266092172102921 0.1166157428427305 0.009705963544547558
0.02660283053259406 0.1166078419886908 0.00827521551400423
0.026604183527603086 0.11659826664532046 0.007840516977012157
0.026603977480911093 0.11659494412605466 0.008266684599220753
0.026595601297873292 0.11658235176195807 0.006417384371161461
0.026588152266103525 0.11657551701515638 0.006667565554380417
0.026584814863426294 0.11657047038671768 0.007867900654673576
0.026583237951951617 0.11656020640533174 0.0073828669264912605
0.026582131188873988 0.11655077803579754 0.006514793261885643
0.026580167716143088 0.11654591193249897 0.006389575079083443
0.02657518264045506 0.11653600471564703 0.006500378251075745
0.026570418060517305 0.1165274286042418 0.006291004363447428
0.02656732684343034 0.11652087619388402 0.006058590020984411
0.02656518536650075 0.11651372675870181 0.006239417940378189
0.0265623559731478 0.1165036635016212 0.006407733540982008
0.02655923484248434 0.11649692926310438 0.006165801081806421
0.026555101544541514 0.11649036515840823 0.00599404564127326
0.026549937514348202 0.11647995595396833 0.006127084605395794
0.026547055945095183 0.11647642873377101 0.00603378564119339
0.02654259970915232 0.11646279100887827 0.005757565144449472
0.026540453116337223 0.1164576187165778 0.005777905695140362
0.02653679922282721 0.11644685732476145 0.0059911650605499744
0.026533557782668714 0.11643908248234874 0.006033426616340876
0.02653063330552727 0.11643258800630814 0.005928682629019022
0.026527378927986543 0.1164239236321811 0.00584833137691021
0.026523344606138196 0.11641241795379283 0.0058077541179955006
0.02652015687125091 0.11640678474177985 0.00574158551171422
0.02651568786432988 0.1163980340741069 0.005732806399464607
0.02651149199738031 0.1163906515801006 0.005873865447938442
0.02650754909564282 0.11638175406347191 0.0059830970130860806
0.02650465432557444 0.11637379264686018 0.005914572160691023
0.026501789289059816 0.11636421307372463 0.0058068265207111835
0.02649936047236509 0.11635782348153054 0.005749225616455078
0.026495760618909795 0.11634940920480062 0.005683653987944126
0.026491515742396804 0.11634018199708794 0.005657927133142948
0.026487365094023347 0.11633104846983187 0.005741967353969812
0.026483299145740432 0.1163207864119563 0.005853618960827589
0.026480641233166943 0.11631567563539474 0.005880203563719988
0.02647695909584516 0.11630652656578326 0.00583610637113452
0.02647347348216223 0.11629887480852312 0.005796035751700401
0.026469452129948987 0.1162888761233064 0.00575920520350337
0.02646629782803417 0.11628184220732943 0.005729157943278551
0.02646265120142969 0.11627214808104319 0.005753733217716217
0.026459543273577496 0.11626503937392939 0.005781404674053192
0.026455717552143286 0.11625557954533355 0.005749938543885946
0.026451906175789044 0.11624647914213417 0.0057068392634391785
0.026448020646387023 0.11623681411365144 0.005691516678780317
0.02644454618992048 0.116228682221784 0.005693815182894468
0.026441039887504666 0.11622066449801248 0.005720954388380051
0.026437836221743435 0.11621431687362194 0.00576806953176856
0.02643365098264195 0.11620361734266867 0.005787975620478392
0.026430485116923495 0.1161965695341823 0.005752948112785816
0.026427387393666298 0.11618923263114994 0.00569792278110981
0.02642354755594178 0.11617893228192847 0.005657817702740431
0.026419862943599055 0.11617007198498269 0.005638003349304199
0.02641649550082139 0.1161630269292235 0.005653223488479853
0.026412463322578326 0.11615286222384777 0.0056883166544139385
0.026409136099164295 0.11614515193897078 0.005701221991330385
0.026405698318249432 0.11613682012379499 0.005687772296369076
0.02640201958384289 0.1161278069914779 0.00566380238160491
0.026397865989027616 0.1161170704141205 0.005643265321850777
0.026394864122070615 0.11611112973140003 0.005639090668410063
0.026391354741603472 0.11610260039145062 0.005649038124829531
0.0263874860139613 0.11609235134296197 0.005653777625411749
0.026384304826276753 0.11608520018949753 0.005639927927404642
0.026381371159023892 0.11607928463073734 0.00561845488846302
0.0263774650134083 0.11606918368563335 0.005601712968200445
0.026373882938804133 0.11606043671787894 0.005597489885985851
0.026370698595585673 0.11605352122335343 0.005607570055872202
0.026367228530179775 0.1160455269630484 0.005614728666841984
0.026363375220232185 0.1160357582085467 0.005606227554380894
0.02635986642721972 0.11602708103547511 0.005587226711213589
0.026356872973795062 0.11602036684368687 0.005568705033510923
0.02635304161879954 0.11601017524593858 0.0055601936765015125
0.026349833147162775 0.11600296790144506 0.005561606027185917
0.026346299817647738 0.11599448856580684 0.005563637707382441
0.02634303763530177 0.11598707135589581 0.005557231139391661
0.02633997438630723 0.11598040157061125 0.00554313650354743
0.026336027902953904 0.11596997453520853 0.005527528468519449
0.02633291432627538 0.11596311710103571 0.005515687633305788
0.026329185516845807 0.11595340506228592 0.005510850343853235
0.026325936661982137 0.11594552252257193 0.0055081406608223915
0.02632270361969429 0.11593775167660125 0.005500721745193005
0.02631940869531483 0.11593001129910989 0.005487800110131502
0.026315612942111384 0.11592031170697753 0.0054730623960494995
0.026311927670789118 0.11591097015346301 0.005462875589728355
0.026308972916953808 0.11590449896287305 0.005458048544824123
0.02630589092482337 0.11589735226973305 0.005453032907098532
0.02630308755512002 0.11589144940101495 0.005442422349005938
0.026299549539487807 0.11588244859616231 0.005426784511655569
0.026295886733812737 0.11587289352024455 0.005410132464021444
0.02629204820781043 0.11586257012230171 0.00539857754483819
0.026289050654394804 0.11585586373321666 0.005392391234636307
0.026285986077659362 0.11584886634218712 0.005386468023061752
0.02628241710204646 0.11583960096238642 0.005377243272960186
0.026279248893365192 0.11583197671326625 0.005363104864954948
0.026275724544223424 0.11582285043672806 0.005347799509763718
0.026273502241854665 0.11581939836902105 0.0053349267691373825
0.02626953697323748 0.11580842863432719 0.005325517151504755
0.026265985448338067 0.11579908837954427 0.005316287279129028
0.02626319331909248 0.11579293753755426 0.005304564721882343
0.026260067265001893 0.11578540764143924 0.005289782304316759
0.02625608211368373 0.11577424496341862 0.00527514424175024
0.026253264342440037 0.11576804307416876 0.005262911785393953
0.026250335824066377 0.11576127785173747 0.0052529023960232735
0.026246922528488474 0.11575240620975928 0.005242506042122841
0.0262440250159158 0.11574578673840356 0.005229680798947811
0.026241482417895944 0.11574068425650624 0.0052142515778541565
0.02623801204614335 0.11573150227383094 0.005199127830564976
0.02623483544911664 0.11572351307522034 0.005185731686651707
0.026231341555457498 0.11571416198041222 0.005173619836568832
0.026228858568556813 0.11570917899289235 0.005160423461347818
0.026224997049230505 0.115698254710951 0.005146325565874577
0.026222172223401227 0.1156917668542039 0.005131332203745842
0.02621897072384615 0.11568363789588457 0.00511718587949872
0.02621605397624372 0.11567667244547854 0.005103558301925659
0.026212983735361833 0.11566899353326261 0.005090333521366119
0.026209959586867386 0.115661458994137 0.0050751157104969025
0.026207214603304628 0.11565513744130095 0.005058889277279377
0.02620419079778897 0.1156476497542268 0.005042695440351963
0.026201178344074028 0.11564019536766883 0.005028456449508667
0.02619766500680875 0.11563051407962972 0.005014447495341301
0.026195064937195603 0.11562469841237281 0.004999866709113121
iteration: 18 | epoch: 1292 |   loss: 0.115625  |   KL divergence: 0.026195  |  JS divergence: 0.006616
('==== Found maximium gradient [0.0031193472, 0.0028031557, 0.0020778968] of '
 'gate e^[Y8 Z1], e^[Y1 Z8], e^[X8 Y9] ====')
learning rate =  0.000540440100228171
0.026191594987473144 0.11561513062592518 0.006836971268057823
0.026186787856228133 0.11560744091633328 0.010439452715218067
0.026191182409748454 0.11560151355507423 0.01461073849350214
0.026168966903953296 0.1155829813655579 0.007336955051869154
0.026162997394108156 0.11557942977129165 0.012399394996464252
0.02616420161438772 0.11556816614434856 0.010687114670872688
0.026166913064839523 0.11555457609203879 0.006825436372309923
0.02617017535841442 0.11554950369848953 0.008080090396106243
0.026167952587761556 0.11554115223708615 0.009524303488433361
0.026159962110708476 0.11552813789609676 0.00819251500070095
0.026151875535233536 0.1155218464561443 0.006398276891559362
0.026143956357015573 0.11550988645077931 0.006675857584923506
0.026140377227357205 0.1155029593580732 0.007789869327098131
0.026138867621703348 0.1154930012413287 0.007757031824439764
0.0261389694339718 0.11548505559714557 0.006644636392593384
0.026138438720098203 0.11547639931014851 0.005707204341888428
0.026136548675232216 0.11546844396009451 0.005947753321379423
0.02613231553074823 0.11545869074008272 0.006492191459983587
0.026126653687594387 0.115449489902159 0.006277988199144602
0.02611983850653827 0.11543767848857675 0.005418348591774702
0.026114793804290173 0.1154308421449611 0.005085836164653301
0.0261103528982013 0.11542064759449559 0.00562073802575469
0.026107467275748947 0.11541138508898563 0.005838966928422451
0.02610551397562905 0.11540311754031402 0.00528684351593256
0.02610329792239805 0.11539369022418029 0.004713426809757948
iteration: 19 | epoch: 1317 |   loss: 0.115394  |   KL divergence: 0.026103  |  JS divergence: 0.006591
('==== Found maximium gradient [0.0023047493, 0.0020662325, 0.0018035664] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y3 Z1] ====')
learning rate =  0.0004136671571946856
0.026101007754712163 0.11538599681430245 0.006022152490913868
0.026091804560589155 0.11538521334214887 0.01776544377207756
0.0260938080849584 0.11537059436418738 0.007865567691624165
0.026099028186668552 0.1153680926402401 0.012746166437864304
0.02609746969158374 0.1153606668628415 0.01404044684022665
0.026090505940127295 0.11535059106015609 0.00911366380751133
0.02608286749364607 0.1153400563042752 0.005731662735342979
0.026078513226920574 0.11533725260865418 0.009464445523917675
0.026074105198526654 0.11532756277972238 0.010935619473457336
0.02607144569116681 0.1153198920351108 0.0086209150031209
0.026070470803047183 0.11531291109542725 0.0053535024635493755
0.02607101861297608 0.1153081080132055 0.006069290451705456
0.026070349571878787 0.11529941754009379 0.00818474031984806
0.026068751235891148 0.11529249729345553 0.00828380137681961
0.026065485989467445 0.11528515525573212 0.0066137248650193214
0.02606056251954965 0.11527609992515336 0.005221547093242407
0.026056354279097867 0.11527281014585913 0.005882324185222387
0.026050932588021627 0.11526322019738894 0.006879988592118025
0.02604731151074075 0.1152571176365466 0.006702613551169634
0.02604447594933299 0.11524855559210305 0.005581696052104235
0.026043619774585434 0.11524277071437272 0.004812522325664759
iteration: 20 | epoch: 1338 |   loss: 0.115243  |   KL divergence: 0.026044  |  JS divergence: 0.006574
('==== Found maximium gradient [0.0017727646, 0.0017091463, 0.0015237922] of '
 'gate e^[X8 Y0], e^[Y1 Z2], e^[Y2 Z1] ====')
learning rate =  0.0003343813732635199
0.02604369271431021 0.11523761064740429 0.00596792483702302
0.026044110651422113 0.11523399964787555 0.015545179136097431
0.02604012650930676 0.11522434789870106 0.006888819858431816
0.026035220373145485 0.11521784053045495 0.011069292202591896
0.02603228290308875 0.11521556949691136 0.011356381699442863
0.026030020376936268 0.11520617821304253 0.007255214266479015
0.026030028636934946 0.11520011869092947 0.005882462486624718
0.026029430481484185 0.11519277406235702 0.008692480623722076
0.026027749422404052 0.11518872317729156 0.008907340466976166
0.026024142403153414 0.11518278356696961 0.00673109432682395
0.026019666681026524 0.11517476374233229 0.005283680744469166
0.026016997116963175 0.11517271348268841 0.006492991931736469
0.02601367058364987 0.11516410880418426 0.0075489492155611515
0.026012514858794446 0.11516143608039979 0.006892954930663109
0.026010405095239855 0.11515278818995499 0.005348671227693558
0.026009246770641502 0.11514801099361556 0.0050706202164292336
0.026007734529952257 0.11514271408291163 0.006066615227609873
0.02600515822796081 0.11513467134941838 0.006416496355086565
0.026002103847193425 0.11512658014955766 0.00574825145304203
0.025999500558552192 0.11512203145344448 0.004919845145195723
iteration: 21 | epoch: 1358 |   loss: 0.115122  |   KL divergence: 0.026000  |  JS divergence: 0.006560
('==== Found maximium gradient [0.0016094263, 0.0015601643, 0.0014866589] of '
 'gate e^[X8 Y0], e^[Y1 Z0], e^[Y10 Z9] ====')
learning rate =  0.0003105805421752233
0.025996780053021726 0.11511756003878106 0.00555420434102416
0.02599415714346709 0.11511470387605728 0.011392539367079735
0.025991952797808145 0.115104014984778 0.007406298071146011
0.025991907661918834 0.11509717742877125 0.007796587888151407
0.025989449974570693 0.11509080247546868 0.007879281416535378
0.02598514251064784 0.11508651736834469 0.007610799744725227
0.025979753715737935 0.11507994269207873 0.006369792390614748
0.025975260059370057 0.11507047010996278 0.005379429552704096
0.025974322635996156 0.11506691773061083 0.00564225809648633
0.02597390328956274 0.1150602558542677 0.006374439224600792
0.025973096786273273 0.1150536960452123 0.006172880530357361
0.025971211536472198 0.11504782980820726 0.005251408088952303
0.02596756710397796 0.11503895957382197 0.004881270695477724
iteration: 22 | epoch: 1371 |   loss: 0.115039  |   KL divergence: 0.025968  |  JS divergence: 0.006551
('==== Found maximium gradient [0.001584053, 0.0015312508, 0.0014868903] of '
 'gate RY[3], e^[Y1 Z0], e^[Y10 Z9] ====')
learning rate =  0.00030691574478933356
0.02596497757197244 0.11503687533958358 0.00584422005340457
0.025967502451733182 0.11503129416164967 0.012883440591394901
0.025953306664894468 0.11502614688528479 0.012596377171576023
0.02595148866609767 0.11501838966687984 0.009035415016114712
0.025955207087644573 0.11501442351393551 0.00916722510010004
0.02595770087522214 0.11501186317520304 0.01082702912390232
0.025954768717695552 0.11500372370317578 0.008148420602083206
0.025949690640100276 0.114997355459338 0.005685816053301096
0.025944323162992437 0.11499137809860732 0.007857833057641983
0.025941171060632068 0.11498982762820226 0.008609862066805363
0.02593838104457734 0.11498221042990234 0.006733388639986515
0.025937686762128095 0.11497641826801434 0.005376559216529131
0.025937142850704878 0.11496828104271621 0.006459631957113743
0.025936946547978075 0.11496462631255862 0.007063510827720165
0.025934690843686117 0.11495779616477549 0.0063516744412481785
0.025932023597193668 0.11495355817565804 0.005636387970298529
0.025929252059328476 0.11495022069498216 0.005622597876936197
0.025925966381826017 0.11494347229701998 0.00556650385260582
0.025922921894800527 0.11493531118006042 0.00526241073384881
0.025921254425450166 0.11493084149522459 0.00515460129827261
0.025919622361673784 0.11492560060629764 0.005193009972572327
0.025918087955621238 0.1149213534610379 0.0051392060704529285
0.025915961525759187 0.11491572296044719 0.00511827552691102
0.025913621767314036 0.1149100039499314 0.005084388889372349
0.025911267601829997 0.11490424411835422 0.004811015911400318
iteration: 23 | epoch: 1396 |   loss: 0.114904  |   KL divergence: 0.025911  |  JS divergence: 0.006535
('==== Found maximium gradient [0.0016031674, 0.0012552079, 0.0011552783] of '
 'gate e^[Y8 Z0], e^[Y8 Z1], e^[X3 Y2] ====')
learning rate =  0.0002703173468095059
0.02590911759720487 0.11489865452674386 0.005115921143442392
0.025915630999659607 0.11489775197737485 0.01150911021977663
0.025902395892260188 0.11489008734653573 0.008837223052978516
0.025900783190539498 0.11488426223338322 0.007762229070067406
0.0259012840404634 0.1148786179960421 0.006685043219476938
0.025902403185292446 0.11487513615189518 0.008036710321903229
0.025900866080573327 0.11487031487367214 0.006547094788402319
0.02589707814687666 0.11486574767954986 0.004586097318679094
iteration: 24 | epoch: 1404 |   loss: 0.114866  |   KL divergence: 0.025897  |  JS divergence: 0.006531
('==== Found maximium gradient [0.0013813741, 0.001337216, 0.0012993827] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y9 Z10] ====')
learning rate =  0.00026794864679568624
0.025892477004156225 0.11485965424404374 0.006310879252851009
0.025904253721772595 0.11486132186352215 0.020760323852300644
0.025892325370809953 0.11484937603225479 0.007001688703894615
0.025885924977113582 0.11484823903409194 0.011547362431883812
0.02588289574014194 0.11484275151857595 0.015389584004878998
0.025881899464528384 0.11483613466461635 0.012109489180147648
0.025881139362696128 0.11482879921169231 0.006259162910282612
0.02588098265968628 0.11482332510807362 0.006378913763910532
0.02588108412109074 0.1148188635842994 0.010338936001062393
0.02588007408988844 0.11481212142439046 0.01094991248100996
0.02587835462989466 0.11480764746935178 0.00841860007494688
0.025875735919823936 0.11480569181410501 0.005187392700463533
0.025871451842129467 0.11480082906696888 0.005333996843546629
0.0258674153713799 0.11479642854795194 0.007703311275690794
0.025864224983470283 0.11479046068634051 0.008714064955711365
0.02586194283598143 0.11478242906125218 0.007716406136751175
0.025861326260786653 0.11477787104320498 0.00552721181884408
0.025861129055383382 0.11477426879645546 0.004420045763254166
iteration: 25 | epoch: 1422 |   loss: 0.114774  |   KL divergence: 0.025861  |  JS divergence: 0.006521
('==== Found maximium gradient [0.0011269823, 0.0010750294, 0.0010459576] of '
 'gate e^[Y1 Z3], RY[3], e^[X0 Y10] ====')
learning rate =  0.00021663500411619235
0.025860295321420125 0.11476937221089013 0.005988897755742073
0.025852892179740516 0.11476803785481626 0.01708647981286049
0.02585233094266942 0.11475794884338837 0.00753662409260869
0.025856720869764382 0.11475431861017664 0.007581495214253664
0.02585828466920919 0.11475452223657868 0.011627012863755226
0.02585360038127115 0.11474498559802923 0.010385842062532902
0.025848627462087832 0.11474050807666122 0.006376180797815323
0.025844393184920128 0.11473711754591259 0.004870169330388308
iteration: 26 | epoch: 1430 |   loss: 0.114737  |   KL divergence: 0.025844  |  JS divergence: 0.006517
('==== Found maximium gradient [0.0022228204, 0.0022186413, 0.0014847646] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[X1 Y8] ====')
learning rate =  0.0004011288420395289
0.025841389321659615 0.11473316180411393 0.008375410921871662
0.025870591129692103 0.11475502047943101 0.03964116796851158
0.025839295422682585 0.11471819953355376 0.010948465205729008
0.025835383992148235 0.1147235593712091 0.02283768355846405
0.025832512916290747 0.11472294286892533 0.029890676960349083
0.025827666504961103 0.11471310977494488 0.02195640839636326
0.025825620415368233 0.11469860436267582 0.009989834390580654
0.025828727814028937 0.11469259430929701 0.011979312635958195
0.025832585800296314 0.11468978860495536 0.019779859110713005
0.02583296057394437 0.11468688037544168 0.020701130852103233
0.025827709030810563 0.11467563494519414 0.015164569020271301
0.02582068494092101 0.11466465366276991 0.007496309000998735
0.025815119953033927 0.11466009855970384 0.008932738564908504
0.025810531524730673 0.11465642728201626 0.014693637378513813
0.025806843884394064 0.11465306544988849 0.016363007947802544
0.025802751460745788 0.11464330160495792 0.013343112543225288
0.025801108340520417 0.1146375506542391 0.007447876036167145
0.02580040631552363 0.11462869834809221 0.005184514913707972
0.025801659248039708 0.11462446114337622 0.009930313564836979
0.025801934230097787 0.11461867790952115 0.012634462676942348
0.02580111228345261 0.1146160676546033 0.011316414922475815
0.025796178106388786 0.11460392381682072 0.0069274092093110085
0.025791999734184914 0.11459977545785713 0.004075360484421253
iteration: 27 | epoch: 1453 |   loss: 0.114600  |   KL divergence: 0.025792  |  JS divergence: 0.006501
('==== Found maximium gradient [0.0018921134, 0.0018586777, 0.0012743562] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[X1 Y8] ====')
learning rate =  0.00033977952512408193
0.02578771827550616 0.11459539704788549 0.008105982095003128
0.02581138419359897 0.11462060173696215 0.04255424439907074
0.02578578493926641 0.11458673335017995 0.012144234962761402
0.025779732352795518 0.11458864823223963 0.02203657291829586
0.02577894310348423 0.11458907052808726 0.03154876083135605
0.02577556324397541 0.1145792495187014 0.02408108115196228
0.02577455137950194 0.11456841865791022 0.010421562008559704
0.02577814608826724 0.11456195510902312 0.010743622668087482
0.02578383935442588 0.11456284388644312 0.01951834000647068
0.025784806368735064 0.11455939629677817 0.02116192877292633
0.025779596453190962 0.11455195980321559 0.016055850312113762
0.025770976170922003 0.1145446765210404 0.008004291914403439
0.02576246855648699 0.11453899385541698 0.007507366593927145
0.02575742237566537 0.11453756279361228 0.013447750359773636
0.02575612392051291 0.11453607283095962 0.015799442306160927
0.02575602747494277 0.11452531394045243 0.013503681868314743
0.025759242591370506 0.11452112263383836 0.008238526992499828
0.025761995323849932 0.11451552884555126 0.005268279928714037
0.025763175749381098 0.11451120240002738 0.008820830844342709
0.025761856505360337 0.11450807645277823 0.011395076289772987
0.025757279617981438 0.11450167622578027 0.010698843747377396
0.025752057703613163 0.11449797467892427 0.007554733194410801
0.02574736946495388 0.11449556937781409 0.005004514008760452
0.02574269051935521 0.11448728130444515 0.006525660865008831
0.02574049307162883 0.11448189721799049 0.008572090417146683
0.02574038153156362 0.11447856829173259 0.008600817993283272
0.02574076482092585 0.11447336546600176 0.006683846935629845
0.0257410436815132 0.1144677606681531 0.004593446850776672
iteration: 28 | epoch: 1481 |   loss: 0.114468  |   KL divergence: 0.025741  |  JS divergence: 0.006487
('==== Found maximium gradient [0.0013491118, 0.0012886494, 0.0012514937] of '
 'gate e^[Y9 Z8], e^[Y8 Z9], e^[Y8 Z1] ====')
learning rate =  0.00025940844884676247
0.025740666923792666 0.11446323077183858 0.0055251638405025005
0.025732083119490923 0.11448122690894319 0.03532452881336212
0.025730019801498714 0.11445842396937413 0.01085401140153408
0.025741862293330572 0.11445659178045398 0.01595756784081459
0.025746763648020008 0.11446056760613567 0.025333477184176445
0.025740196999032627 0.11445356839140657 0.021854640915989876
0.02573042277938472 0.11444271774733956 0.01202948484569788
0.025724853777169012 0.11444076728828931 0.00605434738099575
0.0257221498612443 0.11443793404568553 0.01365613006055355
0.025721488261705724 0.1144367732988349 0.01813594438135624
0.02572083325712399 0.1144328240085101 0.016974397003650665
0.025719364467006102 0.11442276431233522 0.011668631806969643
0.025720238392682476 0.11442052330750649 0.005357588641345501
0.025720964894578046 0.11441770277542619 0.006538711488246918
0.025720454337217438 0.11441315568519128 0.011206690222024918
0.025719134336603625 0.11441014951719924 0.013006090186536312
0.025716437325920407 0.11440515556129582 0.011314586736261845
0.025713897293405796 0.11440247914851054 0.007226401939988136
0.025710994755057753 0.11439796783177193 0.004182680509984493
iteration: 29 | epoch: 1500 |   loss: 0.114398  |   KL divergence: 0.025711  |  JS divergence: 0.006479
('==== Found maximium gradient [0.0016333167, 0.0015436057, 0.0011443998] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[Y0 Z1] ====')
learning rate =  0.00029120653597626935
0.025707916850532184 0.11439200255208887 0.007090127561241388
0.025722497425111623 0.11441330198345993 0.04260566458106041
0.025711401389282747 0.11438881515768899 0.012895089574158192
0.025710392843183535 0.11438791019886936 0.02302182838320732
0.025708630972111048 0.11439158742808045 0.031389862298965454
0.025700970414249256 0.11438265938496063 0.02438727393746376
0.025695512966260166 0.11437263751998118 0.011247347109019756
0.02569695538713268 0.114369484823464 0.010495541617274284
0.02570273336279665 0.11437046638554908 0.019758805632591248
0.02570718833261023 0.11437015537334737 0.021998494863510132
0.025706465107542757 0.11436351152765602 0.01699938252568245
0.025701750469043407 0.11435575191661694 0.008390508592128754
0.02569671514464497 0.11435545250846357 0.007292806636542082
0.025690076394625887 0.11434803982833436 0.013779670931398869
0.025686866949341188 0.11434934320222492 0.016416339203715324
0.025684002946949863 0.11434250192782301 0.014162997715175152
0.02568451758094445 0.11434022215355966 0.00888944324105978
0.02568527832085367 0.11433229720548244 0.0055993045680224895
0.02568762008988818 0.11433069760579108 0.00869081262499094
0.02568895830445761 0.11432987182770243 0.011318027041852474
0.025687077576295562 0.11432249843438229 0.0109305614605546
0.025685175379612703 0.11432125412371037 0.008169809356331825
0.02568152261461972 0.11431552737299663 0.005554326809942722
0.025677853571517827 0.11430976009371607 0.006340231280773878
0.025675291704746743 0.11430693748236873 0.008321240544319153
0.025673166554428653 0.1143035494729683 0.008786007761955261
0.025671334965988918 0.11429896515679777 0.007373080123215914
0.025670724323308407 0.11429718487023978 0.005215846933424473
0.02566949714330195 0.1142904304952382 0.004797668661922216
iteration: 30 | epoch: 1529 |   loss: 0.114290  |   KL divergence: 0.025669  |  JS divergence: 0.006467
('==== Found maximium gradient [0.0014067594, 0.0011521237, 0.0009722581] of '
 'gate e^[X2 Y1], e^[Y0 Z10], e^[Y0 Z1] ====')
learning rate =  0.00023809372442299047
0.025669465699379872 0.11428754744711088 0.00646433187648654
0.02568037045279111 0.1143039813613692 0.03785635530948639
0.025665476919420883 0.11428405267095852 0.011304906569421291
0.025664618926074127 0.11428017141866419 0.018688997253775597
0.02566897882787427 0.11428312759830378 0.02736085280776024
0.025669120171031908 0.11427909509984849 0.02208312600851059
0.025665271042149003 0.11426786949308566 0.010818308219313622
0.025661589165934015 0.11426191868092658 0.008354202844202518
0.025659088156605805 0.11426226782114915 0.016551164910197258
0.025656296145777722 0.1142606884673055 0.019431542605161667
0.02565267367434531 0.11425204589858527 0.016067950055003166
0.025652017289223908 0.11425015740456317 0.009222359396517277
0.02565158958537926 0.11424346482559652 0.006030824035406113
0.025653206330325508 0.11424386203559272 0.010588412173092365
0.025652866965963306 0.11423869366603404 0.013456305488944054
0.0256517301899433 0.1142353721702177 0.012553848326206207
0.02564977055616155 0.11423266408881987 0.00894151907414198
0.025646778126481484 0.11422692665416194 0.005719609092921019
0.025644019401228915 0.11422171993111938 0.006989270448684692
0.025642772122687486 0.11422195019924154 0.009449987672269344
0.025640466151033207 0.11421638541981821 0.009954645298421383
0.025638644008967766 0.11421174409431561 0.008265308104455471
0.02563777134190199 0.11420981102292484 0.005719335749745369
0.02563673717886527 0.11420559707947363 0.005083837546408176
0.025635390173203598 0.11419884065170184 0.0065806955099105835
0.025635430498984785 0.11419782613653726 0.007462562993168831
0.025634075160896743 0.11419127156962793 0.006853145081549883
0.025633291733852454 0.11418849798550997 0.005388136487454176
0.025631320889922843 0.11418245008230271 0.004608016926795244
iteration: 31 | epoch: 1558 |   loss: 0.114182  |   KL divergence: 0.025631  |  JS divergence: 0.006455
('==== Found maximium gradient [0.0015328862, 0.0014366636, 0.000997187] of '
 'gate e^[X9 Y1], e^[X8 Y1], e^[Y2 Z1] ====')
learning rate =  0.00026852992666628146
0.025630346027146356 0.11418286143252919 0.0057146428152918816
0.02563739812519731 0.11420800856924805 0.04596342891454697
0.025626206629081442 0.1141774741929951 0.010464068502187729
0.025627826613514846 0.11417639422200186 0.026321830227971077
0.025630998182069625 0.11418372567812113 0.035114116966724396
0.02562590136866776 0.11417333630732279 0.025990145280957222
0.025619750434222013 0.11415860756653635 0.009894284419715405
0.02561912319889971 0.11415684016947204 0.012062154710292816
0.02562039856719376 0.11415721944110872 0.023040710017085075
0.025619812514653468 0.11415470697359513 0.02500917762517929
0.025616236898159908 0.11414664643748632 0.018747584894299507
0.02561279369908736 0.11414007616063467 0.00824365857988596
0.025611507763079775 0.11413765906090864 0.007556282915174961
0.025610977382978593 0.11413360751009463 0.015743838623166084
0.02561231705460411 0.11413789409413358 0.01895948313176632
0.025608965994573258 0.11412548797977404 0.016314903274178505
0.025606111103005317 0.11411831086826671 0.009703481569886208
0.02560429062162263 0.11411587090832664 0.004862071480602026
iteration: 32 | epoch: 1576 |   loss: 0.114116  |   KL divergence: 0.025604  |  JS divergence: 0.006448
('==== Found maximium gradient [0.0016797923, 0.0016217981, 0.0014252545] of '
 'gate e^[Y1 Z2], e^[X2 Y1], e^[Y2 Z1] ====')
learning rate =  0.0003158751331430638
0.0256031196173711 0.11411446170025777 0.010027151554822922
0.02562715397554061 0.11416302681410849 0.06461462378501892
0.02560156462730321 0.11410623820707536 0.016759464517235756
0.025605638168409255 0.11411460347501388 0.032237883657217026
0.02561224743121769 0.11412712029295603 0.04794219508767128
0.025606095711452004 0.1141117264277391 0.03759521245956421
0.025599132944838725 0.1140950557602049 0.015557636506855488
0.025598168359182997 0.11408959661011132 0.013748528435826302
0.025600947392137842 0.11409350422485061 0.02968507632613182
0.025600538090639002 0.11409251735880553 0.03385874256491661
0.025594973170492752 0.11408080359123544 0.026688437908887863
0.025590191593113376 0.11407555685356732 0.013531583361327648
0.02558671045859942 0.11406999131110677 0.009693127125501633
0.025586544809424377 0.11407029136158353 0.019722187891602516
0.025586143248897866 0.11406489898342172 0.024718033149838448
0.025586216527157604 0.11406117866595601 0.022203803062438965
0.025584691684430276 0.1140509065843113 0.014174263924360275
0.02558414286955564 0.11404508450112265 0.006980696693062782
0.02558491598767343 0.11404676076722733 0.011919724754989147
0.025583365301176154 0.11404268906642814 0.017486456781625748
0.02558075219101911 0.11403931473070714 0.018026286736130714
0.02557703686625322 0.11403422875389 0.013713536784052849
0.0255728864370361 0.11402631330477639 0.007519849576056004
0.025570533270582885 0.11402213431094925 0.007515093311667442
0.025569574071274616 0.1140193496612671 0.012137860991060734
0.02556985519470777 0.11401866806676932 0.013973635621368885
0.025569304212881946 0.11401247183135285 0.011853652074933052
0.025569589894925714 0.11400897714220283 0.007237524259835482
0.025568942071826774 0.11400182836267997 0.005337304901331663
0.025568269442826266 0.11399733466844841 0.008758515119552612
0.02556753310800177 0.11399732207679081 0.010914565064013004
0.02556438721116569 0.11399135983789019 0.00992790050804615
0.025561343489718794 0.11398769265868168 0.006639943458139896
0.025558235240109646 0.11398197323702057 0.00465481448918581
iteration: 33 | epoch: 1610 |   loss: 0.113982  |   KL divergence: 0.025558  |  JS divergence: 0.006433
('==== Found maximium gradient [0.0017050819, 0.0013558865, 0.001248625] of '
 'gate e^[X2 Y1], RY[1], e^[X0 Y1] ====')
learning rate =  0.00028993786127049626
0.025555872224567268 0.11397544947306834 0.007325274869799614
0.025589645681719717 0.11402658592471465 0.06402801722288132
0.02556000627630904 0.1139745821325277 0.017298875376582146
0.025557557166624185 0.1139803915735811 0.03173816576600075
0.02556281433063081 0.11399515381847844 0.048474863171577454
0.025559286466477704 0.1139815947537543 0.03954652324318886
0.02555456933620142 0.11396183825880078 0.017905551940202713
0.025555779798030365 0.11395674165222426 0.010280068032443523
0.025560396978480716 0.1139637150149133 0.027970217168331146
0.02555942987587747 0.11396054762635689 0.03457776457071304
0.025553997402191754 0.11395550139241148 0.02953282929956913
0.025545716892711748 0.11394460692650671 0.017094802111387253
0.025540192902727514 0.11393758330030505 0.007398306857794523
0.025540785797961752 0.11394138676823139 0.016382023692131042
0.025542356244930165 0.11393779473442169 0.023725589737296104
0.02554416089877782 0.11393361056756358 0.02403469942510128
0.025545133604030677 0.11393017742083937 0.01805819943547249
0.025544684697060553 0.1139249212782778 0.009388755075633526
0.02554284272399243 0.11391686880171267 0.008533680811524391
0.025542089251838804 0.11391758588878094 0.01497990544885397
0.025539735747083285 0.11391585425789413 0.01818007230758667
0.02553607692389268 0.11391105604646337 0.016531195491552353
0.02553220724127888 0.11390470264827396 0.011425803415477276
0.02552992665907107 0.11390166736021437 0.007218714337795973
0.025529033048085913 0.11389934006187225 0.009437577798962593
0.025529311317875482 0.11389731294160053 0.012769526802003384
0.025529808957107596 0.1138939146242716 0.013255346566438675
0.02552961650918924 0.11388752228682104 0.010768408887088299
0.025530721396368507 0.11388791959880452 0.007286046165972948
0.025529930286440773 0.11388257113595943 0.0067204260267317295
0.02552836407945074 0.11387856175936109 0.008915749378502369
0.02552546039999625 0.1138740115165916 0.010116622783243656
0.025522360836663413 0.11387167353522332 0.009252265095710754
0.025518565040009322 0.11386568214448894 0.007182138506323099
0.02551675825057706 0.11386408117048967 0.00603174464777112
0.0255161740930758 0.1138613579844665 0.006810721941292286
0.025516107667015397 0.11385556922021199 0.007684133481234312
0.025517428381161278 0.11385412551480495 0.0074106971733272076
0.02551781638015457 0.11385026823636647 0.006225695367902517
0.02551719779202505 0.11384573785580329 0.005346222780644894
0.025515694916456975 0.11384206157782596 0.005601033102720976
0.025513326491101523 0.11383858856292793 0.006136342883110046
0.02551095501339478 0.11383676293699586 0.006092904135584831
0.025508155890156592 0.11383227265139673 0.005554763600230217
0.025506203259775005 0.1138285638140086 0.00509640434756875
0.02550528738591141 0.11382509007756077 0.005006726831197739
0.025505474972810336 0.11382273698927858 0.005046865902841091
0.025505142433262643 0.11381664181318883 0.004950878210365772
iteration: 34 | epoch: 1658 |   loss: 0.113817  |   KL divergence: 0.025505  |  JS divergence: 0.006414
('==== Found maximium gradient [0.0013932876, 0.001054625, 0.00083278905] of '
 'gate e^[X9 Y1], e^[X8 Y1], e^[Y1 Z9] ====')
learning rate =  0.00022351799925935192
0.0255050926979293 0.11381269033634703 0.005099909845739603
0.02549448310980648 0.11384225571234391 0.04766872525215149
0.025502535813205246 0.11381139818968612 0.013908273540437222
0.02551532464122313 0.11381318800131715 0.024475455284118652
0.025519364485620612 0.11382442003327578 0.03498586267232895
0.025510522124214282 0.11381382694141107 0.02870100736618042
0.02549984425479476 0.11380463499101143 0.015631020069122314
0.02549176408330769 0.11379833846508963 0.010614085011184216
0.0254898927941984 0.11380200561062635 0.01906987652182579
0.025490391713195133 0.11380125070005359 0.023853154852986336
0.025492222189746193 0.11379738954676397 0.02208591066300869
0.02549449048666974 0.1137928878807073 0.015482530929148197
0.025495807032627958 0.11378711017651569 0.007967871613800526
0.025496485032238274 0.11378452953235413 0.009518743492662907
0.02549644363709908 0.11378597868648326 0.015458029694855213
0.02549468355806431 0.11378604498903162 0.01772340200841427
0.02549040995318777 0.11377772187607742 0.01521771028637886
0.02548765950817581 0.11377434180252859 0.009199234656989574
0.02548604893148236 0.11377149567544499 0.004399992525577545
iteration: 35 | epoch: 1677 |   loss: 0.113771  |   KL divergence: 0.025486  |  JS divergence: 0.006409
('==== Found maximium gradient [0.0018884976, 0.0017744864, 0.0012414154] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[X1 Y2] ====')
learning rate =  0.0003317898506435537
0.0254858906567147 0.11377114356447271 0.009269440546631813
0.025523659164283806 0.11382555503450507 0.07287956029176712
0.02550340221874883 0.11377131301179233 0.027116425335407257
0.02548489798252735 0.11377469016933227 0.03415120020508766
0.025479029531887347 0.11379484190050865 0.05475226044654846
0.025475219492813714 0.11378123196110325 0.04626588150858879
0.02547553256514313 0.11375734595114873 0.02125568315386772
0.025485336659246634 0.11375083024292035 0.011447891592979431
0.025497417196861473 0.1137599795594254 0.031885214149951935
0.025499962593612667 0.1137644305148231 0.039228405803442
0.025490550579906235 0.1137551532686552 0.03354368358850479
0.025477334031828565 0.11374410179134405 0.02005445398390293
0.025468295656003538 0.1137366361410564 0.009172100573778152
0.025466922388034413 0.11373544661819644 0.018518302589654922
0.025470287452828026 0.11373738503095873 0.027633866295218468
0.02547254183588986 0.11373538784557437 0.02855016104876995
0.025471644962431445 0.11372903391084262 0.02109334245324135
0.025470691603261417 0.11372670532468265 0.0087022315710783
0.025469803419703847 0.11372096916557865 0.008494263514876366
0.0254711596751311 0.11372054236322136 0.018261190503835678
0.02547193856473902 0.11371844895123816 0.021974025294184685
0.02547014845949669 0.11371005621701642 0.018942464143037796
0.025468720767745437 0.11370865052282417 0.011507433839142323
0.025465196773215872 0.11370268096512952 0.005762822926044464
0.025461877396971908 0.1137007995807951 0.010655993595719337
0.025458789433183422 0.11369965640798062 0.015606827102601528
0.025456684806841615 0.11369766216751051 0.01625226065516472
0.02545519255510983 0.11368983758967281 0.012275255285203457
0.025456511213536887 0.11368644747601789 0.005748898256570101
0.025459951272223516 0.1136892952706753 0.005953972693532705
0.025460351130256048 0.1136826652050201 0.011177115142345428
0.02545968241567622 0.11368014299226716 0.012970066629350185
0.025456861541582276 0.11367669511914943 0.010694720782339573
0.025452910163423048 0.1136716353133247 0.006209481507539749
0.025450158550107876 0.11366875498756825 0.00479824747890234
iteration: 36 | epoch: 1712 |   loss: 0.113669  |   KL divergence: 0.025450  |  JS divergence: 0.006398
('==== Found maximium gradient [0.0015173162, 0.0013199726, 0.00094727793] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[X2 Y1] ====')
learning rate =  0.000256694680282039
0.025449159952777585 0.11366708405475702 0.008427874185144901
0.02549363084569787 0.11370785955820445 0.06395678222179413
0.02545014799943112 0.1136604781952891 0.016567056998610497
0.025437196448064997 0.11367136772358506 0.033820100128650665
0.02544503572446067 0.11368335684885532 0.0476454421877861
0.02544925273758816 0.11366925961172063 0.03699455410242081
0.025452877173377325 0.1136578728761092 0.01663368195295334
0.02545617888851192 0.11365386963659076 0.015035047195851803
0.025459203513547007 0.11366353783004617 0.029126454144716263
0.025455735239351088 0.11366060404288568 0.033303964883089066
0.025449129791402198 0.11365245311801522 0.02703649364411831
0.025443905998154583 0.11364864897544906 0.014599036425352097
0.02543937144336272 0.11364067312597087 0.008222291246056557
0.025438653529380142 0.11364134813409178 0.018346957862377167
0.025439831760550233 0.1136453806500952 0.024694444611668587
0.025439958678771964 0.11364340155470536 0.023351768031716347
0.025438599419988876 0.11363399656935544 0.015359504148364067
0.025439324826645713 0.11363145429926723 0.005136189982295036
0.02544081344061079 0.11363058384644888 0.010143301449716091
0.025442731588026766 0.11363341424669515 0.017461443319916725
0.02544266186461635 0.11363249657388758 0.018978510051965714
0.025440355268225075 0.11362668559587769 0.014746843837201595
0.02543776683492282 0.11362229035622813 0.007379536051303148
0.025435684926254296 0.11362119759671852 0.005982653237879276
0.025433226369808135 0.11361935294327007 0.011827347800135612
0.02543117675240052 0.11361974266668642 0.014722764492034912
0.02542792168244296 0.11361275917256315 0.013257243670523167
0.025427133872212626 0.11361060074675565 0.00846010260283947
0.02542695135526318 0.11360306299856539 0.004241526126861572
iteration: 37 | epoch: 1741 |   loss: 0.113603  |   KL divergence: 0.025427  |  JS divergence: 0.006391
('==== Found maximium gradient [0.0014578184, 0.0012852284, 0.0010210318] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[X1 Y8] ====')
learning rate =  0.0002534969554271076
0.025430550584347938 0.11360649086133832 0.007822482846677303
0.02545079696136326 0.11365481309611929 0.07036039978265762
0.02542218197511873 0.11360577170884993 0.022314345464110374
0.02543057911969412 0.11361137291152629 0.03414652496576309
0.02544368054765655 0.1136230453666274 0.050586067140102386
0.02544268740997325 0.11361389658156441 0.0420495867729187
0.02543272858821583 0.1135987286674567 0.019668348133563995
0.025424865926838774 0.11359364473355514 0.010781530290842056
0.025422993253507324 0.11360012781124798 0.02986021712422371
0.02542335199556431 0.11360481864829337 0.036579255014657974
0.025421101275996637 0.11359226704875187 0.03023003600537777
0.025422276774656513 0.11358939257720295 0.016187584027647972
0.02542256416063187 0.11358024685888504 0.008062480948865414
0.025425258092900853 0.11358594460676673 0.01875070296227932
0.025425193366504693 0.11358766912935152 0.025728868320584297
0.025422363577775803 0.1135832856212085 0.0250481516122818
0.02541934423927891 0.11357757513067279 0.017612168565392494
0.025417737739564145 0.11357252177769865 0.007069638464599848
0.025417867389263608 0.11357001755763611 0.009624836035072803
0.025418593295878117 0.11357059711198608 0.018081270158290863
0.02541780728570368 0.11357083134948309 0.020785383880138397
0.025414656987969034 0.1135670475020415 0.016874922439455986
0.0254111541235409 0.11356199165091556 0.00865512527525425
0.02541013509926631 0.11356142953174052 0.005301350727677345
0.025410365523230553 0.11355815274142138 0.011982053518295288
0.025412065425921927 0.1135570535064024 0.015573437325656414
0.025413767401313014 0.11355760613878729 0.014326714910566807
0.02541333715045805 0.11355436622664851 0.00929204374551773
0.025412061546407745 0.11355323654083796 0.004441512282937765
iteration: 38 | epoch: 1770 |   loss: 0.113553  |   KL divergence: 0.025412  |  JS divergence: 0.006385
('==== Found maximium gradient [0.0012706707, 0.0011668205, 0.0011217041] of '
 'gate e^[Y2 Z1], RY[0], e^[Y1 Z2] ====')
learning rate =  0.00023760734848575634
0.025408466316954252 0.11354503401504819 0.008154535666108131
0.025432821424236737 0.11359398554245005 0.07219881564378738
0.025410694636159293 0.11354484095883628 0.017986774444580078
0.025403059558329673 0.1135533629545984 0.037929877638816833
0.025417467191323574 0.11356601568345662 0.054684970527887344
0.02541798992456084 0.11355629428300282 0.043946970254182816
0.025409253855938126 0.11354179228861827 0.01844037137925625
0.025402832308464345 0.11353363853138014 0.014908756129443645
0.025404515997490204 0.11353961912403202 0.03257690370082855
0.025407200385744705 0.11354190206211238 0.03753317892551422
0.025407282524896428 0.11353794820120877 0.03082604520022869
0.025403541668783287 0.11352821357417807 0.01675962656736374
0.02539969595007314 0.11352361750677645 0.0075636329129338264
0.025397768736985432 0.11352458103731823 0.01969393715262413
0.025398034724750426 0.11352810363620583 0.02720475383102894
0.025396777061096026 0.11351963587074906 0.02577260509133339
0.02539700020111356 0.11351623110239951 0.01742716133594513
0.02539745693281463 0.11351622182392786 0.0076212151907384396
0.025395800907326314 0.11351190338482892 0.010496151633560658
0.025394150637542773 0.11351127114027135 0.01788380555808544
0.025392541593349797 0.113510334802792 0.020329810678958893
0.025392031928632444 0.11350979324760384 0.0166639294475317
0.025392639024488586 0.11350910733463015 0.00870911218225956
0.025392577864473437 0.11350407023983021 0.005564925726503134
0.025392091145595548 0.11350150373051779 0.012158885598182678
0.025389562493191915 0.11349708474169601 0.015625569969415665
0.02538783127039862 0.11349982684132007 0.014320707879960537
0.025384745398187157 0.11349342561747547 0.009398291818797588
0.025384907006776557 0.11349357144546623 0.004452748689800501
iteration: 39 | epoch: 1799 |   loss: 0.113494  |   KL divergence: 0.025385  |  JS divergence: 0.006378
('==== Found maximium gradient [0.0013276897, 0.0011305809, 0.0011229982] of '
 'gate e^[Y1 Z2], RY[2], e^[Y2 Z1] ====')
learning rate =  0.00023950220095694428
0.025386051632540846 0.11349194236009023 0.007763133849948645
0.025411856952205946 0.1135468371238862 0.08343303203582764
0.025375383390469713 0.11349369959632247 0.025298185646533966
0.025387810103094384 0.11350013478327015 0.03998861089348793
0.025406145529908747 0.11351457392784604 0.061284348368644714
0.02540570554981654 0.11350318376215113 0.051349882036447525
0.025393416169534756 0.11348676629544756 0.024630263447761536
0.02538180343806628 0.11347890169285348 0.010880581103265285
0.02537776972801633 0.11348574443537945 0.03420218080282211
0.025378051434758714 0.11349324808473002 0.0438806414604187
0.025377036727537532 0.11348555080139874 0.0382293201982975
0.02537699368340399 0.11347582221617264 0.022169874981045723
0.025378660030120244 0.11346909917667469 0.0061379713006317616
0.025381935317033484 0.11347032171510087 0.01917394995689392
0.02538373607416955 0.11347292814882974 0.030088825151324272
0.025381577252754146 0.11346870308369758 0.031439196318387985
0.025378267679405826 0.11346512989712249 0.023831656202673912
0.02537519697863394 0.1134605082653243 0.010715381242334843
0.025373723628801633 0.11345701006773021 0.007633439265191555
0.025373973935745843 0.11345788343790435 0.018781514838337898
0.025373665680968743 0.11345877296855233 0.024188125506043434
0.025371336573425367 0.11345559450646045 0.022065922617912292
0.02536807587833895 0.11344967727628012 0.01402776874601841
0.025366139587445324 0.11344523369285406 0.004962073639035225
iteration: 40 | epoch: 1823 |   loss: 0.113445  |   KL divergence: 0.025366  |  JS divergence: 0.006373
('==== Found maximium gradient [0.0017054077, 0.0016471021, 0.0011366373] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y1 Z0] ====')
learning rate =  0.0003036073076404698
0.025366925586377494 0.11344551631924181 0.0103042833507061
0.02543261759044132 0.1135626376205075 0.11971399188041687
0.02537184851081583 0.11345151802962741 0.029460031539201736
0.02537237238661005 0.11347605310037161 0.061898283660411835
0.025387837138321802 0.11350727913662356 0.08860588818788528
0.02538369743783661 0.11347983184557446 0.06950549781322479
0.02537827186881765 0.11344758319485879 0.032116346061229706
0.025380749248310006 0.11344450134179403 0.02639986388385296
0.02538379006088279 0.11345621939878302 0.0521286278963089
0.025378772588147386 0.11345950978509549 0.06084905192255974
0.02536714026613357 0.11345185836167457 0.05094439908862114
0.02535615208265684 0.11343783825396182 0.030573466792702675
0.025353823569853738 0.11343256962327147 0.017997704446315765
0.02536006951919657 0.1134374460094658 0.031197845935821533
0.025367005406055222 0.11343535504184128 0.04234636574983597
0.02537284636548728 0.1134358054635869 0.04205168038606644
0.025373058831204512 0.1134266192568195 0.0316755473613739
0.02537188945244194 0.11342545559957638 0.017682252451777458
0.025367843344974484 0.11342044925648685 0.016831345856189728
0.025363603004553925 0.11341893443631738 0.02726803906261921
0.025359815086118405 0.1134213871943076 0.03247725963592529
0.025355121777640377 0.11341831638243736 0.029344741255044937
0.025351218331541664 0.11341165440798957 0.019823968410491943
0.025351152784450676 0.11341059747898208 0.011034900322556496
0.02535332260458572 0.11340860193447187 0.015683306381106377
0.025356815778151954 0.1134074819853307 0.022834723815321922
0.025360206648106037 0.11340912383301338 0.024205338209867477
0.025359962976415483 0.11340368279485986 0.01915787346661091
0.025358479882288495 0.11340203315908888 0.010654385201632977
0.025355847353709673 0.11340097304471285 0.008848324418067932
0.025351971861433953 0.11339583534311747 0.015429715625941753
0.025350114280589385 0.11339776935445081 0.01887514628469944
0.02534803898229391 0.1133946457068769 0.016782401129603386
0.025347322609283157 0.11339181294285924 0.010404188185930252
0.025348241570304984 0.11339055978656433 0.005628959741443396
0.025349230277171897 0.11338668614645545 0.010320848785340786
0.02535059154499083 0.11338601668339651 0.014159017242491245
0.025350811254468295 0.1133855084665729 0.013430051505565643
0.025348544264342653 0.11337965011971544 0.008706474676728249
0.025347293093744255 0.11338138443735869 0.004306838382035494
iteration: 41 | epoch: 1863 |   loss: 0.113381  |   KL divergence: 0.025347  |  JS divergence: 0.006366
('==== Found maximium gradient [0.001142316, 0.0011181053, 0.00095591054] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[Y8 Z0] ====')
learning rate =  0.00021506000209690174
0.025344599355367335 0.11337698889096672 0.0080949105322361
0.025381352922192117 0.11343296720200241 0.08854912221431732
0.02533868520002115 0.11337520404883492 0.023035122081637383
0.02534164737512491 0.11338445001863018 0.04484791308641434
0.025356027684701424 0.11340171060211782 0.067542165517807
0.025352067503118324 0.11338872887253153 0.053829919546842575
0.025343190817024817 0.11337350519516014 0.023107443004846573
0.025340705539572236 0.11336714695411557 0.014858195558190346
0.025346699653238464 0.1133747548509163 0.03892375901341438
0.025352078585311133 0.11338143486025679 0.0476393960416317
0.025348816038515236 0.11337203139282227 0.04026605188846588
0.025341817870247425 0.11336450194297593 0.021824302151799202
0.02533456011908891 0.11335597926987792 0.005464841146022081
0.02533424929040315 0.11336375980242715 0.022674966603517532
0.025334733383922788 0.11336013819996271 0.03379657119512558
0.025337326477826355 0.11336037212258168 0.03405306488275528
0.025337471419968893 0.11335355150367306 0.024737171828746796
0.02533740691426438 0.11335230647906422 0.009740360081195831
0.025335689223916318 0.11334715524901424 0.008776873350143433
0.025335793328473313 0.11334993532191706 0.02106592245399952
0.025334860117390303 0.11334778807377388 0.02626442164182663
0.02533350107294647 0.11334468002008251 0.02322666347026825
0.025331356473759795 0.11333974772776446 0.013927438296377659
0.025330287117894337 0.11334082739923525 0.003912375308573246
iteration: 42 | epoch: 1887 |   loss: 0.113341  |   KL divergence: 0.025330  |  JS divergence: 0.006361
('==== Found maximium gradient [0.0018436518, 0.0018276481, 0.0010092794] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[X1 Y3] ====')
learning rate =  0.00032162077320155584
0.02532859496063221 0.11333879368080914 0.011881466954946518
0.02541443833220751 0.11348037409860738 0.14545202255249023
0.025359965302633312 0.11335037354960628 0.04384317994117737
0.0253336657097655 0.11336367928583907 0.07030357420444489
0.025331003732102002 0.11341180311014758 0.10998208075761795
0.025323536678645488 0.11338870036880568 0.09162981808185577
0.02531852772981119 0.11333918467486083 0.0427858904004097
0.02533221825593856 0.11332847440007017 0.017854396253824234
0.02535559293735369 0.11335167389594619 0.06116602197289467
0.02536505128505112 0.11336455704304335 0.07861294597387314
0.025354261084919106 0.11335333454302376 0.06897135823965073
0.025333501120033228 0.11333034175975697 0.040949445217847824
0.0253180387882046 0.11331982367485596 0.011577471159398556
0.025313923194885315 0.11332451335932911 0.03339637443423271
0.02531755337982686 0.11333382595473182 0.0538988895714283
0.025321301702684332 0.11333520888466889 0.057476986199617386
0.02532090806457411 0.11332508263061475 0.04472862929105759
0.025318010468027088 0.11331055088719091 0.02114803157746792
0.02531810064326695 0.11330637687226958 0.010490290820598602
0.025321900158945795 0.1133116828319522 0.0316983163356781
0.025325212801130467 0.11331456551859626 0.04311300069093704
0.025325326491804235 0.11331133549965151 0.04087779298424721
0.02532219309318666 0.1133038365039158 0.026997920125722885
0.02531753571284308 0.11329606044274869 0.007786362897604704
0.025314719704607348 0.1132979177340413 0.015363017097115517
0.025311333360763882 0.11329620044243442 0.02902468666434288
0.025309340435899906 0.11329895521556835 0.033007342368364334
0.025305955934845338 0.11329198917198541 0.026928981766104698
0.025305503209854 0.11329051356191698 0.013884293846786022
0.02530641112335761 0.11328534806767222 0.005943389143794775
0.025309155876597343 0.11328178914085515 0.017515094950795174
0.025313464141745626 0.11328697041126169 0.02430754341185093
0.02531340212665566 0.11328287711584847 0.023041365668177605
0.02530983761479886 0.11327528436773102 0.014724179171025753
0.025306387728939006 0.1132749539044853 0.004123712424188852
iteration: 43 | epoch: 1922 |   loss: 0.113275  |   KL divergence: 0.025306  |  JS divergence: 0.006354
('==== Found maximium gradient [0.0016137481, 0.0015929132, 0.00095567934] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y8 Z0] ====')
learning rate =  0.00028413326247946573
0.025302475894924324 0.1132716049954554 0.011051361449062824
0.025404492372288527 0.11340316279944186 0.13950732350349426
0.025308069414892304 0.11327628692077403 0.03488818183541298
0.02529063927515194 0.11329964791889975 0.06996026635169983
0.025304856731375613 0.11334020389660955 0.10636911541223526
0.025304939446996057 0.11331406085453176 0.08652724325656891
0.0253046008315191 0.11327342033377136 0.03949237987399101
0.02531553131159949 0.11326604349158 0.020937252789735794
0.025330906469536823 0.11328747061977348 0.06051128730177879
0.02533359216654786 0.11329772855629619 0.07629898935556412
0.025321072607075362 0.1132868528365465 0.06602200865745544
0.025302614756286278 0.11326379279232199 0.03762177750468254
0.0252907011809287 0.11325252777354182 0.007570043671876192
0.02528919312272237 0.11325902711840022 0.033652402460575104
0.025291766694205457 0.11326640137563852 0.05310511589050293
0.025293223011548502 0.11326781589565053 0.055052973330020905
0.02529046620557164 0.11325252381008077 0.0411282517015934
0.02529076487507076 0.11324532949312369 0.01757071726024151
0.025293686712378118 0.11324051610855623 0.011612849310040474
0.025299226268675496 0.11324451289753325 0.031478192657232285
0.025302739561740457 0.11324890094863968 0.04105120524764061
0.02530091047381739 0.11324588398837836 0.03787952661514282
0.025295238252810538 0.11323848257925513 0.02432538941502571
0.025288903770606767 0.11323128587542246 0.007024291902780533
0.025285266983597232 0.11323144177033928 0.015459848567843437
0.02528331347070624 0.1132321780860037 0.027667341753840446
0.025282049649763914 0.113230051938506 0.030894853174686432
0.02528193168037302 0.11322763864011376 0.024792980402708054
0.025282028172511344 0.11322080229068643 0.012381741777062416
0.025283329545429983 0.11321569015112762 0.006259229965507984
0.02528662964669762 0.11322062036029445 0.017073897644877434
0.025286872424296815 0.11321868783831028 0.02301906794309616
0.025285523084938304 0.11321817613265905 0.021413659676909447
0.025281551560214367 0.1132116928331364 0.01349087804555893
0.025278246963035843 0.11320860171341977 0.004651382565498352
iteration: 44 | epoch: 1957 |   loss: 0.113209  |   KL divergence: 0.025278  |  JS divergence: 0.006347
('==== Found maximium gradient [0.0015251067, 0.0014933001, 0.0012486508] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y9 Z8] ====')
learning rate =  0.0002855410131193117
0.02527631164844323 0.11320802969286316 0.011111986823379993
0.025368981814074903 0.11334881895419069 0.15057457983493805
0.02528115768009636 0.1132141982160374 0.03677249699831009
0.025281678304131104 0.11323568097946958 0.07579648494720459
0.025301132773918836 0.11328405132206702 0.11397384852170944
0.02528981754638098 0.11325598229369832 0.09186415374279022
0.02527465474239057 0.1132077992749586 0.04024742916226387
0.02527930040350098 0.1132016305946661 0.020987417548894882
0.02529492160513902 0.11322262527401498 0.06479411572217941
0.02530182430631176 0.11323548618411725 0.08120542764663696
0.02529425108428518 0.11322524826030952 0.06962306052446365
0.025280082761567464 0.1131990365732062 0.03877800703048706
0.02527306458475722 0.113190681900406 0.00613571610301733
0.02527261426849333 0.11319459405558169 0.036335524171590805
0.025274417535837333 0.11320569947527445 0.05678316205739975
0.02527275914169083 0.11320687346703824 0.05856751650571823
0.025268151002862598 0.11319430667436123 0.04353184625506401
0.025265962103312896 0.11318246552242311 0.018223818391561508
0.02526902490120312 0.11318297347063196 0.012783550657331944
0.025273223963571567 0.11318590522327354 0.03424367681145668
0.025276147503915783 0.11318971471772683 0.04448988661170006
0.02527470913115157 0.1131842319144277 0.04088350012898445
0.025271298763646602 0.11317774324254348 0.02585875615477562
0.02526777862787949 0.11317433622182689 0.006312699522823095
0.02526484249961608 0.11317349264535015 0.01727229915559292
0.025263090701366724 0.1131751161568929 0.03082062117755413
0.025261446152858327 0.11317307003763517 0.03407716751098633
0.025260870957988728 0.11317180228473278 0.026807567104697227
0.02525894252358981 0.11316144447245881 0.0124569833278656
0.025260579661260957 0.1131639591049158 0.006928132381290197
0.025261852393764394 0.1131627022459267 0.01963813789188862
0.025262529386421047 0.113159632048665 0.025843167677521706
0.02526230666063358 0.11315775564970817 0.02335456945002079
0.02526100839623744 0.11315793657269005 0.013764971867203712
0.025257302830581037 0.11315095715828116 0.0035618371330201626
iteration: 45 | epoch: 1992 |   loss: 0.113151  |   KL divergence: 0.025257  |  JS divergence: 0.006341
('==== Found maximium gradient [0.0018240961, 0.0017736757, 0.0008969518] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y1 Z8] ====')
learning rate =  0.0003115076164908302
0.02525514180916819 0.11314894218790959 0.012914668768644333
0.02535654190566628 0.11333109312064256 0.17673732340335846
0.025268136500760298 0.11315836942783726 0.044656455516815186
0.025260078127665623 0.1131874063111655 0.08772383630275726
0.025285175471649726 0.11324462690398712 0.13408181071281433
0.025277727773663133 0.11321028284924813 0.10937245190143585
0.025258476855252728 0.11315228137611001 0.049620673060417175
0.025255942389282367 0.11314150405672166 0.023311642929911613
0.02527063941219697 0.11316957893199915 0.0744280219078064
0.02528097435739696 0.11318490580885598 0.09446749836206436
0.025275865279671177 0.11317151885371071 0.08223754912614822
0.025260861594134685 0.11314637240445939 0.047540467232465744
0.025247596041007115 0.1131294747185606 0.009201887995004654
0.025245219226692248 0.11313660893916716 0.04040069878101349
0.025249242426530313 0.11314835861106157 0.06483086198568344
0.025252149763141676 0.11314986704227155 0.06808343529701233
0.025250179352129178 0.1131379716716045 0.05190294235944748
0.025246196298654336 0.1131236220986772 0.02334156446158886
0.025245911347759747 0.11312109306840316 0.012900189496576786
0.02524912468663163 0.11312457523236832 0.037740930914878845
0.025253262755764998 0.11313108984624391 0.0503203384578228
0.025251777608723654 0.1131242392016989 0.04719353839755058
0.02524677257178386 0.11311688632701189 0.030876601114869118
0.025240805478945604 0.11311158959053638 0.008707687258720398
0.02523693958507684 0.11310902239957707 0.018292738124728203
0.025236172422358705 0.11310771650534464 0.03396656736731529
0.025238687262928827 0.113113057712061 0.038367919623851776
0.025238172897650853 0.11310558686595236 0.031060554087162018
0.025237131392620474 0.11309990327762165 0.015576114878058434
0.025237008889561097 0.11309919520867545 0.007137048989534378
0.025236628804814178 0.11309465161982067 0.02083820290863514
0.02523829034069086 0.11309834197073305 0.0282137393951416
0.025236850019609344 0.11309311043694203 0.02613549679517746
0.025234325028746365 0.11309029191976563 0.016161682084202766
0.025230927446856087 0.11308654740815777 0.004933370277285576
iteration: 46 | epoch: 2027 |   loss: 0.113087  |   KL divergence: 0.025231  |  JS divergence: 0.006334
('==== Found maximium gradient [0.0018677794, 0.0016676236, 0.0015062605] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[X1 Y2] ====')
learning rate =  0.0003374095346318482
0.025229378535612752 0.11308687174546804 0.013623679988086224
0.025387305685504305 0.11333604447817913 0.20863978564739227
0.025237250102150395 0.11309752926360737 0.05486133694648743
0.025232695532457064 0.11314371929099504 0.10017997026443481
0.02526695067319469 0.11322482805498653 0.1580810248851776
0.025255285032287925 0.11317281589575232 0.13282662630081177
0.025235381907157326 0.11310209528323062 0.06567057967185974
0.025236163081934132 0.11308222943105639 0.023059090599417686
0.02525622835026472 0.11311437167915936 0.08352518826723099
0.02526903969117502 0.11314010001475805 0.11228382587432861
0.02526013449831646 0.11312424192957567 0.10263044387102127
0.025240932365637087 0.1130923160549712 0.06451164931058884
0.02522525052021761 0.11306702579231358 0.014674032106995583
0.02522295562299668 0.11307254616324262 0.04036969691514969
0.02522847541752905 0.11309438621686096 0.0739206075668335
0.025229224162839445 0.11309854220397972 0.08308238536119461
0.02522353321051666 0.11308334413818115 0.06811875849962234
0.02521731410869963 0.11306243775619094 0.03621344268321991
0.025217970199517666 0.11305593909809712 0.00802911352366209
0.025223914520950724 0.11305865893754305 0.03861890360713005
0.02523180455657975 0.11307131501467016 0.05869002267718315
0.025233170564592032 0.11307144306427187 0.06036804988980293
0.025228261728806947 0.11306178747968948 0.044902168214321136
0.025220565802212748 0.11304750721965333 0.01850643754005432
0.025216406563887572 0.11304525257888073 0.01296080183237791
0.02521544448601931 0.11305035158732676 0.035731371492147446
0.025214744214295537 0.11305394191523106 0.04646540433168411
0.025211027763452076 0.11304439589610463 0.04249655082821846
0.025209096130546192 0.11303963299841399 0.026408415287733078
0.025209110100816112 0.11303568128203627 0.005958049092441797
0.02521127718609582 0.11303429306113338 0.01864328235387802
0.025214488502199116 0.11303742953457294 0.03213770315051079
0.025214962066058853 0.11303507991905798 0.0346420519053936
0.025212942791978176 0.1130295221997089 0.026281479746103287
0.025209586194149536 0.11302228841444387 0.011121708899736404
0.025208072854345814 0.11302342543334538 0.009031319990754128
0.025205977265406403 0.11302094690693229 0.02163139171898365
0.02520395905879532 0.11301849314435637 0.026840699836611748
0.025201881045413023 0.1130153546803066 0.02297844924032688
0.025200783404128138 0.11301396205338952 0.012263000942766666
0.025200331240069797 0.11301071562773725 0.004745571408420801
iteration: 47 | epoch: 2068 |   loss: 0.113011  |   KL divergence: 0.025200  |  JS divergence: 0.006325
('==== Found maximium gradient [0.0023854624, 0.0022700704, 0.001373774] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[X9 Y10] ====')
learning rate =  0.0004120017141465489
0.025200521248306323 0.11300639952496451 0.015054212883114815
0.02536903929561156 0.11341511617102353 0.27427393198013306
0.025204460294509567 0.1130404836100368 0.07511702179908752
0.025249849720832634 0.11310168772783545 0.12849070131778717
0.02532125108321865 0.11322966360063381 0.2059302181005478
0.025294614618423847 0.11316953983284088 0.17572063207626343
0.025229613212431945 0.11304666913047917 0.0889943316578865
0.025196063428301343 0.11300020019564384 0.022801712155342102
0.025209270888169936 0.11305772559357812 0.10551735758781433
0.025227665808704627 0.11310754455081938 0.14601892232894897
0.0252234293981052 0.11308959790290382 0.13610702753067017
0.02520611980239515 0.11303380377794617 0.08839866518974304
0.025196129758487576 0.11298852686987301 0.02322310209274292
0.025206390280247536 0.11299900982956315 0.04728594049811363
0.02522219136072628 0.11303248071716897 0.09282445907592773
0.025224203237190244 0.11304267786093339 0.10771714895963669
0.0252110859258855 0.1130270362412632 0.09124848991632462
0.02519225127326964 0.11299449273192311 0.051660988479852676
0.025183458290143325 0.11297858248605276 0.007169291842728853
0.025187097689713403 0.11298153422809272 0.045485083013772964
0.02519749851004424 0.11300233821957692 0.07411365211009979
0.025200179700851408 0.11300716380667791 0.07917966693639755
0.025191903724727325 0.11298849468847882 0.06159660220146179
0.025182369784014003 0.11297075712071777 0.028744569048285484
0.02517810295800832 0.11296101855391626 0.011475750245153904
0.025182496859521175 0.11296971334605829 0.04181975871324539
0.025187750885001456 0.11297612511560491 0.05817741900682449
0.025188814177592965 0.11297383233563964 0.056098200380802155
0.02518481944581219 0.11296277272649015 0.037798069417476654
0.02517907117364336 0.11294959700152454 0.010651200078427792
0.025176873410693947 0.11294895210874017 0.019456341862678528
0.025177171180781433 0.1129546891235968 0.03928074240684509
0.025175808816002766 0.11295223039950471 0.0455034114420414
0.02517384957648882 0.1129479900379437 0.037204910069704056
0.02517187335452967 0.11294183559240316 0.018443260341882706
0.025171440100401326 0.1129382397166569 0.006945386994630098
0.025171472363620336 0.11293471557620742 0.0246200580149889
0.025171742877090883 0.11293536577855248 0.03390683978796005
0.025170177883816893 0.11293311172617805 0.031379181891679764
0.02516731387531492 0.11292679499461872 0.018895750865340233
0.025166109630087825 0.1129244818920489 0.004320049658417702
iteration: 48 | epoch: 2109 |   loss: 0.112924  |   KL divergence: 0.025166  |  JS divergence: 0.006316
('==== Found maximium gradient [0.0020810212, 0.0020006106, 0.0013225065] of '
 'gate e^[Y1 Z2], e^[Y2 Z1], e^[Y3 Z1] ====')
learning rate =  0.00036664451655146334
0.02516502422976741 0.1129186727213908 0.016595887020230293
0.025316451051819282 0.1132633577148237 0.2533908784389496
0.025179562514811182 0.11293891068829855 0.06170545145869255
0.025211262826391696 0.11300688845147623 0.1263565570116043
0.025251319438205425 0.11311272342605436 0.19156228005886078
0.025211068474305057 0.1130406114946434 0.15623240172863007
0.025160959055470413 0.11293445230516042 0.07276061922311783
0.02515702013056928 0.11292029644880651 0.035829611122608185
0.025187343024210107 0.1129721085226693 0.10553666204214096
0.02520860286521951 0.11300226036807226 0.13500382006168365
0.02520227658885059 0.11297984772672821 0.11908342689275742
0.025179428412100857 0.1129282863526456 0.07125101238489151
0.02516299305951298 0.11290053682370782 0.017712049186229706
0.025162401350951095 0.11291276751165603 0.05536658316850662
0.025168441528608046 0.11293754455253867 0.09133806824684143
0.025167812248575838 0.1129406533086424 0.0980350598692894
0.025160426908878725 0.11292379988701189 0.07674399018287659
0.025152727992084168 0.1128968220950646 0.03690972179174423
0.025154696182323827 0.11288938029807707 0.015170126222074032
0.025163904940427178 0.11289901107423421 0.05143461003899574
0.025170344286556692 0.11290743085590652 0.07179126888513565
0.02516773205793814 0.11290552923112873 0.06962201744318008
0.025157263343311476 0.11289256727092077 0.04774104058742523
0.025145071094663254 0.11287296698475295 0.015386789105832577
0.025142245672738733 0.1128767426315649 0.02262813039124012
0.02514422685804947 0.11288142146828807 0.046950582414865494
0.02514827016120253 0.1128854962281772 0.055544398725032806
0.02514988499058962 0.11288005678846767 0.0469195730984211
0.025149342036018242 0.11287014444551587 0.02555963769555092
0.025148079428693355 0.11286139294697013 0.007573306560516357
0.025148815062748194 0.1128661992136013 0.02727624960243702
0.02514707440202517 0.11286719972026457 0.04011231288313866
0.025142790906511503 0.11286378473809003 0.039464496076107025
0.025137370015986968 0.11285620413825742 0.02671010233461857
0.025134954933024724 0.11285468488595986 0.008597721345722675
0.025133997039481423 0.11284855962830218 0.01576431654393673
0.025136289685334053 0.11284923648347162 0.028719976544380188
0.02513850600358853 0.1128498693386393 0.031611695885658264
0.025137764646953956 0.11284357102661843 0.024016784504055977
0.025136100243633802 0.11283972620578654 0.00999963004142046
0.025133483601187914 0.112835257129308 0.009290315210819244
0.025131536255617475 0.11283454746960651 0.02036134898662567
0.025129644752727366 0.11283328176953719 0.024024752900004387
0.025128212061739565 0.11283177403558026 0.01912698708474636
0.025126219906149008 0.11282426849442734 0.008753458969295025
0.025126556902382576 0.1128240112958637 0.007327193394303322
0.025126275716390256 0.11282078099681202 0.015775300562381744
0.02512586944302218 0.11281970783956238 0.018701523542404175
0.025124153389023098 0.11281598458160606 0.014929075725376606
0.025122417830531884 0.11281303766201846 0.007132419850677252
0.025120458247783566 0.11280751955346108 0.006321035325527191
0.025120365058786592 0.11280823352578916 0.012256912887096405
0.025119312939898504 0.11280402511646079 0.013969656080007553
0.025118480108991197 0.11280147539603035 0.010669315233826637
0.025116828296585167 0.11279648897048856 0.005181577522307634
0.02511621770396081 0.11279709304518198 0.006435004062950611
0.02511478283687671 0.11279455010321358 0.010461574420332909
0.025112730148662464 0.11278897058896298 0.010946091264486313
0.02511191428193875 0.11278758189335768 0.007773806806653738
0.025110672005502384 0.1127826327095533 0.00413745641708374
iteration: 49 | epoch: 2169 |   loss: 0.112783  |   KL divergence: 0.025111  |  JS divergence: 0.006300
('==== Found maximium gradient [0.0009913603, 0.00089636503, 0.00086333964] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], e^[X8 Y0] ====')
Convergence criterion has reached, break the loop!
