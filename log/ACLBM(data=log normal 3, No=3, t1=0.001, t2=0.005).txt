('==== Found maximium gradient [0.6633792, 0.66337913, 0.42681465] of gate '
 'e^[Y0 Z1], e^[Y1 Z0], RY[0] ====')
learning rate =  0.11901341161298669
0.4315549082444933 0.4315549082444933 1.16256582736969
0.2085879470010289 0.2085879470010289 0.6370769739151001
0.11359420976006981 0.11359420976006981 0.2555930018424988
0.11664511382809992 0.11664511382809992 0.33100056648254395
0.1680497545833358 0.1680497545833358 0.7521302700042725
0.18389779803917938 0.18389779803917938 0.7874664068222046
0.16390764245590123 0.16390764245590123 0.5959736704826355
0.13868324106998037 0.13868324106998037 0.4414282739162445
0.12034442368459525 0.12034442368459525 0.32484278082847595
0.11134110106881677 0.11134110106881677 0.25579026341438293
0.11014129694170222 0.11014129694170222 0.2464207261800766
0.11385287540250404 0.11385287540250404 0.271619975566864
0.11897320599244277 0.11897320599244277 0.29688146710395813
0.12218568039117012 0.12218568039117012 0.30480971932411194
0.1217752219005295 0.1217752219005295 0.2917865216732025
0.11833606879156013 0.11833606879156013 0.2632358968257904
0.11372989817938127 0.11372989817938127 0.23035593330860138
0.10944443766838512 0.10944443766838512 0.20567388832569122
0.1058664467786746 0.1058664467786746 0.19434453547000885
0.10282861121152762 0.10282861121152762 0.18772193789482117
0.10048223709526065 0.10048223709526065 0.17361128330230713
0.0994839425744686 0.0994839425744686 0.15395592153072357
0.10027142028499814 0.10027142028499814 0.1470334231853485
0.10228320108581934 0.10228320108581934 0.1613510549068451
0.10411083089183079 0.10411083089183079 0.17975854873657227
0.10444131561502909 0.10444131561502909 0.18429507315158844
0.10287530132661171 0.10287530132661171 0.1693870574235916
0.1000480053225517 0.1000480053225517 0.13852804899215698
0.09719237821630797 0.09719237821630797 0.0998278260231018
0.09547432552856334 0.09547432552856334 0.0665806382894516
0.09539494365369236 0.09539494365369236 0.06096119433641434
0.09658606789241442 0.09658606789241442 0.08196037262678146
0.09813259133079846 0.09813259133079846 0.10485367476940155
0.0991274805877532 0.0991274805877532 0.11812679469585419
0.09906699857562129 0.09906699857562129 0.11782559007406235
0.09798432104260046 0.09798432104260046 0.10310932248830795
0.0963991203545628 0.0963991203545628 0.0757947564125061
0.09507741313973633 0.09507741313973633 0.04126165434718132
0.0946038988442081 0.0946038988442081 0.020866669714450836
0.095015140447409 0.095015140447409 0.045707132667303085
0.09582130243908044 0.09582130243908044 0.07082194089889526
0.09639915341499895 0.09639915341499895 0.08375591784715652
0.09640440696793794 0.09640440696793794 0.08264625817537308
0.09590079638391352 0.09590079638391352 0.06921716779470444
0.09522682411575126 0.09522682411575126 0.04803340882062912
0.09475726254810163 0.09475726254810163 0.02810618281364441
0.0946811263072272 0.0946811263072272 0.027775779366493225
0.09490563358069289 0.09490563358069289 0.04160883277654648
0.09516663623749574 0.09516663623749574 0.05164766311645508
0.095256211415998 0.095256211415998 0.05383974313735962
0.09514583805182088 0.09514583805182088 0.04916926100850105
0.09493592349816425 0.09493592349816425 0.04057862609624863
0.0947439115916885 0.0947439115916885 0.03192625194787979
0.09464441476711366 0.09464441476711366 0.027436869218945503
0.09464844958382716 0.09464844958382716 0.02857620269060135
0.09470445560059945 0.09470445560059945 0.031775955110788345
0.09474313097274088 0.09474313097274088 0.033542461693286896
0.09473511497348737 0.09473511497348737 0.033152636140584946
0.09469628663870808 0.09469628663870808 0.03155773878097534
0.09464714772261883 0.09464714772261883 0.029536930844187737
0.09459419883414823 0.09459419883414823 0.02684604562819004
0.09454648724620862 0.09454648724620862 0.02317315712571144
0.09451843159657025 0.09451843159657025 0.01944831572473049
0.0945175533773434 0.0945175533773434 0.01796191930770874
0.09453863311200486 0.09453863311200486 0.01989484764635563
0.09456649950136618 0.09456649950136618 0.023130550980567932
0.09457638024375314 0.09457638024375314 0.024820005521178246
0.09455055116055744 0.09455055116055744 0.023288818076252937
0.09449702463029663 0.09449702463029663 0.018309161067008972
0.0944490803140586 0.0944490803140586 0.011218961328268051
0.0944354071143667 0.0944354071143667 0.006886832416057587
0.09445756386863582 0.09445756386863582 0.011448976583778858
0.09449356690102595 0.09449356690102595 0.01698918826878071
0.09451326437939497 0.09451326437939497 0.01953894831240177
0.09449956802846891 0.09449956802846891 0.01816154271364212
0.09446211378959746 0.09446211378959746 0.013214888982474804
0.09442911098973134 0.09442911098973134 0.006052172742784023
0.09442163556630127 0.09442163556630127 0.0020102954003959894
iteration: 1 | epoch: 79 |   loss: 0.094422  |   KL divergence: 0.094422  |  JS divergence: 0.028467
('==== Found maximium gradient [0.28739497, 0.24836639, 0.19031838] of gate '
 'e^[Y1 Z2], e^[Y0 Z2], e^[X1 Y2] ====')
learning rate =  0.04905817354331112
0.0944367931917333 0.0944367931917333 0.42493680119514465
0.06715693166767604 0.06715693166767604 0.3629711866378784
0.042847125501153174 0.042847125501153174 0.2096141278743744
0.031184795507635046 0.031184795507635046 0.16490241885185242
0.023516866492499396 0.023516866492499396 0.14328666031360626
0.019619685672746336 0.019619685672746336 0.13659368455410004
0.01980914670790405 0.01980914670790405 0.16758640110492706
0.022095123176365278 0.022095123176365278 0.2122829705476761
0.022604174203986086 0.022604174203986086 0.22305478155612946
0.02030606357971582 0.02030606357971582 0.20129945874214172
0.016790052499486095 0.016790052499486095 0.1701306700706482
0.013586243928881712 0.013586243928881712 0.14160683751106262
0.011440443544274667 0.011440443544274667 0.12049601227045059
0.010374014346258929 0.010374014346258929 0.10898303240537643
0.009963855121829963 0.009963855121829963 0.10626020282506943
0.009709600643881208 0.009709600643881208 0.10801030695438385
0.009303246873144705 0.009303246873144705 0.10851570963859558
0.008735003113862067 0.008735003113862067 0.10517487674951553
0.008155860734068775 0.008155860734068775 0.10020714998245239
0.0076204116088226595 0.0076204116088226595 0.09696108102798462
0.006991784335192767 0.006991784335192767 0.09517817944288254
0.006095920877595036 0.006095920877595036 0.09125243127346039
0.004937921771918449 0.004937921771918449 0.0824112668633461
0.003744043133515166 0.003744043133515166 0.0691443383693695
0.0027830420328148996 0.0027830420328148996 0.054627615958452225
0.0021740241291308346 0.0021740241291308346 0.04273243993520737
0.0018644816127409633 0.0018644816127409633 0.0355834998190403
0.0017496606274908701 0.0017496606274908701 0.03313598409295082
0.001783934919475599 0.001783934919475599 0.03614037483930588
0.0019621129706292907 0.0019621129706292907 0.04482030123472214
0.0022194628443981974 0.0022194628443981974 0.055474914610385895
0.0023950152129738767 0.0023950152129738767 0.06316769123077393
0.0023297640950339683 0.0023297640950339683 0.06466729938983917
0.0019980758565465925 0.0019980758565465925 0.059401120990514755
0.001528301484878964 0.001528301484878964 0.049392834305763245
0.0010884177041297098 0.0010884177041297098 0.038384608924388885
0.0007662066384351916 0.0007662066384351916 0.02985619194805622
0.0005518035143065522 0.0005518035143065522 0.024420250207185745
0.00040990416851206714 0.00040990416851206714 0.020447855815291405
0.0003339595391202554 0.0003339595391202554 0.01805081218481064
0.00033420122820473474 0.00033420122820473474 0.018979227170348167
0.0003988999151381353 0.0003988999151381353 0.022454438731074333
0.0004886498862294911 0.0004886498862294911 0.026230312883853912
0.0005567165069624014 0.0005567165069624014 0.02913634292781353
0.0005686449896477892 0.0005686449896477892 0.030549440532922745
0.0005134834820257912 0.0005134834820257912 0.029740259051322937
0.00040906740889088767 0.00040906740889088767 0.026286495849490166
0.0002948900365293602 0.0002948900365293602 0.020957868546247482
0.00020783331211378332 0.00020783331211378332 0.016097987070679665
0.00015802101612892323 0.00015802101612892323 0.0141677875071764
0.00013027475360019667 0.00013027475360019667 0.014339916408061981
0.00011132214484383405 0.00011132214484383405 0.014331700280308723
0.00010157658383929671 0.00010157658383929671 0.01406787522137165
0.00010455930394760661 0.00010455930394760661 0.014464219100773335
0.00011303439861746101 0.00011303439861746101 0.015110538341104984
0.0001137901044428076 0.0001137901044428076 0.014867047779262066
0.0001045260907695778 0.0001045260907695778 0.01358348224312067
9.312058636400827e-05 9.312058636400827e-05 0.012155788019299507
8.460599063460686e-05 8.460599063460686e-05 0.011267970316112041
7.808732461468898e-05 7.808732461468898e-05 0.01065109670162201
7.096289690448139e-05 7.096289690448139e-05 0.010068779811263084
6.316623582177197e-05 6.316623582177197e-05 0.009867312386631966
5.545462951252493e-05 5.545462951252493e-05 0.010005894117057323
4.717039485288761e-05 4.717039485288761e-05 0.00979391299188137
3.7933705471094497e-05 3.7933705471094497e-05 0.008913525380194187
2.8526004619558822e-05 2.8526004619558822e-05 0.007713234983384609
2.0509707075066184e-05 2.0509707075066184e-05 0.00646853307262063
1.3658368657563295e-05 1.3658368657563295e-05 0.0050081294029951096
1.0874210895228924e-05 1.0874210895228924e-05 0.0037339888513088226
iteration: 2 | epoch: 148 |   loss: 0.000011  |   KL divergence: 0.000011  |  JS divergence: 0.000003
('==== Found maximium gradient [0.003173558, 0.0029324898, 0.0028492007] of '
 'gate e^[Y2 Z0], e^[X0 Y1], e^[X1 Y0] ====')
learning rate =  0.0005976499656660878
1.3876559293382346e-05 1.3876559293382346e-05 0.006721169222146273
6.455721246836389e-06 6.455721246836389e-06 0.004325223155319691
iteration: 3 | epoch: 150 |   loss: 0.000006  |   KL divergence: 0.000006  |  JS divergence: 0.000002
('==== Found maximium gradient [0.0019490061, 0.0019288231, 0.00093475106] of '
 'gate e^[Y2 Z0], e^[Y2 Z1], e^[Y1 Z2] ====')
learning rate =  0.0003345194006838814
2.552565649536337e-06 2.552565649536337e-06 0.003924211952835321
iteration: 4 | epoch: 151 |   loss: 0.000003  |   KL divergence: 0.000003  |  JS divergence: 0.000001
('==== Found maximium gradient [0.00073598936, 0.00059236644, 0.00040793774] '
 'of gate e^[Y2 Z0], e^[Y2 Z1], e^[Y1 Z0] ====')
Convergence criterion has reached, break the loop!
