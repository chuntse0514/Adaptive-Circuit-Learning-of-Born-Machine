('==== Found maximium gradient [0.1265235, 0.12652348, 0.12652348] of gate '
 'RY[1], e^[X8 Y1], e^[X0 Y1] ====')
learning rate =  0.025304696990574888
0.0597238943306861 0.30243661999702454
0.04730104073116009 0.14394240081310272
0.04292429008314605 0.13857817649841309
0.043893694008079034 0.18749067187309265
0.04328027044705466 0.17155756056308746
0.041023169854136246 0.11505627632141113
0.039687768646871145 0.06254103034734726
0.04034069199110489 0.08428104966878891
0.041851787744000626 0.12579770386219025
0.042375239810155285 0.14006493985652924
0.04142178146019025 0.1241803839802742
0.03991435211904288 0.0881657525897026
0.03896759548711419 0.05197756737470627
0.03897211993889566 0.05375005677342415
0.039464008197896305 0.07982795685529709
0.039715055206272235 0.09475011378526688
0.03940870623728259 0.09070543199777603
0.03878308749393699 0.0704863965511322
0.03827704141567134 0.04310809448361397
0.038137368783811784 0.0302116721868515
0.03829209977647675 0.046207401901483536
0.038492646310553755 0.06246534362435341
0.03854530664769377 0.06735185533761978
0.03843050172204216 0.06029244512319565
0.038257679159784855 0.045848578214645386
0.038137885212699396 0.034014731645584106
0.03809646811628324 0.03610079362988472
0.03807284307820119 0.04502835124731064
0.037990762264442896 0.04885708540678024
0.03783427828532312 0.04366512969136238
0.037665228480418894 0.03074379451572895
0.03756921469896497 0.016451576724648476
0.03758329011980747 0.018378576263785362
0.03766569122953055 0.0304485484957695
0.03773276611310055 0.0376213937997818
0.037723125720362585 0.036994658410549164
0.03764014766544389 0.029731005430221558
0.03753568060854694 0.020258421078324318
0.0374592577670039 0.017081858590245247
0.03742365056426329 0.02192084491252899
0.037404914204514694 0.025622226297855377
0.037376617587455606 0.024169091135263443
0.03733565481349108 0.018170854076743126
0.03730124862418212 0.012200703844428062
0.0372901855893751 0.013982641510665417
0.03729324903098132 0.01939328759908676
0.03728467798910721 0.0216719638556242
0.03724806236287374 0.01922701857984066
0.037196408432244116 0.013425573706626892
0.037154607977851556 0.00906736496835947
0.03713617696391055 0.01163236889988184
0.03712787401532345 0.015285574831068516
0.037109628957279685 0.015630220994353294
0.03707667541801303 0.012435993179678917
0.03704322978716883 0.008105347864329815
0.037020921570639555 0.007891068235039711
0.0370083577512131 0.011079107411205769
0.03699455906423763 0.012699337676167488
0.0369731436309518 0.011544348672032356
0.03694658909798052 0.008735982701182365
0.03692250433256686 0.0072493418119847775
0.03690291180109102 0.008603396825492382
0.03688351668649513 0.009884229861199856
0.036861157504246345 0.009217427112162113
0.036836474256980015 0.006879262160509825
0.03681468012700392 0.005175551399588585
0.03679860329791432 0.0064730457961559296
0.03678482355135545 0.00823725014925003
0.03676761119350964 0.008414827287197113
0.03674550595071008 0.006991890724748373
0.03672272342996965 0.005396553780883551
0.03670283589927953 0.005482833366841078
0.036685172795287074 0.006419509183615446
0.03666707223163142 0.006501738913357258
0.03664794538315378 0.005573736969381571
0.036629595196616446 0.004777464084327221
epoch: 1 | iteration: 77 |   loss: 0.036630  |   KL divergence: 0.036630  |  JS divergence: 0.009367
('==== Found maximium gradient [0.04979384, 0.047794268, 0.044589955] of gate '
 'e^[Y8 Z1], e^[Y1 Z8], e^[Y8 Z0] ====')
learning rate =  0.00948822619269784
0.0366129260617304 0.08233383297920227
0.035487989436453184 0.05636194348335266
0.03485145682520348 0.03463440015912056
0.034596525245563864 0.02119750715792179
0.03463648925497378 0.028031297028064728
0.03476948359323022 0.03783296421170235
0.034813292379123464 0.03844062238931656
0.034810009623033204 0.03730832412838936
0.03476317679297593 0.033786188811063766
0.03468130054102644 0.026212437078356743
0.03462664997935054 0.021215448155999184
0.03461025595142134 0.021634653210639954
0.034600449951310744 0.022138504311442375
0.0345961864662838 0.023240812122821808
0.0345909156422205 0.02500130422413349
0.03456194730339389 0.023845484480261803
0.034514388763504614 0.019634520635008812
0.034476660444481284 0.015661580488085747
0.03445560084297567 0.012646292336285114
0.03444743007273119 0.009666661731898785
0.03445938039121802 0.010858212597668171
0.034483210293194504 0.015015593729913235
0.03449801136417872 0.017123132944107056
0.034496688168558574 0.0171444620937109
0.03448338322185081 0.016428258270025253
0.034459036477898455 0.014195041730999947
0.03442930903568464 0.009899485856294632
0.0344101444392323 0.005958734080195427
0.03440409408195513 0.0051788934506475925
0.03440693763648209 0.005988460499793291
0.034416203390990635 0.008280454203486443
0.034426317304860586 0.01066764909774065
0.03442826870837343 0.011124025098979473
0.03442261823458646 0.010056580416858196
0.03441355786040275 0.00868377648293972
0.03440319099177602 0.0066115595400333405
0.034394474917777265 0.00403851643204689
epoch: 2 | iteration: 114 |   loss: 0.034394  |   KL divergence: 0.034396  |  JS divergence: 0.008752
('==== Found maximium gradient [0.039663088, 0.03962704, 0.03634067] of gate '
 'e^[Y10 Z0], e^[Y0 Z10], e^[Y9 Z8] ====')
learning rate =  0.0077150133564923284
0.034392644871971294 0.06693515181541443
0.03399178721335272 0.06551308184862137
0.03322507888576248 0.027373656630516052
0.0331301872652778 0.029395628720521927
0.03326076658282177 0.04278493672609329
0.03325616276085775 0.040454596281051636
0.0331930743742027 0.03267430141568184
0.03318552819407129 0.030762698501348495
0.03322029797156624 0.03452298790216446
0.033208750924173476 0.03432966396212578
0.03313371514877013 0.027582664042711258
0.0330593763360124 0.018294120207428932
0.03304207425978781 0.016349991783499718
0.033074410440040156 0.022901201620697975
0.0331004916383756 0.02740156464278698
0.03308170799386502 0.02631857804954052
0.03302995404195003 0.02072855643928051
0.0329850527524994 0.01441869419068098
0.032968438478605255 0.012912335805594921
0.032973426328935115 0.015329909510910511
0.03297909156441703 0.01620694436132908
0.03297705581004604 0.01436108723282814
0.03297535244259939 0.012138446792960167
0.03298225786480569 0.012921683490276337
0.03299328448379665 0.015571779571473598
0.03299519791959652 0.016615591943264008
0.03297962143606599 0.014582838863134384
0.0329558093644832 0.010008168406784534
0.0329378149760324 0.005440277513116598
0.032933859651428754 0.006134852301329374
0.03293878617050948 0.008982137776911259
0.032943817565392275 0.009907323867082596
0.03294443608107502 0.008942502550780773
0.0329433886515655 0.007834409363567829
0.03294430867962657 0.008185810409486294
0.03294547145377682 0.00894593633711338
0.03294279389647989 0.008396036922931671
0.03293572522874851 0.006215916480869055
0.03293010891203451 0.0038170493207871914
epoch: 3 | iteration: 153 |   loss: 0.032930  |   KL divergence: 0.032931  |  JS divergence: 0.008401
('==== Found maximium gradient [0.03462411, 0.03277575, 0.031866226] of gate '
 'e^[Y1 Z3], e^[Y3 Z1], e^[Y9 Z10] ====')
learning rate =  0.006621717033055654
0.032929172194365836 0.05751088261604309
0.032735725418350826 0.05993562936782837
0.032072422891861026 0.024342017248272896
0.03201535240274733 0.027397284284234047
0.032141985808609094 0.03974555432796478
0.032116447813909946 0.036569129675626755
0.03203620571343156 0.028073560446500778
0.032022214730487275 0.02622385509312153
0.03206299956020168 0.030660927295684814
0.032068536640167 0.031114909797906876
0.032012110434541156 0.025211220607161522
0.03194789413843011 0.016891099512577057
0.03192970151617782 0.015256818383932114
0.03195426256383134 0.021043209359049797
0.03197579103304907 0.02485198713839054
0.031961020433490424 0.0236357469111681
0.03191790354799495 0.01846918649971485
0.031877616319222965 0.012911228463053703
0.03186214957021231 0.011824618093669415
0.03186535120898551 0.013887457549571991
0.03186979193088284 0.01440207939594984
0.03186930890810432 0.012637907639145851
0.03186877379466205 0.010961723513901234
0.0318748457215773 0.01209777221083641
0.03188259399699 0.014432207681238651
0.03188187058839679 0.015045102685689926
0.031868075273894396 0.012950446456670761
0.03184785909443716 0.008930915035307407
0.03183380752876454 0.0056337350979447365
0.03182961134055752 0.006457557901740074
0.03183221050815313 0.00834534503519535
0.03183425651742253 0.008653686381876469
0.03183462904596944 0.0077409506775438786
0.03183439106321246 0.007282433565706015
0.03183517746542049 0.007990957237780094
0.031834201387026397 0.008456888608634472
0.03182951161030337 0.0075205168686807156
0.031823489315938286 0.0053946636617183685
0.031819873453918235 0.003941412549465895
epoch: 4 | iteration: 192 |   loss: 0.031820  |   KL divergence: 0.031820  |  JS divergence: 0.008126
('==== Found maximium gradient [0.028075257, 0.02763683, 0.013818681] of gate '
 'e^[Y1 Z2], e^[Y2 Z1], CRY[1, 2] ====')
learning rate =  0.004820747296643935
0.031819414194473226 0.04204246401786804
0.03176235233820525 0.04076350852847099
0.031451930760091444 0.011419657617807388
0.031487162554398165 0.018346872180700302
0.03161244591688816 0.030857330188155174
0.03160724418820095 0.02987937442958355
0.03153902450066782 0.023386763408780098
0.031500060030928013 0.01959478296339512
0.0315004214104917 0.02049974352121353
0.03149283744739122 0.01971396803855896
0.03146132162434122 0.015041876584291458
0.03143459458488143 0.009812260046601295
0.03143705265265845 0.011293613351881504
0.03146038173733433 0.0163118913769722
0.03147545281649901 0.018588071689009666
0.031463746413960596 0.01682146079838276
0.03143777819292533 0.012180800549685955
0.031417617131990226 0.007795826066285372
0.031414474369476905 0.00806717574596405
0.031419842722166254 0.010413198731839657
0.031420595953783194 0.010995933786034584
0.03141420139161691 0.009632157161831856
0.03140673113616801 0.00807888898998499
0.031404917749860775 0.008301562629640102
0.03140677058564077 0.009390812367200851
0.031406297420449564 0.00934656709432602
0.031399588307166854 0.007589842192828655
0.03139053923629872 0.005019201431423426
0.031385243259847616 0.004188234452158213
epoch: 5 | iteration: 221 |   loss: 0.031385  |   KL divergence: 0.031386  |  JS divergence: 0.008011
('==== Found maximium gradient [0.010613589, 0.010149783, 0.009774778] of gate '
 'e^[Y0 Z2], e^[Y2 Z0], e^[Y1 Z9] ====')
learning rate =  0.002037032651085615
0.03138442557649362 0.01854431815445423
0.03135226511292931 0.016395144164562225
0.031299165104216764 0.008516239002346992
0.031284639651467036 0.005897717550396919
0.03129341980273681 0.009800796397030354
0.03129359549596919 0.010122042149305344
0.03128776418516934 0.008794311434030533
0.03128472185605189 0.008225413970649242
0.03128546206086027 0.008611761033535004
0.031282144249557844 0.007702424190938473
0.031275998140383246 0.005903084296733141
0.031271456763175484 0.004766312427818775
epoch: 6 | iteration: 233 |   loss: 0.031271  |   KL divergence: 0.031272  |  JS divergence: 0.007984
('==== Found maximium gradient [0.006631339, 0.0061606425, 0.003925123] of '
 'gate e^[Y0 Z9], e^[Y9 Z0], e^[Y9 Z1] ====')
learning rate =  0.001139208856909242
0.03127105083749948 0.011375902220606804
0.031258162864990724 0.009363518096506596
0.031240927992593828 0.004760558716952801
epoch: 7 | iteration: 236 |   loss: 0.031241  |   KL divergence: 0.031242  |  JS divergence: 0.007971
('==== Found maximium gradient [0.003341055, 0.0032451167, 0.00322085] of gate '
 'e^[Y2 Z9], e^[Y3 Z2], e^[Y2 Z3] ====')
learning rate =  0.0006538838530335012
0.03123826502942848 0.006929542403668165
0.031230211159606225 0.00528688682243228
0.031225328648014444 0.0036067147739231586
epoch: 8 | iteration: 239 |   loss: 0.031225  |   KL divergence: 0.031226  |  JS divergence: 0.007968
('==== Found maximium gradient [0.0026112276, 0.0019237229, 0.0019161368] of '
 'gate e^[X8 Y0], e^[Y1 Z0], e^[Y0 Z1] ====')
learning rate =  0.000434983521601442
0.031223002353090952 0.005022230092436075
0.031218495036459275 0.003870783606544137
epoch: 9 | iteration: 241 |   loss: 0.031218  |   KL divergence: 0.031219  |  JS divergence: 0.007966
('==== Found maximium gradient [0.0023234522, 0.0018079357, 0.0014994724] of '
 'gate e^[X0 Y1], e^[X8 Y0], e^[X1 Y8] ====')
learning rate =  0.0003814966863878458
0.031215558237636228 0.004555303603410721
epoch: 10 | iteration: 242 |   loss: 0.031216  |   KL divergence: 0.031217  |  JS divergence: 0.007963
('==== Found maximium gradient [0.0021434233, 0.0019186826, 0.001833563] of '
 'gate e^[X10 Y0], e^[X2 Y0], e^[Y8 Z1] ====')
learning rate =  0.0003939129975629479
0.031213304665828757 0.004944687709212303
epoch: 11 | iteration: 243 |   loss: 0.031213  |   KL divergence: 0.031214  |  JS divergence: 0.007964
('==== Found maximium gradient [0.0021776275, 0.0019840908, 0.0015427098] of '
 'gate e^[X10 Y0], e^[X2 Y0], e^[X0 Y1] ====')
learning rate =  0.00038399010576338293
0.031207824552278548 0.005674091167747974
0.031202315226409982 0.0052992976270616055
0.0311968396349098 0.0052756271325051785
0.031191633820099186 0.005808821879327297
0.0311879554631316 0.006063347216695547
0.03118203193117905 0.005912041757255793
0.031176918190996064 0.0055132959969341755
0.03117227154495044 0.005133252125233412
0.031167125142793056 0.004927655216306448
epoch: 12 | iteration: 252 |   loss: 0.031167  |   KL divergence: 0.031168  |  JS divergence: 0.007949
('==== Found maximium gradient [0.002286736, 0.0016589345, 0.0015970205] of '
 'gate e^[X8 Y0], e^[X10 Y9], e^[X0 Y1] ====')
learning rate =  0.00037473011659409715
0.031162509731367707 0.005830729845911264
0.031158072129507837 0.0073594823479652405
0.031150694402135134 0.006856514140963554
0.031144063880401973 0.006171543151140213
0.031137237477665815 0.005884869024157524
0.03113137142197616 0.0058320737443864346
0.03112559636238711 0.005832459311932325
0.03111872541623041 0.005882161669433117
0.03111250973964546 0.006000550929456949
0.031105802475018707 0.006139988545328379
0.031099281585772826 0.006224694196134806
0.031092866585124487 0.00619804160669446
0.031086032420577135 0.006067763082683086
0.031080283053939256 0.005894558969885111
0.031073699679391838 0.005745834670960903
0.031066801260019955 0.005675704218447208
0.031060201670198496 0.005705352872610092
0.031054108827803354 0.0057996828109025955
0.031047411914611443 0.005878158379346132
0.031040524027467743 0.005871194414794445
0.031034257214259044 0.005774178542196751
0.031028004173455165 0.005647075828164816
0.031021305386092633 0.00555971497669816
0.03101449367471243 0.00554489903151989
0.031008318241338272 0.005595772061496973
0.031001639549969894 0.00568121625110507
0.0309950409598507 0.005755768157541752
0.030988677513863437 0.0057747820392251015
0.030982338085726147 0.005722192581743002
0.03097590135096756 0.0056258756667375565
0.030969464753502235 0.0055367411114275455
0.030963041902895123 0.005491944029927254
0.030956346272089832 0.005498414393514395
0.03095022494545817 0.005538057070225477
0.030943983893668585 0.005577956326305866
0.030937453940845898 0.005585505161434412
0.03093118619886036 0.005546941887587309
0.030924950251303568 0.005476977210491896
0.030918592294087388 0.005406489130109549
0.03091250234527334 0.005361984949558973
0.030906246213364456 0.005352904088795185
0.030900397894783056 0.005368008278310299
0.030893999571960082 0.005382278002798557
0.03088778185458203 0.00537176663056016
0.03088138368245729 0.005332238506525755
0.030875744754190595 0.005279415287077427
0.030869465636464984 0.005235993769019842
0.030863668990122148 0.005216164514422417
0.030857744708723166 0.005219281185418367
0.03085144129562628 0.005231358576565981
0.030845567568292757 0.005232437048107386
0.030839773490986412 0.00521167553961277
0.030833757594248223 0.005173496436327696
0.030827948301972063 0.005132101941853762
0.030822916077515968 0.005100998096168041
0.03081619941454986 0.005083550699055195
0.03081098043721353 0.00507380673661828
0.030805157188209503 0.00506041431799531
0.030799440661941062 0.005035168491303921
0.030793938258004493 0.005000536795705557
0.03078830404394376 0.004964855033904314
epoch: 13 | iteration: 313 |   loss: 0.030788  |   KL divergence: 0.030789  |  JS divergence: 0.007846
('==== Found maximium gradient [0.0033544074, 0.0030223923, 0.0022367015] of '
 'gate e^[Y8 Z9], e^[Y9 Z8], e^[X8 Y0] ====')
learning rate =  0.0005818331632152583
0.030783008359670835 0.007053989917039871
0.030769653696746398 0.006787243764847517
0.030755349470326668 0.005918629001826048
0.03074325190238318 0.005753477104008198
0.030731422381381435 0.005817800294607878
0.03072051070160796 0.005898275878280401
0.030708169082318777 0.006055657286196947
0.030697135376999616 0.006180537864565849
0.03068621992381748 0.0062077841721475124
0.030674322180162254 0.006173011381179094
0.030663075144813905 0.006120647769421339
0.030651485230682472 0.006025886163115501
0.030640771040520137 0.005848655477166176
0.030629917876248906 0.005625739693641663
0.030618725333934914 0.005448401905596256
0.030607933608949346 0.005358133930712938
0.030597045876825026 0.005331835243850946
0.030585990902293404 0.005353989545255899
0.03057561499942507 0.00543662765994668
0.03056420032094417 0.005567793734371662
0.03055387450756262 0.005692112725228071
0.0305436382851789 0.005759276915341616
0.030532899861536393 0.005771299824118614
0.030522681715210997 0.00576601130887866
0.03051222737454981 0.005767564754933119
0.030502077559438658 0.005775942467153072
0.03049168031535841 0.0057864258997142315
0.030481954603701532 0.005795104429125786
0.030471786512134662 0.005788083653897047
0.03046186490408194 0.005745930131524801
0.03045235165960426 0.0056663136929273605
0.030442859151225722 0.005572738591581583
0.030432859422061705 0.005496382713317871
0.03042335685624629 0.005457022693008184
0.030413868161374574 0.0054602595046162605
0.030404351382326496 0.005500905215740204
0.03039489361220927 0.00556332478299737
0.03038587865441022 0.005622588098049164
0.030376554105931916 0.005658379755914211
0.030367591482044664 0.005670253653079271
0.03035825020767812 0.005672983825206757
0.030349464404428435 0.005678040441125631
0.0303405903653945 0.005685353651642799
0.030331603675886925 0.005691506899893284
0.030323281344722588 0.005693601444363594
0.030314639464623767 0.005685599520802498
0.030305736369893935 0.005661507602781057
0.030297625456919886 0.005624671000987291
0.03028902725289231 0.005586163140833378
0.03028035871945356 0.005557030905038118
0.030272008529993594 0.005545195657759905
0.030263317078828653 0.00555255264043808
0.030255813173866806 0.005571823567152023
0.03024727034098734 0.005589818581938744
0.030239569135484264 0.005599036347121
0.030231036080156252 0.005601608194410801
0.030223027861580036 0.005603954661637545
0.030215068402953585 0.005608908366411924
0.030207025678925956 0.00561442831531167
0.03019936676443026 0.005615674424916506
0.030191360382141395 0.005607323255389929
0.030183578014383365 0.0055869752541184425
0.030176508212550197 0.005558046977967024
0.030168399309681477 0.005528532899916172
0.03016113528038072 0.005505857989192009
0.03015312663286717 0.005493239499628544
0.03014524871652563 0.0054879761300981045
0.03013795785455359 0.0054841358214616776
0.030130359069405963 0.005476915743201971
0.03012330391242357 0.005466459784656763
0.030115975765977018 0.005455948878079653
0.03010852149580704 0.005447515286505222
0.030101603824626275 0.0054405140690505505
0.030094050434427068 0.005432663485407829
0.03008667991097608 0.005420211236923933
0.030079897268915558 0.00540090212598443
0.030072936896839902 0.005376195069402456
0.030065699380556678 0.005350219085812569
0.03005879128257062 0.005326359067112207
0.030051627011992772 0.005304980557411909
0.03004435101885669 0.0052840691059827805
0.030037777299438753 0.00526178115978837
0.030031185739567277 0.005238375160843134
0.03002400005214657 0.0052159433253109455
0.030017816638052995 0.005195986945182085
0.030010964232571522 0.005177944432944059
0.030004419369218063 0.005160133354365826
0.029997828396626867 0.005140264052897692
0.029991195366932226 0.005116899497807026
0.029985216206967254 0.0050897677429020405
0.029978723101005036 0.00506044365465641
0.02997243098166208 0.0050307936035096645
0.02996599485236796 0.005001555196940899
0.029959875602046306 0.004972183145582676
epoch: 14 | iteration: 407 |   loss: 0.029960  |   KL divergence: 0.029960  |  JS divergence: 0.007615
('==== Found maximium gradient [0.004559289, 0.0040469593, 0.003429032] of '
 'gate e^[Y9 Z0], e^[Y0 Z9], e^[Y10 Z0] ====')
learning rate =  0.0008076571533030008
0.029953608739922144 0.00856438186019659
0.029939274931788447 0.010562834329903126
0.02992850505832733 0.013085695914924145
0.029908080207634875 0.009804594330489635
0.02989278970065353 0.009733772836625576
0.029878329361832524 0.010680236853659153
0.02986004062490599 0.009473232552409172
0.02984314617469102 0.008165414445102215
0.029828881371350865 0.008875817991793156
0.02981402616064323 0.009352166205644608
0.029798277087922327 0.008340282365679741
0.029781561839032467 0.007466054987162352
0.029767150558464104 0.008061575703322887
0.02975262767781936 0.0085941506549716
0.029737141973991237 0.007952827028930187
0.02972145662166342 0.007051011547446251
0.029707096792628965 0.007211664691567421
0.029693260316611646 0.007721193600445986
0.0296782917613658 0.007404476869851351
0.029664160612979124 0.006605242844671011
0.02964944791359071 0.006499077659100294
0.029636254885663932 0.006993431597948074
0.029622210489016552 0.007030337583273649
0.029607865663771462 0.006518777925521135
0.029594676726396332 0.006267919670790434
0.029581693253270064 0.006518266163766384
0.02956848823192659 0.0065690879710018635
0.029555083450563756 0.006164156831800938
0.02954185803014551 0.005850965157151222
0.029529977107630577 0.005978656467050314
0.0295175849479299 0.006093686446547508
0.02950504903560982 0.005882554687559605
0.029493119666960322 0.005656827706843615
0.029481575518588862 0.005690152291208506
0.029470009932574925 0.0057143354788422585
0.029458124511318844 0.005505125503987074
0.029446426157096244 0.005287217441946268
0.02943591195740113 0.00527259660884738
0.02942519072209417 0.005274072755128145
0.029414680353533767 0.005129328463226557
0.029404423966545103 0.00499018793925643
epoch: 15 | iteration: 448 |   loss: 0.029404  |   KL divergence: 0.029405  |  JS divergence: 0.007464
('==== Found maximium gradient [0.00364207, 0.0030143987, 0.0028533847] of '
 'gate e^[Y2 Z0], e^[Y2 Z1], e^[Y1 Z2] ====')
learning rate =  0.0006376318367375584
0.029394093793114445 0.007430936675518751
0.029380117352663306 0.008332340978085995
0.029365022392404315 0.00822663027793169
0.02935093575446186 0.007924309931695461
0.029336433505087932 0.007493877783417702
0.029322714169590362 0.0076117911376059055
0.02930940387769606 0.007111388258635998
0.029295262088680683 0.00672253267839551
0.02928163169716519 0.006687423679977655
0.029269278407782533 0.00673929275944829
0.02925673290982767 0.006695149466395378
0.02924373980230384 0.006497201509773731
0.02923157779669601 0.006415132433176041
0.029220073041941876 0.006226370111107826
0.029208126343931703 0.005738796666264534
0.029196643420311884 0.005513652227818966
0.02918571056017367 0.0055687702260911465
0.029174496948090017 0.005367181729525328
0.02916364866287125 0.00522309634834528
0.029154161252231713 0.005443379282951355
0.029144131279300614 0.005474070552736521
0.029133783241071028 0.005286244209855795
0.029123982002222513 0.005277041345834732
0.029115257180054678 0.005182258319109678
0.029105627355852006 0.004868526943027973
epoch: 16 | iteration: 473 |   loss: 0.029106  |   KL divergence: 0.029106  |  JS divergence: 0.007384
('==== Found maximium gradient [0.0029156837, 0.0028788338, 0.0023883267] of '
 'gate e^[Y0 Z8], e^[Y8 Z0], e^[Y8 Z1] ====')
learning rate =  0.0005476373671925841
0.029097123509902498 0.00667507154867053
0.02909401013136995 0.013459235429763794
0.02907362484946966 0.006056867074221373
0.029065098514172112 0.008478105068206787
0.029056457963407285 0.009998642839491367
0.02904502964800634 0.008341698907315731
0.029033187809507754 0.0057172407396137714
0.029022890597975123 0.006077395286411047
0.029015159210052384 0.007488401606678963
0.029006450854356658 0.007649549283087254
0.028997263932887027 0.00662655383348465
0.02898786093771406 0.00522095151245594
0.028978793410962603 0.0049603781662881374
epoch: 17 | iteration: 486 |   loss: 0.028979  |   KL divergence: 0.028980  |  JS divergence: 0.007352
('==== Found maximium gradient [0.0023421017, 0.0022505901, 0.0021294618] of '
 'gate e^[X0 Y8], e^[X9 Y8], e^[Y9 Z10] ====')
learning rate =  0.0004484819526965969
0.028971273533682482 0.00681485328823328
0.02896743925433596 0.011581904254853725
0.02895345078090481 0.006229504477232695
0.028945459840596086 0.006405130960047245
0.02893947675885137 0.008893651887774467
0.028930639948205713 0.008013328537344933
0.02892093072037101 0.005978037603199482
0.028912958231906483 0.0058717671781778336
0.02890653565627739 0.007152519188821316
0.028898396191821833 0.007353276014328003
0.02889080340148112 0.006266786716878414
0.02888200010972963 0.0050386604852974415
0.02887495596807991 0.004954800475388765
epoch: 18 | iteration: 499 |   loss: 0.028875  |   KL divergence: 0.028875  |  JS divergence: 0.007328
('==== Found maximium gradient [0.0021101253, 0.002029717, 0.0017862751] of '
 'gate e^[X2 Y3], RY[9], e^[X2 Y9] ====')
learning rate =  0.00039603295786247374
0.02886788281767415 0.006535049062222242
0.028864282757723285 0.010188586078584194
0.02885280286767629 0.005949077196419239
0.028845461586182966 0.005782225634902716
0.028840570196130032 0.007757693063467741
0.02883333722206627 0.007118236273527145
0.028824923238516972 0.005466776434332132
0.028818044488571462 0.005238587036728859
0.028811573774621405 0.006224620621651411
0.028805138706335137 0.006442991551011801
0.02879741491613057 0.005643025506287813
0.028790947236651186 0.004791064653545618
epoch: 19 | iteration: 511 |   loss: 0.028791  |   KL divergence: 0.028792  |  JS divergence: 0.007309
('==== Found maximium gradient [0.0015602709, 0.0015104711, 0.0015094903] of '
 'gate e^[Y2 Z9], RY[3], e^[Y9 Z2] ====')
learning rate =  0.00030538564066486256
0.028784392920418317 0.005565514322370291
0.028780041326883103 0.008771626278758049
0.028771060322668886 0.005444282200187445
0.028765898076635005 0.0059380861930549145
0.028760598158518894 0.0068145859986543655
0.02875385996972904 0.006116409320384264
0.02874764089947831 0.005260782316327095
0.028741475539278673 0.005342438351362944
0.028736186275152904 0.005859382916241884
0.028730363023029105 0.005929897539317608
0.02872450019395408 0.005499327555298805
0.02871874666169888 0.005021990276873112
0.028712974677445612 0.004894523415714502
epoch: 20 | iteration: 524 |   loss: 0.028713  |   KL divergence: 0.028714  |  JS divergence: 0.007290
('==== Found maximium gradient [0.0014890457, 0.0014271408, 0.001252193] of '
 'gate e^[X3 Y2], e^[X2 Y3], e^[Y3 Z1] ====')
learning rate =  0.00027861504235647
0.02870771501713367 0.0056174686178565025
0.028703160076366883 0.007761066779494286
0.0286950112728829 0.0054994309321045876
0.0286891927645369 0.005648621823638678
0.028683768199090985 0.0063453721813857555
0.028678065587581195 0.005877197720110416
0.028671736314711056 0.005286178085952997
0.028665890822620936 0.005429522600024939
0.028661121768486553 0.00585615960881114
0.028655334187712607 0.0059202201664447784
0.028649101222815623 0.005650946404784918
0.02864338892467565 0.005398815032094717
0.02863746250793251 0.005358893424272537
0.028632119720484878 0.005433208309113979
0.02862581828982731 0.0054308148100972176
0.028619829619459435 0.0053127119317650795
0.02861404743143771 0.005185086280107498
0.028608388166083375 0.005148908589035273
0.028603244742653064 0.005188550800085068
0.02859700311834068 0.00520589342340827
0.02859122532734845 0.00515021663159132
0.02858501673053751 0.0050698015838861465
0.02857973878683794 0.00504459859803319
0.028573232985278002 0.005089021287858486
0.02856759383371621 0.005142253823578358
0.02856189179628634 0.005155876744538546
0.028556021282701308 0.0051478794775903225
0.02855009805679047 0.005157191772013903
0.028544658476917822 0.005177892278879881
0.02853888257706428 0.005172186531126499
0.028532707404076242 0.005131326615810394
0.028526569684449374 0.0050890943966805935
0.028521258449225963 0.005075764376670122
0.02851526249602119 0.005085630342364311
0.028508916455289725 0.005095967091619968
0.028503537436385 0.005099656525999308
0.028497276245181852 0.005101810675114393
0.028491660173934997 0.005101973190903664
0.02848526311390185 0.005092663690447807
0.02848075824767084 0.0050724283792078495
0.02847419440517389 0.005049759987741709
0.028467754717030423 0.005034665111452341
0.028462602881813688 0.005032213404774666
0.02845673432620408 0.005041277036070824
0.02845102571521927 0.005054744891822338
0.028445043112531387 0.005064812954515219
0.028439121839741288 0.00506868539378047
0.028433378151533392 0.0050678616389632225
0.02842746032132944 0.005063431337475777
0.02842161829097719 0.005056456197053194
0.028415307038330576 0.005049347877502441
0.028409729204478772 0.005044728517532349
0.028404432257364054 0.005041737575083971
0.028399002279862678 0.005037994123995304
0.028392896501539346 0.005032886750996113
0.028386888806801812 0.005027906969189644
0.02838160971647192 0.005024166777729988
0.028375804011102318 0.005022451747208834
0.02836995667161712 0.0050228969193995
0.028364448269253908 0.005024912301450968
0.028358434452285496 0.005026177503168583
0.028352416211309763 0.005024787969887257
0.02834663154881513 0.0050198715180158615
0.028341250565863667 0.005012650974094868
0.028335125050725017 0.005005369894206524
0.02832959953621313 0.005000445991754532
0.028323662564220177 0.004998174030333757
epoch: 21 | iteration: 591 |   loss: 0.028324  |   KL divergence: 0.028324  |  JS divergence: 0.007193
('==== Found maximium gradient [0.0016633474, 0.0012774843, 0.0012728572] of '
 'gate e^[Y2 Z1], e^[Y1 Z2], RY[3] ====')
learning rate =  0.0002832867892947984
0.0283183311168336 0.005567231681197882
0.028310777505902402 0.005631038453429937
0.02830489734578566 0.005816051736474037
0.028298278433347826 0.0055948966182768345
0.028291866870755602 0.005440732929855585
0.02828594707644475 0.005432457663118839
0.02827899480464223 0.005462360102683306
0.028272261689342243 0.005282435566186905
0.028266446448761345 0.005328990984708071
0.028259695024985293 0.005393697414547205
0.02825390327054391 0.005284403450787067
0.02824775832777717 0.005245786625891924
0.028241659287789225 0.005269326735287905
0.028235215030882513 0.005258851684629917
0.028228600909918737 0.005257186014205217
0.028222170760448053 0.005230817943811417
0.028215549591799956 0.005180011969059706
0.028209263610254824 0.005178317427635193
0.028203093436331438 0.005182069726288319
0.028196647070326427 0.005153283942490816
0.028191111121682336 0.00515536917373538
0.028184357780769533 0.005177386570721865
0.028178157364490416 0.005172664299607277
0.028171480895273632 0.005172742065042257
0.02816577029813684 0.005183468107134104
0.028159248878751084 0.005172913894057274
0.028153452470590253 0.005154210142791271
0.028146698273840844 0.005140444729477167
0.028141133747849552 0.0051323603838682175
0.028134184751384912 0.0051426333375275135
0.02812803092820546 0.005156314466148615
0.028121445141803137 0.005154239945113659
0.02811546515582268 0.005147926509380341
0.0281090229180164 0.005135946441441774
0.02810275439411658 0.005117239896208048
0.02809657515851538 0.0051092710345983505
0.02809055525656124 0.0051076896488666534
0.028084338081123934 0.00510061951354146
0.028077853783390748 0.005094085820019245
0.028071610633700592 0.005093309096992016
0.028065254603593603 0.005099589470773935
0.028059135261853742 0.005105353891849518
0.028052890335352677 0.005098163615912199
0.028046885202188482 0.0050839320756495
0.028040646315880127 0.005072700325399637
0.028034490625626914 0.005066634621471167
0.028028464123676586 0.005067779682576656
0.028022310036691016 0.00506952777504921
0.02801606290813809 0.005064092110842466
0.028010194711977715 0.00505449203774333
0.028003435527486666 0.005045287776738405
0.02799753610997132 0.005039445590227842
0.027990894185679707 0.0050347032956779
0.027985385200546824 0.005027297418564558
0.02797864661388861 0.005020163021981716
0.027972670079071147 0.005015154834836721
0.027966765559741036 0.005010634660720825
0.02796091227667178 0.0050049275159835815
0.027954069532478018 0.004995760507881641
epoch: 22 | iteration: 650 |   loss: 0.027954  |   KL divergence: 0.027955  |  JS divergence: 0.007100
('==== Found maximium gradient [0.0014536853, 0.0012515656, 0.0012493666] of '
 'gate e^[Y3 Z1], e^[Y1 Z3], e^[Y2 Z1] ====')
learning rate =  0.0002643365170600668
0.027948625797610045 0.005486814770847559
0.02794180154878309 0.005721635185182095
0.027936589386728737 0.006053232122212648
0.027929275038067282 0.005472247023135424
0.027924024120948944 0.006083481013774872
0.02791716002999193 0.0058404747396707535
0.027911542688107534 0.005701184738427401
0.0279058206574083 0.005906549282371998
0.02789946168713696 0.0057817441411316395
0.02789380182884355 0.005432192236185074
0.02788798161189433 0.005340369418263435
0.027881899789389937 0.005457674153149128
0.027875517682452965 0.005411513149738312
0.02787002411547533 0.005237865727394819
0.02786408687861408 0.005197165533900261
0.027858559864101462 0.005274307448416948
0.027851978528945057 0.005273903254419565
0.027846242652467927 0.005222036968916655
0.02784004836791324 0.0052689677104353905
0.027834409155350216 0.005365121643990278
0.027828571468110304 0.005354566033929586
0.027822582965166022 0.005255313124507666
0.02781691044291401 0.005192976910620928
0.027810423871023816 0.005171647295355797
0.027805022939880263 0.005114833824336529
0.027798775400936268 0.005046566482633352
0.027793024143214287 0.005042896140366793
0.027787064354364864 0.005075821187347174
0.02778111973667951 0.0050675468519330025
0.02777609250605252 0.005029620602726936
0.027769915963438096 0.005018934607505798
0.02776458117032367 0.005026137921959162
0.027758392539924015 0.005012608598917723
0.027752598062570633 0.004989082459360361
epoch: 23 | iteration: 684 |   loss: 0.027753  |   KL divergence: 0.027753  |  JS divergence: 0.007049
('==== Found maximium gradient [0.001221392, 0.0011460073, 0.0010799161] of '
 'gate e^[X2 Y3], e^[Y2 Z1], e^[X0 Y1] ====')
learning rate =  0.0002301115777332104
0.027747283891838177 0.0053623877465724945
0.027740938137127892 0.005656333174556494
0.02773593421475512 0.005383486393839121
0.027730158565762112 0.004951892886310816
epoch: 24 | iteration: 688 |   loss: 0.027730  |   KL divergence: 0.027731  |  JS divergence: 0.007043
('==== Found maximium gradient [0.00126414, 0.0012103915, 0.0011995897] of '
 'gate e^[Y2 Z0], RY[3], e^[Y0 Z2] ====')
learning rate =  0.00024500646778208887
0.02772482183498802 0.005492509808391333
0.027719857325947277 0.007961925119161606
0.027712048382386646 0.005416997708380222
0.02770570152027783 0.005974358879029751
0.027699401060412035 0.0067947376519441605
0.027693523946838695 0.006210040766745806
0.027686508889751247 0.005451802164316177
0.027680103565105516 0.005455289967358112
0.02767415693668379 0.005777007434517145
0.027667687710053932 0.005745012313127518
0.02766197514754248 0.0053911409340798855
0.027655257504924327 0.005111410282552242
0.027649325997430814 0.005121520720422268
0.027643349135373523 0.005262917838990688
0.02763623359754353 0.005296075716614723
0.027631072456667627 0.005178548861294985
0.02762450803224569 0.005024276673793793
0.027618472867469802 0.004930014722049236
epoch: 25 | iteration: 706 |   loss: 0.027618  |   KL divergence: 0.027619  |  JS divergence: 0.007014
('==== Found maximium gradient [0.0010807129, 0.0009937262, 0.00096419145] of '
 'gate e^[X1 Y0], e^[Y2 Z9], e^[Y0 Z10] ====')
learning rate =  0.00020281674945410718
0.027612995853055294 0.005198786035180092
0.02760817222787231 0.007303123362362385
0.02760154078835612 0.005163405556231737
0.027596226388551894 0.005090709775686264
0.02759145316041758 0.005858824122697115
0.02758552129654028 0.005700003821402788
0.02758047380603184 0.005166150163859129
0.027574831073446937 0.00500536197796464
0.02756935209891219 0.0052706035785377026
0.027564414902174688 0.005437540356069803
0.027559043068248627 0.00524182291701436
0.027553942866630605 0.004869703669101
epoch: 26 | iteration: 718 |   loss: 0.027554  |   KL divergence: 0.027554  |  JS divergence: 0.006997
('==== Found maximium gradient [0.0010437153, 0.0009593117, 0.0009133615] of '
 'gate e^[X0 Y1], e^[X2 Y9], e^[X1 Y9] ====')
learning rate =  0.00019472544979847833
0.027548216052099804 0.004973975941538811
epoch: 27 | iteration: 719 |   loss: 0.027548  |   KL divergence: 0.027549  |  JS divergence: 0.006996
('==== Found maximium gradient [0.0015014305, 0.0012575929, 0.0012506085] of '
 'gate e^[X0 Y1], e^[X9 Y1], e^[X8 Y1] ====')
learning rate =  0.00026832455240369057
0.027542701241623505 0.0060720681212842464
0.02754016112300697 0.010220536030828953
0.02752981530992071 0.005923394113779068
0.027522897465796864 0.006302834488451481
0.027516788768072474 0.007566729094833136
0.027509976511600812 0.006657423451542854
0.027502050996664057 0.005337550770491362
0.027495231977655722 0.00540246581658721
0.02748899418709161 0.006047071423381567
0.027482538515538953 0.0060593485832214355
0.02747538095386056 0.005488762632012367
0.027468572235802118 0.005022600758820772
0.027461290049954575 0.0050596692599356174
0.027455256023324773 0.005245788022875786
0.027448778733157257 0.005179383791983128
0.02744215497921503 0.004882717039436102
epoch: 28 | iteration: 735 |   loss: 0.027442  |   KL divergence: 0.027443  |  JS divergence: 0.006968
('==== Found maximium gradient [0.0009323526, 0.000928546, 0.00090132374] of '
 'gate e^[X0 Y1], e^[Y2 Z9], e^[Y1 Z9] ====')
Convergence criterion has reached, break the loop!